@node Top
@top Practical Common Lisp

@menu
* Introduction Why Lisp?::
* Lather Rinse Repeat A Tour of the REPL::
* Practical A Simple Database::
* Syntax and Semantics::
* Functions::
* Variables::
* Macros Standard Control Constructs::
* Macros Defining Your Own::
* Practical Building a Unit Test Framework::
* Numbers Characters and Strings::
* Collections::
* They Called It LISP for a Reason List Processing::
* Beyond Lists Other Uses for Cons Cells::
* Files and File I/O::
* Practical A Portable Pathname Library::
* Object Reorientation Generic Functions::
* Object Reorientation Classes::
* A Few FORMAT Recipes::
* Beyond Exception Handling Conditions and Restarts::
* The Special Operators::
* Programming in the Large Packages and Symbols::
* LOOP for Black Belts::
* Practical A Spam Filter::
* Practical Parsing Binary Files::
* Practical An ID3 Parser::
* Practical Web Programming with AllegroServe::
* Practical An MP3 Database::
* Practical A Shoutcast Server::
* Practical An MP3 Browser::
* Practical An HTML Generation Library the Interpreter::
* Practical An HTML Generation Library the Compiler::
* Conclusion What's Next?::
@end menu

@node Introduction Why Lisp?
@chapter Introduction: Why Lisp?
@anchor{#introduction-why-lisp}
If you think the greatest pleasure in programming comes from getting a
lot done with code that simply and clearly expresses your intention,
then programming in Common Lisp is likely to be about the most fun you
can have with a computer. You'll get more done, faster, using it than
you would using pretty much any other language.

That's a bold claim. Can I justify it? Not in a just a few pages in this
chapter--you're going to have to learn some Lisp and see for
yourself--thus the rest of this book. For now, let me start with some
anecdotal evidence, the story of my own road to Lisp. Then, in the next
section, I'll explain the payoff I think you'll get from learning Common
Lisp.

I'm one of what must be a fairly small number of second-generation Lisp
hackers. My father got his start in computers writing an operating
system in assembly for the machine he used to gather data for his
doctoral dissertation in physics. After running computer systems at
various physics labs, by the 1980s he had left physics altogether and
was working at a large pharmaceutical company. That company had a
project under way to develop software to model production processes in
its chemical plants--if you increase the size of this vessel, how does
it affect annual production? The original team, writing in FORTRAN, had
burned through half the money and almost all the time allotted to the
project with nothing to show for their efforts. This being the 1980s and
the middle of the artificial intelligence (AI) boom, Lisp was in the
air. So my dad--at that point not a Lisper--went to Carnegie Mellon
University (CMU) to talk to some of the folks working on what was to
become Common Lisp about whether Lisp might be a good language for this
project.

The CMU folks showed him some demos of stuff they were working on, and
he was convinced. He in turn convinced his bosses to let his team take
over the failing project and do it in Lisp. A year later, and using only
what was left of the original budget, his team delivered a working
application with features that the original team had given up any hope
of delivering. My dad credits his team's success to their decision to
use Lisp.

Now, that's just one anecdote. And maybe my dad is wrong about why they
succeeded. Or maybe Lisp was better only in comparison to other
languages of the day. These days we have lots of fancy new languages,
many of which have incorporated features from Lisp. Am I really saying
Lisp can offer you the same benefits today as it offered my dad in the
1980s? Read on.

Despite my father's best efforts, I didn't learn any Lisp in high
school. After a college career that didn't involve much programming in
any language, I was seduced by the Web and back into computers. I worked
first in Perl, learning enough to be dangerous while building an online
discussion forum for @emph{Mother Jones} magazine's Web site and then
moving to a Web shop, Organic Online, where I worked on big--for the
time--Web sites such as the one Nike put up during the 1996 Olympics.
Later I moved onto Java as an early developer at WebLogic, now part of
BEA. After WebLogic, I joined another startup where I was the lead
programmer on a team building a transactional messaging system in Java.
Along the way, my general interest in programming languages led me to
explore such mainstream languages as C, C++, and Python, as well as less
well-known ones such as Smalltalk, Eiffel, and Beta.

So I knew two languages inside and out and was familiar with another
half dozen. Eventually, however, I realized my interest in programming
languages was really rooted in the idea planted by my father's tales of
Lisp--that different languages really are different, and that, despite
the formal Turing equivalence of all programming languages, you really
can get more done more quickly in some languages than others and have
more fun doing it. Yet, ironically, I had never spent that much time
with Lisp itself. So, I started doing some Lisp hacking in my free time.
And whenever I did, it was exhilarating how quickly I was able to go
from idea to working code.

For example, one vacation, having a week or so to hack Lisp, I decided
to try writing a version of a program--a system for breeding genetic
algorithms to play the game of Go--that I had written early in my career
as a Java programmer. Even handicapped by my then rudimentary knowledge
of Common Lisp and having to look up even basic functions, it still felt
more productive than it would have been to rewrite the same program in
Java, even with several extra years of Java experience acquired since
writing the first version.

A similar experiment led to the library I'll discuss in Chapter 24.
Early in my time at WebLogic I had written a library, in Java, for
taking apart Java class files. It worked, but the code was a bit of a
mess and hard to modify or extend. I had tried several times, over the
years, to rewrite that library, thinking that with my ever-improving
Java chops I'd find some way to do it that didn't bog down in piles of
duplicated code. I never found a way. But when I tried to do it in
Common Lisp, it took me only two days, and I ended up not only with a
Java class file parser but with a general-purpose library for taking
apart any kind of binary file. You'll see how that library works in
Chapter 24 and use it in Chapter 25 to write a parser for the ID3 tags
embedded in MP3 files.
@menu
* Why Lisp?::
* Where It Began::
* Who This Book Is For::
@end menu

@node Why Lisp?
@section Why Lisp?
@anchor{#why-lisp}
It's hard, in only a few pages of an introductory chapter, to explain
why users of a language like it, and it's even harder to make the case
for why you should invest your time in learning a certain language.
Personal history only gets us so far. Perhaps I like Lisp because of
some quirk in the way my brain is wired. It could even be genetic, since
my dad has it too. So before you dive into learning Lisp, it's
reasonable to want to know what the payoff is going to be.

For some languages, the payoff is relatively obvious. For instance, if
you want to write low-level code on Unix, you should learn C. Or if you
want to write certain kinds of cross-platform applications, you should
learn Java. And any of a number companies still use a lot of C++, so if
you want to get a job at one of them, you should learn C++.

For most languages, however, the payoff isn't so easily categorized;
it has to do with subjective criteria such as how it feels to use the
language. Perl advocates like to say that Perl "makes easy things easy
and hard things possible" and revel in the fact that, as the Perl
motto has it, "There's more than one way to do it."@footnote{Perl is
also worth learning as "the duct tape of the Internet."} Python's
fans, on the other hand, think Python is clean and simple and think
Python code is easier to understand because, as @emph{their} motto
says, "There's only one way to do it."

So, why Common Lisp? There's no immediately obvious payoff for adopting
Common Lisp the way there is for C, Java, and C++ (unless, of course,
you happen to own a Lisp Machine). The benefits of using Lisp have much
more to do with the experience of using it. I'll spend the rest of this
book showing you the specific features of Common Lisp and how to use
them so you can see for yourself what it's like. For now I'll try to
give you a sense of Lisp's philosophy.

The nearest thing Common Lisp has to a motto is the koan-like
description, "the programmable programming language." While cryptic,
that description gets at the root of the biggest advantage Common Lisp
still has over other languages. More than any other language, Common
Lisp follows the philosophy that what's good for the language's designer
is good for the language's users. Thus, when you're programming in
Common Lisp, you almost never find yourself wishing the language
supported some feature that would make your program easier to write,
because, as you'll see throughout this book, you can just add the
feature yourself.

Consequently, a Common Lisp program tends to provide a much clearer
mapping between your ideas about how the program works and the code
you actually write. Your ideas aren't obscured by boilerplate code and
endlessly repeated idioms. This makes your code easier to maintain
because you don't have to wade through reams of code every time you
need to make a change. Even systemic changes to a program's behavior
can often be achieved with relatively small changes to the actual
code. This also means you'll develop code more quickly; there's less
code to write, and you don't waste time thrashing around trying to
find a clean way to express yourself within the limitations of the
language.@footnote{Unfortunately, there's little actual research on
the productivity of different languages. One report that shows Lisp
coming out well compared to C++ and Java in the combination of
programmer and program efficiency is discussed at
@code{http://www.norvig.com/java-lisp.html}.}

Common Lisp is also an excellent language for exploratory
programming--if you don't know exactly how your program is going to work
when you first sit down to write it, Common Lisp provides several
features to help you develop your code incrementally and interactively.

For starters, the interactive read-eval-print loop, which I'll
introduce in the next chapter, lets you continually interact with your
program as you develop it. Write a new function. Test it. Change
it. Try a different approach. You never have to stop for a lengthy
compilation cycle.@footnote{Psychologists have identified a state of
mind called @emph{flow} in which we're capable of incredible
concentration and productivity. The importance of flow to programming
has been recognized for nearly two decades since it was discussed in
the classic book about human factors in programming @emph{Peopleware:
Productive Projects and Teams} by Tom DeMarco and Timothy Lister
(Dorset House, 1987). The two key facts about flow are that it takes
around 15 minutes to get into a state of flow and that even brief
interruptions can break you right out of it, requiring another
15-minute immersion to reenter. DeMarco and Lister, like most
subsequent authors, concerned themselves mostly with flow-destroying
interruptions such as ringing telephones and inopportune visits from
the boss. Less frequently considered but probably just as important to
programmers are the interruptions caused by our tools.  Languages that
require, for instance, a lengthy compilation before you can try your
latest code can be just as inimical to flow as a noisy phone or a nosy
boss. So, one way to look at Lisp is as a language designed to keep
you in a state of flow.}

Other features that support a flowing, interactive programming style
are Lisp's dynamic typing and the Common Lisp condition
system. Because of the former, you spend less time convincing the
compiler you should be allowed to run your code and more time actually
running it and working on it,@footnote{This point is bound to be
somewhat controversial, at least with some folks. Static versus
dynamic typing is one of the classic religious wars in programming. If
you're coming from C++ and Java (or from statically typed functional
languages such as Haskel and ML) and refuse to consider living without
static type checks, you might as well put this book down now. However,
before you do, you might first want to check out what self-described
"statically typed bigot" Robert Martin (author of @emph{Designing
Object Oriented C++ Applications Using the Booch Method} [Prentice
Hall, 1995]) and C++ and Java author Bruce Eckel (author of
@emph{Thinking in C++} [Prentice Hall, 1995] and @emph{Thinking in
Java} [Prentice Hall, 1998]) have had to say about dynamic typing on
their weblogs
(@code{http://www.artima.com/weblogs/viewpost.jsp?thread=4639} and
@code{http://www.mindview.net/WebLog/log-0025}). On the other hand,
folks coming from Smalltalk, Python, Perl, or Ruby should feel right
at home with this aspect of Common Lisp.} and the latter lets you
develop even your error handling code interactively.

Another consequence of being "a programmable programming language" is
that Common Lisp, in addition to incorporating small changes that make
particular programs easier to write, can easily adopt big new ideas
about how programming languages should work. For instance, the original
implementation of the Common Lisp Object System (CLOS), Common Lisp's
powerful object system, was as a library written in portable Common
Lisp. This allowed Lisp programmers to gain actual experience with the
facilities it provided before it was officially incorporated into the
language.

Whatever new paradigm comes down the pike next, it's extremely likely
that Common Lisp will be able to absorb it without requiring any
changes to the core language. For example, a Lisper has recently
written a library, AspectL, that adds support for aspect-oriented
programming (AOP) to Common Lisp.@footnote{AspectL is an interesting
project insofar as AspectJ, its Java-based predecessor, was written by
Gregor Kiczales, one of the designers of Common Lisp's object and
metaobject systems. To many Lispers, AspectJ seems like Kiczales's
attempt to backport his ideas from Common Lisp into Java. However,
Pascal Costanza, the author of AspectL, thinks there are interesting
ideas in AOP that could be useful in Common Lisp. Of course, the
reason he's able to implement AspectL as a library is because of the
incredible flexibility of the Common Lisp Meta Object Protocol
Kiczales designed. To implement AspectJ, Kiczales had to write what
was essentially a separate compiler that compiles a new language into
Java source code. The AspectL project page is at
@code{http://common-lisp.net/ project/aspectl/}.} If AOP turns out to
be the next big thing, Common Lisp will be able to support it without
any changes to the base language and without extra preprocessors and
extra compilers.@footnote{Or to look at it another, more technically
accurate, way, Common Lisp comes with a built-in facility for
integrating compilers for embedded languages.}

@node Where It Began
@section Where It Began
@anchor{#where-it-began} Common Lisp is the modern descendant of the
Lisp language first conceived by John McCarthy in 1956. Lisp circa
1956 was designed for "symbolic data processing"@footnote{@emph{Lisp
1.5 Programmer's Manual} (M.I.T. Press, 1962)} and derived its name
from one of the things it was quite good at: LISt Processing. We've
come a long way since then: Common Lisp sports as fine an array of
modern data types as you can ask for: a condition system that, as
you'll see in Chapter 19, provides a whole level of flexibility
missing from the exception systems of languages such as Java, Python,
and C++; powerful facilities for doing object-oriented programming;
and several language facilities that just don't exist in other
programming languages. How is this possible? What on Earth would
provoke the evolution of such a well-equipped language?

Well, McCarthy was (and still is) an artificial intelligence (AI)
researcher, and many of the features he built into his initial version
of the language made it an excellent language for AI programming. During
the AI boom of the 1980s, Lisp remained a favorite tool for programmers
writing software to solve hard problems such as automated theorem
proving, planning and scheduling, and computer vision. These were
problems that required a lot of hard-to-write software; to make a dent
in them, AI programmers needed a powerful language, and they grew Lisp
into the language they needed. And the Cold War helped--as the Pentagon
poured money into the Defense Advanced Research Projects Agency (DARPA),
a lot of it went to folks working on problems such as large-scale
battlefield simulations, automated planning, and natural language
interfaces. These folks also used Lisp and continued pushing it to do
what they needed.

The same forces that drove Lisp's feature evolution also pushed the
envelope along other dimensions--big AI problems eat up a lot of
computing resources however you code them, and if you run Moore's law in
reverse for 20 years, you can imagine how scarce computing resources
were on circa-80s hardware. The Lisp guys had to find all kinds of ways
to squeeze performance out of their implementations. Modern Common Lisp
implementations are the heirs to those early efforts and often include
quite sophisticated, native machine code-generating compilers. While
today, thanks to Moore's law, it's possible to get usable performance
from a purely interpreted language, that's no longer an issue for Common
Lisp. As I'll show in Chapter 32, with proper (optional) declarations, a
good Lisp compiler can generate machine code quite similar to what might
be generated by a C compiler.

The 1980s were also the era of the Lisp Machines, with several
companies, most famously Symbolics, producing computers that ran Lisp
natively from the chips up. Thus, Lisp became a systems programming
language, used for writing the operating system, editors, compilers, and
pretty much everything else that ran on the Lisp Machines.

In fact, by the early 1980s, with various AI labs and the Lisp machine
vendors all providing their own Lisp implementations, there was such a
proliferation of Lisp systems and dialects that the folks at DARPA began
to express concern about the Lisp community splintering. To address this
concern, a grassroots group of Lisp hackers got together in 1981 and
began the process of standardizing a new language called Common Lisp
that combined the best features from the existing Lisp dialects. Their
work was documented in the book @emph{Common Lisp the Language} by Guy
Steele (Digital Press, 1984)--@emph{CLtL} to the Lisp-cognoscenti.

By 1986 the first Common Lisp implementations were available, and the
writing was on the wall for the dialects it was intended to replace. In
1996, the American National Standards Institute (ANSI) released a
standard for Common Lisp that built on and extended the language
specified in CLtL, adding some major new features such as the CLOS and
the condition system. And even that wasn't the last word: like CLtL
before it, the ANSI standard intentionally leaves room for implementers
to experiment with the best way to do things: a full Lisp implementation
provides a rich runtime environment with access to GUI widgets, multiple
threads of control, TCP/IP sockets, and more. These days Common Lisp is
evolving much like other open-source languages--the folks who use it
write the libraries they need and often make them available to others.
In the last few years, in particular, there has been a spurt of activity
in open-source Lisp libraries.

So, on one hand, Lisp is one of computer science's "classical"
languages, based on ideas that have stood the test of
time.@footnote{Ideas first introduced in Lisp include the if/then/else
construct, recursive function calls, dynamic memory allocation,
garbage collection, first-class functions, lexical closures,
interactive programming, incremental compilation, and dynamic typing.
} On the other, it's a thoroughly modern, general-purpose language
whose design reflects a deeply pragmatic approach to solving real
problems as efficiently and robustly as possible. The only downside of
Lisp's "classical" heritage is that lots of folks are still walking
around with ideas about Lisp based on some particular flavor of Lisp
they were exposed to at some particular time in the nearly half
century since McCarthy invented Lisp. If someone tells you Lisp is
only interpreted, that it's slow, or that you have to use recursion
for everything, ask them what dialect of Lisp they're talking about
and whether people were wearing bell-bottoms when they learned
it.@footnote{One of the most commonly repeated myths about Lisp is
that it's "dead." While it's true that Common Lisp isn't as widely
used as, say, Visual Basic or Java, it seems strange to describe a
language that continues to be used for new development and that
continues to attract new users as "dead." Some recent Lisp success
stories include Paul Graham's Viaweb, which became Yahoo Store when
Yahoo bought his company; ITA Software's airfare pricing and shopping
system, QPX, used by the online ticket seller Orbitz and others;
Naughty Dog's game for the PlayStation 2, Jak and Daxter, which is
largely written in a domain-specific Lisp dialect Naughty Dog invented
called GOAL, whose compiler is itself written in Common Lisp; and the
Roomba, the autonomous robotic vacuum cleaner, whose software is
written in L, a downwardly compatible subset of Common Lisp. Perhaps
even more telling is the growth of the Common-Lisp.net Web site, which
hosts open-source Common Lisp projects, and the number of local Lisp
user groups that have sprung up in the past couple of years.}

But I learned Lisp Once, And IT Wasn't Like what you're describing
If you've used Lisp in the past, you may have ideas about what "Lisp" is
that have little to do with Common Lisp. While Common Lisp supplanted
most of the dialects it's descended from, it isn't the only remaining
Lisp dialect, and depending on where and when you were exposed to Lisp,
you may very well have learned one of these other dialects.

Other than Common Lisp, the one general-purpose Lisp dialect that still
has an active user community is Scheme. Common Lisp borrowed a few
important features from Scheme but never intended to replace it.

Originally designed at M.I.T., where it was quickly put to use as a
teaching language for undergraduate computer science courses, Scheme has
always been aimed at a different language niche than Common Lisp. In
particular, Scheme's designers have focused on keeping the core language
as small and as simple as possible. This has obvious benefits for a
teaching language and also for programming language researchers who like
to be able to formally prove things about languages.

It also has the benefit of making it relatively easy to understand the
whole language as specified in the standard. But, it does so at the cost
of omitting many useful features that are standardized in Common Lisp.
Individual Scheme implementations may provide these features in
implementation-specific ways, but their omission from the standard makes
it harder to write portable Scheme code than to write portable Common
Lisp code.

Scheme also emphasizes a functional programming style and the use of
recursion much more than Common Lisp does. If you studied Lisp in
college and came away with the impression that it was only an academic
language with no real-world application, chances are you learned Scheme.
This isn't to say that's a particularly fair characterization of Scheme,
but it's even less applicable to Common Lisp, which was expressly
designed to be a real-world engineering language rather than a
theoretically "pure" language.

If you've learned Scheme, you should also be aware that a number of
subtle differences between Scheme and Common Lisp may trip you up. These
differences are also the basis for several perennial religious wars
between the hotheads in the Common Lisp and Scheme communities. I'll try
to point out some of the more important differences as we go along.

Two other Lisp dialects still in widespread use are Elisp, the extension
language for the Emacs editor, and Autolisp, the extension language for
Autodesk's AutoCAD computer-aided design tool. Although it's possible
more lines of Elisp and Autolisp have been written than of any other
dialect of Lisp, neither can be used outside their host application, and
both are quite old-fashioned Lisps compared to either Scheme or Common
Lisp. If you've used one of these dialects, prepare to hop in the Lisp
time machine and jump forward several decades.

@node Who This Book Is For
@section Who This Book Is For
@anchor{#who-this-book-is-for}
This book is for you if you're curious about Common Lisp, regardless of
whether you're already convinced you want to use it or if you just want
to know what all the fuss is about.

If you've learned some Lisp already but have had trouble making the leap
from academic exercises to real programs, this book should get you on
your way. On the other hand, you don't have to be already convinced that
you want to use Lisp to get something out of this book.

If you're a hard-nosed pragmatist who wants to know what advantages
Common Lisp has over languages such as Perl, Python, Java, C, or C#,
this book should give you some ideas. Or maybe you don't even care about
using Lisp--maybe you're already sure Lisp isn't really any better than
other languages you know but are annoyed by some Lisper telling you
that's because you just don't "get it." If so, this book will give you a
straight-to-the-point introduction to Common Lisp. If, after reading
this book, you still think Common Lisp is no better than your current
favorite languages, you'll be in an excellent position to explain
exactly why.

I cover not only the syntax and semantics of the language but also how
you can use it to write software that does useful stuff. In the first
part of the book, I'll cover the language itself, mixing in a few
"practical" chapters, where I'll show you how to write real code. Then,
after I've covered most of the language, including several parts that
other books leave for you to figure out on your own, the remainder of
the book consists of nine more practical chapters where I'll help you
write several medium-sized programs that actually do things you might
find useful: filter spam, parse binary files, catalog MP3s, stream MP3s
over a network, and provide a Web interface for the MP3 catalog and
server.

After you finish this book, you'll be familiar with all the most
important features of the language and how they fit together, you'll
have used Common Lisp to write several nontrivial programs, and you'll
be well prepared to continue exploring the language on your own. While
everyone's road to Lisp is different, I hope this book will help smooth
the way for you. So, let's begin.

@node Lather Rinse Repeat A Tour of the REPL
@chapter Lather, Rinse, Repeat: A Tour of the REPL
@anchor{#lather-rinse-repeat-a-tour-of-the-repl} In this chapter
you'll set up your programming environment and write your first Common
Lisp programs. We'll use the easy-to-install Lisp in a Box developed
by Matthew Danish and Mikel Evins, which packages a Common Lisp
implementation with Emacs, a powerful Lisp-aware text editor, and
SLIME,@footnote{Superior Lisp Interaction Mode for Emacs} a Common
Lisp development environment built on top of Emacs.

This combo provides a state-of-the-art Common Lisp development
environment that supports the incremental, interactive development
style that characterizes Lisp programming. The SLIME environment has
the added advantage of providing a fairly uniform user interface
regardless of the operating system and Common Lisp implementation you
choose. I'll use the Lisp in a Box environment in order to have a
specific development environment to talk about; folks who want to
explore other development environments such as the graphical
integrated development environments (IDEs) provided by some of the
commercial Lisp vendors or environments based on other editors
shouldn't have too much trouble translating the basics.@footnote{If
you've had a bad experience with Emacs previously, you should treat
Lisp in a Box as an IDE that happens to use an Emacs-like editor as
its text editor; there will be no need to become an Emacs guru to
program Lisp. It is, however, orders of magnitude more enjoyable to
program Lisp with an editor that has some basic Lisp awareness. At a
minimum, you'll want an editor that can automatically match @code{()}s
for you and knows how to automatically indent Lisp code. Because Emacs
is itself largely written in a Lisp dialect, Elisp, it has quite a bit
of support for editing Lisp code. Emacs is also deeply embedded into
the history of Lisp and the culture of Lisp hackers: the original
Emacs and its immediate predecessors, TECMACS and TMACS, were written
by Lispers at the Massachusetts Institute of Technology (MIT). The
editors on the Lisp Machines were versions of Emacs written entirely
in Lisp. The first two Lisp Machine Emacs, following the hacker
tradition of recursive acronyms, were EINE and ZWEI, which stood for
EINE Is Not Emacs and ZWEI Was EINE Initially.  Later ones used a
descendant of ZWEI, named, more prosaically, ZMACS.}

@menu
* Choosing a Lisp Implementation::
* Getting Up and Running with Lisp in a Box::
* Free Your Mind Interactive Programming::
* Experimenting in the REPL::
* "Hello World" Lisp Style::
* Saving Your Work::
@end menu

@node Choosing a Lisp Implementation
@section Choosing a Lisp Implementation
@anchor{#choosing-a-lisp-implementation} The first thing you have to
do is to choose a Lisp implementation. This may seem like a strange
thing to have to do for folks used to languages such as Perl, Python,
Visual Basic (VB), C#, and Java. The difference between Common Lisp
and these languages is that Common Lisp is defined by its
standard--there is neither a single implementation controlled by a
benevolent dictator, as with Perl and Python, nor a canonical
implementation controlled by a single company, as with VB, C#, and
Java.  Anyone who wants to read the standard and implement the
language is free to do so. Furthermore, changes to the standard have
to be made in accordance with a process controlled by the standards
body American National Standards Institute (ANSI). That process is
designed to keep any one entity, such as a single vendor, from being
able to arbitrarily change the standard.@footnote{Practically
speaking, there's very little likelihood of the language standard
itself being revised--while there are a small handful of warts that
folks might like to clean up, the ANSI process isn't amenable to
opening an existing standard for minor tweaks, and none of the warts
that might be cleaned up actually cause anyone any serious
difficulty. The future of Common Lisp standardization is likely to
proceed via de facto standards, much like the "standardization" of
Perl and Python--as different implementers experiment with application
programming interfaces (APIs) and libraries for doing things not
specified in the language standard, other implementers may adopt them
or people will develop portability libraries to smooth over the
differences between implementations for features not specified in the
language standard.} Thus, the Common Lisp standard is a contract
between any Common Lisp vendor and Common Lisp programmers. The
contract tells you that if you write a program that uses the features
of the language the way they're described in the standard, you can
count on your program behaving the same in any conforming
implementation.

On the other hand, the standard may not cover everything you may want to
do in your programs--some things were intentionally left unspecified in
order to allow continuing experimentation by implementers in areas where
there wasn't consensus about the best way for the language to support
certain features. So every implementation offers some features above and
beyond what's specified in the standard. Depending on what kind of
programming you're going to be doing, it may make sense to just pick one
implementation that has the extra features you need and use that. On the
other hand, if we're delivering Lisp source to be used by others, such
as libraries, you'll want--as far as possible--to write portable Common
Lisp. For writing code that should be mostly portable but that needs
facilities not defined by the standard, Common Lisp provides a flexible
way to write code "conditionalized" on the features available in a
particular implementation. You'll see an example of this kind of code in
Chapter 15 when we develop a simple library that smoothes over some
differences between how different Lisp implementations deal with
filenames.

For the moment, however, the most important characteristic of an
implementation is whether it runs on our favorite operating
system. The folks at Franz, makers of Allegro Common Lisp, are making
available a trial version of their product for use with this book that
runs on Linux, Windows, and OS X. Folks looking for an open-source
implementation have several options. SBCL@footnote{Steel Bank Common
Lisp} is a high-quality open-source implementation that compiles to
native code and runs on a wide variety of Unixes, including Linux and
OS X. SBCL is derived from CMUCL,@footnote{CMU Common Lisp} which is a
Common Lisp developed at Carnegie Mellon University, and, like CMUCL,
is largely in the public domain, except a few sections licensed under
Berkeley Software Distribution (BSD) style licenses. CMUCL itself is
another fine choice, though SBCL tends to be easier to install and now
supports 21-bit Unicode.@footnote{SBCL forked from CMUCL in order to
focus on cleaning up the internals and making it easier to
maintain. But the fork has been amiable; bug fixes tend to propagate
between the two projects, and there's talk that someday they will
merge back together.} For OS X users, OpenMCL is an excellent
choice--it compiles to machine code, supports threads, and has quite
good integration with OS X's Carbon and Cocoa toolkits. Other
open-source and commercial implementations are available. See Chapter
32 for resources from which you can get more information.

All the Lisp code in this book should work in any conforming Common Lisp
implementation unless otherwise noted, and SLIME will smooth out some of
the differences between implementations by providing us with a common
interface for interacting with Lisp. The output shown in this book is
from Allegro running on GNU/Linux; in some cases, other Lisp's may
generate slightly different error messages or debugger output.

@node Getting Up and Running with Lisp in a Box
@section Getting Up and Running with Lisp in a Box
@anchor{#getting-up-and-running-with-lisp-in-a-box}
Since the Lisp in a Box packaging is designed to get new Lispers up and
running in a first-rate Lisp development environment with minimum
hassle, all you need to do to get it running is to grab the appropriate
package for your operating system and the preferred Lisp from the Lisp
in a Box Web site listed in Chapter 32 and then follow the installation
instructions.

Since Lisp in a Box uses Emacs as its editor, you'll need to know at
least a bit about how to use it. Perhaps the best way to get started
with Emacs is to work through its built-in tutorial. To start the
tutorial, select the first item of the Help menu, Emacs tutorial. Or
press the Ctrl key, type @code{h}, release the Ctrl key, and then press
@code{t}. Most Emacs commands are accessible via such key combinations;
because key combinations are so common, Emacs users have a notation for
describing key combinations that avoids having to constantly write out
combinations such as "Press the Ctrl key, type @code{h}, release the
Ctrl key, and then press @code{t}." Keys to be pressed together--a
so-called key chord--are written together and separated by a hyphen.
Keys, or key chords, to be pressed in sequence are separated by spaces.
In a key chord, @code{C} represents the Ctrl key and @code{M} represents
the Meta key (also known as Alt). Thus, we could write the key
combination we just described that starts the tutorial like so:
@code{C-h t}.

The tutorial describes other useful commands and the key combinations
that invoke them. Emacs also comes with extensive online documentation
using its own built-in hypertext documentation browser, Info. To read
the manual, type @code{C-h i}. The Info system comes with its own
tutorial, accessible simply by pressing @code{h} while reading the
manual. Finally, Emacs provides quite a few ways to get help, all bound
to key combos starting with @code{C-h}. Typing @code{C-h ?} brings up a
complete list. Two of the most useful, besides the tutorial, are
@code{C-h k}, which lets us type any key combo and tells us what command
it invokes, and @code{C-h w}, which lets us enter the name of a command
and tells us what key combination invokes it.

The other crucial bit of Emacs terminology, for folks who refuse to work
through the tutorial, is the notion of a @emph{buffer}. While working in
Emacs, each file you edit will be represented by a different buffer,
only one of which is "current" at any given time. The current buffer
receives all input--whatever you type and any commands you invoke.
Buffers are also used to represent interactions with programs such as
Common Lisp. Thus, one common action you'll take is to "switch buffers,"
which means to make a different buffer the current buffer so you can
edit a particular file or interact with a particular program. The
command @code{switch-to-buffer}, bound to the key combination
@code{C-x b}, prompts for the name of a buffer in the area at the bottom
of the Emacs frame. When entering a buffer name, hitting Tab will
complete the name based on the characters typed so far or will show a
list of possible completions. The prompt also suggests a default buffer,
which you can accept just by hitting Return. You can also switch buffers
by selecting a buffer from the Buffers menu.

In certain contexts, other key combinations may be available for
switching to certain buffers. For instance, when editing Lisp source
files, the key combo @code{C-c C-z} switches to the buffer where you
interact with Lisp.

@node Free Your Mind Interactive Programming
@section Free Your Mind: Interactive Programming
@anchor{#free-your-mind-interactive-programming}
When you start Lisp in a Box, you should see a buffer containing a
prompt that looks like this:

@verbatim
CL-USER>
@end verbatim

This is the Lisp prompt. Like a Unix or DOS shell prompt, the Lisp
prompt is a place where you can type expressions that will cause things
to happen. However, instead of reading and interpreting a line of shell
commands, Lisp reads Lisp expressions, evaluates them according to the
rules of Lisp, and prints the result. Then it does it again with the
next expression you type. That endless cycle of reading, evaluating, and
printing is why it's called the @emph{read-eval-print loop}, or REPL for
short. It's also referred to as the @emph{top-level}, the
@emph{top-level listener}, or the @emph{Lisp listener}.

From within the environment provided by the REPL, you can define and
redefine program elements such as variables, functions, classes, and
methods; evaluate any Lisp expression; load files containing Lisp source
code or compiled code; compile whole files or individual functions;
enter the debugger; step through code; and inspect the state of
individual Lisp objects.

All those facilities are built into the language, accessible via
functions defined in the language standard. If you had to, you could
build a pretty reasonable programming environment out of just the REPL
and any text editor that knows how to properly indent Lisp code. But for
the true Lisp programming experience, you need an environment, such as
SLIME, that lets you interact with Lisp both via the REPL and while
editing source files. For instance, you don't want to have to cut and
paste a function definition from a source file to the REPL or have to
load a whole file just because you changed one function; your Lisp
environment should let us evaluate or compile both individual
expressions and whole files directly from your editor.

@node Experimenting in the REPL
@section Experimenting in the REPL
@anchor{#experimenting-in-the-repl}
To try the REPL, you need a Lisp expression that can be read, evaluated,
and printed. One of the simplest kinds of Lisp expressions is a number.
At the Lisp prompt, you can type @code{10} followed by Return and should
see something like this:

@verbatim
CL-USER> 10
10
@end verbatim

The first @code{10} is the one you typed. The Lisp reader, the @emph{R}
in REPL, reads the text "10" and creates a Lisp object representing the
number 10. This object is a @emph{self-evaluating} object, which means
that when given to the evaluator, the @emph{E} in REPL, it evaluates to
itself. This value is then given to the printer, which prints the
@code{10} on the line by itself. While that may seem like a lot of work
just to get back to where you started, things get a bit more interesting
when you give Lisp something meatier to chew on. For instance, you can
type @code{(+ 2 3)} at the Lisp prompt.

@verbatim
CL-USER> (+ 2 3)
5
@end verbatim

Anything in parentheses is a list, in this case a list of three
elements, the symbol @code{+}, and the numbers 2 and 3. Lisp, in
general, evaluates lists by treating the first element as the name of a
function and the rest of the elements as expressions to be evaluated to
yield the arguments to the function. In this case, the symbol @code{+}
names a function that performs addition. 2 and 3 evaluate to themselves
and are then passed to the addition function, which returns 5. The value
5 is passed to the printer, which prints it. Lisp can evaluate a list
expression in other ways, but we needn't get into them right away. First
we have to write. . .

@node "Hello World" Lisp Style
@section "Hello, World," Lisp Style
@anchor{#hello-world-lisp-style} No programming book is complete
without a "hello, world"@footnote{The venerable "hello, world"
predates even the classic Kernighan and Ritchie C book that played a
big role in its popularization. The original "hello, world" seems to
have come from Brian Kernighan's "A Tutorial Introduction to the
Language B" that was part of the @emph{Bell Laboratories Computing
Science Technical Report #8: The Programming Language B} published in
January 1973. (It's available online at
@code{http://cm.bell-labs.com/cm/cs/who/dmr/bintro.html}.)}
program. As it turns out, it's trivially easy to get the REPL to print
"hello, world."

@verbatim
CL-USER> "hello, world"
"hello, world"
@end verbatim

This works because strings, like numbers, have a literal syntax that's
understood by the Lisp reader and are self-evaluating objects: Lisp
reads the double-quoted string and instantiates a string object in
memory that, when evaluated, evaluates to itself and is then printed in
the same literal syntax. The quotation marks aren't part of the string
object in memory--they're just the syntax that tells the reader to read
a string. The printer puts them back on when it prints the string
because it tries to print objects in the same syntax the reader
understands.

However, this may not really qualify as a "hello, world" @emph{program}.
It's more like the "hello, world" @emph{value}.

You can take a step toward a real program by writing some code that as
a side effect prints the string "hello, world" to standard
output. Common Lisp provides a couple ways to emit output, but the
most flexible is the @code{FORMAT} function. @code{FORMAT} takes a
variable number of arguments, but the only two required arguments are
the place to send the output and a string. You'll see in the next
chapter how the string can contain embedded directives that allow you
to interpolate subsequent arguments into the string, a la
@code{printf} or Python's string-@code{%}. As long as the string
doesn't contain an @code{~}, it will be emitted as-is. If you pass
@code{t} as its first argument, it sends its output to standard
output. So a @code{FORMAT} expression that will print "hello, world"
looks like this:

@verbatim
CL-USER> (format t "hello, world")
hello, world
NIL
@end verbatim

One thing to note about the result of the @code{FORMAT} expression is
the @code{NIL} on the line after the "hello, world" output. That
@code{NIL} is the result of evaluating the @code{FORMAT} expression,
printed by the REPL. (@code{NIL} is Lisp's version of false and/or
null.  More on that in Chapter 4.) Unlike the other expressions we've
seen so far, a @code{FORMAT} expression is more interesting for its
side effect--printing to standard output in this case--than for its
return value. But every expression in Lisp evaluates to some
result.@footnote{Well, as you'll see when I discuss returning multiple
values, it's technically possible to write expressions that evaluate
to no value, but even such expressions are treated as returning
@code{NIL} when evaluated in a context that expects a value.}

However, it's still arguable whether you've yet written a true
"program." But you're getting there. And you're seeing the bottom-up
style of programming supported by the REPL: you can experiment with
different approaches and build a solution from parts you've already
tested. Now that you have a simple expression that does what you want,
you just need to package it in a function. Functions are one of the
basic program building blocks in Lisp and can be defined with a
@code{DEFUN} expression such as this:

@verbatim
CL-USER> (defun hello-world () (format t "hello, world"))
HELLO-WORLD
@end verbatim

The @code{hello-world} after the @code{DEFUN} is the name of the
function. In Chapter 4 we'll look at exactly what characters can be used
in a name, but for now suffice it to say that lots of characters, such
as @code{-}, that are illegal in names in other languages are legal in
Common Lisp. It's standard Lisp style--not to mention more in line with
normal English typography--to form compound names with hyphens, such as
@code{hello-world}, rather than with underscores, as in
@code{hello_world}, or with inner caps such as @code{helloWorld}. The
@code{()}s after the name delimit the parameter list, which is empty in
this case because the function takes no arguments. The rest is the body
of the function.

At one level, this expression, like all the others you've seen, is
just another expression to be read, evaluated, and printed by the
REPL. The return value in this case is the name of the function you
just defined.@footnote{I'll discuss in Chapter 4 why the name has been
converted to all uppercase.} But like the @code{FORMAT} expression,
this expression is more interesting for the side effects it has than
for its return value. Unlike the @code{FORMAT} expression, however,
the side effects are invisible: when this expression is evaluated, a
new function that takes no arguments and with the body @code{(format t
"hello, world")} is created and given the name @code{HELLO-WORLD}.

Once you've defined the function, you can call it like this:

@verbatim
CL-USER> (hello-world)
hello, world
NIL
@end verbatim

You can see that the output is just the same as when you evaluated the
@code{FORMAT} expression directly, including the @code{NIL} value
printed by the REPL. Functions in Common Lisp automatically return the
value of the last expression evaluated.

@node Saving Your Work
@section Saving Your Work
@anchor{#saving-your-work}
You could argue that this is a complete "hello, world" program of sorts.
However, it still has a problem. If you exit Lisp and restart, the
function definition will be gone. Having written such a fine function,
you'll want to save your work.

Easy enough. You just need to create a file in which to save the
definition. In Emacs you can create a new file by typing @code{C-x C-f}
and then, when Emacs prompts you, entering the name of the file you want
to create. It doesn't matter particularly where you put the file. It's
customary to name Common Lisp source files with a @code{.lisp}
extension, though some folks use @code{.cl} instead.

Once you've created the file, you can type the definition you previously
entered at the REPL. Some things to note are that after you type the
opening parenthesis and the word @code{DEFUN}, at the bottom of the
Emacs window, SLIME will tell you the arguments expected. The exact form
will depend somewhat on what Common Lisp implementation you're using,
but it'll probably look something like this:

@verbatim
(defun name varlist &rest body)
@end verbatim

The message will disappear as you start to type each new element but
will reappear each time you enter a space. When you're entering the
definition in the file, you might choose to break the definition
across two lines after the parameter list. If you hit Return and then
Tab, SLIME will automatically indent the second line appropriately,
like this:@footnote{You could also have entered the definition as two
lines at the REPL, as the REPL reads whole expressions, not lines.}

@verbatim
(defun hello-world ()
  (format t "hello, world"))
@end verbatim

SLIME will also help match up the parentheses--as you type a closing
parenthesis, it will flash the corresponding opening parenthesis. Or you
can just type @code{C-c C-q} to invoke the command
@code{slime-close-parens-at-point}, which will insert as many closing
parentheses as necessary to match all the currently open parentheses.

Now you can get this definition into your Lisp environment in several
ways. The easiest is to type @code{C-c C-c} with the cursor anywhere in
or immediately after the @code{DEFUN} form, which runs the command
@code{slime-compile-defun}, which in turn sends the definition to Lisp
to be evaluated and compiled. To make sure this is working, you can make
some change to @code{hello-world}, recompile it, and then go back to the
REPL, using @code{C-c C-z} or @code{C-x b}, and call it again. For
instance, you could make it a bit more grammatical.

@verbatim
(defun hello-world ()
  (format t "Hello, world!"))
@end verbatim

Next, recompile with @code{C-c C-c} and then type @code{C-c C-z} to
switch to the REPL to try the new version.

@verbatim
CL-USER> (hello-world)
Hello, world!
NIL
@end verbatim

You'll also probably want to save the file you've been working on; in
the @code{hello.lisp} buffer, type @code{C-x C-s} to invoke the Emacs
command @code{save-buffer}.

Now to try reloading this function from the source file, you'll need
to quit Lisp and restart. To quit you can use a SLIME shortcut: at the
REPL, type a comma. At the bottom of the Emacs window, you will be
prompted for a command. Type @code{quit} (or @code{sayoonara}), and
then hit Enter. This will quit Lisp and close all the buffers created
by SLIME such as the REPL buffer.@footnote{SLIME shortcuts aren't part
of Common Lisp--they're commands to SLIME.} Now restart SLIME by
typing @code{M-x slime}.

Just for grins, you can try to invoke @code{hello-world}.

@verbatim
CL-USER> (hello-world)
@end verbatim

At that point SLIME will pop up a new buffer that starts with something
that looks like this:

@verbatim
attempt to call `HELLO-WORLD' which is an undefined function.
   [Condition of type UNDEFINED-FUNCTION]

Restarts:
  0: [TRY-AGAIN] Try calling HELLO-WORLD again.
  1: [RETURN-VALUE] Return a value instead of calling HELLO-WORLD.
  2: [USE-VALUE] Try calling a function other than HELLO-WORLD.
  3: [STORE-VALUE] Setf the symbol-function of HELLO-WORLD and call it again.
  4: [ABORT] Abort handling SLIME request.
  5: [ABORT] Abort entirely from this process.

Backtrace:
  0: (SWANK::DEBUG-IN-EMACS #<UNDEFINED-FUNCTION @ #x716b082a>)
  1: ((FLET SWANK:SWANK-DEBUGGER-HOOK SWANK::DEBUG-IT))
  2: (SWANK:SWANK-DEBUGGER-HOOK #<UNDEFINED-FUNCTION @ #x716b082a> #<Function SWANK-DEBUGGER-HOOK>)
  3: (ERROR #<UNDEFINED-FUNCTION @ #x716b082a>)
  4: (EVAL (HELLO-WORLD))
  5: (SWANK::EVAL-REGION "(hello-world)
" T)
@end verbatim

Blammo! What happened? Well, you tried to invoke a function that doesn't
exist. But despite the burst of output, Lisp is actually handling this
situation gracefully. Unlike Java or Python, Common Lisp doesn't just
bail--throwing an exception and unwinding the stack. And it definitely
doesn't dump core just because you tried to invoke a missing function.
Instead Lisp drops you into the debugger.

While you're in the debugger you still have full access to Lisp, so you
can evaluate expressions to examine the state of our program and maybe
even fix things. For now don't worry about that; just type @code{q} to
exit the debugger and get back to the REPL. The debugger buffer will go
away, and the REPL will show this:

@verbatim
CL-USER> (hello-world)
; Evaluation aborted
CL-USER>
@end verbatim

There's obviously more that can be done from within the debugger than
just abort--we'll see, for instance, in Chapter 19 how the debugger
integrates with the error handling system. For now, however, the
important thing to know is that you can always get out of it, and back
to the REPL, by typing @code{q}.

Back at the REPL you can try again. Things blew up because Lisp didn't
know the definition of @code{hello-world}. So you need to let Lisp know
about the definition we saved in the file @code{hello.lisp}. You have
several ways you could do this. You could switch back to the buffer
containing the file (type @code{C-x b} and then enter @code{hello.lisp}
when prompted) and recompile the definition as you did before with
@code{C-c C-c}. Or you can load the whole file, which would be a more
convenient approach if the file contained a bunch of definitions, using
the @code{LOAD} function at the REPL like this:

@verbatim
CL-USER> (load "hello.lisp")
; Loading /home/peter/my-lisp-programs/hello.lisp
T
@end verbatim

The @code{T} means everything loaded correctly.@footnote{If for some
reason the @code{LOAD} doesn't go cleanly, you'll get another error
and drop back into the debugger. If this happens, the most likely
reason is that Lisp can't find the file, probably because its idea of
the current working directory isn't the same as where the file is
located. In that case, you can quit the debugger by typing @code{q}
and then use the SLIME shortcut @code{cd} to change Lisp's idea of the
current directory--type a comma and then @code{cd} when prompted for a
command and then the name of the directory where @code{hello.lisp} was
saved.} Loading a file with @code{LOAD} is essentially equivalent to
typing each of the expressions in the file at the REPL in the order
they appear in the file, so after the call to @code{LOAD},
@code{hello-world} should be defined:

@verbatim
CL-USER> (hello-world)
Hello, world!
NIL
@end verbatim

Another way to load a file's worth of definitions is to compile the file
first with @code{COMPILE-FILE} and then @code{LOAD} the resulting
compiled file, called a @emph{FASL file}, which is short for
@emph{fast-load file}. @code{COMPILE-FILE} returns the name of the FASL
file, so we can compile and load from the REPL like this:

@verbatim
CL-USER> (load (compile-file "hello.lisp"))
;;; Compiling file hello.lisp
;;; Writing fasl file hello.fasl
;;; Fasl write complete
; Fast loading /home/peter/my-lisp-programs/hello.fasl
T
@end verbatim

SLIME also provides support for loading and compiling files without
using the REPL. When you're in a source code buffer, you can use
@code{C-c C-l} to load the file with @code{slime-load-file}. Emacs will
prompt for the name of a file to load with the name of the current file
already filled in; you can just hit Enter. Or you can type
@code{C-c C-k} to compile and load the file represented by the current
buffer. In some Common Lisp implementations, compiling code this way
will make it quite a bit faster; in others, it won't, typically because
they always compile everything.

This should be enough to give you a flavor of how Lisp programming
works. Of course I haven't covered all the tricks and techniques yet,
but you've seen the essential elements--interacting with the REPL trying
things out, loading and testing new code, tweaking and debugging.
Serious Lisp hackers often keep a Lisp image running for days on end,
adding, redefining, and testing bits of their program incrementally.

Also, even when the Lisp app is deployed, there's often still a way to
get to a REPL. You'll see in Chapter 26 how you can use the REPL and
SLIME to interact with the Lisp that's running a Web server at the same
time as it's serving up Web pages. It's even possible to use SLIME to
connect to a Lisp running on a different machine, allowing you--for
instance--to debug a remote server just like a local one.

An even more impressive instance of remote debugging occurred on
NASA's 1998 Deep Space 1 mission. A half year after the space craft
launched, a bit of Lisp code was going to control the spacecraft for
two days while conducting a sequence of experiments. Unfortunately, a
subtle race condition in the code had escaped detection during ground
testing and was already in space. When the bug manifested in the
wild--100 million miles away from Earth--the team was able to diagnose
and fix the running code, allowing the experiments to
complete.@footnote{@code{http://www.flownet.com/gat/jpl-lisp.html}}
One of the programmers described it as follows:

@quotation
Debugging a program running on a $100M piece of hardware that is 100
million miles away is an interesting experience. Having a
read-eval-print loop running on the spacecraft proved invaluable in
finding and fixing the problem.
@end quotation

You're not quite ready to send any Lisp code into deep space, but in the
next chapter you'll take a crack at writing a program a bit more
interesting than "hello, world."

@node Practical A Simple Database
@chapter Practical: A Simple Database
@anchor{#practical-a-simple-database}
Obviously, before you can start building real software in Lisp, you'll
have to learn the language. But let's face it--you may be thinking,
"'Practical Common Lisp,' isn't that an oxymoron? Why should you be
expected to bother learning all the details of a language unless it's
actually good for something you care about?" So I'll start by giving you
a small example of what you can do with Common Lisp. In this chapter
you'll write a simple database for keeping track of CDs. You'll use
similar techniques in Chapter 27 when you build a database of MP3s for
our streaming MP3 server. In fact, you could think of this as part of
the MP3 software project--after all, in order to have a bunch of MP3s to
listen to, it might be helpful to be able to keep track of which CDs you
have and which ones you need to rip.

In this chapter, I'll cover just enough Lisp as we go along for you to
understand how the code works. But I'll gloss over quite a few details.
For now you needn't sweat the small stuff--the next several chapters
will cover all the Common Lisp constructs used here, and more, in a much
more systematic way.

One terminology note: I'll discuss a handful of Lisp operators in this
chapter. In Chapter 4, you'll learn that Common Lisp provides three
distinct kinds of operators: @emph{functions}, @emph{macros}, and
@emph{special operators}. For the purposes of this chapter, you don't
really need to know the difference. I will, however, refer to
different operators as functions or macros or special operators as
appropriate, rather than trying to hide the details behind the word
@emph{operator}.  For now you can treat @emph{function}, @emph{macro},
and @emph{special operator} as all more or less
equivalent.@footnote{Before I proceed, however, it's crucially
important that you forget anything you may know about #define-style
"macros" as implemented in the C pre-processor. Lisp macros are a
totally different beast.}

Also, keep in mind that I won't bust out all the most sophisticated
Common Lisp techniques for your very first post-"hello, world" program.
The point of this chapter isn't that this is how you would write a
database in Lisp; rather, the point is for you to get an idea of what
programming in Lisp is like and to see how even a relatively simple Lisp
program can be quite featureful.

@menu
* CDs and Records::
* Filing CDs::
* Looking at the Database Contents::
* Improving the User Interaction::
* Saving and Loading the Database::
* Querying the Database::
* Updating Existing Records--Another Use for WHERE::
* Removing Duplication and Winning Big::
* Wrapping Up The Database::
@end menu

@node CDs and Records
@section CDs and Records
@anchor{#cds-and-records}
To keep track of CDs that need to be ripped to MP3s and which CDs should
be ripped first, each record in the database will contain the title and
artist of the CD, a rating of how much the user likes it, and a flag
saying whether it has been ripped. So, to start with, you'll need a way
to represent a single database record (in other words, one CD). Common
Lisp gives you lots of choices of data structures from a simple
four-item list to a user-defined class, using the Common Lisp Object
System (CLOS).

For now you can stay at the simple end of the spectrum and use a list.
You can make a list with the @code{LIST} function, which, appropriately
enough, returns a list of its arguments.

@verbatim
CL-USER> (list 1 2 3)
(1 2 3)
@end verbatim

You could use a four-item list, mapping a given position in the list to
a given field in the record. However, another flavor of list--called a
@emph{property list}, or @emph{plist} for short--is even more
convenient. A plist is a list where every other element, starting with
the first, is a @emph{symbol} that describes what the next element in
the list is. I won't get into all the details of exactly what a symbol
is right now; basically it's a name. For the symbols that name the
fields in the CD database, you can use a particular kind of symbol,
called a @emph{keyword} symbol. A keyword is any name that starts with a
colon (@code{:}), for instance, @code{:foo}. Here's an example of a
plist using the keyword symbols @code{:a}, @code{:b}, and @code{:c} as
property names:

@verbatim
CL-USER> (list :a 1 :b 2 :c 3)
(:A 1 :B 2 :C 3)
@end verbatim

Note that you can create a property list with the same @code{LIST}
function as you use to create other lists; it's the contents that make
it a plist.

The thing that makes plists a convenient way to represent the records in
a database is the function @code{GETF}, which takes a plist and a symbol
and returns the value in the plist following the symbol, making a plist
a sort of poor man's hash table. Lisp has real hash tables too, but
plists are sufficient for your needs here and can more easily be saved
to a file, which will come in handy later.

@verbatim
CL-USER> (getf (list :a 1 :b 2 :c 3) :a)
1
CL-USER> (getf (list :a 1 :b 2 :c 3) :c)
3
@end verbatim

Given all that, you can easily enough write a function @code{make-cd}
that will take the four fields as arguments and return a plist
representing that CD.

@verbatim
(defun make-cd (title artist rating ripped)
  (list :title title :artist artist :rating rating :ripped ripped))
@end verbatim

The word @code{DEFUN} tells us that this form is defining a new
function. The name of the function is @code{make-cd}. After the name
comes the parameter list. This function has four parameters:
@code{title}, @code{artist}, @code{rating}, and @code{ripped}.
Everything after the parameter list is the body of the function. In this
case the body is just one form, a call to @code{LIST}. When
@code{make-cd} is called, the arguments passed to the call will be bound
to the variables in the parameter list. For instance, to make a record
for the CD @emph{Roses} by Kathy Mattea, you might call @code{make-cd}
like this:

@verbatim
CL-USER> (make-cd "Roses" "Kathy Mattea" 7 t)
(:TITLE "Roses" :ARTIST "Kathy Mattea" :RATING 7 :RIPPED T)
@end verbatim

@node Filing CDs
@section Filing CDs
@anchor{#filing-cds} A single record, however, does not a database
make. You need some larger construct to hold the records. Again, for
simplicity's sake, a list seems like a good choice. Also for
simplicity you can use a global variable, @code{*db*}, which you can
define with the @code{DEFVAR} macro. The asterisks (*) in the name are
a Lisp naming convention for global variables.@footnote{Using a global
variable also has some drawbacks--for instance, you can have only one
database at a time. In Chapter 27, with more of the language under
your belt, you'll be ready to build a more flexible database. You'll
also see, in Chapter 6, how even using a global variable is more
flexible in Common Lisp than it may be in other languages.}

@verbatim
(defvar *db* nil)
@end verbatim

You can use the @code{PUSH} macro to add items to @code{*db*}. But it's
probably a good idea to abstract things a tiny bit, so you should define
a function @code{add-record} that adds a record to the database.

@verbatim
(defun add-record (cd) (push cd *db*))
@end verbatim

Now you can use @code{add-record} and @code{make-cd} together to add CDs
to the database.

@verbatim
CL-USER> (add-record (make-cd "Roses" "Kathy Mattea" 7 t))
((:TITLE "Roses" :ARTIST "Kathy Mattea" :RATING 7 :RIPPED T))
CL-USER> (add-record (make-cd "Fly" "Dixie Chicks" 8 t))
((:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T)
 (:TITLE "Roses" :ARTIST "Kathy Mattea" :RATING 7 :RIPPED T))
CL-USER> (add-record (make-cd "Home" "Dixie Chicks" 9 t))
((:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 9 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T)
 (:TITLE "Roses" :ARTIST "Kathy Mattea" :RATING 7 :RIPPED T))
@end verbatim

The stuff printed by the REPL after each call to @code{add-record} is
the return value, which is the value returned by the last expression in
the function body, the @code{PUSH}. And @code{PUSH} returns the new
value of the variable it's modifying. So what you're actually seeing is
the value of the database after the record has been added.

@node Looking at the Database Contents
@section Looking at the Database Contents
@anchor{#looking-at-the-database-contents}
You can also see the current value of @code{*db*} whenever you want by
typing @code{*db*} at the REPL.

@verbatim
CL-USER> *db*
((:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 9 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T)
 (:TITLE "Roses" :ARTIST "Kathy Mattea" :RATING 7 :RIPPED T))
@end verbatim

However, that's not a very satisfying way of looking at the output. You
can write a @code{dump-db} function that dumps out the database in a
more human-readable format, like this:

@verbatim
TITLE:    Home
ARTIST:   Dixie Chicks
RATING:   9
RIPPED:   T

TITLE:    Fly
ARTIST:   Dixie Chicks
RATING:   8
RIPPED:   T

TITLE:    Roses
ARTIST:   Kathy Mattea
RATING:   7
RIPPED:   T
@end verbatim

The function looks like this:

@verbatim
(defun dump-db ()
  (dolist (cd *db*)
    (format t "~{~a:~10t~a~%~}~%" cd)))
@end verbatim

This function works by looping over all the elements of @code{*db*} with
the @code{DOLIST} macro, binding each element to the variable @code{cd}
in turn. For each value of @code{cd}, you use the @code{FORMAT} function
to print it.

Admittedly, the @code{FORMAT} call is a little cryptic. However,
@code{FORMAT} isn't particularly more complicated than C or Perl's
@code{printf} function or Python's string-@code{%} operator. In Chapter
18 I'll discuss @code{FORMAT} in greater detail. For now we can take
this call bit by bit. As you saw in Chapter 2, @code{FORMAT} takes at
least two arguments, the first being the stream where it sends its
output; @code{t} is shorthand for the stream @code{*standard-output*}.

The second argument to @code{FORMAT} is a format string that can
contain both literal text and directives telling @code{FORMAT} things
such as how to interpolate the rest of its arguments. Format
directives start with @code{~} (much the way @code{printf}'s
directives start with @code{%}). @code{FORMAT} understands dozens of
directives, each with their own set of options.@footnote{One of the
coolest @code{FORMAT} directives is the @code{~R} directive. Ever want
to know how to say a really big number in English words? Lisp
knows. Evaluate this:

@verbatim
(format nil "~r" 1606938044258990275541962092)
@end verbatim
and you should get back (wrapped for legibility):
@quotation
"one octillion six hundred six septillion nine hundred thirty-eight
sextillion forty-four quintillion two hundred fifty-eight quadrillion
nine hundred ninety trillion two hundred seventy-five billion five
hundred forty-one million nine hundred sixty-two thousand ninety-two"
@end quotation
} However, for now I'll just focus on the ones you need to write
@code{dump-db}.

The @code{~a} directive is the @emph{aesthetic} directive; it means to
consume one argument and output it in a human-readable form. This will
render keywords without the leading : and strings without quotation
marks. For instance:

@verbatim
CL-USER> (format t "~a" "Dixie Chicks")
Dixie Chicks
NIL
@end verbatim

or:

@verbatim
CL-USER> (format t "~a" :title)
TITLE
NIL
@end verbatim

The @code{~t} directive is for tabulating. The @code{~10t} tells
@code{FORMAT} to emit enough spaces to move to the tenth column before
processing the next @code{~a}. A @code{~t} doesn't consume any
arguments.

@verbatim
CL-USER> (format t "~a:~10t~a" :artist "Dixie Chicks")
ARTIST:   Dixie Chicks
NIL
@end verbatim

Now things get slightly more complicated. When @code{FORMAT} sees
@code{~@{} the next argument to be consumed must be a list.
@code{FORMAT} loops over that list, processing the directives between
the @code{~@{} and @code{~}@}, consuming as many elements of the list as
needed each time through the list. In @code{dump-db}, the @code{FORMAT}
loop will consume one keyword and one value from the list each time
through the loop. The @code{~%} directive doesn't consume any arguments
but tells @code{FORMAT} to emit a newline. Then after the @code{~}@}
ends the loop, the last @code{~%} tells @code{FORMAT} to emit one more
newline to put a blank line between each CD.

Technically, you could have also used @code{FORMAT} to loop over the
database itself, turning our @code{dump-db} function into a one-liner.

@verbatim
(defun dump-db ()
  (format t "~{~{~a:~10t~a~%~}~%~}" *db*))
@end verbatim

That's either very cool or very scary depending on your point of view.

@node Improving the User Interaction
@section Improving the User Interaction
@anchor{#improving-the-user-interaction}
While our @code{add-record} function works fine for adding records, it's
a bit Lispy for the casual user. And if they want to add a bunch of
records, it's not very convenient. So you may want to write a function
to prompt the user for information about a set of CDs. Right away you
know you'll need some way to prompt the user for a piece of information
and read it. So let's write that.

@verbatim
(defun prompt-read (prompt)
  (format *query-io* "~a: " prompt)
  (force-output *query-io*)
  (read-line *query-io*))
@end verbatim

You use your old friend @code{FORMAT} to emit a prompt. Note that
there's no @code{~%} in the format string, so the cursor will stay on
the same line. The call to @code{FORCE-OUTPUT} is necessary in some
implementations to ensure that Lisp doesn't wait for a newline before it
prints the prompt.

Then you can read a single line of text with the aptly named
@code{READ-LINE} function. The variable @code{*query-io*} is a global
variable (which you can tell because of the @code{*} naming convention
for global variables) that contains the input stream connected to the
terminal. The return value of @code{prompt-read} will be the value of
the last form, the call to @code{READ-LINE}, which returns the string it
read (without the trailing newline.)

You can combine your existing @code{make-cd} function with
@code{prompt-read} to build a function that makes a new CD record from
data it gets by prompting for each value in turn.

@verbatim
(defun prompt-for-cd ()
  (make-cd
   (prompt-read "Title")
   (prompt-read "Artist")
   (prompt-read "Rating")
   (prompt-read "Ripped [y/n]")))
@end verbatim

That's almost right. Except @code{prompt-read} returns a string, which,
while fine for the Title and Artist fields, isn't so great for the
Rating and Ripped fields, which should be a number and a boolean.
Depending on how sophisticated a user interface you want, you can go to
arbitrary lengths to validate the data the user enters. For now let's
lean toward the quick and dirty: you can wrap the @code{prompt-read} for
the rating in a call to Lisp's @code{PARSE-INTEGER} function, like this:

@verbatim
(parse-integer (prompt-read "Rating"))
@end verbatim

Unfortunately, the default behavior of @code{PARSE-INTEGER} is to signal
an error if it can't parse an integer out of the string or if there's
any non-numeric junk in the string. However, it takes an optional
keyword argument @code{:junk-allowed}, which tells it to relax a bit.

@verbatim
(parse-integer (prompt-read "Rating") :junk-allowed t)
@end verbatim

But there's still one problem: if it can't find an integer amidst all
the junk, @code{PARSE-INTEGER} will return @code{NIL} rather than a
number. In keeping with the quick-and-dirty approach, you may just want
to call that 0 and continue. Lisp's @code{OR} macro is just the thing
you need here. It's similar to the "short-circuiting" @code{||} in Perl,
Python, Java, and C; it takes a series of expressions, evaluates them
one at a time, and returns the first non-nil value (or @code{NIL} if
they're all @code{NIL}). So you can use the following:

@verbatim
(or (parse-integer (prompt-read "Rating") :junk-allowed t) 0)
@end verbatim

to get a default value of 0.

Fixing the code to prompt for Ripped is quite a bit simpler. You can
just use the Common Lisp function @code{Y-OR-N-P}.

@verbatim
(y-or-n-p "Ripped [y/n]: ")
@end verbatim

In fact, this will be the most robust part of @code{prompt-for-cd}, as
@code{Y-OR-N-P} will reprompt the user if they enter something that
doesn't start with @emph{y}, @emph{Y}, @emph{n}, or @emph{N}.

Putting those pieces together you get a reasonably robust
@code{prompt-for-cd} function.

@verbatim
(defun prompt-for-cd ()
  (make-cd
   (prompt-read "Title")
   (prompt-read "Artist")
   (or (parse-integer (prompt-read "Rating") :junk-allowed t) 0)
   (y-or-n-p "Ripped [y/n]: ")))
@end verbatim

Finally, you can finish the "add a bunch of CDs" interface by wrapping
@code{prompt-for-cd} in a function that loops until the user is done.
You can use the simple form of the @code{LOOP} macro, which repeatedly
executes a body of expressions until it's exited by a call to
@code{RETURN}. For example:

@verbatim
(defun add-cds ()
  (loop (add-record (prompt-for-cd))
      (if (not (y-or-n-p "Another? [y/n]: ")) (return))))
@end verbatim

Now you can use @code{add-cds} to add some more CDs to the database.

@verbatim
CL-USER> (add-cds)
Title: Rockin' the Suburbs
Artist: Ben Folds
Rating: 6
Ripped  [y/n]: y
Another?  [y/n]: y
Title: Give Us a Break
Artist: Limpopo
Rating: 10
Ripped  [y/n]: y
Another?  [y/n]: y
Title: Lyle Lovett
Artist: Lyle Lovett
Rating: 9
Ripped  [y/n]: y
Another?  [y/n]: n
NIL
@end verbatim

@node Saving and Loading the Database
@section Saving and Loading the Database
@anchor{#saving-and-loading-the-database}
Having a convenient way to add records to the database is nice. But it's
not so nice that the user is going to be very happy if they have to
reenter all the records every time they quit and restart Lisp. Luckily,
with the data structures you're using to represent the data, it's
trivially easy to save the data to a file and reload it later. Here's a
@code{save-db} function that takes a filename as an argument and saves
the current state of the database:

@verbatim
(defun save-db (filename)
  (with-open-file (out filename
                   :direction :output
                   :if-exists :supersede)
    (with-standard-io-syntax
      (print *db* out))))
@end verbatim

The @code{WITH-OPEN-FILE} macro opens a file, binds the stream to a
variable, executes a set of expressions, and then closes the file. It
also makes sure the file is closed even if something goes wrong while
evaluating the body. The list directly after @code{WITH-OPEN-FILE} isn't
a function call but rather part of the syntax defined by
@code{WITH-OPEN-FILE}. It contains the name of the variable that will
hold the file stream to which you'll write within the body of
@code{WITH-OPEN-FILE}, a value that must be a file name, and then some
options that control how the file is opened. Here you specify that
you're opening the file for writing with @code{:direction :output} and
that you want to overwrite an existing file of the same name if it
exists with @code{:if-exists :supersede}.

Once you have the file open, all you have to do is print the contents of
the database with @code{(print *db* out)}. Unlike @code{FORMAT},
@code{PRINT} prints Lisp objects in a form that can be read back in by
the Lisp reader. The macro @code{WITH-STANDARD-IO-SYNTAX} ensures that
certain variables that affect the behavior of @code{PRINT} are set to
their standard values. You'll use the same macro when you read the data
back in to make sure the Lisp reader and printer are operating
compatibly.

The argument to @code{save-db} should be a string containing the name of
the file where the user wants to save the database. The exact form of
the string will depend on what operating system they're using. For
instance, on a Unix box they should be able to call @code{save-db} like
this:

@verbatim
CL-USER> (save-db "~/my-cds.db")
((:TITLE "Lyle Lovett" :ARTIST "Lyle Lovett" :RATING 9 :RIPPED T)
 (:TITLE "Give Us a Break" :ARTIST "Limpopo" :RATING 10 :RIPPED T)
 (:TITLE "Rockin' the Suburbs" :ARTIST "Ben Folds" :RATING 6 :RIPPED
  T)
 (:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 9 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T)
 (:TITLE "Roses" :ARTIST "Kathy Mattea" :RATING 9 :RIPPED T))
@end verbatim

On Windows, the filename might be something like "@code{c:/my-cds.db}"
or "@code{c:\\my-cds.db}."@footnote{Windows actually understands
forward slashes in filenames even though it normally uses a backslash
as the directory separator. This is convenient since otherwise you
have to write double backslashes because backslash is the escape
character in Lisp strings.}

You can open this file in any text editor to see what it looks like. You
should see something a lot like what the REPL prints if you type
@code{*db*}.

The function to load the database back in is similar.

@verbatim
(defun load-db (filename)
  (with-open-file (in filename)
    (with-standard-io-syntax
      (setf *db* (read in)))))
@end verbatim

This time you don't need to specify @code{:direction} in the options to
@code{WITH-OPEN-FILE}, since you want the default of @code{:input}. And
instead of printing, you use the function @code{READ} to read from the
stream @code{in}. This is the same reader used by the REPL and can read
any Lisp expression you could type at the REPL prompt. However, in this
case, you're just reading and saving the expression, not evaluating it.
Again, the @code{WITH-STANDARD-IO-SYNTAX} macro ensures that @code{READ}
is using the same basic syntax that @code{save-db} did when it
@code{PRINT}ed the data.

The @code{SETF} macro is Common Lisp's main assignment operator. It sets
its first argument to the result of evaluating its second argument. So
in @code{load-db} the @code{*db*} variable will contain the object read
from the file, namely, the list of lists written by @code{save-db}. You
do need to be careful about one thing--@code{load-db} clobbers whatever
was in @code{*db*} before the call. So if you've added records with
@code{add-record} or @code{add-cds} that haven't been saved with
@code{save-db}, you'll lose them.

@node Querying the Database
@section Querying the Database
@anchor{#querying-the-database}
Now that you have a way to save and reload the database to go along with
a convenient user interface for adding new records, you soon may have
enough records that you won't want to be dumping out the whole database
just to look at what's in it. What you need is a way to query the
database. You might like, for instance, to be able to write something
like this:

@verbatim
(select :artist "Dixie Chicks")
@end verbatim

and get a list of all the records where the artist is the Dixie Chicks.
Again, it turns out that the choice of saving the records in a list will
pay off.

The function @code{REMOVE-IF-NOT} takes a predicate and a list and
returns a list containing only the elements of the original list that
match the predicate. In other words, it has removed all the elements
that don't match the predicate. However, @code{REMOVE-IF-NOT} doesn't
really remove anything--it creates a new list, leaving the original list
untouched. It's like running grep over a file. The predicate argument
can be any function that accepts a single argument and returns a boolean
value--@code{NIL} for false and anything else for true.

For instance, if you wanted to extract all the even elements from a list
of numbers, you could use @code{REMOVE-IF-NOT} as follows:

@verbatim
CL-USER> (remove-if-not #'evenp '(1 2 3 4 5 6 7 8 9 10))
(2 4 6 8 10)
@end verbatim

In this case, the predicate is the function @code{EVENP}, which returns
true if its argument is an even number. The funny notation @code{#'} is
shorthand for "Get me the function with the following name." Without the
@code{#'}, Lisp would treat @code{evenp} as the name of a variable and
look up the value of the variable, not the function.

You can also pass @code{REMOVE-IF-NOT} an anonymous function. For
instance, if @code{EVENP} didn't exist, you could write the previous
expression as the following:

@verbatim
CL-USER> (remove-if-not #'(lambda (x) (= 0 (mod x 2))) '(1 2 3 4 5 6 7 8 9 10))
(2 4 6 8 10)
@end verbatim

In this case, the predicate is this anonymous function:

@verbatim
(lambda (x) (= 0 (mod x 2)))
@end verbatim

which checks that its argument is equal to 0 modulus 2 (in other words,
is even). If you wanted to extract only the odd numbers using an
anonymous function, you'd write this:

@verbatim
CL-USER> (remove-if-not #'(lambda (x) (= 1 (mod x 2))) '(1 2 3 4 5 6 7 8 9 10))
(1 3 5 7 9)
@end verbatim

Note that @code{lambda} isn't the name of the function--it's the
indicator you're defining an anonymous function.@footnote{The word
lambda is used in Lisp because of an early connection to the lambda
calculus, a mathematical formalism invented for studying mathematical
functions.}  Other than the lack of a name, however, a @code{LAMBDA}
expression looks a lot like a @code{DEFUN}: the word @code{lambda} is
followed by a parameter list, which is followed by the body of the
function.

To select all the Dixie Chicks' albums in the database using
@code{REMOVE-IF-NOT}, you need a function that returns true when the
artist field of a record is @code{"Dixie Chicks"}. Remember that we
chose the plist representation for the database records because the
function @code{GETF} can extract named fields from a plist. So assuming
@code{cd} is the name of a variable holding a single database record,
you can use the expression @code{(getf cd :artist)} to extract the name
of the artist. The function @code{EQUAL}, when given string arguments,
compares them character by character. So
@code{(equal (getf cd :artist) "Dixie Chicks")} will test whether the
artist field of a given CD is equal to @code{"Dixie Chicks"}. All you
need to do is wrap that expression in a @code{LAMBDA} form to make an
anonymous function and pass it to @code{REMOVE-IF-NOT}.

@verbatim
CL-USER> (remove-if-not
  #'(lambda (cd) (equal (getf cd :artist) "Dixie Chicks")) *db*)
((:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 9 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T))
@end verbatim

Now suppose you want to wrap that whole expression in a function that
takes the name of the artist as an argument. You can write that like
this:

@verbatim
(defun select-by-artist (artist)
  (remove-if-not
   #'(lambda (cd) (equal (getf cd :artist) artist))
   *db*))
@end verbatim

Note how the anonymous function, which contains code that won't run
until it's invoked in @code{REMOVE-IF-NOT}, can nonetheless refer to the
variable @code{artist}. In this case the anonymous function doesn't just
save you from having to write a regular function--it lets you write a
function that derives part of its meaning--the value of
@code{artist}--from the context in which it's embedded.

So that's @code{select-by-artist}. However, selecting by artist is only
one of the kinds of queries you might like to support. You @emph{could}
write several more functions, such as @code{select-by-title},
@code{select-by-rating}, @code{select-by-title-and-artist}, and so on.
But they'd all be about the same except for the contents of the
anonymous function. You can instead make a more general @code{select}
function that takes a function as an argument.

@verbatim
(defun select (selector-fn)
  (remove-if-not selector-fn *db*))
@end verbatim

So what happened to the @code{#'}? Well, in this case you don't want
@code{REMOVE-IF-NOT} to use the function named @code{selector-fn}. You
want it to use the anonymous function that was passed as an argument to
@code{select} in the @emph{variable} @code{selector-fn}. Though, the
@code{#'} comes back in the @emph{call} to @code{select}.

@verbatim
CL-USER> (select #'(lambda (cd) (equal (getf cd :artist) "Dixie Chicks")))
((:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 9 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T))
@end verbatim

But that's really quite gross-looking. Luckily, you can wrap up the
creation of the anonymous function.

@verbatim
(defun artist-selector (artist)
  #'(lambda (cd) (equal (getf cd :artist) artist)))
@end verbatim

This is a function that returns a function and one that references a
variable that--it seems--won't exist after @code{artist-selector}
returns.@footnote{The technical term for a function that references a
variable in its enclosing scope is a closure because the function
"closes over" the variable. I'll discuss closures in more detail in
Chapter 6.} It may seem odd now, but it actually works just the way
you'd want--if you call @code{artist-selector} with an argument of
@code{"Dixie Chicks"}, you get an anonymous function that matches CDs
whose @code{:artist} field is @code{"Dixie Chicks"}, and if you call
it with @code{"Lyle Lovett"}, you get a different function that will
match against an @code{:artist} field of @code{"Lyle Lovett"}. So now
you can rewrite the call to @code{select} like this:

@verbatim
CL-USER> (select (artist-selector "Dixie Chicks"))
((:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 9 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 8 :RIPPED T))
@end verbatim

Now you just need some more functions to generate selectors. But just as
you don't want to have to write @code{select-by-title},
@code{select-by-rating}, and so on, because they would all be quite
similar, you're not going to want to write a bunch of nearly identical
selector-function generators, one for each field. Why not write one
general-purpose selector-function generator, a function that, depending
on what arguments you pass it, will generate a selector function for
different fields or maybe even a combination of fields? You can write
such a function, but first you need a crash course in a feature called
@emph{keyword parameters}.

In the functions you've written so far, you've specified a simple list
of parameters, which are bound to the corresponding arguments in the
call to the function. For instance, the following function:

@verbatim
(defun foo (a b c) (list a b c))
@end verbatim

has three parameters, @code{a}, @code{b}, and @code{c}, and must be
called with three arguments. But sometimes you may want to write a
function that can be called with varying numbers of arguments. Keyword
parameters are one way to achieve this. A version of @code{foo} that
uses keyword parameters might look like this:

@verbatim
(defun foo (&key a b c) (list a b c))
@end verbatim

The only difference is the @code{&key} at the beginning of the argument
list. However, the calls to this new @code{foo} will look quite
different. These are all legal calls with the result to the right of the
==>:

@verbatim
(foo :a 1 :b 2 :c 3)  ==> (1 2 3)
(foo :c 3 :b 2 :a 1)  ==> (1 2 3)
(foo :a 1 :c 3)       ==> (1 NIL 3)
(foo)                 ==> (NIL NIL NIL)
@end verbatim

As these examples show, the value of the variables @code{a}, @code{b},
and @code{c} are bound to the values that follow the corresponding
keyword. And if a particular keyword isn't present in the call, the
corresponding variable is set to @code{NIL}. I'm glossing over a bunch
of details of how keyword parameters are specified and how they relate
to other kinds of parameters, but you need to know one more detail.

Normally if a function is called with no argument for a particular
keyword parameter, the parameter will have the value @code{NIL}.
However, sometimes you'll want to be able to distinguish between a
@code{NIL} that was explicitly passed as the argument to a keyword
parameter and the default value @code{NIL}. To allow this, when you
specify a keyword parameter you can replace the simple name with a list
consisting of the name of the parameter, a default value, and another
parameter name, called a @emph{supplied-p} parameter. The supplied-p
parameter will be set to true or false depending on whether an argument
was actually passed for that keyword parameter in a particular call to
the function. Here's a version of @code{foo} that uses this feature:

@verbatim
(defun foo (&key a (b 20) (c 30 c-p)) (list a b c c-p))
@end verbatim

Now the same calls from earlier yield these results:

@verbatim
(foo :a 1 :b 2 :c 3)  ==> (1 2 3 T)
(foo :c 3 :b 2 :a 1)  ==> (1 2 3 T)
(foo :a 1 :c 3)       ==> (1 20 3 T)
(foo)                 ==> (NIL 20 30 NIL)
@end verbatim

The general selector-function generator, which you can call @code{where}
for reasons that will soon become apparent if you're familiar with SQL
databases, is a function that takes four keyword parameters
corresponding to the fields in our CD records and generates a selector
function that selects any CDs that match all the values given to
@code{where}. For instance, it will let you say things like this:

@verbatim
(select (where :artist "Dixie Chicks"))
@end verbatim

or this:

@verbatim
(select (where :rating 10 :ripped nil))
@end verbatim

The function looks like this:

@verbatim
(defun where (&key title artist rating (ripped nil ripped-p))
  #'(lambda (cd)
      (and
       (if title    (equal (getf cd :title)  title)  t)
       (if artist   (equal (getf cd :artist) artist) t)
       (if rating   (equal (getf cd :rating) rating) t)
       (if ripped-p (equal (getf cd :ripped) ripped) t))))
@end verbatim

This function returns an anonymous function that returns the logical
@code{AND} of one clause per field in our CD records. Each clause
checks if the appropriate argument was passed in and then either
compares it to the value in the corresponding field in the CD record
or returns @code{t}, Lisp's version of truth, if the parameter wasn't
passed in.  Thus, the selector function will return @code{t} only for
CDs that match all the arguments passed to @code{where}.@footnote{Note
that in Lisp, an IF form, like everything else, is an expression that
returns a value. It's actually more like the ternary operator
(@code{?:}) in Perl, Java, and C in that this is legal in those
languages:

@verbatim
some_var = some_boolean ? value1 : value2;
@end verbatim

while this isn't:

@verbatim
some_var = if (some_boolean) value1; else value2;
@end verbatim

because in those languages, @code{if} is a statement, not an
expression.} Note that you need to use a three-item list to specify
the keyword parameter @code{ripped} because you need to know whether
the caller actually passed @code{:ripped nil}, meaning, "Select CDs
whose ripped field is nil," or whether they left out @code{:ripped}
altogether, meaning "I don't care what the value of the ripped field
is."

@node Updating Existing Records--Another Use for WHERE
@section Updating Existing Records--Another Use for WHERE
@anchor{#updating-existing-records--another-use-for-where}
Now that you've got nice generalized @code{select} and @code{where}
functions, you're in a good position to write the next feature that
every database needs--a way to update particular records. In SQL the
@code{update} command is used to update a set of records matching a
particular @code{where} clause. That seems like a good model, especially
since you've already got a @code{where}-clause generator. In fact, the
@code{update} function is mostly just the application of a few ideas
you've already seen: using a passed-in selector function to choose the
records to update and using keyword arguments to specify the values to
change. The main new bit is the use of a function @code{MAPCAR} that
maps over a list, @code{*db*} in this case, and returns a new list
containing the results of calling a function on each item in the
original list.

@verbatim
(defun update (selector-fn &key title artist rating (ripped nil ripped-p))
  (setf *db*
        (mapcar
         #'(lambda (row)
             (when (funcall selector-fn row)
               (if title    (setf (getf row :title) title))
               (if artist   (setf (getf row :artist) artist))
               (if rating   (setf (getf row :rating) rating))
               (if ripped-p (setf (getf row :ripped) ripped)))
             row) *db*)))
@end verbatim

One other new bit here is the use of @code{SETF} on a complex form such
as @code{(getf row :title)}. I'll discuss @code{SETF} in greater detail
in Chapter 6, but for now you just need to know that it's a general
assignment operator that can be used to assign lots of "places" other
than just variables. (It's a coincidence that @code{SETF} and
@code{GETF} have such similar names--they don't have any special
relationship.) For now it's enough to know that after
@code{(setf (getf row :title) title)}, the plist referenced by row will
have the value of the variable @code{title} following the property name
@code{:title}. With this @code{update} function if you decide that you
@emph{really} dig the Dixie Chicks and that all their albums should go
to 11, you can evaluate the following form:

@verbatim
CL-USER> (update (where :artist "Dixie Chicks") :rating 11)
NIL
@end verbatim

And it is so.

@verbatim
CL-USER> (select (where :artist "Dixie Chicks"))
((:TITLE "Home" :ARTIST "Dixie Chicks" :RATING 11 :RIPPED T)
 (:TITLE "Fly" :ARTIST "Dixie Chicks" :RATING 11 :RIPPED T))
@end verbatim

You can even more easily add a function to delete rows from the
database.

@verbatim
(defun delete-rows (selector-fn)
  (setf *db* (remove-if selector-fn *db*)))
@end verbatim

The function @code{REMOVE-IF} is the complement of
@code{REMOVE-IF-NOT}; it returns a list with all the elements that do
match the predicate removed. Like @code{REMOVE-IF-NOT}, it doesn't
actually affect the list it's passed but by saving the result back
into @code{*db*}, @code{delete-rows}@footnote{You need to use the name
@code{delete-rows} rather than the more obvious @code{delete} because
there's already a function in Common Lisp called @code{DELETE}. The
Lisp package system gives you a way to deal with such naming
conflicts, so you could have a function named delete if you
wanted. But I'm not ready to explain packages just yet.} actually
changes the contents of the database.@footnote{If you're worried that
this code creates a memory leak, rest assured: Lisp was the language
that invented garbage collection (and heap allocation for that
matter). The memory used by the old value of @code{*db*} will be
automatically reclaimed, assuming no one else is holding on to a
reference to it, which none of this code is.}

@node Removing Duplication and Winning Big
@section Removing Duplication and Winning Big
@anchor{#removing-duplication-and-winning-big} So far @emph{all} the
database code supporting insert, select, update, and delete, not to
mention a command-line user interface for adding new records and
dumping out the contents, is just a little more than 50
lines. Total.@footnote{A friend of mine was once interviewing an
engineer for a programming job and asked him a typical interview
question: how do you know when a function or method is too big? Well,
said the candidate, I don't like any method to be bigger than my
head. You mean you can't keep all the details in your head? No, I mean
I put my head up against my monitor, and the code shouldn't be bigger
than my head.}

Yet there's still some annoying code duplication. And it turns out you
can remove the duplication and make the code more flexible at the same
time. The duplication I'm thinking of is in the where function. The body
of the @code{where} function is a bunch of clauses like this, one per
field:

@verbatim
(if title (equal (getf cd :title) title) t)
@end verbatim

Right now it's not so bad, but like all code duplication it has the same
cost: if you want to change how it works, you have to change multiple
copies. And if you change the fields in a CD, you'll have to add or
remove clauses to @code{where}. And @code{update} suffers from the same
kind of duplication. It's doubly annoying since the whole point of the
@code{where} function is to dynamically generate a bit of code that
checks the values you care about; why should it have to do work at
runtime checking whether @code{title} was even passed in?

Imagine that you were trying to optimize this code and discovered that
it was spending too much time checking whether @code{title} and the
rest of the keyword parameters to @code{where} were even
set?@footnote{It's unlikely that the cost of checking whether keyword
parameters had been passed would be a detectible drag on performance
since checking whether a variable is @code{NIL} is going to be pretty
cheap. On the other hand, these functions returned by @code{where} are
going to be right in the middle of the inner loop of any
@code{select}, @code{update}, or @code{delete-rows} call, as they have
to be called once per entry in the database. Anyway, for illustrative
purposes, this will have to do.} If you really wanted to remove all
those runtime checks, you could go through a program and find all the
places you call @code{where} and look at exactly what arguments you're
passing.  Then you could replace each call to @code{where} with an
anonymous function that does only the computation necessary. For
instance, if you found this snippet of code:

@verbatim
(select (where :title "Give Us a Break" :ripped t))
@end verbatim

you could change it to this:

@verbatim
(select
 #'(lambda (cd)
     (and (equal (getf cd :title) "Give Us a Break")
          (equal (getf cd :ripped) t))))
@end verbatim

Note that the anonymous function is different from the one that
@code{where} would have returned; you're not trying to save the call to
@code{where} but rather to provide a more efficient selector function.
This anonymous function has clauses only for the fields that you
actually care about at this call site, so it doesn't do any extra work
the way a function returned by @code{where} might.

You can probably imagine going through all your source code and fixing
up all the calls to @code{where} in this way. But you can probably also
imagine that it would be a huge pain. If there were enough of them, and
it was important enough, it might even be worthwhile to write some kind
of preprocessor that converts @code{where} calls to the code you'd write
by hand.

The Lisp feature that makes this trivially easy is its macro system. I
can't emphasize enough that the Common Lisp macro shares essentially
nothing but the name with the text-based macros found in C and C++.
Where the C pre-processor operates by textual substitution and
understands almost nothing of the structure of C and C++, a Lisp macro
is essentially a code generator that gets run for you automatically by
the compiler.@footnote{Macros are also run by the
interpreter--however, it's easier to understand the point of macros
when you think about compiled code. As with everything else in this
chapter, I'll cover this in greater detail in future chapters.} When a
Lisp expression contains a call to a macro, instead of evaluating the
arguments and passing them to the function, the Lisp compiler passes
the arguments, unevaluated, to the macro code, which returns a new
Lisp expression that is then evaluated in place of the original macro
call.

I'll start with a simple, and silly, example and then show how you can
replace the @code{where} function with a @code{where} macro. Before I
can write this example macro, I need to quickly introduce one new
function: @code{REVERSE} takes a list as an argument and returns a new
list that is its reverse. So @code{(reverse '(1 2 3))} evaluates to
@code{(3 2 1)}. Now let's create a macro.

@verbatim
(defmacro backwards (expr) (reverse expr))
@end verbatim

The main syntactic difference between a function and a macro is that you
define a macro with @code{DEFMACRO} instead of @code{DEFUN}. After that
a macro definition consists of a name, just like a function, a parameter
list, and a body of expressions, both also like a function. However, a
macro has a totally different effect. You can use this macro as follows:

@verbatim
CL-USER> (backwards ("hello, world" t format))
hello, world
NIL
@end verbatim

How did that work? When the REPL started to evaluate the
@code{backwards} expression, it recognized that @code{backwards} is the
name of a macro. So it left the expression
@code{("hello, world" t format)} unevaluated, which is good because it
isn't a legal Lisp form. It then passed that list to the
@code{backwards} code. The code in @code{backwards} passed the list to
@code{REVERSE}, which returned the list
@code{(format t "hello, world")}. @code{backwards} then passed that
value back out to the REPL, which then evaluated it in place of the
original expression.

The @code{backwards} macro thus defines a new language that's a lot like
Lisp--just backward--that you can drop into anytime simply by wrapping a
backward Lisp expression in a call to the @code{backwards} macro. And,
in a compiled Lisp program, that new language is just as efficient as
normal Lisp because all the macro code--the code that generates the new
expression--runs at compile time. In other words, the compiler will
generate exactly the same code whether you write
@code{(backwards ("hello, world" t format))} or
@code{(format t "hello, world")}.

So how does that help with the code duplication in @code{where}? Well,
you can write a macro that generates exactly the code you need for each
particular call to @code{where}. Again, the best approach is to build
our code bottom up. In the hand-optimized selector function, you had an
expression of the following form for each actual field referred to in
the original call to @code{where}:

@verbatim
(equal (getf cd field) value)
@end verbatim

So let's write a function that, given the name of a field and a value,
returns such an expression. Since an expression is just a list, you
might think you could write something like this:

@verbatim
(defun make-comparison-expr (field value)    ; wrong
  (list equal (list getf cd field) value))
@end verbatim

However, there's one trick here: as you know, when Lisp sees a simple
name such as @code{field} or @code{value} other than as the first
element of a list, it assumes it's the name of a variable and looks up
its value. That's fine for @code{field} and @code{value}; it's exactly
what you want. But it will treat @code{equal}, @code{getf}, and
@code{cd} the same way, which @emph{isn't} what you want. However, you
also know how to stop Lisp from evaluating a form: stick a single
forward quote (@code{'}) in front of it. So if you write
@code{make-comparison-expr} like this, it will do what you want:

@verbatim
(defun make-comparison-expr (field value)
  (list 'equal (list 'getf 'cd field) value))
@end verbatim

You can test it out in the REPL.

@verbatim
CL-USER> (make-comparison-expr :rating 10)
(EQUAL (GETF CD :RATING) 10)
CL-USER> (make-comparison-expr :title "Give Us a Break")
(EQUAL (GETF CD :TITLE) "Give Us a Break")
@end verbatim

It turns out that there's an even better way to do it. What you'd really
like is a way to write an expression that's mostly not evaluated and
then have some way to pick out a few expressions that you @emph{do} want
evaluated. And, of course, there's just such a mechanism. A back quote
(@code{`}) before an expression stops evaluation just like a forward
quote.

@verbatim
CL-USER> `(1 2 3)
(1 2 3)
CL-USER> '(1 2 3)
(1 2 3)
@end verbatim

However, in a back-quoted expression, any subexpression that's preceded
by a comma is evaluated. Notice the effect of the comma in the second
expression:

@verbatim
`(1 2 (+ 1 2))        ==> (1 2 (+ 1 2))
`(1 2 ,(+ 1 2))       ==> (1 2 3)
@end verbatim

Using a back quote, you can write @code{make-comparison-expr} like this:

@verbatim
(defun make-comparison-expr (field value)
  `(equal (getf cd ,field) ,value))
@end verbatim

Now if you look back to the hand-optimized selector function, you can
see that the body of the function consisted of one comparison expression
per field/value pair, all wrapped in an @code{AND} expression. Assume
for the moment that you'll arrange for the arguments to the @code{where}
macro to be passed as a single list. You'll need a function that can
take the elements of such a list pairwise and collect the results of
calling @code{make-comparison-expr} on each pair. To implement that
function, you can dip into the bag of advanced Lisp tricks and pull out
the mighty and powerful @code{LOOP} macro.

@verbatim
(defun make-comparisons-list (fields)
  (loop while fields
     collecting (make-comparison-expr (pop fields) (pop fields))))
@end verbatim

A full discussion of @code{LOOP} will have to wait until Chapter 22; for
now just note that this @code{LOOP} expression does exactly what you
need: it loops while there are elements left in the @code{fields} list,
popping off two at a time, passing them to @code{make-comparison-expr},
and collecting the results to be returned at the end of the loop. The
@code{POP} macro performs the inverse operation of the @code{PUSH} macro
you used to add records to @code{*db*}.

Now you just need to wrap up the list returned by
@code{make-comparison-list} in an @code{AND} and an anonymous function,
which you can do in the @code{where} macro itself. Using a back quote to
make a template that you fill in by interpolating the value of
@code{make-comparisons-list}, it's trivial.

@verbatim
(defmacro where (&rest clauses)
  `#'(lambda (cd) (and ,@(make-comparisons-list clauses))))
@end verbatim

This macro uses a variant of @code{,} (namely, the @code{,@@}) before
the call to @code{make-comparisons-list}. The @code{,@@} "splices" the
value of the following expression--which must evaluate to a list--into
the enclosing list. You can see the difference between @code{,} and
@code{,@@} in the following two expressions:

@verbatim
`(and ,(list 1 2 3))   ==> (AND (1 2 3))
`(and ,@(list 1 2 3))  ==> (AND 1 2 3)
@end verbatim

You can also use @code{,@@} to splice into the middle of a list.

@verbatim
`(and ,@(list 1 2 3) 4) ==> (AND 1 2 3 4)
@end verbatim

The other important feature of the @code{where} macro is the use of
@code{&rest} in the argument list. Like @code{&key}, @code{&rest}
modifies the way arguments are parsed. With a @code{&rest} in its
parameter list, a function or macro can take an arbitrary number of
arguments, which are collected into a single list that becomes the value
of the variable whose name follows the @code{&rest}. So if you call
@code{where} like this:

@verbatim
(where :title "Give Us a Break" :ripped t)
@end verbatim

the variable @code{clauses} will contain the list.

@verbatim
(:title "Give Us a Break" :ripped t)
@end verbatim

This list is passed to @code{make-comparisons-list}, which returns a
list of comparison expressions. You can see exactly what code a call to
@code{where} will generate using the function @code{MACROEXPAND-1}. If
you pass @code{MACROEXPAND-1}, a form representing a macro call, it will
call the macro code with appropriate arguments and return the expansion.
So you can check out the previous @code{where} call like this:

@verbatim
CL-USER> (macroexpand-1 '(where :title "Give Us a Break" :ripped t))
#'(LAMBDA (CD)
    (AND (EQUAL (GETF CD :TITLE) "Give Us a Break")
         (EQUAL (GETF CD :RIPPED) T)))
T
@end verbatim

Looks good. Let's try it for real.

@verbatim
CL-USER> (select (where :title "Give Us a Break" :ripped t))
((:TITLE "Give Us a Break" :ARTIST "Limpopo" :RATING 10 :RIPPED T))
@end verbatim

It works. And the @code{where} macro with its two helper functions is
actually one line shorter than the old @code{where} function. And it's
more general in that it's no longer tied to the specific fields in our
CD records.

@node Wrapping Up The Database
@section Wrapping Up
@anchor{#wrapping-up-cddb}
Now, an interesting thing has happened. You removed duplication and made
the code more efficient @emph{and} more general at the same time. That's
often the way it goes with a well-chosen macro. This makes sense because
a macro is just another mechanism for creating abstractions--abstraction
at the syntactic level, and abstractions are by definition more concise
ways of expressing underlying generalities. Now the only code in the
mini-database that's specific to CDs and the fields in them is in the
@code{make-cd}, @code{prompt-for-cd}, and @code{add-cd} functions. In
fact, our new @code{where} macro would work with any plist-based
database.

However, this is still far from being a complete database. You can
probably think of plenty of features to add, such as supporting multiple
tables or more elaborate queries. In Chapter 27 we'll build an MP3
database that incorporates some of those features.

The point of this chapter was to give you a quick introduction to just a
handful of Lisp's features and show how they're used to write code
that's a bit more interesting than "hello, world." In the next chapter
we'll begin a more systematic overview of Lisp.

@node Syntax and Semantics
@chapter Syntax and Semantics
@anchor{#syntax-and-semantics}
After that whirlwind tour, we'll settle down for a few chapters to take
a more systematic look at the features you've used so far. I'll start
with an overview of the basic elements of Lisp's syntax and semantics,
which means, of course, that I must first address that burning question...

@menu
* What's with All the Parentheses?::
* Breaking Open the Black Box::
* S-expressions::
* S-expressions As Lisp Forms::
* Function Calls::
* Special Operators::
* Macros::
* Truth Falsehood and Equality::
* Formatting Lisp Code::
@end menu

@node What's with All the Parentheses?
@section What's with All the Parentheses?
@anchor{#whats-with-all-the-parentheses}
Lisp's syntax is quite a bit different from the syntax of languages
descended from Algol. The two most immediately obvious characteristics
are the extensive use of parentheses and prefix notation. For whatever
reason, a lot of folks are put off by this syntax. Lisp's detractors
tend to describe the syntax as "weird" and "annoying." Lisp, they say,
must stand for Lots of Irritating Superfluous Parentheses. Lisp folks,
on the other hand, tend to consider Lisp's syntax one of its great
virtues. How is it that what's so off-putting to one group is a source
of delight to another?

I can't really make the complete case for Lisp's syntax until I've
explained Lisp's macros a bit more thoroughly, but I can start with an
historical tidbit that suggests it may be worth keeping an open mind:
when John McCarthy first invented Lisp, he intended to implement a
more Algol-like syntax, which he called @emph{M-expressions}. However,
he never got around to it. He explained why not in his article
"History of
Lisp."@footnote{@code{http://www-formal.stanford.edu/jmc/history/lisp/node3.html}}

@quotation
The project of defining M-expressions precisely and compiling them or at
least translating them into S-expressions was neither finalized nor
explicitly abandoned. It just receded into the indefinite future, and a
new generation of programmers appeared who preferred [S-expressions] to
any FORTRAN-like or ALGOL-like notation that could be devised.
@end quotation
In other words, the people who have actually used Lisp over the past 45
years have @emph{liked} the syntax and have found that it makes the
language more powerful. In the next few chapters, you'll begin to see
why.

@node Breaking Open the Black Box
@section Breaking Open the Black Box
@anchor{#breaking-open-the-black-box}
Before we look at the specifics of Lisp's syntax and semantics, it's
worth taking a moment to look at how they're defined and how this
differs from many other languages.

In most programming languages, the language processor--whether an
interpreter or a compiler--operates as a black box: you shove a sequence
of characters representing the text of a program into the black box, and
it--depending on whether it's an interpreter or a compiler--either
executes the behaviors indicated or produces a compiled version of the
program that will execute the behaviors when it's run.

Inside the black box, of course, language processors are usually divided
into subsystems that are each responsible for one part of the task of
translating a program text into behavior or object code. A typical
division is to split the processor into three phases, each of which
feeds into the next: a lexical analyzer breaks up the stream of
characters into tokens and feeds them to a parser that builds a tree
representing the expressions in the program, according to the language's
grammar. This tree--called an @emph{abstract syntax tree}--is then fed
to an evaluator that either interprets it directly or compiles it into
some other language such as machine code. Because the language processor
is a black box, the data structures used by the processor, such as the
tokens and abstract syntax trees, are of interest only to the language
implementer.

In Common Lisp things are sliced up a bit differently, with
consequences for both the implementer and for how the language is
defined. Instead of a single black box that goes from text to program
behavior in one step, Common Lisp defines @emph{two} black boxes, one
that translates text into Lisp objects and another that implements the
semantics of the language in terms of those objects. The first box is
called the @emph{reader}, and the second is called the
@emph{evaluator}.@footnote{Lisp implementers, like implementers of any
language, have many ways they can implement an evaluator, ranging from
a "pure" interpreter that interprets the objects given to the
evaluator directly to a compiler that translates the objects into
machine code that it then runs. In the middle are implementations that
compile the input into an intermediate form such as bytecodes for a
virtual machine and then interprets the bytecodes. Most Common Lisp
implementations these days use some form of compilation even when
evaluating code at run time.}

Each black box defines one level of syntax. The reader defines how
strings of characters can be translated into Lisp objects called
@emph{s-expressions}.@footnote{Sometimes the phrase
@emph{s-expression} refers to the textual representation and sometimes
to the objects that result from reading the textual
representation. Usually either it's clear from context which is meant
or the distinction isn't that important.} Since the s-expression
syntax includes syntax for lists of arbitrary objects, including other
lists, s-expressions can represent arbitrary tree expressions, much
like the abstract syntax tree generated by the parsers for non-Lisp
languages.

The evaluator then defines a syntax of Lisp @emph{forms} that can be
built out of s-expressions. Not all s-expressions are legal Lisp forms
any more than all sequences of characters are legal s-expressions. For
instance, both @code{(foo 1 2)} and @code{("foo" 1 2)} are
s-expressions, but only the former can be a Lisp form since a list that
starts with a string has no meaning as a Lisp form.

This split of the black box has a couple of consequences. One is that
you can use s-expressions, as you saw in Chapter 3, as an
externalizable data format for data other than source code, using
@code{READ} to read it and @code{PRINT} to print it.@footnote{Not all
Lisp objects can be written out in a way that can be read back in. But
anything you can @code{READ} can be printed back out "readably" with
@code{PRINT}.} The other consequence is that since the semantics of
the language are defined in terms of trees of objects rather than
strings of characters, it's easier to generate code within the
language than it would be if you had to generate code as
text. Generating code completely from scratch is only marginally
easier--building up lists vs. building up strings is about the same
amount of work. The real win, however, is that you can generate code
by manipulating existing data. This is the basis for Lisp's macros,
which I'll discuss in much more detail in future chapters. For now
I'll focus on the two levels of syntax defined by Common Lisp: the
syntax of s-expressions understood by the reader and the syntax of
Lisp forms understood by the evaluator.

@node S-expressions
@section S-expressions
@anchor{#s-expressions} The basic elements of s-expressions are
@emph{lists} and @emph{atoms}.  Lists are delimited by parentheses and
can contain any number of whitespace-separated elements. Atoms are
everything else.@footnote{The empty list, @code{()}, which can also be
written @code{NIL}, is both an atom and a list.} The elements of lists
are themselves s-expressions (in other words, atoms or nested
lists). Comments--which aren't, technically speaking,
s-expressions--start with a semicolon, extend to the end of a line,
and are treated essentially like whitespace.

And that's pretty much it. Since lists are syntactically so trivial, the
only remaining syntactic rules you need to know are those governing the
form of different kinds of atoms. In this section I'll describe the
rules for the most commonly used kinds of atoms: numbers, strings, and
names. After that, I'll cover how s-expressions composed of these
elements can be evaluated as Lisp forms.

Numbers are fairly straightforward: any sequence of digits--possibly
prefaced with a sign (@code{+} or @code{-}), containing a decimal point
(@code{.}) or a solidus (@code{/}), or ending with an exponent
marker--is read as a number. For example:

@verbatim
123       ; the integer one hundred twenty-three
3/7       ; the ratio three-sevenths
1.0       ; the floating-point number one in default precision
1.0e0     ; another way to write the same floating-point number
1.0d0     ; the floating-point number one in "double" precision
1.0e-4    ; the floating-point equivalent to one-ten-thousandth
+42       ; the integer forty-two
-42       ; the integer negative forty-two
-1/4      ; the ratio negative one-quarter
-2/8      ; another way to write negative one-quarter
246/2     ; another way to write the integer one hundred twenty-three
@end verbatim

These different forms represent different kinds of numbers: integers,
ratios, and floating point. Lisp also supports complex numbers, which
have their own notation and which I'll discuss in Chapter 10.

As some of these examples suggest, you can notate the same number in
many ways. But regardless of how you write them, all rationals--integers
and ratios--are represented internally in "simplified" form. In other
words, the objects that represent -2/8 or 246/2 aren't distinct from the
objects that represent -1/4 and 123. Similarly, @code{1.0} and
@code{1.0e0} are just different ways of writing the same number. On the
other hand, @code{1.0}, @code{1.0d0}, and @code{1} can all denote
different objects because the different floating-point representations
and integers are different types. We'll save the details about the
characteristics of different kinds of numbers for Chapter 10.

Strings literals, as you saw in the previous chapter, are enclosed in
double quotes. Within a string a backslash (@code{\}) escapes the next
character, causing it to be included in the string regardless of what it
is. The only two characters that @emph{must} be escaped within a string
are double quotes and the backslash itself. All other characters can be
included in a string literal without escaping, regardless of their
meaning outside a string. Some example string literals are as follows:

@verbatim
"foo"     ; the string containing the characters f, o, and o.
"fo\o"    ; the same string
"fo\\o"   ; the string containing the characters f, o, \, and o.
"fo\"o"   ; the string containing the characters f, o, ", and o.
@end verbatim

Names used in Lisp programs, such as @code{FORMAT} and
@code{hello-world}, and @code{*db*} are represented by objects called
@emph{symbols}. The reader knows nothing about how a given name is
going to be used--whether it's the name of a variable, a function, or
something else. It just reads a sequence of characters and builds an
object to represent the name.@footnote{In fact, as you'll see later,
names aren't intrinsically tied to any one kind of thing. You can use
the same name, depending on context, to refer to both a variable and a
function, not to mention several other possibilities.} Almost any
character can appear in a name. Whitespace characters can't, though,
because the elements of lists are separated by whitespace. Digits can
appear in names as long as the name as a whole can't be interpreted as
a number.  Similarly, names can contain periods, but the reader can't
read a name that consists only of periods. Ten characters that serve
other syntactic purposes can't appear in names: open and close
parentheses, double and single quotes, backtick, comma, colon,
semicolon, backslash, and vertical bar. And even those characters
@emph{can}, if you're willing to escape them by preceding the
character to be escaped with a backslash or by surrounding the part of
the name containing characters that need escaping with vertical bars.

Two important characteristics of the way the reader translates names
to symbol objects have to do with how it treats the case of letters in
names and how it ensures that the same name is always read as the same
symbol. While reading names, the reader converts all unescaped
characters in a name to their uppercase equivalents. Thus, the reader
will read @code{foo}, @code{Foo}, and @code{FOO} as the same symbol:
@code{FOO}. However, @code{\f\o\o} and @code{|foo|} will both be read
as @code{foo}, which is a different object than the symbol
@code{FOO}. This is why when you define a function at the REPL and it
prints the name of the function, it's been converted to
uppercase. Standard style, these days, is to write code in all
lowercase and let the reader change names to uppercase.@footnote{The
case-converting behavior of the reader can, in fact, be customized,
but understanding when and how to change it requires a much deeper
discussion of the relation between names, symbols, and other program
elements than I'm ready to get into just yet.}

To ensure that the same textual name is always read as the same
symbol, the reader @emph{interns} symbols--after it has read the name
and converted it to all uppercase, the reader looks in a table called
a @emph{package} for an existing symbol with the same name. If it
can't find one, it creates a new symbol and adds it to the
table. Otherwise, it returns the symbol already in the table. Thus,
anywhere the same name appears in any s-expression, the same object
will be used to represent it.@footnote{I'll discuss the relation
between symbols and packages in more detail in Chapter 21.}

Because names can contain many more characters in Lisp than they can in
Algol-derived languages, certain naming conventions are distinct to
Lisp, such as the use of hyphenated names like @code{hello-world}.
Another important convention is that global variables are given names
that start and end with @code{*}. Similarly, constants are given names
starting and ending in @code{+}. And some programmers will name
particularly low-level functions with names that start with @code{%} or
even @code{%%}. The names defined in the language standard use only the
alphabetic characters (A-Z) plus @code{*}, @code{+}, @code{-}, @code{/},
@code{1}, @code{2}, @code{<}, @code{=}, @code{>}, and @code{&}.

The syntax for lists, numbers, strings, and symbols can describe a good
percentage of Lisp programs. Other rules describe notations for literal
vectors, individual characters, and arrays, which I'll cover when I talk
about the associated data types in Chapters 10 and 11. For now the key
thing to understand is how you can combine numbers, strings, and symbols
with parentheses-delimited lists to build s-expressions representing
arbitrary trees of objects. Some simple examples look like this:

@verbatim
x             ; the symbol X
()            ; the empty list
(1 2 3)       ; a list of three numbers
("foo" "bar") ; a list of two strings
(x y z)       ; a list of three symbols
(x 1 "foo")   ; a list of a symbol, a number, and a string
(+ (* 2 3) 4) ; a list of a symbol, a list, and a number.
@end verbatim

An only slightly more complex example is the following four-item list
that contains two symbols, the empty list, and another list, itself
containing two symbols and a string:

@verbatim
(defun hello-world ()
  (format t "hello, world"))
@end verbatim

@node S-expressions As Lisp Forms
@section S-expressions As Lisp Forms
@anchor{#s-expressions-as-lisp-forms} After the reader has translated
a bunch of text into s-expressions, the s-expressions can then be
evaluated as Lisp code. Or some of them can--not every s-expressions
that the reader can read can necessarily be evaluated as Lisp
code. Common Lisp's evaluation rule defines a second level of syntax
that determines which s-expressions can be treated as Lisp
forms.@footnote{Of course, other levels of correctness exist in Lisp,
as in other languages. For instance, the s-expression that results
from reading @code{(foo 1 2)} is syntactically well-formed but can be
evaluated only if @code{foo} is the name of a function or macro.} The
syntactic rules at this level are quite simple. Any atom--any nonlist
or the empty list--is a legal Lisp form as is any list that has a
symbol as its first element.@footnote{One other rarely used kind of
Lisp form is a list whose first element is a @emph{lambda form}. I'll
discuss this kind of form in Chapter 5.}

Of course, the interesting thing about Lisp forms isn't their syntax but
how they're evaluated. For purposes of discussion, you can think of the
evaluator as a function that takes as an argument a syntactically
well-formed Lisp form and returns a value, which we can call the
@emph{value} of the form. Of course, when the evaluator is a compiler,
this is a bit of a simplification--in that case, the evaluator is given
an expression and generates code that will compute the appropriate value
when it's run. But this simplification lets me describe the semantics of
Common Lisp in terms of how the different kinds of Lisp forms are
evaluated by this notional function.

The simplest Lisp forms, atoms, can be divided into two categories:
symbols and everything else. A symbol, evaluated as a form, is
considered the name of a variable and evaluates to the current value
of the variable.@footnote{One other possibility exists--it's possible
to define @emph{symbol macros} that are evaluated slightly
differently. We won't worry about them.} I'll discuss in Chapter 6 how
variables get their values in the first place. You should also note
that certain "variables" are that old oxymoron of programming:
"constant variables." For instance, the symbol @code{PI} names a
constant variable whose value is the best possible floating-point
approximation to the mathematical constant @emph{pi}.

All other atoms--numbers and strings are the kinds you've seen so
far--are @emph{self-evaluating} objects. This means when such an
expression is passed to the notional evaluation function, it's simply
returned. You saw examples of self-evaluating objects in Chapter 2 when
you typed @code{10} and @code{"hello, world"} at the REPL.

It's also possible for symbols to be self-evaluating in the sense that
the variables they name can be assigned the value of the symbol itself.
Two important constants that are defined this way are @code{T} and
@code{NIL}, the canonical true and false values. I'll discuss their role
as booleans in the section "Truth, Falsehood, and Equality."

Another class of self-evaluating symbols are the @emph{keyword}
symbols--symbols whose names start with @code{:}. When the reader
interns such a name, it automatically defines a constant variable with
the name and with the symbol as the value.

Things get more interesting when we consider how lists are evaluated.
All legal list forms start with a symbol, but three kinds of list
forms are evaluated in three quite different ways. To determine what
kind of form a given list is, the evaluator must determine whether the
symbol that starts the list is the name of a function, a macro, or a
special operator. If the symbol hasn't been defined yet--as may be the
case if you're compiling code that contains references to functions
that will be defined later--it's assumed to be a function
name.@footnote{In Common Lisp a symbol can name both an
operator--function, macro, or special operator--and a variable. This
is one of the major differences between Common Lisp and Scheme. The
difference is sometimes described as Common Lisp being a Lisp-2 vs.
Scheme being a Lisp-1--a Lisp-2 has two namespaces, one for operators
and one for variables, but a Lisp-1 uses a single namespace. Both
choices have advantages, and partisans can debate endlessly which is
better.}  I'll refer to the three kinds of forms as @emph{function
call forms}, @emph{macro forms}, and @emph{special forms}.

@node Function Calls
@section Function Calls
@anchor{#function-calls}
The evaluation rule for function call forms is simple: evaluate the
remaining elements of the list as Lisp forms and pass the resulting
values to the named function. This rule obviously places some additional
syntactic constraints on a function call form: all the elements of the
list after the first must themselves be well-formed Lisp forms. In other
words, the basic syntax of a function call form is as follows, where
each of the arguments is itself a Lisp form:

@verbatim
(function-name argument*)
@end verbatim

Thus, the following expression is evaluated by first evaluating
@code{1}, then evaluating @code{2}, and then passing the resulting
values to the @code{+} function, which returns 3:

@verbatim
(+ 1 2)
@end verbatim

A more complex expression such as the following is evaluated in similar
fashion except that evaluating the arguments @code{(+ 1 2)} and
@code{(- 3 4)} entails first evaluating their arguments and applying the
appropriate functions to them:

@verbatim
(* (+ 1 2) (- 3 4))
@end verbatim

Eventually, the values 3 and -1 are passed to the @code{*} function,
which returns -3.

As these examples show, functions are used for many of the things that
require special syntax in other languages. This helps keep Lisp's syntax
regular.

@node Special Operators
@section Special Operators
@anchor{#special-operators}
That said, not all operations can be defined as functions. Because all
the arguments to a function are evaluated before the function is called,
there's no way to write a function that behaves like the @code{IF}
operator you used in Chapter 3. To see why, consider this form:

@verbatim
(if x (format t "yes") (format t "no"))
@end verbatim

If @code{IF} were a function, the evaluator would evaluate the argument
expressions from left to right. The symbol @code{x} would be evaluated
as a variable yielding some value; then @code{(format t "yes")} would be
evaluated as a function call, yielding @code{NIL} after printing "yes"
to standard output. Then @code{(format t "no")} would be evaluated,
printing "no" and also yielding @code{NIL}. Only after all three
expressions were evaluated would the resulting values be passed to
@code{IF}, too late for it to control which of the two @code{FORMAT}
expressions gets evaluated.

To solve this problem, Common Lisp defines a couple dozen so-called
special operators, @code{IF} being one, that do things that functions
can't do. There are 25 in all, but only a small handful are used
directly in day-to-day programming.@footnote{The others provide
useful, but somewhat esoteric, features. I'll discuss them as the
features they support come up.}

When the first element of a list is a symbol naming a special operator,
the rest of the expressions are evaluated according to the rule for that
operator.

The rule for @code{IF} is pretty easy: evaluate the first expression. If
it evaluates to non-@code{NIL}, then evaluate the next expression and
return its value. Otherwise, return the value of evaluating the third
expression or @code{NIL} if the third expression is omitted. In other
words, the basic form of an @code{IF} expression is as follows:

@verbatim
(if test-form then-form [ else-form ])
@end verbatim

The @emph{test-form} will always be evaluated and then one or the other
of the @emph{then-form} or @emph{else-form}.

An even simpler special operator is @code{QUOTE}, which takes a single
expression as its "argument" and simply returns it, unevaluated. For
instance, the following evaluates to the list @code{(+ 1 2)}, not the
value 3:

@verbatim
(quote (+ 1 2))
@end verbatim

There's nothing special about this list; you can manipulate it just
like any list you could create with the @code{LIST}
function.@footnote{Well, one difference exists--literal objects such
as quoted lists, but also including double-quoted strings, literal
arrays, and vectors (whose syntax you'll see later), must not be
modified.  Consequently, any lists you plan to manipulate you should
create with @code{LIST}.}

@code{QUOTE} is used commonly enough that a special syntax for it is
built into the reader. Instead of writing the following:

@verbatim
(quote (+ 1 2))
@end verbatim

you can write this:

@verbatim
'(+ 1 2)
@end verbatim

This syntax is a small extension of the s-expression syntax understood
by the reader. From the point of view of the evaluator, both those
expressions will look the same: a list whose first element is the
symbol @code{QUOTE} and whose second element is the list @code{(+ 1
2)}.@footnote{This syntax is an example of a @emph{reader macro}.
Reader macros modify the syntax the reader uses to translate text into
Lisp objects. It is, in fact, possible to define your own reader
macros, but that's a rarely used facility of the language. When most
Lispers talk about "extending the syntax" of the language, they're
talking about regular macros, as I'll discuss in a moment.}

In general, the special operators implement features of the language
that require some special processing by the evaluator. For instance,
several special operators manipulate the environment in which other
forms will be evaluated. One of these, which I'll discuss in detail in
Chapter 6, is @code{LET}, which is used to create new variable bindings.
The following form evaluates to 10 because the second @code{x} is
evaluated in an environment where it's the name of a variable
established by the @code{LET} with the value 10:

@verbatim
(let ((x 10)) x)
@end verbatim

@node Macros
@section Macros
@anchor{#macros}
While special operators extend the syntax of Common Lisp beyond what can
be expressed with just function calls, the set of special operators is
fixed by the language standard. Macros, on the other hand, give users of
the language a way to extend its syntax. As you saw in Chapter 3, a
macro is a function that takes s-expressions as arguments and returns a
Lisp form that's then evaluated in place of the macro form. The
evaluation of a macro form proceeds in two phases: First, the elements
of the macro form are passed, unevaluated, to the macro function.
Second, the form returned by the macro function--called its
@emph{expansion--}is evaluated according to the normal evaluation rules.

It's important to keep the two phases of evaluating a macro form clear
in your mind. It's easy to lose track when you're typing expressions at
the REPL because the two phases happen one after another and the value
of the second phase is immediately returned. But when Lisp code is
compiled, the two phases happen at completely different times, so it's
important to keep clear what's happening when. For instance, when you
compile a whole file of source code with the function
@code{COMPILE-FILE}, all the macro forms in the file are recursively
expanded until the code consists of nothing but function call forms and
special forms. This macroless code is then compiled into a FASL file
that the @code{LOAD} function knows how to load. The compiled code,
however, isn't executed until the file is loaded. Because macros
generate their expansion at compile time, they can do relatively large
amounts of work generating their expansion without having to pay for it
when the file is loaded or the functions defined in the file are called.

Since the evaluator doesn't evaluate the elements of the macro form
before passing them to the macro function, they don't need to be
well-formed Lisp forms. Each macro assigns a meaning to the
s-expressions in the macro form by virtue of how it uses them to
generate its expansion. In other words, each macro defines its own local
syntax. For instance, the @code{backwards} macro from Chapter 3 defines
a syntax in which an expression is a legal @code{backwards} form if it's
a list that's the reverse of a legal Lisp form.

I'll talk quite a bit more about macros throughout this book. For now
the important thing for you to realize is that macros--while
syntactically similar to function calls--serve quite a different
purpose, providing a hook into the compiler.@footnote{People without
experience using Lisp's macros or, worse yet, bearing the scars of C
preprocessor-inflicted wounds, tend to get nervous when they realize
that macro calls look like regular function calls. This turns out not
to be a problem in practice for several reasons. One is that macro
forms are usually formatted differently than function calls. For
instance, you write the following:

@verbatim
(dolist (x foo)
  (print x))
@end verbatim

rather than this:

@verbatim
(dolist (x foo) (print x))
@end verbatim

or

@verbatim
(dolist (x foo)
       (print x))
@end verbatim

the way you would if @code{DOLIST} was a function. A good Lisp
environment will automatically format macro calls correctly, even for
user-defined macros.

And even if a @code{DOLIST} form was written on a single line, there
are several clues that it's a macro: For one, the expression @code{(x
foo)} is meaningful by itself only if @code{x} is the name of a
function or macro. Combine that with the later occurrence of @code{x}
as a variable, and it's pretty suggestive that @code{DOLIST} is a
macro that's creating a binding for a variable named @code{x}. Naming
conventions also help--looping constructs, which are invariably
macros--are frequently given names starting with @emph{do}.}

@node Truth Falsehood and Equality
@section Truth, Falsehood, and Equality
@anchor{#truth-falsehood-and-equality} Two last bits of basic
knowledge you need to get under your belt are Common Lisp's notion of
truth and falsehood and what it means for two Lisp objects to be
"equal." Truth and falsehood are--in this realm--straightforward: the
symbol @code{NIL} is the only false value, and everything else is
true. The symbol @code{T} is the canonical true value and can be used
when you need to return a non-@code{NIL} value and don't have anything
else handy. The only tricky thing about @code{NIL} is that it's the
only object that's both an atom and a list: in addition to falsehood,
it's also used to represent the empty list.@footnote{Using the empty
list as false is a reflection of Lisp's heritage as a list-processing
language much as the use of the integer 0 as false in C is a
reflection of its heritage as a bit-twiddling language. Not all Lisps
handle boolean values the same way. Another of the many subtle
differences upon which a good Common Lisp vs. Scheme flame war can
rage for days is Scheme's use of a distinct false value @code{#f},
which isn't the same value as either the symbol @code{nil} or the
empty list, which are also distinct from each other.} This equivalence
between @code{NIL} and the empty list is built into the reader: if the
reader sees @code{()}, it reads it as the symbol @code{NIL}. They're
completely interchangeable.  And because @code{NIL}, as I mentioned
previously, is the name of a constant variable with the symbol
@code{NIL} as its value, the expressions @code{nil}, @code{()},
@code{'nil}, and @code{'()} all evaluate to the same thing--the
unquoted forms are evaluated as a reference to the constant variable
whose value is the symbol @code{NIL}, but in the quoted forms the
@code{QUOTE} special operator evaluates to the symbol directly. For
the same reason, both @code{t} and @code{'t} will evaluate to the same
thing: the symbol @code{T}.

Using phrases such as "the same thing" of course begs the question of
what it means for two values to be "the same." As you'll see in future
chapters, Common Lisp provides a number of type-specific equality
predicates: @code{=} is used to compare numbers, @code{CHAR=} to compare
characters, and so on. In this section I'll discuss the four "generic"
equality predicates--functions that can be passed any two Lisp objects
and will return true if they're equivalent and false otherwise. They
are, in order of discrimination, @code{EQ}, @code{EQL}, @code{EQUAL},
and @code{EQUALP}.

@code{EQ} tests for "object identity"--two objects are @code{EQ} if
they're identical. Unfortunately, the object identity of numbers and
characters depends on how those data types are implemented in a
particular Lisp. Thus, @code{EQ} may consider two numbers or two
characters with the same value to be equivalent, or it may not.
Implementations have enough leeway that the expression @code{(eq 3 3)}
can legally evaluate to either true or false. More to the point,
@code{(eq x x)} can evaluate to either true or false if the value of
@code{x} happens to be a number or character.

Thus, you should never use @code{EQ} to compare values that may be
numbers or characters. It may seem to work in a predictable way for
certain values in a particular implementation, but you have no guarantee
that it will work the same way if you switch implementations. And
switching implementations may mean simply upgrading your implementation
to a new version--if your Lisp implementer changes how they represent
numbers or characters, the behavior of @code{EQ} could very well change
as well.

Thus, Common Lisp defines @code{EQL} to behave like @code{EQ} except
that it also is guaranteed to consider two objects of the same class
representing the same numeric or character value to be equivalent. Thus,
@code{(eql 1 1)} is guaranteed to be true. And @code{(eql 1 1.0)} is
guaranteed to be false since the integer value 1 and the floating-point
value are instances of different classes.

There are two schools of thought about when to use @code{EQ} and when to
use @code{EQL}: The "use @code{EQ} when possible" camp argues you should
use @code{EQ} when you know you aren't going to be com-paring numbers or
characters because (a) it's a way to indicate that you aren't going to
be comparing numbers or characters and (b) it will be marginally more
efficient since @code{EQ} doesn't have to check whether its arguments
are numbers or characters.

The "always use @code{EQL}" camp says you should never use @code{EQ}
because (a) the potential gain in clarity is lost because every time
someone reading your code--including you--sees an @code{EQ}, they have
to stop and check whether it's being used correctly (in other words,
that it's never going to be called upon to compare numbers or
characters) and (b) that the efficiency difference between @code{EQ} and
@code{EQL} is in the noise compared to real performance bottlenecks.

The code in this book is written in the "always use @code{EQL}"
style.@footnote{Even the language standard is a bit ambivalent about
which of @code{EQ} or @code{EQL} should be preferred. @emph{Object
identity} is defined by @code{EQ}, but the standard defines the phrase
@emph{the} @emph{same} when talking about objects to mean @code{EQL}
unless another predicate is explicitly mentioned. Thus, if you want to
be 100 percent technically correct, you can say that @code{(- 3 2)}
and @code{(- 4 3)} evaluate to "the same" object but not that they
evaluate to "identical" objects. This is, admittedly, a bit of an
@emph{angels-on-pinheads} kind of issue.}

The other two equality predicates, @code{EQUAL} and @code{EQUALP}, are
general in the sense that they can operate on all types of objects, but
they're much less fundamental than @code{EQ} or @code{EQL}. They each
define a slightly less discriminating notion of equivalence than
@code{EQL}, allowing different objects to be considered equivalent.
There's nothing special about the particular notions of equivalence
these functions implement except that they've been found to be handy by
Lisp programmers in the past. If these predicates don't suit your needs,
you can always define your own predicate function that compares
different types of objects in the way you need.

@code{EQUAL} loosens the discrimination of @code{EQL} to consider lists
equivalent if they have the same structure and contents, recursively,
according to @code{EQUAL}. @code{EQUAL} also considers strings
equivalent if they contain the same characters. It also defines a looser
definition of equivalence than @code{EQL} for bit vectors and pathnames,
two data types I'll discuss in future chapters. For all other types, it
falls back on @code{EQL}.

@code{EQUALP} is similar to @code{EQUAL} except it's even less
discriminating. It considers two strings equivalent if they contain the
same characters, ignoring differences in case. It also considers two
characters equivalent if they differ only in case. Numbers are
equivalent under @code{EQUALP} if they represent the same mathematical
value. Thus, @code{(equalp 1 1.0)} is true. Lists with @code{EQUALP}
elements are @code{EQUALP}; likewise, arrays with @code{EQUALP} elements
are @code{EQUALP}. As with @code{EQUAL}, there are a few other data
types that I haven't covered yet for which @code{EQUALP} can consider
two objects equivalent that neither @code{EQL} nor @code{EQUAL} will.
For all other data types, @code{EQUALP} falls back on @code{EQL}.

@node Formatting Lisp Code
@section Formatting Lisp Code
@anchor{#formatting-lisp-code}
While code formatting is, strictly speaking, neither a syntactic nor a
semantic matter, proper formatting is important to reading and writing
code fluently and idiomatically. The key to formatting Lisp code is to
indent it properly. The indentation should reflect the structure of the
code so that you don't need to count parentheses to see what goes with
what. In general, each new level of nesting gets indented a bit more,
and, if line breaks are necessary, items at the same level of nesting
are lined up. Thus, a function call that needs to be broken up across
multiple lines might be written like this:

@verbatim
(some-function arg-with-a-long-name
               another-arg-with-an-even-longer-name)
@end verbatim

Macro and special forms that implement control constructs are typically
indented a little differently: the "body" elements are indented two
spaces relative to the opening parenthesis of the form. Thus:

@verbatim
(defun print-list (list)
  (dolist (i list)
    (format t "item: ~a~%" i)))
@end verbatim

However, you don't need to worry too much about these rules because a
proper Lisp environment such as SLIME will take care of it for you. In
fact, one of the advantages of Lisp's regular syntax is that it's fairly
easy for software such as editors to know how to indent it. Since the
indentation is supposed to reflect the structure of the code and the
structure is marked by parentheses, it's easy to let the editor indent
your code for you.

In SLIME, hitting Tab at the beginning of each line will cause it to be
indented appropriately, or you can re-indent a whole expression by
positioning the cursor on the opening parenthesis and typing
@code{C-M-q}. Or you can re-indent the whole body of a function from
anywhere within it by typing @code{C-c M-q}.

Indeed, experienced Lisp programmers tend to rely on their editor
handling indenting automatically, not just to make their code look nice
but to detect typos: once you get used to how code is supposed to be
indented, a misplaced parenthesis will be instantly recognizable by the
weird indentation your editor gives you. For example, suppose you were
writing a function that was supposed to look like this:

@verbatim
(defun foo ()
  (if (test)
    (do-one-thing)
    (do-another-thing)))
@end verbatim

Now suppose you accidentally left off the closing parenthesis after
@code{test}. Because you don't bother counting parentheses, you quite
likely would have added an extra parenthesis at the end of the
@code{DEFUN} form, giving you this code:

@verbatim
(defun foo ()
  (if (test
    (do-one-thing)
    (do-another-thing))))
@end verbatim

However, if you had been indenting by hitting Tab at the beginning of
each line, you wouldn't have code like that. Instead you'd have this:

@verbatim
(defun foo ()
  (if (test
       (do-one-thing)
       (do-another-thing))))
@end verbatim

Seeing the then and else clauses indented way out under the condition
rather than just indented slightly relative to the @code{IF} shows you
immediately that something is awry.

Another important formatting rule is that closing parentheses are always
put on the same line as the last element of the list they're closing.
That is, don't write this:

@verbatim
(defun foo ()
  (dotimes (i 10)
    (format t "~d. hello~%" i)
  )
)
@end verbatim

but instead write this:

@verbatim
(defun foo ()
  (dotimes (i 10)
    (format t "~d. hello~%" i)))
@end verbatim

The string of @code{)))}s at the end may seem forbidding, but as long
your code is properly indented the parentheses should fade away--no need
to give them undue prominence by spreading them across several lines.

Finally, comments should be prefaced with one to four semicolons
depending on the scope of the comment as follows:

@verbatim
;;;; Four semicolons are used for a file header comment.

;;; A comment with three semicolons will usually be a paragraph
;;; comment that applies to a large section of code that follows,

(defun foo (x)
  (dotimes (i x)
    ;; Two semicolons indicate this comment applies to the code
    ;; that follows. Note that this comment is indented the same
    ;; as the code that follows.
    (some-function-call)
    (another i)              ; this comment applies to this line only
    (and-another)            ; and this is for this line
    (baz)))
@end verbatim

Now you're ready to start looking in greater detail at the major
building blocks of Lisp programs, functions, variables, and macros. Up
next: functions.

@node Functions
@chapter Functions
@anchor{#functions}
After the rules of syntax and semantics, the three most basic components
of all Lisp programs are functions, variables and macros. You used all
three while building the database in Chapter 3, but I glossed over a lot
of the details of how they work and how to best use them. I'll devote
the next few chapters to these three topics, starting with functions,
which--like their counterparts in other languages--provide the basic
mechanism for abstracting, well, functionality.

The bulk of Lisp itself consists of functions. More than three quarters
of the names defined in the language standard name functions. All the
built-in data types are defined purely in terms of what functions
operate on them. Even Lisp's powerful object system is built upon a
conceptual extension to functions, generic functions, which I'll cover
in Chapter 16.

And, despite the importance of macros to The Lisp Way, in the end all
real functionality is provided by functions. Macros run at compile
time, so the code they generate--the code that will actually make up
the program after all the macros are expanded--will consist entirely
of calls to functions and special operators. Not to mention, macros
themselves are also functions, albeit functions that are used to
generate code rather than to perform the actions of the
program.@footnote{Despite the importance of functions in Common Lisp,
it isn't really accurate to describe it as a @emph{functional}
language.  It's true some of Common Lisp's features, such as its list
manipulation functions, are designed to be used in a body-form* style
and that Lisp has a prominent place in the history of functional
programming--McCarthy introduced many ideas that are now considered
important in functional programming--but Common Lisp was intentionally
designed to support many different styles of programming. In the Lisp
family, Scheme is the nearest thing to a "pure" functional language,
and even it has several features that disqualify it from absolute
purity compared to languages such as Haskell and ML.}

@menu
* Defining New Functions::
* Function Parameter Lists::
* Optional Parameters::
* Rest Parameters::
* Keyword Parameters::
* Mixing Different Parameter Types::
* Function Return Values::
* Functions As Data aka Higher-Order Functions::
* Anonymous Functions::
@end menu

@node Defining New Functions
@section Defining New Functions
@anchor{#defining-new-functions}
Normally functions are defined using the @code{DEFUN} macro. The basic
skeleton of a @code{DEFUN} looks like this:

@verbatim
(defun name (parameter*)
  "Optional documentation string."
  body-form*)
@end verbatim

Any symbol can be used as a function name.@footnote{Well, almost any
symbol. It's undefined what happens if you use any of the names
defined in the language standard as a name for one of your own
functions. However, as you'll see in Chapter 21, the Lisp package
system allows you to create names in different namespaces, so this
isn't really an issue.} Usually function names contain only alphabetic
characters and hyphens, but other characters are allowed and are used
in certain naming conventions. For instance, functions that convert
one kind of value to another sometimes use @code{->} in the name. For
example, a function to convert strings to widgets might be called
@code{string->widget}. The most important naming convention is the one
mentioned in Chapter 2, which is that you construct compound names
with hyphens rather than underscores or inner caps. Thus,
@code{frob-widget} is better Lisp style than either @code{frob_widget}
or @code{frobWidget}.

A function's parameter list defines the variables that will be used to
hold the arguments passed to the function when it's
called.@footnote{Parameter lists are sometimes also called
@emph{lambda lists} because of the historical relationship between
Lisp's notion of functions and the lambda calculus.} If the function
takes no arguments, the list is empty, written as @code{()}. Different
flavors of parameters handle required, optional, multiple, and keyword
arguments. I'll discuss the details in the next section.

If a string literal follows the parameter list, it's a documentation
string that should describe the purpose of the function. When the
function is defined, the documentation string will be associated with
the name of the function and can later be obtained using the
@code{DOCUMENTATION} function.@footnote{For example, the following:

@verbatim
(documentation 'foo 'function)
@end verbatim

returns the documentation string for the function @code{foo}. Note,
however, that documentation strings are intended for human
consumption, not programmatic access. A Lisp implementation isn't
@emph{required} to store them and is allowed to discard them at any
time, so portable programs shouldn't depend on their presence. In some
implementations an implementation-defined variable needs to be set
before it will store documentation strings.}

Finally, the body of a @code{DEFUN} consists of any number of Lisp
expressions. They will be evaluated in order when the function is called
and the value of the last expression is returned as the value of the
function. Or the @code{RETURN-FROM} special operator can be used to
return immediately from anywhere in a function, as I'll discuss in a
moment.

In Chapter 2 we wrote a @code{hello-world} function, which looked like
this:

@verbatim
(defun hello-world () (format t "hello, world"))
@end verbatim

You can now analyze the parts of this function. Its name is
@code{hello-world}, its parameter list is empty so it takes no
arguments, it has no documentation string, and its body consists of one
expression.

@verbatim
(format t "hello, world")
@end verbatim

The following is a slightly more complex function:

@verbatim
(defun verbose-sum (x y)
  "Sum any two numbers after printing a message."
  (format t "Summing ~d and ~d.~%" x y)
  (+ x y))
@end verbatim

This function is named @code{verbose-sum}, takes two arguments that will
be bound to the parameters @code{x} and @code{y}, has a documentation
string, and has a body consisting of two expressions. The value returned
by the call to @code{+} becomes the return value of @code{verbose-sum}.

@node Function Parameter Lists
@section Function Parameter Lists
@anchor{#function-parameter-lists}
There's not a lot more to say about function names or documentation
strings, and it will take a good portion of the rest of this book to
describe all the things you can do in the body of a function, which
leaves us with the parameter list.

The basic purpose of a parameter list is, of course, to declare the
variables that will receive the arguments passed to the function. When a
parameter list is a simple list of variable names--as in
@code{verbose-sum}--the parameters are called @emph{required
parameters}. When a function is called, it must be supplied with one
argument for every required parameter. Each parameter is bound to the
corresponding argument. If a function is called with too few or too many
arguments, Lisp will signal an error.

However, Common Lisp's parameter lists also give you more flexible ways
of mapping the arguments in a function call to the function's
parameters. In addition to required parameters, a function can have
optional parameters. Or a function can have a single parameter that's
bound to a list containing any extra arguments. And, finally, arguments
can be mapped to parameters using keywords rather than position. Thus,
Common Lisp's parameter lists provide a convenient solution to several
common coding problems.

@node Optional Parameters
@section Optional Parameters
@anchor{#optional-parameters} While many functions, like
@code{verbose-sum}, need only required parameters, not all functions
are quite so simple. Sometimes a function will have a parameter that
only certain callers will care about, perhaps because there's a
reasonable default value. An example is a function that creates a data
structure that can grow as needed. Since the data structure can grow,
it doesn't matter--from a correctness point of view--what the initial
size is. But callers who have a good idea how many items they're going
to put into the data structure may be able to improve performance by
specifying a specific initial size. Most callers, though, would
probably rather let the code that implements the data structure pick a
good general-purpose value. In Common Lisp you can accommodate both
kinds of callers by using an optional parameter; callers who don't
care will get a reasonable default, and other callers can provide a
specific value.@footnote{In languages that don't support optional
parameters directly, programmers typically find ways to simulate
them. One technique is to use distinguished "no-value" values that the
caller can pass to indicate they want the default value of a given
parameter. In C, for example, it's common to use @code{NULL} as such a
distinguished value. However, such a protocol between the function and
its callers is ad hoc--in some functions or for some arguments
@code{NULL} may be the distinguished value while in other functions or
for other arguments the magic value may be -1 or some @code{#defined}
constant.}

To define a function with optional parameters, after the names of any
required parameters, place the symbol @code{&optional} followed by the
names of the optional parameters. A simple example looks like this:

@verbatim
(defun foo (a b &optional c d) (list a b c d))
@end verbatim

When the function is called, arguments are first bound to the required
parameters. After all the required parameters have been given values, if
there are any arguments left, their values are assigned to the optional
parameters. If the arguments run out before the optional parameters do,
the remaining optional parameters are bound to the value @code{NIL}.
Thus, the function defined previously gives the following results:

@verbatim
(foo 1 2)     ==> (1 2 NIL NIL)
(foo 1 2 3)   ==> (1 2 3 NIL)
(foo 1 2 3 4) ==> (1 2 3 4)
@end verbatim

Lisp will still check that an appropriate number of arguments are passed
to the function--in this case between two and four, inclusive--and will
signal an error if the function is called with too few or too many.

Of course, you'll often want a different default value than @code{NIL}.
You can specify the default value by replacing the parameter name with a
list containing a name and an expression. The expression will be
evaluated only if the caller doesn't pass enough arguments to provide a
value for the optional parameter. The common case is simply to provide a
value as the expression.

@verbatim
(defun foo (a &optional (b 10)) (list a b))
@end verbatim

This function requires one argument that will be bound to the parameter
@code{a}. The second parameter, @code{b}, will take either the value of
the second argument, if there is one, or 10.

@verbatim
(foo 1 2) ==> (1 2)
(foo 1)   ==> (1 10)
@end verbatim

Sometimes, however, you may need more flexibility in choosing the
default value. You may want to compute a default value based on other
parameters. And you can--the default-value expression can refer to
parameters that occur earlier in the parameter list. If you were writing
a function that returned some sort of representation of a rectangle and
you wanted to make it especially convenient to make squares, you might
use an argument list like this:

@verbatim
(defun make-rectangle (width &optional (height width)) ...)
@end verbatim

which would cause the @code{height} parameter to take the same value as
the @code{width} parameter unless explicitly specified.

Occasionally, it's useful to know whether the value of an optional
argument was supplied by the caller or is the default value. Rather than
writing code to check whether the value of the parameter is the default
(which doesn't work anyway, if the caller happens to explicitly pass the
default value), you can add another variable name to the parameter
specifier after the default-value expression. This variable will be
bound to true if the caller actually supplied an argument for this
parameter and @code{NIL} otherwise. By convention, these variables are
usually named the same as the actual parameter with a "-supplied-p" on
the end. For example:

@verbatim
(defun foo (a b &optional (c 3 c-supplied-p))
  (list a b c c-supplied-p))
@end verbatim

This gives results like this:

@verbatim
(foo 1 2)   ==> (1 2 3 NIL)
(foo 1 2 3) ==> (1 2 3 T)
(foo 1 2 4) ==> (1 2 4 T)
@end verbatim

@node Rest Parameters
@section Rest Parameters
@anchor{#rest-parameters}
Optional parameters are just the thing when you have discrete parameters
for which the caller may or may not want to provide values. But some
functions need to take a variable number of arguments. Several of the
built-in functions you've seen already work this way. @code{FORMAT} has
two required arguments, the stream and the control string. But after
that it needs a variable number of arguments depending on how many
values need to be interpolated into the control string. The @code{+}
function also takes a variable number of arguments--there's no
particular reason to limit it to summing just two numbers; it will sum
any number of values. (It even works with zero arguments, returning 0,
the identity under addition.) The following are all legal calls of those
two functions:

@verbatim
(format t "hello, world")
(format t "hello, ~a" name)
(format t "x: ~d y: ~d" x y)
(+)
(+ 1)
(+ 1 2)
(+ 1 2 3)
@end verbatim

Obviously, you could write functions taking a variable number of
arguments by simply giving them a lot of optional parameters. But that
would be incredibly painful--just writing the parameter list would be
bad enough, and that doesn't get into dealing with all the parameters
in the body of the function. To do it properly, you'd have to have as
many optional parameters as the number of arguments that can legally
be passed in a function call. This number is implementation dependent
but guaranteed to be at least 50. And in current implementations it
ranges from 4,096 to 536,870,911.@footnote{The constant
@code{CALL-ARGUMENTS-LIMIT} tells you the implementation-specific
value.} Blech. That kind of mind-bending tedium is definitely
@emph{not} The Lisp Way.

Instead, Lisp lets you include a catchall parameter after the symbol
@code{&rest}. If a function includes a @code{&rest} parameter, any
arguments remaining after values have been doled out to all the required
and optional parameters are gathered up into a list that becomes the
value of the @code{&rest} parameter. Thus, the parameter lists for
@code{FORMAT} and @code{+} probably look something like this:

@verbatim
(defun format (stream string &rest values) ...)
(defun + (&rest numbers) ...)
@end verbatim

@node Keyword Parameters
@section Keyword Parameters
@anchor{#keyword-parameters}
Optional and rest parameters give you quite a bit of flexibility, but
neither is going to help you out much in the following situation:
Suppose you have a function that takes four optional parameters. Now
suppose that most of the places the function is called, the caller wants
to provide a value for only one of the four parameters and, further,
that the callers are evenly divided as to which parameter they will use.

The callers who want to provide a value for the first parameter are
fine--they just pass the one optional argument and leave off the rest.
But all the other callers have to pass some value for between one and
three arguments they don't care about. Isn't that exactly the problem
optional parameters were designed to solve?

Of course it is. The problem is that optional parameters are still
positional--if the caller wants to pass an explicit value for the fourth
optional parameter, it turns the first three optional parameters into
required parameters for that caller. Luckily, another parameter flavor,
keyword parameters, allow the caller to specify which values go with
which parameters.

To give a function keyword parameters, after any required,
@code{&optional}, and @code{&rest} parameters you include the symbol
@code{&key} and then any number of keyword parameter specifiers, which
work like optional parameter specifiers. Here's a function that has only
keyword parameters:

@verbatim
(defun foo (&key a b c) (list a b c))
@end verbatim

When this function is called, each keyword parameters is bound to the
value immediately following a keyword of the same name. Recall from
Chapter 4 that keywords are names that start with a colon and that
they're automatically defined as self-evaluating constants.

If a given keyword doesn't appear in the argument list, then the
corresponding parameter is assigned its default value, just like an
optional parameter. Because the keyword arguments are labeled, they can
be passed in any order as long as they follow any required arguments.
For instance, @code{foo} can be invoked as follows:

@verbatim
(foo)                ==> (NIL NIL NIL)
(foo :a 1)           ==> (1 NIL NIL)
(foo :b 1)           ==> (NIL 1 NIL)
(foo :c 1)           ==> (NIL NIL 1)
(foo :a 1 :c 3)      ==> (1 NIL 3)
(foo :a 1 :b 2 :c 3) ==> (1 2 3)
(foo :a 1 :c 3 :b 2) ==> (1 2 3)
@end verbatim

As with optional parameters, keyword parameters can provide a default
value form and the name of a supplied-p variable. In both keyword and
optional parameters, the default value form can refer to parameters that
appear earlier in the parameter list.

@verbatim
(defun foo (&key (a 0) (b 0 b-supplied-p) (c (+ a b)))
  (list a b c b-supplied-p))

(foo :a 1)           ==> (1 0 1 NIL)
(foo :b 1)           ==> (0 1 1 T)
(foo :b 1 :c 4)      ==> (0 1 4 T)
(foo :a 2 :b 1 :c 4) ==> (2 1 4 T)
@end verbatim

Also, if for some reason you want the keyword the caller uses to specify
the parameter to be different from the name of the actual parameter, you
can replace the parameter name with another list containing the keyword
to use when calling the function and the name to be used for the
parameter. The following definition of @code{foo}:

@verbatim
(defun foo (&key ((:apple a)) ((:box b) 0) ((:charlie c) 0 c-supplied-p))
  (list a b c c-supplied-p))
@end verbatim

lets the caller call it like this:

@verbatim
(foo :apple 10 :box 20 :charlie 30) ==> (10 20 30 T)
@end verbatim

This style is mostly useful if you want to completely decouple the
public API of the function from the internal details, usually because
you want to use short variable names internally but descriptive keywords
in the API. It's not, however, very frequently used.

@node Mixing Different Parameter Types
@section Mixing Different Parameter Types
@anchor{#mixing-different-parameter-types}
It's possible, but rare, to use all four flavors of parameters in a
single function. Whenever more than one flavor of parameter is used,
they must be declared in the order I've discussed them: first the names
of the required parameters, then the optional parameters, then the rest
parameter, and finally the keyword parameters. Typically, however, in
functions that use multiple flavors of parameters, you'll combine
required parameters with one other flavor or possibly combine
@code{&optional} and @code{&rest} parameters. The other two
combinations, either @code{&optional} or @code{&rest} parameters
combined with @code{&key} parameters, can lead to somewhat surprising
behavior.

Combining @code{&optional} and @code{&key} parameters yields surprising
enough results that you should probably avoid it altogether. The problem
is that if a caller doesn't supply values for all the optional
parameters, then those parameters will eat up the keywords and values
intended for the keyword parameters. For instance, this function
unwisely mixes @code{&optional} and @code{&key} parameters:

@verbatim
(defun foo (x &optional y &key z) (list x y z))
@end verbatim

If called like this, it works fine:

@verbatim
(foo 1 2 :z 3) ==> (1 2 3)
@end verbatim

And this is also fine:

@verbatim
(foo 1)  ==> (1 nil nil)
@end verbatim

But this will signal an error:

@verbatim
(foo 1 :z 3) ==> ERROR
@end verbatim

This is because the keyword @code{:z} is taken as a value to fill the
optional @code{y} parameter, leaving only the argument 3 to be
processed. At that point, Lisp will be expecting either a keyword/value
pair or nothing and will complain. Perhaps even worse, if the function
had had two @code{&optional} parameters, this last call would have
resulted in the values @code{:z} and 3 being bound to the two
@code{&optional} parameters and the @code{&key} parameter @code{z}
getting the default value @code{NIL} with no indication that anything
was amiss.

In general, if you find yourself writing a function that uses both
@code{&optional} and @code{&key} parameters, you should probably just
change it to use all @code{&key} parameters--they're more flexible,
and you can always add new keyword parameters without disturbing
existing callers of the function. You can also remove keyword
parameters, as long as no one is using them.@footnote{Four standard
functions take both@code{ &optional} and @code{&key}
arguments--@code{READ-FROM-STRING}, @code{PARSE-NAMESTRING},
@code{WRITE-LINE}, and @code{WRITE-STRING}.  They were left that way
during standardization for backward compatibility with earlier Lisp
dialects. @code{READ-FROM-STRING} tends to be the one that catches new
Lisp programmers most frequently--a call such as
@code{(read-from-string s :start 10)} seems to ignore the
@code{:start} keyword argument, reading from index 0 instead of 10.
That's because @code{READ-FROM-STRING }also has two @code{&optional}
parameters that swallowed up the arguments @code{:start} and 10.} In
general, using keyword parameters helps make code much easier to
maintain and evolve--if you need to add some new behavior to a
function that requires new parameters, you can add keyword parameters
without having to touch, or even recompile, any existing code that
calls the function.

You can safely combine @code{&rest} and @code{&key} parameters, but the
behavior may be a bit surprising initially. Normally the presence of
either @code{&rest} or @code{&key} in a parameter list causes all the
values remaining after the required and @code{&optional} parameters have
been filled in to be processed in a particular way--either gathered into
a list for a @code{&rest} parameter or assigned to the appropriate
@code{&key} parameters based on the keywords. If both @code{&rest} and
@code{&key} appear in a parameter list, then both things happen--all the
remaining values, which include the keywords themselves, are gathered
into a list that's bound to the @code{&rest} parameter, and the
appropriate values are also bound to the @code{&key} parameters. So,
given this function:

@verbatim
(defun foo (&rest rest &key a b c) (list rest a b c))
@end verbatim

you get this result:

@verbatim
(foo :a 1 :b 2 :c 3)  ==> ((:A 1 :B 2 :C 3) 1 2 3)
@end verbatim

@node Function Return Values
@section Function Return Values
@anchor{#function-return-values}
All the functions you've written so far have used the default behavior
of returning the value of the last expression evaluated as their own
return value. This is the most common way to return a value from a
function.

However, sometimes it's convenient to be able to return from the middle
of a function such as when you want to break out of nested control
constructs. In such cases you can use the @code{RETURN-FROM} special
operator to immediately return any value from the function.

You'll see in Chapter 20 that @code{RETURN-FROM} is actually not tied to
functions at all; it's used to return from a block of code defined with
the @code{BLOCK} special operator. However, @code{DEFUN} automatically
wraps the whole function body in a block with the same name as the
function. So, evaluating a @code{RETURN-FROM} with the name of the
function and the value you want to return will cause the function to
immediately exit with that value. @code{RETURN-FROM} is a special
operator whose first "argument" is the name of the block from which to
return. This name isn't evaluated and thus isn't quoted.

The following function uses nested loops to find the first pair of
numbers, each less than 10, whose product is greater than the argument,
and it uses @code{RETURN-FROM} to return the pair as soon as it finds
it:

@verbatim
(defun foo (n)
  (dotimes (i 10)
    (dotimes (j 10)
      (when (> (* i j) n)
        (return-from foo (list i j))))))
@end verbatim

Admittedly, having to specify the name of the function you're
returning from is a bit of a pain--for one thing, if you change the
function's name, you'll need to change the name used in the
@code{RETURN-FROM} as well.@footnote{Another macro, @code{RETURN},
doesn't require a name.  However, you can't use it instead of
@code{RETURN-FROM} to avoid having to specify the function name; it's
syntactic sugar for returning from a block named @code{NIL}. I'll
cover it, along with the details of @code{BLOCK} and
@code{RETURN-FROM}, in Chapter 20.} But it's also the case that
explicit @code{RETURN-FROM}s are used much less frequently in Lisp
than @code{return} statements in C-derived languages, because
@emph{all} Lisp expressions, including control constructs such as
loops and conditionals, evaluate to a value. So it's not much of a
problem in practice.

@node Functions As Data aka Higher-Order Functions
@section Functions As Data, a.k.a. Higher-Order Functions
@anchor{#functions-as-data-a.k.a.-higher-order-functions} While the
main way you use functions is to call them by name, a number of
situations exist where it's useful to be able treat functions as
data. For instance, if you can pass one function as an argument to
another, you can write a general-purpose sorting function while
allowing the caller to provide a function that's responsible for
comparing any two elements. Then the same underlying algorithm can be
used with many different comparison functions. Similarly, callbacks
and hooks depend on being able to store references to code in order to
run it later. Since functions are already the standard way to abstract
bits of code, it makes sense to allow functions to be treated as
data.@footnote{Lisp, of course, isn't the only language to treat
functions as data. C uses function pointers, Perl uses subroutine
references, Python uses a scheme similar to Lisp, and C# introduces
delegates, essentially typed function pointers, as an improvement over
Java's rather clunky reflection and anonymous class mechanisms.}

In Lisp, functions are just another kind of object. When you define a
function with @code{DEFUN}, you're really doing two things: creating a
new function object and giving it a name. It's also possible, as you saw
in Chapter 3, to use @code{LAMBDA} expressions to create a function
without giving it a name. The actual representation of a function
object, whether named or anonymous, is opaque--in a native-compiling
Lisp, it probably consists mostly of machine code. The only things you
need to know are how to get hold of it and how to invoke it once you've
got it.

The special operator @code{FUNCTION} provides the mechanism for getting
at a function object. It takes a single argument and returns the
function with that name. The name isn't quoted. Thus, if you've defined
a function @code{foo}, like so:

@verbatim
CL-USER> (defun foo (x) (* 2 x))
FOO
@end verbatim

you can get the function object like this:@footnote{The exact printed
representation of a function object will differ from implementation to
implementation.}

@verbatim
CL-USER> (function foo)
#<Interpreted Function FOO>
@end verbatim

In fact, you've already used @code{FUNCTION}, but it was in disguise.
The syntax @code{#'}, which you used in Chapter 3, is syntactic sugar
for @code{FUNCTION}, just the way @code{'} is syntactic sugar for
@code{QUOTE}.@footnote{The best way to think of @code{FUNCTION} is as
a special kind of quotation.@code{ QUOTE}ing a symbol prevents it from
being evaluated at all, resulting in the symbol itself rather than the
value of the variable named by that symbol. @code{FUNCTION} also
circumvents the normal evaluation rule but, instead of preventing the
symbol from being evaluated at all, causes it to be evaluated as the
name of a function, just the way it would if it were used as the
function name in a function call expression.} Thus, you can also get
the function object for @code{foo} like this:

@verbatim
CL-USER> #'foo
#<Interpreted Function FOO>
@end verbatim

Once you've got the function object, there's really only one thing you
can do with it--invoke it. Common Lisp provides two functions for
invoking a function through a function object: @code{FUNCALL} and
@code{APPLY}.@footnote{There's actually a third, the special operator
@code{MULTIPLE-VALUE-CALL}, but I'll save that for when I discuss
expressions that return multiple values in Chapter 20.} They differ
only in how they obtain the arguments to pass to the function.

@code{FUNCALL} is the one to use when you know the number of arguments
you're going to pass to the function at the time you write the code. The
first argument to @code{FUNCALL} is the function object to be invoked,
and the rest of the arguments are passed onto that function. Thus, the
following two expressions are equivalent:

@verbatim
(foo 1 2 3) === (funcall #'foo 1 2 3)
@end verbatim

However, there's little point in using @code{FUNCALL} to call a function
whose name you know when you write the code. In fact, the previous two
expressions will quite likely compile to exactly the same machine
instructions.

The following function demonstrates a more apt use of @code{FUNCALL}. It
accepts a function object as an argument and plots a simple ASCII-art
histogram of the values returned by the argument function when it's
invoked on the values from @code{min} to @code{max}, stepping by
@code{step}.

@verbatim
(defun plot (fn min max step)
  (loop for i from min to max by step do
        (loop repeat (funcall fn i) do (format t "*"))
        (format t "~%")))
@end verbatim

The @code{FUNCALL} expression computes the value of the function for
each value of @code{i}. The inner @code{LOOP} uses that computed value
to determine how many times to print an asterisk to standard output.

Note that you don't use @code{FUNCTION} or @code{#'} to get the function
value of @code{fn}; you @emph{want} it to be interpreted as a variable
because it's the variable's value that will be the function object. You
can call @code{plot} with any function that takes a single numeric
argument, such as the built-in function @code{EXP} that returns the
value of @emph{e} raised to the power of its argument.

@verbatim
CL-USER> (plot #'exp 0 4 1/2)
*
*
**
****
*******
************
********************
*********************************
******************************************************
NIL
@end verbatim

@code{FUNCALL}, however, doesn't do you any good when the argument list
is known only at runtime. For instance, to stick with the @code{plot}
function for another moment, suppose you've obtained a list containing a
function object, a minimum and maximum value, and a step value. In other
words, the list contains the values you want to pass as arguments to
@code{plot}. Suppose this list is in the variable @code{plot-data}. You
could invoke @code{plot} on the values in that list like this:

@verbatim
(plot (first plot-data) (second plot-data) (third plot-data) (fourth plot-data))
@end verbatim

This works fine, but it's pretty annoying to have to explicitly unpack
the arguments just so you can pass them to @code{plot}.

That's where @code{APPLY} comes in. Like @code{FUNCALL}, the first
argument to @code{APPLY} is a function object. But after the function
object, instead of individual arguments, it expects a list. It then
applies the function to the values in the list. This allows you to write
the following instead:

@verbatim
(apply #'plot plot-data)
@end verbatim

As a further convenience, @code{APPLY} can also accept "loose" arguments
as long as the last argument is a list. Thus, if @code{plot-data}
contained just the min, max, and step values, you could still use
@code{APPLY} like this to plot the @code{EXP} function over that range:

@verbatim
(apply #'plot #'exp plot-data)
@end verbatim

@code{APPLY} doesn't care about whether the function being applied takes
@code{&optional}, @code{&rest}, or @code{&key} arguments--the argument
list produced by combining any loose arguments with the final list must
be a legal argument list for the function with enough arguments for all
the required parameters and only appropriate keyword parameters.

@node Anonymous Functions
@section Anonymous Functions
@anchor{#anonymous-functions}
Once you start writing, or even simply using, functions that accept
other functions as arguments, you're bound to discover that sometimes
it's annoying to have to define and name a whole separate function
that's used in only one place, especially when you never call it by
name.

When it seems like overkill to define a new function with @code{DEFUN},
you can create an "anonymous" function using a @code{LAMBDA} expression.
As discussed in Chapter 3, a @code{LAMBDA} expression looks like this:

@verbatim
(lambda (parameters) body)
@end verbatim

One way to think of @code{LAMBDA} expressions is as a special kind of
function name where the name itself directly describes what the function
does. This explains why you can use a @code{LAMBDA} expression in the
place of a function name with @code{#'}.

@verbatim
(funcall #'(lambda (x y) (+ x y)) 2 3) ==> 5
@end verbatim

You can even use a @code{LAMBDA} expression as the "name" of a function
in a function call expression. If you wanted, you could write the
previous @code{FUNCALL} expression more concisely.

@verbatim
((lambda (x y) (+ x y)) 2 3) ==> 5
@end verbatim

But this is almost never done; it's merely worth noting that it's
legal in order to emphasize that @code{LAMBDA} expressions can be used
anywhere a normal function name can be.@footnote{In Common Lisp it's
also possible to use a @code{LAMBDA} expression as an argument to
@code{FUNCALL} (or some other function that takes a function argument
such as @code{SORT} or @code{MAPCAR}) with no @code{#'} before it,
like this:

@verbatim
(funcall (lambda (x y) (+ x y)) 2 3)
@end verbatim

This is legal and is equivalent to the version with the @code{#'} but
for a tricky reason. Historically @code{LAMBDA} expressions by
themselves weren't expressions that could be evaluated. That is
@code{LAMBDA} wasn't the name of a function, macro, or special operator.
Rather, a list starting with the symbol @code{LAMBDA} was a special
syntactic construct that Lisp recognized as a kind of function name.

But if that were still true, then @code{(funcall (lambda (...) ...))}
would be illegal because @code{FUNCALL} is a function and the normal
evaluation rule for a function call would require that the @code{LAMBDA}
expression be evaluated. However, late in the ANSI standardization
process, in order to make it possible to implement ISLISP, another Lisp
dialect being standardized at the same time, strictly as a user-level
compatibility layer on top of Common Lisp, a @code{LAMBDA} macro was
defined that expands into a call to @code{FUNCTION} wrapped around the
@code{LAMBDA} expression. In other words, the following @code{LAMBDA}
expression:

@verbatim
(lambda () 42)
@end verbatim

exands into the following when it occurs in a context where it
evaluated:

@verbatim
(function (lambda () 42))   ; or #'(lambda () 42)
@end verbatim

This makes its use in a value position, such as an argument to
@code{FUNCALL}, legal. In other words, it's pure syntactic sugar. Most
folks either always use @code{#'} before @code{LAMBDA} expressions in
value positions or never do. In this book, I always use @code{#'}.}

Anonymous functions can be useful when you need to pass a function as an
argument to another function and the function you need to pass is simple
enough to express inline. For instance, suppose you wanted to plot the
function @emph{2x}. You @emph{could} define the following function:

@verbatim
(defun double (x) (* 2 x))
@end verbatim

which you could then pass to @code{plot}.

@verbatim
CL-USER> (plot #'double 0 10 1)

**
****
******
********
**********
************
**************
****************
******************
********************
NIL
@end verbatim

But it's easier, and arguably clearer, to write this:

@verbatim
CL-USER> (plot #'(lambda (x) (* 2 x)) 0 10 1)

**
****
******
********
**********
************
**************
****************
******************
********************
NIL
@end verbatim

The other important use of @code{LAMBDA} expressions is in making
@emph{closures}, functions that capture part of the environment where
they're created. You used closures a bit in Chapter 3, but the details
of how closures work and what they're used for is really more about how
variables work than functions, so I'll save that discussion for the next
chapter.

@node Variables
@chapter Variables
@anchor{#variables} The next basic building block we need to look at
are variables. Common Lisp supports two kinds of variables: lexical
and dynamic.@footnote{Dynamic variables are also sometimes called
@emph{special} @emph{variables} for reasons you'll see later in this
chapter. It's important to be aware of this synonym, as some folks
(and Lisp implementations) use one term while others use the other.}
These two types correspond roughly to "local" and "global" variables
in other languages. However, the correspondence is only
approximate. On one hand, some languages' "local" variables are in
fact much like Common Lisp's dynamic variables.@footnote{Early Lisps
tended to use dynamic variables for local variables, at least when
interpreted. Elisp, the Lisp dialect used in Emacs, is a bit of a
throwback in this respect, continuing to support only dynamic
variables. Other languages have recapitulated this transition from
dynamic to lexical variables--Perl's @code{local} variables, for
instance, are dynamic while its @code{my} variables, introduced in
Perl 5, are lexical. Python never had true dynamic variables but only
introduced true lexical scoping in version 2.2.  (Python's lexical
variables are still somewhat limited compared to Lisp's because of the
conflation of assignment and binding in the language's syntax.)} And
on the other, some languages' local variables are @emph{lexically
scoped} without providing all the capabilities provided by Common
Lisp's lexical variables. In particular, not all languages that
provide lexically scoped variables support closures.

To make matters a bit more confusing, many of the forms that deal with
variables can be used with both lexical and dynamic variables. So I'll
start by discussing a few aspects of Lisp's variables that apply to both
kinds and then cover the specific characteristics of lexical and dynamic
variables. Then I'll discuss Common Lisp's general-purpose assignment
operator, @code{SETF}, which is used to assign new values to variables
and just about every other place that can hold a value.
@menu
* Variable Basics::
* Lexical Variables and Closures::
* Dynamic aka Special Variables::
* Constants::
* Assignment::
* Generalized Assignment::
* Other Ways to Modify Places::
@end menu

@node Variable Basics
@section Variable Basics
@anchor{#variable-basics} As in other languages, in Common Lisp
variables are named places that can hold a value. However, in Common
Lisp, variables aren't typed the way they are in languages such as
Java or C++. That is, you don't need to declare the type of object
that each variable can hold. Instead, a variable can hold values of
any type and the values carry type information that can be used to
check types at runtime. Thus, Common Lisp is @emph{dynamically
typed}--type errors are detected dynamically.  For instance, if you
pass something other than a number to the @code{+} function, Common
Lisp will signal a type error. On the other hand, Common Lisp
@emph{is} a @emph{strongly typed} language in the sense that all type
errors will be detected--there's no way to treat an object as an
instance of a class that it's not.@footnote{Actually, it's not quite
true to say that all type errors will always be detected--it's
possible to use optional declarations to tell the compiler that
certain variables will always contain objects of a particular type and
to turn off runtime type checking in certain regions of code. However,
declarations of this sort are used to optimize code after it has been
developed and debugged, not during normal development.}

All values in Common Lisp are, conceptually at least, references to
objects.@footnote{As an optimization certain kinds of objects, such as
integers below a certain size and characters, may be represented
directly in memory where other objects would be represented by a
pointer to the actual object. However, since integers and characters
are immutable, it doesn't matter that there may be multiple copies of
"the same" object in different variables. This is the root of the
difference between @code{EQ} and @code{EQL} discussed in Chapter 4.}
Consequently, assigning a variable a new value changes @emph{what}
object the variable refers to but has no effect on the previously
referenced object. However, if a variable holds a reference to a
mutable object, you can use that reference to modify the object, and
the modification will be visible to any code that has a reference to
the same object.

One way to introduce new variables you've already used is to define
function parameters. As you saw in the previous chapter, when you define
a function with @code{DEFUN}, the parameter list defines the variables
that will hold the function's arguments when it's called. For example,
this function defines three variables--@code{x}, @code{y}, and
@code{z}--to hold its arguments.

@verbatim
(defun foo (x y z) (+ x y z))
@end verbatim

Each time a function is called, Lisp creates new @emph{bindings} to hold
the arguments passed by the function's caller. A binding is the runtime
manifestation of a variable. A single variable--the thing you can point
to in the program's source code--can have many different bindings during
a run of the program. A single variable can even have multiple bindings
at the same time; parameters to a recursive function, for example, are
rebound for each call to the function.

As with all Common Lisp variables, function parameters hold object
references.@footnote{In compiler-writer terms Common Lisp functions
are "pass-by-value." However, the values that are passed are
references to objects. This is similar to how Java and Python work.}
Thus, you can assign a new value to a function parameter within the
body of the function, and it will not affect the bindings created for
another call to the same function. But if the object passed to a
function is mutable and you change it in the function, the changes
will be visible to the caller since both the caller and the callee
will be referencing the same object.

Another form that introduces new variables is the @code{LET} special
operator. The skeleton of a @code{LET} form looks like this:

@verbatim
(let (variable*)
  body-form*)
@end verbatim

where each @emph{variable} is a variable initialization form. Each
initialization form is either a list containing a variable name and an
initial value form or--as a shorthand for initializing the variable to
@code{NIL}--a plain variable name. The following @code{LET} form, for
example, binds the three variables @code{x}, @code{y}, and @code{z} with
initial values 10, 20, and @code{NIL}:

@verbatim
(let ((x 10) (y 20) z)
  ...)
@end verbatim

When the @code{LET} form is evaluated, all the initial value forms are
first evaluated. Then new bindings are created and initialized to the
appropriate initial values before the body forms are executed. Within
the body of the @code{LET}, the variable names refer to the newly
created bindings. After the @code{LET}, the names refer to whatever, if
anything, they referred to before the @code{LET}.

The value of the last expression in the body is returned as the value of
the @code{LET} expression. Like function parameters, variables
introduced with @code{LET} are rebound each time the @code{LET} is
entered.@footnote{The variables in @code{LET} forms and function
parameters are created by exactly the same mechanism. In fact, in some
Lisp dialects--though not Common Lisp--@code{LET} is simply a macro that
expands into a call to an anonymous function. That is, in those
dialects, the following:

@verbatim
(let ((x 10)) (format t "~a" x))
@end verbatim

is a macro form that expands into this:

@verbatim
((lambda (x) (format t "~a" x)) 10)
@end verbatim
}

The @emph{scope} of function parameters and @code{LET} variables--the
area of the program where the variable name can be used to refer to
the variable's binding--is delimited by the form that introduces the
variable. This form--the function definition or the @code{LET}--is
called the @emph{binding form}. As you'll see in a bit, the two types
of variables--lexical and dynamic--use two slightly different scoping
mechanisms, but in both cases the scope is delimited by the binding
form.

If you nest binding forms that introduce variables with the same name,
then the bindings of the innermost variable @emph{shadows} the outer
bindings. For instance, when the following function is called, a binding
is created for the parameter @code{x} to hold the function's argument.
Then the first @code{LET} creates a new binding with the initial value
2, and the inner @code{LET} creates yet another binding, this one with
the initial value 3. The bars on the right mark the scope of each
binding.

@verbatim
(defun foo (x)
  (format t "Parameter: ~a~%" x)      ; |<------ x is argument
  (let ((x 2))                        ; |
    (format t "Outer LET: ~a~%" x)    ; | |<---- x is 2
    (let ((x 3))                      ; | |
      (format t "Inner LET: ~a~%" x)) ; | | |<-- x is 3
    (format t "Outer LET: ~a~%" x))   ; | |
  (format t "Parameter: ~a~%" x))     ; |
@end verbatim

Each reference to @code{x} will refer to the binding with the smallest
enclosing scope. Once control leaves the scope of one binding form, the
binding from the immediately enclosing scope is unshadowed and @code{x}
refers to it instead. Thus, calling @code{foo} results in this output:

@verbatim
CL-USER> (foo 1)
Parameter: 1
Outer LET: 2
Inner LET: 3
Outer LET: 2
Parameter: 1
NIL
@end verbatim

In future chapters I'll discuss other constructs that also serve as
binding forms--any construct that introduces a new variable name that's
usable only within the construct is a binding form.

For instance, in Chapter 7 you'll meet the @code{DOTIMES} loop, a basic
counting loop. It introduces a variable that holds the value of a
counter that's incremented each time through the loop. The following
loop, for example, which prints the numbers from 0 to 9, binds the
variable @code{x}:

@verbatim
(dotimes (x 10) (format t "~d " x))
@end verbatim

Another binding form is a variant of @code{LET}, @code{LET*}. The
difference is that in a @code{LET}, the variable names can be used only
in the body of the @code{LET}--the part of the @code{LET} after the
variables list--but in a @code{LET*}, the initial value forms for each
variable can refer to variables introduced earlier in the variables
list. Thus, you can write the following:

@verbatim
(let* ((x 10)
       (y (+ x 10)))
  (list x y))
@end verbatim

but not this:

@verbatim
(let ((x 10)
      (y (+ x 10)))
  (list x y))
@end verbatim

However, you could achieve the same result with nested @code{LET}s.

@verbatim
(let ((x 10))
  (let ((y (+ x 10)))
    (list x y)))
@end verbatim

@node Lexical Variables and Closures
@section Lexical Variables and Closures
@anchor{#lexical-variables-and-closures}
By default all binding forms in Common Lisp introduce @emph{lexically
scoped} variables. Lexically scoped variables can be referred to only by
code that's textually within the binding form. Lexical scoping should be
familiar to anyone who has programmed in Java, C, Perl, or Python since
they all provide lexically scoped "local" variables. For that matter,
Algol programmers should also feel right at home, as Algol first
introduced lexical scoping in the 1960s.

However, Common Lisp's lexical variables are lexical variables with a
twist, at least compared to the original Algol model. The twist is
provided by the combination of lexical scoping with nested
functions. By the rules of lexical scoping, only code textually within
the binding form can refer to a lexical variable. But what happens
when an anonymous function contains a reference to a lexical variable
from an enclosing scope? For instance, in this expression:

@verbatim
(let ((count 0)) #'(lambda () (setf count (1+ count))))
@end verbatim

the reference to @code{count} inside the @code{LAMBDA} form should be
legal according to the rules of lexical scoping. Yet the anonymous
function containing the reference will be returned as the value of the
@code{LET} form and can be invoked, via @code{FUNCALL}, by code that's
@emph{not} in the scope of the @code{LET}. So what happens? As it turns
out, when @code{count} is a lexical variable, it just works. The binding
of @code{count} created when the flow of control entered the @code{LET}
form will stick around for as long as needed, in this case for as long
as someone holds onto a reference to the function object returned by the
@code{LET} form. The anonymous function is called a @emph{closure}
because it "closes over" the binding created by the @code{LET}.

The key thing to understand about closures is that it's the binding, not
the value of the variable, that's captured. Thus, a closure can not only
access the value of the variables it closes over but can also assign new
values that will persist between calls to the closure. For instance, you
can capture the closure created by the previous expression in a global
variable like this:

@verbatim
(defparameter *fn* (let ((count 0)) #'(lambda () (setf count (1+ count)))))
@end verbatim

Then each time you invoke it, the value of count will increase by one.

@verbatim
CL-USER> (funcall *fn*)
1
CL-USER> (funcall *fn*)
2
CL-USER> (funcall *fn*)
3
@end verbatim

A single closure can close over many variable bindings simply by
referring to them. Or multiple closures can capture the same binding.
For instance, the following expression returns a list of three closures,
one that increments the value of the closed over @code{count} binding,
one that decrements it, and one that returns the current value:

@verbatim
(let ((count 0))
  (list
   #'(lambda () (incf count))
   #'(lambda () (decf count))
   #'(lambda () count)))
@end verbatim

@node Dynamic aka Special Variables
@section Dynamic, a.k.a. Special, Variables
@anchor{#dynamic-a.k.a.-special-variables} Lexically scoped bindings
help keep code understandable by limiting the scope, literally, in
which a given name has meaning. This is why most modern languages use
lexical scoping for local variables. Sometimes, however, you really
want a global variable--a variable that you can refer to from anywhere
in your program. While it's true that indiscriminate use of global
variables can turn code into spaghetti nearly as quickly as
unrestrained use of @code{goto}, global variables do have legitimate
uses and exist in one form or another in almost every programming
language.@footnote{Java disguises global variables as public static
fields, C uses @code{extern} variables, and Python's module-level and
Perl's package-level variables can likewise be accessed from
anywhere.} And as you'll see in a moment, Lisp's version of global
variables, dynamic variables, are both more useful and more
manageable.

Common Lisp provides two ways to create global variables: @code{DEFVAR}
and @code{DEFPARAMETER}. Both forms take a variable name, an initial
value, and an optional documentation string. After it has been
@code{DEFVAR}ed or @code{DEFPARAMETER}ed, the name can be used anywhere
to refer to the current binding of the global variable. As you've seen
in previous chapters, global variables are conventionally named with
names that start and end with @code{*}. You'll see later in this section
why it's quite important to follow that naming convention. Examples of
@code{DEFVAR} and @code{DEFPARAMETER} look like this:

@verbatim
(defvar *count* 0
  "Count of widgets made so far.")

(defparameter *gap-tolerance* 0.001
  "Tolerance to be allowed in widget gaps.")
@end verbatim

The difference between the two forms is that @code{DEFPARAMETER} always
assigns the initial value to the named variable while @code{DEFVAR} does
so only if the variable is undefined. A @code{DEFVAR} form can also be
used with no initial value to define a global variable without giving it
a value. Such a variable is said to be @emph{unbound}.

Practically speaking, you should use @code{DEFVAR} to define variables
that will contain data you'd want to keep even if you made a change to
the source code that uses the variable. For instance, suppose the two
variables defined previously are part of an application for
controlling a widget factory. It's appropriate to define the
@code{*count*} variable with @code{DEFVAR} because the number of
widgets made so far isn't invalidated just because you make some
changes to the widget-making code.@footnote{If you specifically want
to reset a @code{DEFVAR}ed variable, you can either set it directly
with @code{SETF} or make it unbound using @code{MAKUNBOUND} and then
reevaluate the @code{DEFVAR} form.}

On the other hand, the variable @code{*gap-tolerance*} presumably has
some effect on the behavior of the widget-making code itself. If you
decide you need a tighter or looser tolerance and change the value in
the @code{DEFPARAMETER} form, you'd like the change to take effect when
you recompile and reload the file.

After defining a variable with @code{DEFVAR} or @code{DEFPARAMETER}, you
can refer to it from anywhere. For instance, you might define this
function to increment the count of widgets made:

@verbatim
(defun increment-widget-count () (incf *count*))
@end verbatim

The advantage of global variables is that you don't have to pass them
around. Most languages store the standard input and output streams in
global variables for exactly this reason--you never know when you're
going to want to print something to standard out, and you don't want
every function to have to accept and pass on arguments containing those
streams just in case someone further down the line needs them.

However, once a value, such as the standard output stream, is stored in
a global variable and you have written code that references that global
variable, it's tempting to try to temporarily modify the behavior of
that code by changing the variable's value.

For instance, suppose you're working on a program that contains some
low-level logging functions that print to the stream in the global
variable @code{*standard-output*}. Now suppose that in part of the
program you want to capture all the output generated by those functions
into a file. You might open a file and assign the resulting stream to
@code{*standard-output*}. Now the low-level functions will send their
output to the file.

This works fine until you forget to set @code{*standard-output*} back
to the original stream when you're done. If you forget to reset
@code{*standard-output*}, all the other code in the program that uses
@code{*standard-output*} will also send its output to the
file.@footnote{The strategy of temporarily reassigning
*standard-output* also breaks if the system is multithreaded--if there
are multiple threads of control trying to print to different streams
at the same time, they'll all try to set the global variable to the
stream they want to use, stomping all over each other. You could use a
lock to control access to the global variable, but then you're not
really getting the benefit of multiple concurrent threads, since
whatever thread is printing has to lock out all the other threads
until it's done even if they want to print to a different stream.}

What you really want, it seems, is a way to wrap a piece of code in
something that says, "All code below here--all the functions it calls,
all the functions they call, and so on, down to the lowest-level
functions--should use @emph{this} value for the global variable
@code{*standard-output*}." Then when the high-level function returns,
the old value of @code{*standard-output*} should be automatically
restored.

It turns out that that's exactly what Common Lisp's other kind of
variable--dynamic variables--let you do. When you bind a dynamic
variable--for example, with a @code{LET} variable or a function
parameter--the binding that's created on entry to the binding form
replaces the global binding for the duration of the binding
form. Unlike a lexical binding, which can be referenced by code only
within the lexical scope of the binding form, a dynamic binding can be
referenced by any code that's invoked during the execution of the
binding form.@footnote{The technical term for the interval during
which references may be made to a binding is its @emph{extent}. Thus,
@emph{scope} and @emph{extent} are complementary notions--scope refers
to space while extent refers to time. Lexical variables have lexical
scope but @emph{indefinite} extent, meaning they stick around for an
indefinite interval, determined by how long they're needed. Dynamic
variables, by contrast, have indefinite scope since they can be
referred to from anywhere but @emph{dynamic} extent. To further
confuse matters, the combination of indefinite scope and dynamic
extent is frequently referred to by the misnomer @emph{dynamic
scope}.} And it turns out that all global variables are, in fact,
dynamic variables.

Thus, if you want to temporarily redefine @code{*standard-output*}, the
way to do it is simply to rebind it, say, with a @code{LET}.

@verbatim
(let ((*standard-output* *some-other-stream*))
  (stuff))
@end verbatim

In any code that runs as a result of the call to @code{stuff},
references to @code{*standard-output*} will use the binding
established by the @code{LET}. And when @code{stuff} returns and
control leaves the @code{LET}, the new binding of
@code{*standard-output*} will go away and subsequent references to
@code{*standard-output*} will see the binding that was current before
the @code{LET}. At any given time, the most recently established
binding shadows all other bindings. Conceptually, each new binding for
a given dynamic variable is pushed onto a stack of bindings for that
variable, and references to the variable always use the most recent
binding. As binding forms return, the bindings they created are popped
off the stack, exposing previous bindings.@footnote{Though the
standard doesn't specify how to incorporate multithreading into Common
Lisp, implementations that provide multithreading follow the practice
established on the Lisp machines and create dynamic bindings on a
per-thread basis. A reference to a global variable will find the
binding most recently established in the current thread, or the global
binding.}

A simple example shows how this works.

@verbatim
(defvar *x* 10)
(defun foo () (format t "X: ~d~%" *x*))
@end verbatim

The @code{DEFVAR} creates a global binding for the variable @code{*x*}
with the value 10. The reference to @code{*x*} in @code{foo} will look
up the current binding dynamically. If you call @code{foo} from the top
level, the global binding created by the @code{DEFVAR} is the only
binding available, so it prints 10.

@verbatim
CL-USER> (foo)
X: 10
NIL
@end verbatim

But you can use @code{LET} to create a new binding that temporarily
shadows the global binding, and @code{foo} will print a different value.

@verbatim
CL-USER> (let ((*x* 20)) (foo))
X: 20
NIL
@end verbatim

Now call @code{foo} again, with no @code{LET}, and it again sees the
global binding.

@verbatim
CL-USER> (foo)
X: 10
NIL
@end verbatim

Now define another function.

@verbatim
(defun bar ()
  (foo)
  (let ((*x* 20)) (foo))
  (foo))
@end verbatim

Note that the middle call to @code{foo} is wrapped in a @code{LET} that
binds @code{*x*} to the new value 20. When you run @code{bar}, you get
this result:

@verbatim
CL-USER> (bar)
X: 10
X: 20
X: 10
NIL
@end verbatim

As you can see, the first call to @code{foo} sees the global binding,
with its value of 10. The middle call, however, sees the new binding,
with the value 20. But after the @code{LET}, @code{foo} once again sees
the global binding.

As with lexical bindings, assigning a new value affects only the current
binding. To see this, you can redefine @code{foo} to include an
assignment to @code{*x*}.

@verbatim
(defun foo ()
  (format t "Before assignment~18tX: ~d~%" *x*)
  (setf *x* (+ 1 *x*))
  (format t "After assignment~18tX: ~d~%" *x*))
@end verbatim

Now @code{foo} prints the value of @code{*x*}, increments it, and prints
it again. If you just run @code{foo}, you'll see this:

@verbatim
CL-USER> (foo)
Before assignment X: 10
After assignment  X: 11
NIL
@end verbatim

Not too surprising. Now run @code{bar}.

@verbatim
CL-USER> (bar)
Before assignment X: 11
After assignment  X: 12
Before assignment X: 20
After assignment  X: 21
Before assignment X: 12
After assignment  X: 13
NIL
@end verbatim

Notice that @code{*x*} started at 11--the earlier call to @code{foo}
really did change the global value. The first call to @code{foo} from
@code{bar} increments the global binding to 12. The middle call doesn't
see the global binding because of the @code{LET}. Then the last call can
see the global binding again and increments it from 12 to 13.

So how does this work? How does @code{LET} know that when it binds
@code{*x*} it's supposed to create a dynamic binding rather than a
normal lexical binding? It knows because the name has been declared
@emph{special}.@footnote{This is why dynamic variables are also
sometimes called @emph{special variables}.} The name of every variable
defined with @code{DEFVAR} and @code{DEFPARAMETER} is automatically
declared globally special. This means whenever you use such a name in
a binding form--in a @code{LET} or as a function parameter or any
other construct that creates a new variable binding--the binding
that's created will be a dynamic binding. This is why the
@code{*naming*} @code{*convention*} is so important--it'd be bad news
if you used a name for what you thought was a lexical variable and
that variable happened to be globally special. On the one hand, code
you call could change the value of the binding out from under you; on
the other, you might be shadowing a binding established by code higher
up on the stack. If you always name global variables according to the
@code{*} naming convention, you'll never accidentally use a dynamic
binding where you intend to establish a lexical binding.

It's also possible to declare a name locally special. If, in a binding
form, you declare a name special, then the binding created for that
variable will be dynamic rather than lexical. Other code can locally
declare a name special in order to refer to the dynamic binding.
However, locally special variables are relatively rare, so you needn't
worry about them.@footnote{If you must know, you can look up
@code{DECLARE}, @code{SPECIAL}, and @code{LOCALLY} in the HyperSpec.}

Dynamic bindings make global variables much more manageable, but it's
important to notice they still allow action at a distance. Binding a
global variable has two at a distance effects--it can change the
behavior of downstream code, and it also opens the possibility that
downstream code will assign a new value to a binding established higher
up on the stack. You should use dynamic variables only when you need to
take advantage of one or both of these characteristics.

@node Constants
@section Constants
@anchor{#constants}
One other kind of variable I haven't mentioned at all is the oxymoronic
"constant variable." All constants are global and are defined with
@code{DEFCONSTANT}. The basic form of @code{DEFCONSTANT} is like
@code{DEFPARAMETER}.

@verbatim
(defconstant name initial-value-form [ documentation-string ])
@end verbatim

As with @code{DEFVAR} and @code{DEFPARAMETER}, @code{DEFCONSTANT} has
a global effect on the name used--thereafter the name can be used only
to refer to the constant; it can't be used as a function parameter or
rebound with any other binding form. Thus, many Lisp programmers
follow a naming convention of using names starting and ending with
@code{+} for constants. This convention is somewhat less universally
followed than the @code{*}-naming convention for globally special
names but is a good idea for the same reason.@footnote{Several key
constants defined by the language itself don't follow this
convention--not least of which are @code{T} and @code{NIL}. This is
occasionally annoying when one wants to use @code{t} as a local
variable name. Another is @code{PI}, which holds the best long-float
approximation of the mathematical constant pi.}

Another thing to note about @code{DEFCONSTANT} is that while the
language allows you to redefine a constant by reevaluating a
@code{DEFCONSTANT} with a different initial-value-form, what exactly
happens after the redefinition isn't defined. In practice, most
implementations will require you to reevaluate any code that refers to
the constant in order to see the new value since the old value may well
have been inlined. Consequently, it's a good idea to use
@code{DEFCONSTANT} only to define things that are @emph{really}
constant, such as the value of NIL. For things you might ever want to
change, you should use @code{DEFPARAMETER} instead.

@node Assignment
@section Assignment
@anchor{#assignment}
Once you've created a binding, you can do two things with it: get the
current value and set it to a new value. As you saw in Chapter 4, a
symbol evaluates to the value of the variable it names, so you can get
the current value simply by referring to the variable. To assign a new
value to a binding, you use the @code{SETF} macro, Common Lisp's
general-purpose assignment operator. The basic form of @code{SETF} is as
follows:

@verbatim
(setf place value)
@end verbatim

Because @code{SETF} is a macro, it can examine the form of the
@emph{place} it's assigning to and expand into appropriate lower-level
operations to manipulate that place. When the place is a variable, it
expands into a call to the special operator @code{SETQ}, which, as a
special operator, has access to both lexical and dynamic
bindings.@footnote{Some old-school Lispers prefer to use @code{SETQ}
with variables, but modern style tends to use @code{SETF} for all
assignments.} For instance, to assign the value 10 to the variable
@code{x}, you can write this:

@verbatim
(setf x 10)
@end verbatim

As I discussed earlier, assigning a new value to a binding has no effect
on any other bindings of that variable. And it doesn't have any effect
on the value that was stored in the binding prior to the assignment.
Thus, the @code{SETF} in this function:

@verbatim
(defun foo (x) (setf x 10))
@end verbatim

will have no effect on any value outside of @code{foo}. The binding that
was created when @code{foo} was called is set to 10, immediately
replacing whatever value was passed as an argument. In particular, a
form such as the following:

@verbatim
(let ((y 20))
  (foo y)
  (print y))
@end verbatim

will print 20, not 10, as it's the value of @code{y} that's passed to
@code{foo} where it's briefly the value of the variable @code{x} before
the @code{SETF} gives @code{x} a new value.

@code{SETF} can also assign to multiple places in sequence. For
instance, instead of the following:

@verbatim
(setf x 1)
(setf y 2)
@end verbatim

you can write this:

@verbatim
(setf x 1 y 2)
@end verbatim

@code{SETF} returns the newly assigned value, so you can also nest calls
to @code{SETF} as in the following expression, which assigns both
@code{x} and @code{y} the same random value:

@verbatim
(setf x (setf y (random 10)))
@end verbatim

@node Generalized Assignment
@section Generalized Assignment
@anchor{#generalized-assignment}
Variable bindings, of course, aren't the only places that can hold
values. Common Lisp supports composite data structures such as arrays,
hash tables, and lists, as well as user-defined data structures, all of
which consist of multiple places that can each hold a value.

I'll cover those data structures in future chapters, but while we're
on the topic of assignment, you should note that @code{SETF }can
assign any place a value. As I cover the different composite data
structures, I'll point out which functions can serve as
"@code{SETF}able places." The short version, however, is if you need
to assign a value to a place, @code{SETF} is almost certainly the tool
to use. It's even possible to extend @code{SETF} to allow it to assign
to user-defined places though I won't cover that.@footnote{Look up
@code{DEFSETF}, @code{DEFINE-SETF-EXPANDER} for more information.}

In this regard @code{SETF} is no different from the @code{=} assignment
operator in most C-derived languages. In those languages, the @code{=}
operator assigns new values to variables, array elements, and fields of
classes. In languages such as Perl and Python that support hash tables
as a built-in data type, @code{=} can also set the values of individual
hash table entries. Table 6-1 summarizes the various ways @code{=} is
used in those languages.

Table 6-1. Assignment with @code{=} in Other Languages
@multitable {@strong{... hash table entry}} {@strong{Java, C, C++}} {@code{$o->@{'field'@} = 10;}} {@code{hash['key'] = 10}}
@item
@strong{Assigning to ...}
 @tab @strong{Java, C, C++}
 @tab @strong{Perl}
 @tab @strong{Python}
@item
@strong{... variable}
 @tab @code{x = 10;}
 @tab @code{$x = 10;}
 @tab @code{x = 10}
@item
@strong{... array element}
 @tab @code{a[0] = 10;}
 @tab @code{$a[0] = 10;}
 @tab @code{a[0] = 10}
@item
@strong{... hash table entry}
 @tab @code{--}
 @tab @code{$hash@{'key'@} = 10;}
 @tab @code{hash['key'] = 10}
@item
@strong{... field in object}
 @tab @code{o.field = 10;}
 @tab @code{$o->@{'field'@} = 10;}
 @tab @code{o.field = 10}
@end multitable

@code{SETF} works the same way--the first "argument" to @code{SETF} is
a place to store the value, and the second argument provides the
value. As with the @code{=} operator in these languages, you use the
same form to express the place as you'd normally use to fetch the
value.@footnote{The prevalence of Algol-derived syntax for assignment
with the "place" on the left side of the @code{=} and the new value on
the right side has spawned the terminology @emph{lvalue}, short for
"left value," meaning something that can be assigned to, and
@emph{rvalue}, meaning something that provides a value. A compiler
hacker would say, "@code{SETF} treats its first argument as an
lvalue."} Thus, the Lisp equivalents of the assignments in Table
6-1--given that @code{AREF} is the array access function,
@code{GETHASH} does a hash table lookup, and @code{field} might be a
function that accesses a slot named @code{field} of a user-defined
object--are as follows:

@verbatim
Simple variable:    (setf x 10)
Array:              (setf (aref a 0) 10)
Hash table:         (setf (gethash 'key hash) 10)
Slot named 'field': (setf (field o) 10)
@end verbatim

Note that @code{SETF}ing a place that's part of a larger object has
the same semantics as @code{SETF}ing a variable: the place is modified
without any effect on the object that was previously stored in the
place. Again, this is similar to how @code{=} behaves in Java, Perl,
and Python.@footnote{C programmers may want to think of variables and
other places as holding a pointer to the real object; assigning to a
variable simply changes what object it points to while assigning to a
part of a composite object is similar to indirecting through the
pointer to the actual object. C++ programmers should note that the
behavior of @code{=} in C++ when dealing with objects--namely, a
memberwise copy--is quite idiosyncratic.}

@node Other Ways to Modify Places
@section Other Ways to Modify Places
@anchor{#other-ways-to-modify-places}
While all assignments can be expressed with @code{SETF}, certain
patterns involving assigning a new value based on the current value are
sufficiently common to warrant their own operators. For instance, while
you could increment a number with @code{SETF}, like this:

@verbatim
(setf x (+ x 1))
@end verbatim

or decrement it with this:

@verbatim
(setf x (- x 1))
@end verbatim

it's a bit tedious, compared to the C-style @code{++x} and @code{--x}.
Instead, you can use the macros @code{INCF} and @code{DECF}, which
increment and decrement a place by a certain amount that defaults to 1.

@verbatim
(incf x)    === (setf x (+ x 1))
(decf x)    === (setf x (- x 1))
(incf x 10) === (setf x (+ x 10))
@end verbatim

@code{INCF} and @code{DECF} are examples of a kind of macro called
@emph{modify macros}. Modify macros are macros built on top of
@code{SETF} that modify places by assigning a new value based on the
current value of the place. The main benefit of modify macros is that
they're more concise than the same modification written out using
@code{SETF}. Additionally, modify macros are defined in a way that makes
them safe to use with places where the place expression must be
evaluated only once. A silly example is this expression, which
increments the value of an arbitrary element of an array:

@verbatim
(incf (aref *array* (random (length *array*))))
@end verbatim

A naive translation of that into a @code{SETF} expression might look
like this:

@verbatim
(setf (aref *array* (random (length *array*)))
      (1+ (aref *array* (random (length *array*)))))
@end verbatim

However, that doesn't work because the two calls to @code{RANDOM} won't
necessarily return the same value--this expression will likely grab the
value of one element of the array, increment it, and then store it back
as the new value of a different element. The @code{INCF} expression,
however, does the right thing because it knows how to take apart this
expression:

@verbatim
(aref *array* (random (length *array*)))
@end verbatim

to pull out the parts that could possibly have side effects to make sure
they're evaluated only once. In this case, it would probably expand into
something more or less equivalent to this:

@verbatim
(let ((tmp (random (length *array*))))
  (setf (aref *array* tmp) (1+ (aref *array* tmp))))
@end verbatim

In general, modify macros are guaranteed to evaluate both their
arguments and the subforms of the place form exactly once each, in
left-to-right order.

The macro @code{PUSH}, which you used in the mini-database to add
elements to the @code{*db*} variable, is another modify macro. You'll
take a closer look at how it and its counterparts @code{POP} and
@code{PUSHNEW} work in Chapter 12 when I talk about how lists are
represented in Lisp.

Finally, two slightly esoteric but useful modify macros are
@code{ROTATEF} and @code{SHIFTF}. @code{ROTATEF} rotates values between
places. For instance, if you have two variables, @code{a} and @code{b},
this call:

@verbatim
(rotatef a b)
@end verbatim

swaps the values of the two variables and returns @code{NIL}. Since
@code{a} and @code{b} are variables and you don't have to worry about
side effects, the previous @code{ROTATEF} expression is equivalent to
this:

@verbatim
(let ((tmp a)) (setf a b b tmp) nil)
@end verbatim

With other kinds of places, the equivalent expression using @code{SETF}
would be quite a bit more complex.

@code{SHIFTF} is similar except instead of rotating values it shifts
them to the left--the last argument provides a value that's moved to the
second-to-last argument while the rest of the values are moved one to
the left. The original value of the first argument is simply returned.
Thus, the following:

@verbatim
(shiftf a b 10)
@end verbatim

is equivalent--again, since you don't have to worry about side
effects--to this:

@verbatim
(let ((tmp a)) (setf a b b 10) tmp)
@end verbatim

Both @code{ROTATEF} and @code{SHIFTF} can be used with any number of
arguments and, like all modify macros, are guaranteed to evaluate them
exactly once, in left to right order.

With the basics of Common Lisp's functions and variables under your
belt, now you're ready to move onto the feature that continues to
differentiate Lisp from other languages: macros.

@node Macros Standard Control Constructs
@chapter Macros: Standard Control Constructs
@anchor{#macros-standard-control-constructs} While many of the ideas
that originated in Lisp, from the conditional expression to garbage
collection, have been incorporated into other languages, the one
language feature that continues to set Common Lisp apart is its macro
system. Unfortunately, the word @emph{macro} describes a lot of things
in computing to which Common Lisp's macros bear only a vague and
metaphorical similarity. This causes no end of misunderstanding when
Lispers try to explain to non-Lispers what a great feature macros
are.@footnote{To see what this misunderstanding looks like, find any
longish Usenet thread cross-posted between comp.lang.lisp and any
other comp.lang.* group with @emph{macro} in the subject. A rough
paraphrase goes like this:

Lispnik: "Lisp is the best because of its macros!";

Othernik: "You think Lisp is good @emph{because of} macros?! But
macros are horrible and evil; Lisp must be horrible and evil."} To
understand Lisp's macros, you really need to come at them fresh,
without preconceptions based on other things that also happen to be
called macros. So let's start our discussion of Lisp's macros by
taking a step back and looking at various ways languages support
extensibility.

All programmers should be used to the idea that the definition of a
language can include a standard library of functionality that's
implemented in terms of the "core" language--functionality that could
have been implemented by any programmer on top of the language if it
hadn't been defined as part of the standard library. C's standard
library, for instance, can be implemented almost entirely in portable C.
Similarly, most of the ever-growing set of classes and interfaces that
ship with Java's standard Java Development Kit (JDK) are written in
"pure" Java.

One advantage of defining languages in terms of a core plus a standard
library is it makes them easier to understand and implement. But the
real benefit is in terms of expressiveness--since much of what you think
of as "the language" is really just a library--the language is easy to
extend. If C doesn't have a function to do some thing or another that
you need, you can write that function, and now you have a slightly
richer version of C. Similarly, in a language such as Java or Smalltalk
where almost all the interesting parts of the "language" are defined in
terms of classes, by defining new classes you extend the language,
making it more suited for writing programs to do whatever it is you're
trying to do.

While Common Lisp supports both these methods of extending the language,
macros give Common Lisp yet another way. As I discussed briefly in
Chapter 4, each macro defines its own syntax, determining how the
s-expressions it's passed are turned into Lisp forms. With macros as
part of the core language it's possible to build new syntax--control
constructs such as @code{WHEN}, @code{DOLIST}, and @code{LOOP} as well
as definitional forms such as @code{DEFUN} and @code{DEFPARAMETER}--as
part of the "standard library" rather than having to hardwire them into
the core. This has implications for how the language itself is
implemented, but as a Lisp programmer you'll care more that it gives you
another way to extend the language, making it a better language for
expressing solutions to your particular programming problems.

Now, it may seem that the benefits of having another way to extend the
language would be easy to recognize. But for some reason a lot of
folks who haven't actually used Lisp macros--folks who think nothing
of spending their days creating new functional abstractions or
defining hierarchies of classes to solve their programming
problems--get spooked by the idea of being able to define new
syntactic abstractions. The most common cause of macrophobia seems to
be bad experiences with other "macro" systems. Simple fear of the
unknown no doubt plays a role, too.  To avoid triggering any
macrophobic reactions, I'll ease into the subject by discussing
several of the standard control-construct macros defined by Common
Lisp. These are some of the things that, if Lisp didn't have macros,
would have to be built into the language core. When you use them, you
don't have to care that they're implemented as macros, but they
provide a good example of some of the things you can do with
macros.@footnote{Another important class of language constructs that
are defined using macros are all the definitional constructs such as
@code{DEFUN}, @code{DEFPARAMETER}, @code{DEFVAR}, and others. In
Chapter 24 you'll define your own definitional macros that will allow
you to concisely write code for reading and writing binary data.} In
the next chapter, I'll show you how you can define your own macros.

@menu
* WHEN and UNLESS::
* COND::
* AND OR and NOT::
* Looping::
* DOLIST and DOTIMES::
* DO::
* The Mighty LOOP::
@end menu

@node WHEN and UNLESS
@section WHEN and UNLESS
@anchor{#when-and-unless}
As you've already seen, the most basic form of conditional execution--if
@emph{x}, do @emph{y}; otherwise do @emph{z}--is provided by the
@code{IF} special operator, which has this basic form:

@verbatim
(if condition then-form [else-form])
@end verbatim

The @emph{condition} is evaluated and, if its value is non-@code{NIL},
the @emph{then-form} is evaluated and the resulting value returned.
Otherwise, the @emph{else-form}, if any, is evaluated and its value
returned. If @emph{condition} is @code{NIL} and there's no
@emph{else-form}, then the @code{IF} returns @code{NIL}.

@verbatim
(if (> 2 3) "Yup" "Nope") ==> "Nope"
(if (> 2 3) "Yup")        ==> NIL
(if (> 3 2) "Yup" "Nope") ==> "Yup"
@end verbatim

However, @code{IF} isn't actually such a great syntactic construct
because the @emph{then-form} and @emph{else-form} are each restricted to
being a single Lisp form. This means if you want to perform a sequence
of actions in either clause, you need to wrap them in some other syntax.
For instance, suppose in the middle of a spam-filtering program you
wanted to both file a message as spam and update the spam database when
a message is spam. You can't write this:

@verbatim
(if (spam-p current-message)
    (file-in-spam-folder current-message)
    (update-spam-database current-message))
@end verbatim

because the call to @code{update-spam-database} will be treated as the
else clause, not as part of the then clause. Another special operator,
@code{PROGN}, executes any number of forms in order and returns the
value of the last form. So you could get the desired behavior by writing
the following:

@verbatim
(if (spam-p current-message)
    (progn
      (file-in-spam-folder current-message)
      (update-spam-database current-message)))
@end verbatim

That's not too horrible. But given the number of times you'll likely
have to use this idiom, it's not hard to imagine that you'd get tired of
it after a while. "Why," you might ask yourself, "doesn't Lisp provide a
way to say what I really want, namely, 'When @emph{x} is true, do this,
that, and the other thing'?" In other words, after a while you'd notice
the pattern of an @code{IF} plus a @code{PROGN} and wish for a way to
abstract away the details rather than writing them out every time.

This is exactly what macros provide. In this case, Common Lisp comes
with a standard macro, @code{WHEN}, which lets you write this:

@verbatim
(when (spam-p current-message)
  (file-in-spam-folder current-message)
  (update-spam-database current-message))
@end verbatim

But if it wasn't built into the standard library, you could define
@code{WHEN} yourself with a macro such as this, using the backquote
notation I discussed in Chapter 3:@footnote{You can't actually feed
this definition to Lisp because it's illegal to redefine names in the
@code{COMMON-LISP} package where @code{WHEN} comes from. If you really
want to try writing such a macro, you'd need to change the name to
something else, such as @code{my-when}.}

@verbatim
(defmacro when (condition &rest body)
  `(if ,condition (progn ,@body)))
@end verbatim

A counterpart to the @code{WHEN} macro is @code{UNLESS}, which reverses
the condition, evaluating its body forms only if the condition is false.
In other words:

@verbatim
(defmacro unless (condition &rest body)
  `(if (not ,condition) (progn ,@body)))
@end verbatim

Admittedly, these are pretty trivial macros. There's no deep black magic
here; they just abstract away a few language-level bookkeeping details,
allowing you to express your true intent a bit more clearly. But their
very triviality makes an important point: because the macro system is
built right into the language, you can write trivial macros like
@code{WHEN} and @code{UNLESS} that give you small but real gains in
clarity that are then multiplied by the thousands of times you use them.
In Chapters 24, 26, and 31 you'll see how macros can also be used on a
larger scale, creating whole domain-specific embedded languages. But
first let's finish our discussion of the standard control-construct
macros.

@node COND
@section COND
@anchor{#cond}
Another time raw @code{IF} expressions can get ugly is when you have a
multibranch conditional: if @emph{a} do @emph{x}, else if @emph{b} do
@emph{y}; else do @emph{z}. There's no logical problem writing such a
chain of conditional expressions with just @code{IF}, but it's not
pretty.

@verbatim
(if a
    (do-x)
    (if b
       (do-y)
       (do-z)))
@end verbatim

And it would be even worse if you needed to include multiple forms in
the then clauses, requiring @code{PROGN}s. So, not surprisingly, Common
Lisp provides a macro for expressing multibranch conditionals:
@code{COND}. This is the basic skeleton:

@verbatim
(cond
  (test-1 form*)
      .
      .
      .
  (test-N form*))
@end verbatim

Each element of the body represents one branch of the conditional and
consists of a list containing a condition form and zero or more forms to
be evaluated if that branch is chosen. The conditions are evaluated in
the order the branches appear in the body until one of them evaluates to
true. At that point, the remaining forms in that branch are evaluated,
and the value of the last form in the branch is returned as the value of
the @code{COND} as a whole. If the branch contains no forms after the
condition, the value of the condition is returned instead. By
convention, the branch representing the final else clause in an
if/else-if chain is written with a condition of @code{T}. Any
non-@code{NIL} value will work, but a @code{T} serves as a useful
landmark when reading the code. Thus, you can write the previous nested
@code{IF} expression using @code{COND} like this:

@verbatim
(cond (a (do-x))
      (b (do-y))
      (t (do-z)))
@end verbatim

@node AND OR and NOT
@section AND, OR, and NOT
@anchor{#and-or-and-not}
When writing the conditions in @code{IF}, @code{WHEN}, @code{UNLESS},
and @code{COND} forms, three operators that will come in handy are the
boolean logic operators, @code{AND}, @code{OR}, and @code{NOT}.

@code{NOT} is a function so strictly speaking doesn't belong in this
chapter, but it's closely tied to @code{AND} and @code{OR}. It takes a
single argument and inverts its truth value, returning @code{T} if the
argument is @code{NIL} and @code{NIL} otherwise.

@code{AND} and @code{OR}, however, are macros. They implement logical
conjunction and disjunction of any number of subforms and are defined as
macros so they can @emph{short-circuit}. That is, they evaluate only as
many of their subforms--in left-to-right order--as necessary to
determine the overall truth value. Thus, @code{AND} stops and returns
@code{NIL} as soon as one of its subforms evaluates to @code{NIL}. If
all the subforms evaluate to non-@code{NIL}, it returns the value of the
last subform. @code{OR}, on the other hand, stops as soon as one of its
subforms evaluates to non-@code{NIL} and returns the resulting value. If
none of the subforms evaluate to true, @code{OR} returns @code{NIL}.
Here are some examples:

@verbatim
(not nil)             ==> T
(not (= 1 1))         ==> NIL
(and (= 1 2) (= 3 3)) ==> NIL
(or (= 1 2) (= 3 3))  ==> T
@end verbatim

@node Looping
@section Looping
@anchor{#looping}
Control constructs are the other main kind of looping constructs. Common
Lisp's looping facilities are--in addition to being quite powerful and
flexible--an interesting lesson in the have-your-cake-and-eat-it-too
style of programming that macros provide.

As it turns out, none of Lisp's 25 special operators directly support
structured looping. All of Lisp's looping control constructs are
macros built on top of a pair of special operators that provide a
primitive goto facility.@footnote{The special operators, if you must
know, are @code{TAGBODY} and @code{GO}. There's no need to discuss
them now, but I'll cover them in Chapter 20.} Like many good
abstractions, syntactic or otherwise, Lisp's looping macros are built
as a set of layered abstractions starting from the base provided by
those two special operators.

At the bottom (leaving aside the special operators) is a very general
looping construct, @code{DO}. While very powerful, @code{DO} suffers, as
do many general-purpose abstractions, from being overkill for simple
situations. So Lisp also provides two other macros, @code{DOLIST} and
@code{DOTIMES}, that are less flexible than @code{DO} but provide
convenient support for the common cases of looping over the elements of
a list and counting loops. While an implementation can implement these
macros however it wants, they're typically implemented as macros that
expand into an equivalent @code{DO} loop. Thus, @code{DO} provides a
basic structured looping construct on top of the underlying primitives
provided by Common Lisp's special operators, and @code{DOLIST} and
@code{DOTIMES} provide two easier-to-use, if less general, constructs.
And, as you'll see in the next chapter, you can build your own looping
constructs on top of @code{DO} for situations where @code{DOLIST} and
@code{DOTIMES} don't meet your needs.

Finally, the @code{LOOP} macro provides a full-blown mini-language for
expressing looping constructs in a non-Lispy, English-like (or at least
Algol-like) language. Some Lisp hackers love @code{LOOP}; others hate
it. @code{LOOP}'s fans like it because it provides a concise way to
express certain commonly needed looping constructs. Its detractors
dislike it because it's not Lispy enough. But whichever side one comes
down on, it's a remarkable example of the power of macros to add new
constructs to the language.

@node DOLIST and DOTIMES
@section DOLIST and DOTIMES
@anchor{#dolist-and-dotimes}
I'll start with the easy-to-use @code{DOLIST} and @code{DOTIMES} macros.

@code{DOLIST} loops across the items of a list, executing the loop
body with a variable holding the successive items of the
list.@footnote{@code{DOLIST} is similar to Perl's @code{foreach} or
Python's @code{for}. Java added a similar kind of loop construct with
the "enhanced" @code{for} loop in Java 1.5, as part of JSR-201. Notice
what a difference macros make. A Lisp programmer who notices a common
pattern in their code can write a macro to give themselves a
source-level abstraction of that pattern. A Java programmer who
notices the same pattern has to convince Sun that this particular
abstraction is worth adding to the language. Then Sun has to publish a
JSR and convene an industry-wide "expert group" to hash everything
out. That process--according to Sun--takes an average of 18
months. After that, the compiler writers all have to go upgrade their
compilers to support the new feature. And even once the Java
programmer's favorite compiler supports the new version of Java, they
probably @emph{still} can't use the new feature until they're allowed
to break source compatibility with older versions of Java. So an
annoyance that Common Lisp programmers can resolve for themselves
within five minutes plagues Java programmers for years.} This is the
basic skeleton (leaving out some of the more esoteric options):

@verbatim
(dolist (var list-form)
  body-form*)
@end verbatim

When the loop starts, the @emph{list-form} is evaluated once to produce
a list. Then the body of the loop is evaluated once for each item in the
list with the variable @emph{var} holding the value of the item. For
instance:

@verbatim
CL-USER> (dolist (x '(1 2 3)) (print x))
1
2
3
NIL
@end verbatim

Used this way, the @code{DOLIST} form as a whole evaluates to
@code{NIL}.

If you want to break out of a @code{DOLIST} loop before the end of the
list, you can use @code{RETURN}.

@verbatim
CL-USER> (dolist (x '(1 2 3)) (print x) (if (evenp x) (return)))
1
2
NIL
@end verbatim

@code{DOTIMES} is the high-level looping construct for counting loops.
The basic template is much the same as @code{DOLIST}'s.

@verbatim
(dotimes (var count-form)
  body-form*)
@end verbatim

The @emph{count-form} must evaluate to an integer. Each time through the
loop @emph{var} holds successive integers from 0 to one less than that
number. For instance:

@verbatim
CL-USER> (dotimes (i 4) (print i))
0
1
2
3
NIL
@end verbatim

As with @code{DOLIST}, you can use @code{RETURN} to break out of the
loop early.

Because the body of both @code{DOLIST} and @code{DOTIMES} loops can
contain any kind of expressions, you can also nest loops. For example,
to print out the times tables from @code{1 x 1 = 1} to
@code{20 x 20 = 400}, you can write this pair of nested @code{DOTIMES}
loops:

@verbatim
(dotimes (x 20)
  (dotimes (y 20)
    (format t "~3d " (* (1+ x) (1+ y))))
  (format t "~%"))
@end verbatim

@node DO
@section DO
@anchor{#do}
While @code{DOLIST} and @code{DOTIMES} are convenient and easy to use,
they aren't flexible enough to use for all loops. For instance, what if
you want to step multiple variables in parallel? Or use an arbitrary
expression to test for the end of the loop? If neither @code{DOLIST} nor
@code{DOTIMES} meet your needs, you still have access to the more
general @code{DO} loop.

Where @code{DOLIST} and @code{DOTIMES} provide only one loop variable,
@code{DO} lets you bind any number of variables and gives you complete
control over how they change on each step through the loop. You also get
to define the test that determines when to end the loop and can provide
a form to evaluate at the end of the loop to generate a return value for
the @code{DO} expression as a whole. The basic template looks like this:

@verbatim
(do (variable-definition*)
    (end-test-form result-form*)
  statement*)
@end verbatim

Each @emph{variable-definition} introduces a variable that will be in
scope in the body of the loop. The full form of a single variable
definition is a list containing three elements.

@verbatim
(var init-form step-form)
@end verbatim

The @emph{init-form} will be evaluated at the beginning of the loop and
the resulting values bound to the variable @emph{var}. Before each
subsequent iteration of the loop, the @emph{step-form} will be evaluated
and the new value assigned to @emph{var}. The @emph{step-form} is
optional; if it's left out, the variable will keep its value from
iteration to iteration unless you explicitly assign it a new value in
the loop body. As with the variable definitions in a @code{LET}, if the
@emph{init-form} is left out, the variable is bound to @code{NIL}. Also
as with @code{LET}, you can use a plain variable name as shorthand for a
list containing just the name.

At the beginning of each iteration, after all the loop variables have
been given their new values, the @emph{end-test-form} is evaluated. As
long as it evaluates to @code{NIL}, the iteration proceeds, evaluating
the @emph{statements} in order.

When the @emph{end-test-form} evaluates to true, the @emph{result-forms}
are evaluated, and the value of the last result form is returned as the
value of the @code{DO} expression.

At each step of the iteration the step forms for all the variables are
evaluated before assigning any of the values to the variables. This
means you can refer to any of the other loop variables in the step
forms.@footnote{A variant of @code{DO}, @code{DO*}, assigns each
variable its value before evaluating the step form for subsequent
variables. For more details, consult your favorite Common Lisp
reference.} That is, in a loop like this:

@verbatim
(do ((n 0 (1+ n))
     (cur 0 next)
     (next 1 (+ cur next)))
    ((= 10 n) cur))
@end verbatim

the step forms @code{(1+ n)}, @code{next}, and @code{(+ cur next)} are
all evaluated using the old values of @code{n}, @code{cur}, and
@code{next}. Only after all the step forms have been evaluated are the
variables given their new values. (Mathematically inclined readers may
notice that this is a particularly efficient way of computing the
eleventh Fibonacci number.)

This example also illustrates another characteristic of
@code{DO}--because you can step multiple variables, you often don't need
a body at all. Other times, you may leave out the result form,
particularly if you're just using the loop as a control construct. This
flexibility, however, is the reason that @code{DO} expressions can be a
bit cryptic. Where exactly do all the parentheses go? The best way to
understand a @code{DO} expression is to keep in mind the basic template.

@verbatim
(do (variable-definition*)
    (end-test-form result-form*)
  statement*)
@end verbatim

The six parentheses in that template are the only ones required by the
@code{DO} itself. You need one pair to enclose the variable
declarations, one pair to enclose the end test and result forms, and one
pair to enclose the whole expression. Other forms within the @code{DO}
may require their own parentheses--variable definitions are usually
lists, for instance. And the test form is often a function call. But the
skeleton of a @code{DO} loop will always be the same. Here are some
example @code{DO} loops with the skeleton in bold:

@verbatim
(do ((i 0 (1+ i)))
    ((>= i 4))
  (print i))
@end verbatim

Notice that the result form has been omitted. This is, however, not a
particularly idiomatic use of @code{DO}, as this loop is much more
simply written using @code{DOTIMES}.@footnote{The @code{DOTIMES} is
also preferred because the macro expansion will likely include
declarations that allow the compiler to generate more efficient code.}

@verbatim
(dotimes (i 4) (print i))
@end verbatim

As another example, here's the bodiless Fibonacci-computing loop:

@verbatim
(do ((n 0 (1+ n))
     (cur 0 next)
     (next 1 (+ cur next)))
    ((= 10 n) cur))
@end verbatim

Finally, the next loop demonstrates a @code{DO} loop that binds no
variables. It loops while the current time is less than the value of a
global variable, printing "Waiting" once a minute. Note that even with
no loop variables, you still need the empty variables list.

@verbatim
(do ()
    ((> (get-universal-time) *some-future-date*))
  (format t "Waiting~%")
  (sleep 60))
@end verbatim

@node The Mighty LOOP
@section The Mighty LOOP
@anchor{#the-mighty-loop}
For the simple cases you have @code{DOLIST} and @code{DOTIMES}. And if
they don't suit your needs, you can fall back on the completely general
@code{DO}. What more could you want?

Well, it turns out a handful of looping idioms come up over and over
again, such as looping over various data structures: lists, vectors,
hash tables, and packages. Or accumulating values in various ways while
looping: collecting, counting, summing, minimizing, or maximizing. If
you need a loop to do one of these things (or several at the same time),
the @code{LOOP} macro may give you an easier way to express it.

The @code{LOOP} macro actually comes in two flavors--@emph{simple} and
@emph{extended}. The simple version is as simple as can be--an infinite
loop that doesn't bind any variables. The skeleton looks like this:

@verbatim
(loop
  body-form*)
@end verbatim

The forms in body are evaluated each time through the loop, which will
iterate forever unless you use @code{RETURN} to break out. For example,
you could write the previous @code{DO} loop with a simple @code{LOOP}.

@verbatim
(loop
  (when (> (get-universal-time) *some-future-date*)
    (return))
  (format t "Waiting~%")
  (sleep 60))
@end verbatim

The extended @code{LOOP} is quite a different beast. It's distinguished
by the use of certain @emph{loop keywords} that implement a
special-purpose language for expressing looping idioms. It's worth
noting that not all Lispers love the extended @code{LOOP} language. At
least one of Common Lisp's original designers hated it. @code{LOOP}'s
detractors complain that its syntax is totally un-Lispy (in other words,
not enough parentheses). @code{LOOP}'s fans counter that that's the
point: complicated looping constructs are hard enough to understand
without wrapping them up in @code{DO}'s cryptic syntax. It's better,
they say, to have a slightly more verbose syntax that gives you some
clues what the heck is going on.

For instance, here's an idiomatic @code{DO} loop that collects the
numbers from 1 to 10 into a list:

@verbatim
(do ((nums nil) (i 1 (1+ i)))
    ((> i 10) (nreverse nums))
  (push i nums)) ==> (1 2 3 4 5 6 7 8 9 10)
@end verbatim

A seasoned Lisper won't have any trouble understanding that code--it's
just a matter of understanding the basic form of a @code{DO} loop and
recognizing the @code{PUSH}/@code{NREVERSE} idiom for building up a
list. But it's not exactly transparent. The @code{LOOP} version, on the
other hand, is almost understandable as an English sentence.

@verbatim
(loop for i from 1 to 10 collecting i) ==> (1 2 3 4 5 6 7 8 9 10)
@end verbatim

The following are some more examples of simple uses of @code{LOOP}. This
sums the first ten squares:

@verbatim
(loop for x from 1 to 10 summing (expt x 2)) ==> 385
@end verbatim

This counts the number of vowels in a string:

@verbatim
(loop for x across "the quick brown fox jumps over the lazy dog"
      counting (find x "aeiou")) ==> 11
@end verbatim

This computes the eleventh Fibonacci number, similar to the @code{DO}
loop used earlier:

@verbatim
(loop for i below 10
      and a = 0 then b
      and b = 1 then (+ b a)
      finally (return  a))
@end verbatim

The symbols @code{across}, @code{and}, @code{below},
@code{collecting}, @code{counting}, @code{finally}, @code{for},
@code{from}, @code{summing}, @code{then}, and @code{to} are some of
the loop keywords whose presence identifies these as instances of the
extended @code{LOOP}.@footnote{@emph{Loop keywords} is a bit of a
misnomer since they aren't keyword symbols. In fact, @code{LOOP}
doesn't care what package the symbols are from. When the @code{LOOP}
macro parses its body, it considers any appropriately named symbols
equivalent. You could even use true keywords if you
wanted--@code{:for}, @code{:across}, and so on--because they also have
the correct name. But most folks just use plain symbols. Because the
loop keywords are used only as syntactic markers, it doesn't matter if
they're used for other purposes--as function or variable names.}

I'll save the details of @code{LOOP} for Chapter 22, but it's worth
noting here as another example of the way macros can be used to extend
the base language. While @code{LOOP} provides its own language for
expressing looping constructs, it doesn't cut you off from the rest of
Lisp. The loop keywords are parsed according to loop's grammar, but the
rest of the code in a @code{LOOP} is regular Lisp code.

And it's worth pointing out one more time that while the @code{LOOP}
macro is quite a bit more complicated than macros such as @code{WHEN} or
@code{UNLESS}, it @emph{is} just another macro. If it hadn't been
included in the standard library, you could implement it yourself or get
a third-party library that does.

With that I'll conclude our tour of the basic control-construct macros.
Now you're ready to take a closer look at how to define your own macros.

@node Macros Defining Your Own
@chapter Macros: Defining Your Own
@anchor{#macros-defining-your-own}
Now it's time to start writing your own macros. The standard macros I
covered in the previous chapter hint at some of the things you can do
with macros, but that's just the beginning. Common Lisp doesn't support
macros so every Lisp programmer can create their own variants of
standard control constructs any more than C supports functions so every
C programmer can write trivial variants of the functions in the C
standard library. Macros are part of the language to allow you to create
abstractions on top of the core language and standard library that move
you closer toward being able to directly express the things you want to
express.

Perhaps the biggest barrier to a proper understanding of macros is,
ironically, that they're so well integrated into the language. In many
ways they seem like just a funny kind of function--they're written in
Lisp, they take arguments and return results, and they allow you to
abstract away distracting details. Yet despite these many similarities,
macros operate at a different level than functions and create a totally
different kind of abstraction.

Once you understand the difference between macros and functions, the
tight integration of macros in the language will be a huge benefit. But
in the meantime, it's a frequent source of confusion for new Lispers.
The following story, while not true in a historical or technical sense,
tries to alleviate the confusion by giving you a way to think about how
macros work.
@menu
* The Story of Mac A Just-So Story::
* Macro Expansion Time vs Runtime::
* DEFMACRO::
* A Sample Macro do-primes::
* Macro Parameters::
* Generating the Expansion::
* Plugging the Leaks::
* Macro-Writing Macros::
* Beyond Simple Macros::
@end menu

@node The Story of Mac A Just-So Story
@section The Story of Mac: A Just-So Story
@anchor{#the-story-of-mac-a-just-so-story}
Once upon a time, long ago, there was a company of Lisp programmers. It
was so long ago, in fact, that Lisp had no macros. Anything that
couldn't be defined with a function or done with a special operator had
to be written in full every time, which was rather a drag.
Unfortunately, the programmers in this company--though brilliant--were
also quite lazy. Often in the middle of their programs--when the tedium
of writing a bunch of code got to be too much--they would instead write
a note describing the code they needed to write at that place in the
program. Even more unfortunately, because they were lazy, the
programmers also hated to go back and actually write the code described
by the notes. Soon the company had a big stack of programs that nobody
could run because they were full of notes about code that still needed
to be written.

In desperation, the big bosses hired a junior programmer, Mac, whose job
was to find the notes, write the required code, and insert it into the
program in place of the notes. Mac never ran the programs--they weren't
done yet, of course, so he couldn't. But even if they had been
completed, Mac wouldn't have known what inputs to feed them. So he just
wrote his code based on the contents of the notes and sent it back to
the original programmer.

With Mac's help, all the programs were soon completed, and the company
made a ton of money selling them--so much money that the company could
double the size of its programming staff. But for some reason no one
thought to hire anyone to help Mac; soon he was single- handedly
assisting several dozen programmers. To avoid spending all his time
searching for notes in source code, Mac made a small modification to the
compiler the programmers used. Thereafter, whenever the compiler hit a
note, it would e-mail him the note and wait for him to e-mail back the
replacement code. Unfortunately, even with this change, Mac had a hard
time keeping up with the programmers. He worked as carefully as he
could, but sometimes-- especially when the notes weren't clear--he would
make mistakes.

The programmers noticed, however, that the more precisely they wrote
their notes, the more likely it was that Mac would send back correct
code. One day, one of the programmers, having a hard time describing in
words the code he wanted, included in one of his notes a Lisp program
that would generate the code he wanted. That was fine by Mac; he just
ran the program and sent the result to the compiler.

The next innovation came when a programmer put a note at the top of one
of his programs containing a function definition and a comment that
said, "Mac, don't write any code here, but keep this function for later;
I'm going to use it in some of my other notes." Other notes in the same
program said things such as, "Mac, replace this note with the result of
running that other function with the symbols @code{x} and @code{y} as
arguments."

This technique caught on so quickly that within a few days, most
programs contained dozens of notes defining functions that were only
used by code in other notes. To make it easy for Mac to pick out the
notes containing only definitions that didn't require any immediate
response, the programmers tagged them with the standard preface:
"Definition for Mac, Read Only." This--as the programmers were still
quite lazy--was quickly shortened to "DEF. MAC. R/O" and then
"DEFMACRO."

Pretty soon, there was no actual English left in the notes for Mac. All
he did all day was read and respond to e-mails from the compiler
containing DEFMACRO notes and calls to the functions defined in the
DEFMACROs. Since the Lisp programs in the notes did all the real work,
keeping up with the e-mails was no problem. Mac suddenly had a lot of
time on his hands and would sit in his office daydreaming about
white-sand beaches, clear blue ocean water, and drinks with little paper
umbrellas in them.

Several months later the programmers realized nobody had seen Mac for
quite some time. When they went to his office, they found a thin layer
of dust over everything, a desk littered with travel brochures for
various tropical locations, and the computer off. But the compiler still
worked--how could it be? It turned out Mac had made one last change to
the compiler: instead of e-mailing notes to Mac, the compiler now saved
the functions defined by DEFMACRO notes and ran them when called for by
the other notes. The programmers decided there was no reason to tell the
big bosses Mac wasn't coming to the office anymore. So to this day, Mac
draws a salary and from time to time sends the programmers a postcard
from one tropical locale or another.

@node Macro Expansion Time vs Runtime
@section Macro Expansion Time vs. Runtime
@anchor{#macro-expansion-time-vs.-runtime}
The key to understanding macros is to be quite clear about the
distinction between the code that generates code (macros) and the code
that eventually makes up the program (everything else). When you write
macros, you're writing programs that will be used by the compiler to
generate the code that will then be compiled. Only after all the macros
have been fully expanded and the resulting code compiled can the program
actually be run. The time when macros run is called @emph{macro
expansion time}; this is distinct from @emph{runtime}, when regular
code, including the code generated by macros, runs.

It's important to keep this distinction firmly in mind because code
running at macro expansion time runs in a very different environment
than code running at runtime. Namely, at macro expansion time, there's
no way to access the data that will exist at runtime. Like Mac, who
couldn't run the programs he was working on because he didn't know what
the correct inputs were, code running at macro expansion time can deal
only with the data that's inherent in the source code. For instance,
suppose the following source code appears somewhere in a program:

@verbatim
(defun foo (x)
  (when (> x 10) (print 'big)))
@end verbatim

Normally you'd think of @code{x} as a variable that will hold the
argument passed in a call to @code{foo}. But at macro expansion time,
such as when the compiler is running the @code{WHEN} macro, the only
data available is the source code. Since the program isn't running yet,
there's no call to @code{foo} and thus no value associated with
@code{x}. Instead, the values the compiler passes to @code{WHEN} are the
Lisp lists representing the source code, namely, @code{(> x 10)} and
@code{(print 'big)}. Suppose that @code{WHEN} is defined, as you saw in
the previous chapter, with something like the following macro:

@verbatim
(defmacro when (condition &rest body)
  `(if ,condition (progn ,@body)))
@end verbatim

When the code in @code{foo} is compiled, the @code{WHEN} macro will be
run with those two forms as arguments. The parameter @code{condition}
will be bound to the form @code{(> x 10)}, and the form
@code{(print 'big)} will be collected into a list that will become the
value of the @code{&rest} @code{body} parameter. The backquote
expression will then generate this code:

@verbatim
(if (> x 10) (progn (print 'big)))
@end verbatim

by interpolating in the value of @code{condition} and splicing the value
of @code{body} into the @code{PROGN}.

When Lisp is interpreted, rather than compiled, the distinction between
macro expansion time and runtime is less clear because they're
temporally intertwined. Also, the language standard doesn't specify
exactly how an interpreter must handle macros--it could expand all the
macros in the form being interpreted and then interpret the resulting
code, or it could start right in on interpreting the form and expand
macros when it hits them. In either case, macros are always passed the
unevaluated Lisp objects representing the subforms of the macro form,
and the job of the macro is still to produce code that will do something
rather than to do anything directly.

@node DEFMACRO
@section DEFMACRO
@anchor{#defmacro}
As you saw in Chapter 3, macros really are defined with @code{DEFMACRO}
forms, though it stands--of course--for DEFine MACRO, not Definition for
Mac. The basic skeleton of a @code{DEFMACRO} is quite similar to the
skeleton of a @code{DEFUN}.

@verbatim
(defmacro name (parameter*)
  "Optional documentation string."
  body-form*)
@end verbatim

Like a function, a macro consists of a name, a parameter list, an
optional documentation string, and a body of Lisp
expressions.@footnote{As with functions, macros can also contain
declarations, but you don't need to worry about those for now.}
However, as I just discussed, the job of a macro isn't to do anything
directly--its job is to generate code that will later do what you
want.

Macros can use the full power of Lisp to generate their expansion, which
means in this chapter I can only scratch the surface of what you can do
with macros. I can, however, describe a general process for writing
macros that works for all macros from the simplest to the most complex.

The job of a macro is to translate a macro form--in other words, a Lisp
form whose first element is the name of the macro--into code that does a
particular thing. Sometimes you write a macro starting with the code
you'd like to be able to write, that is, with an example macro form.
Other times you decide to write a macro after you've written the same
pattern of code several times and realize you can make your code clearer
by abstracting the pattern.

Regardless of which end you start from, you need to figure out the other
end before you can start writing a macro: you need to know both where
you're coming from and where you're going before you can hope to write
code to do it automatically. Thus, the first step of writing a macro is
to write at least one example of a call to the macro and the code into
which that call should expand.

Once you have an example call and the desired expansion, you're ready
for the second step: writing the actual macro code. For simple macros
this will be a trivial matter of writing a backquoted template with the
macro parameters plugged into the right places. Complex macros will be
significant programs in their own right, complete with helper functions
and data structures.

After you've written code to translate the example call to the
appropriate expansion, you need to make sure the abstraction the macro
provides doesn't "leak" details of its implementation. Leaky macro
abstractions will work fine for certain arguments but not others or will
interact with code in the calling environment in undesirable ways. As it
turns out, macros can leak in a small handful of ways, all of which are
easily avoided as long as you know to check for them. I'll discuss how
in the section "Plugging the Leaks."

To sum up, the steps to writing a macro are as follows:

@enumerate
@item
Write a sample call to the macro and the code it should expand into, or
vice versa.
@item
Write code that generates the handwritten expansion from the arguments
in the sample call.
@item
Make sure the macro abstraction doesn't "leak."
@end enumerate

@node A Sample Macro do-primes
@section A Sample Macro: do-primes
@anchor{#a-sample-macro-do-primes}
To see how this three-step process works, you'll write a macro
@code{do-primes} that provides a looping construct similar to
@code{DOTIMES} and @code{DOLIST} except that instead of iterating over
integers or elements of a list, it iterates over successive prime
numbers. This isn't meant to be an example of a particularly useful
macro--it's just a vehicle for demonstrating the process.

First, you'll need two utility functions, one to test whether a given
number is prime and another that returns the next prime number greater
or equal to its argument. In both cases you can use a simple, but
inefficient, brute-force approach.

@verbatim
(defun primep (number)
  (when (> number 1)
    (loop for fac from 2 to (isqrt number) never (zerop (mod number fac)))))

(defun next-prime (number)
  (loop for n from number when (primep n) return n))
@end verbatim

Now you can write the macro. Following the procedure outlined
previously, you need at least one example of a call to the macro and the
code into which it should expand. Suppose you start with the idea that
you want to be able to write this:

@verbatim
(do-primes (p 0 19)
  (format t "~d " p))
@end verbatim

to express a loop that executes the body once each for each prime number
greater or equal to 0 and less than or equal to 19, with the variable
@code{p} holding the prime number. It makes sense to model this macro on
the form of the standard @code{DOLIST} and @code{DOTIMES} macros; macros
that follow the pattern of existing macros are easier to understand and
use than macros that introduce gratuitously novel syntax.

Without the @code{do-primes} macro, you could write such a loop with
@code{DO} (and the two utility functions defined previously) like this:

@verbatim
(do ((p (next-prime 0) (next-prime (1+ p))))
    ((> p 19))
  (format t "~d " p))
@end verbatim

Now you're ready to start writing the macro code that will translate
from the former to the latter.

@node Macro Parameters
@section Macro Parameters
@anchor{#macro-parameters}
Since the arguments passed to a macro are Lisp objects representing the
source code of the macro call, the first step in any macro is to extract
whatever parts of those objects are needed to compute the expansion. For
macros that simply interpolate their arguments directly into a template,
this step is trivial: simply defining the right parameters to hold the
different arguments is sufficient.

But this approach, it seems, will not suffice for @code{do-primes}. The
first argument to the @code{do-primes} call is a list containing the
name of the loop variable, @code{p}; the lower bound, @code{0}; and the
upper bound, @code{19}. But if you look at the expansion, the list as a
whole doesn't appear in the expansion; the three element are split up
and put in different places.

You could define @code{do-primes} with two parameters, one to hold the
list and a @code{&rest} parameter to hold the body forms, and then take
apart the list by hand, something like this:

@verbatim
(defmacro do-primes (var-and-range &rest body)
  (let ((var (first var-and-range))
        (start (second var-and-range))
        (end (third var-and-range)))
    `(do ((,var (next-prime ,start) (next-prime (1+ ,var))))
         ((> ,var ,end))
       ,@body)))
@end verbatim

In a moment I'll explain how the body generates the correct expansion;
for now you can just note that the variables @code{var}, @code{start},
and @code{end} each hold a value, extracted from @code{var-and-range},
that's then interpolated into the backquote expression that generates
@code{do-primes}'s expansion.

However, you don't need to take apart @code{var-and-range} "by hand"
because macro parameter lists are what are called @emph{destructuring}
parameter lists. Destructuring, as the name suggests, involves taking
apart a structure--in this case the list structure of the forms passed
to a macro.

Within a destructuring parameter list, a simple parameter name can be
replaced with a nested parameter list. The parameters in the nested
parameter list will take their values from the elements of the
expression that would have been bound to the parameter the list
replaced. For instance, you can replace @code{var-and-range} with a list
@code{(var start end)}, and the three elements of the list will
automatically be destructured into those three parameters.

Another special feature of macro parameter lists is that you can use
@code{&body} as a synonym for @code{&rest}. Semantically @code{&body}
and @code{&rest} are equivalent, but many development environments will
use the presence of a @code{&body} parameter to modify how they indent
uses of the macro--typically @code{&body} parameters are used to hold a
list of forms that make up the body of the macro.

So you can streamline the definition of @code{do-primes} and give a hint
to both human readers and your development tools about its intended use
by defining it like this:

@verbatim
(defmacro do-primes ((var start end) &body body)
  `(do ((,var (next-prime ,start) (next-prime (1+ ,var))))
       ((> ,var ,end))
     ,@body))
@end verbatim

In addition to being more concise, destructuring parameter lists also
give you automatic error checking--with @code{do-primes} defined this
way, Lisp will be able to detect a call whose first argument isn't a
three-element list and will give you a meaningful error message just as
if you had called a function with too few or too many arguments. Also,
in development environments such as SLIME that indicate what arguments
are expected as soon as you type the name of a function or macro, if you
use a destructuring parameter list, the environment will be able to tell
you more specifically the syntax of the macro call. With the original
definition, SLIME would tell you @code{do-primes} is called like this:

@verbatim
(do-primes var-and-range &rest body)
@end verbatim

But with the new definition, it can tell you that a call should look
like this:

@verbatim
(do-primes (var start end) &body body)
@end verbatim

Destructuring parameter lists can contain @code{&optional}, @code{&key},
and @code{&rest} parameters and can contain nested destructuring lists.
However, you don't need any of those options to write @code{do-primes}.

@node Generating the Expansion
@section Generating the Expansion
@anchor{#generating-the-expansion}
Because @code{do-primes} is a fairly simple macro, after you've
destructured the arguments, all that's left is to interpolate them into
a template to get the expansion.

For simple macros like @code{do-primes}, the special backquote syntax is
perfect. To review, a backquoted expression is similar to a quoted
expression except you can "unquote" particular subexpressions by
preceding them with a comma, possibly followed by an at (@@) sign.
Without an at sign, the comma causes the value of the subexpression to
be included as is. With an at sign, the value--which must be a list--is
"spliced" into the enclosing list.

Another useful way to think about the backquote syntax is as a
particularly concise way of writing code that generates lists. This way
of thinking about it has the benefit of being pretty much exactly what's
happening under the covers--when the reader reads a backquoted
expression, it translates it into code that generates the appropriate
list structure. For instance, @code{`(,a b)} might be read as
@code{(list a 'b)}. The language standard doesn't specify exactly what
code the reader must produce as long as it generates the right list
structure.

Table 8-1 shows some examples of backquoted expressions along with
equivalent list-building code and the result you'd get if you
evaluated either the backquoted expression or the equivalent
code.@footnote{@code{APPEND}, which I haven't discussed yet, is a
function that takes any number of list arguments and returns the
result of splicing them together into a single list.}

Table 8-1. Backquote Examples
@multitable {@code{`(a ,@@(list 1 2) c)}} {@code{(append (list 'a) (list 1 2) (list 'c))}} {@code{(a (list 1 2) c)}}
@item
Backquote Syntax
 @tab Equivalent List-Building Code
 @tab Result
@item
@code{`(a (+ 1 2) c)}
 @tab @code{(list 'a '(+ 1 2) 'c)}
 @tab @code{(a (+ 1 2) c)}
@item
@code{`(a ,(+ 1 2) c)}
 @tab @code{(list 'a (+ 1 2) 'c)}
 @tab @code{(a 3 c)}
@item
@code{`(a (list 1 2) c)}
 @tab @code{(list 'a '(list 1 2) 'c)}
 @tab @code{(a (list 1 2) c)}
@item
@code{`(a ,(list 1 2) c)}
 @tab @code{(list 'a (list 1 2) 'c)}
 @tab @code{(a (1 2) c)}
@item
@code{`(a ,@@(list 1 2) c)}
 @tab @code{(append (list 'a) (list 1 2) (list 'c))}
 @tab @code{(a 1 2 c)}
@end multitable

It's important to note that backquote is just a convenience. But it's a
big convenience. To appreciate how big, compare the backquoted version
of @code{do-primes} to the following version, which uses explicit
list-building code:

@verbatim
(defmacro do-primes-a ((var start end) &body body)
  (append '(do)
          (list  (list (list var
                             (list 'next-prime start)
                             (list 'next-prime (list '1+ var)))))
          (list (list (list '> var end)))
          body))
@end verbatim

As you'll see in a moment, the current implementation of
@code{do-primes} doesn't handle certain edge cases correctly. But first
you should verify that it at least works for the original example. You
can test it in two ways. You can test it indirectly by simply using
it--presumably, if the resulting behavior is correct, the expansion is
correct. For instance, you can type the original example's use of
@code{do-primes} to the REPL and see that it indeed prints the right
series of prime numbers.

@verbatim
CL-USER> (do-primes (p 0 19) (format t "~d " p))
2 3 5 7 11 13 17 19
NIL
@end verbatim

Or you can check the macro directly by looking at the expansion of a
particular call. The function @code{MACROEXPAND-1} takes any Lisp
expression as an argument and returns the result of doing one level of
macro expansion.@footnote{Another function, @code{MACROEXPAND}, keeps
expanding the result as long as the first element of the resulting
expansion is the name of the macro. However, this will often show you
a much lower-level view of what the code is doing than you want, since
basic control constructs such as @code{DO} are also implemented as
macros. In other words, while it can be educational to see what your
macro ultimately expands into, it isn't a very useful view into what
your own macros are doing.} Because @code{MACROEXPAND-1} is a
function, to pass it a literal macro form you must quote it. You can
use it to see the expansion of the previous call.@footnote{If the
macro expansion is shown all on one line, it's probably because the
variable @code{*PRINT-PRETTY*} is @code{NIL}. If it is, evaluating
@code{(setf *print-pretty* t)} should make the macro expansion easier
to read.}

@verbatim
CL-USER> (macroexpand-1 '(do-primes (p 0 19) (format t "~d " p)))
(DO ((P (NEXT-PRIME 0) (NEXT-PRIME (1+ P))))
    ((> P 19))
  (FORMAT T "~d " P))
T
@end verbatim

Or, more conveniently, in SLIME you can check a macro's expansion by
placing the cursor on the opening parenthesis of a macro form in your
source code and typing @code{C-c RET} to invoke the Emacs function
@code{slime-macroexpand-1}, which will pass the macro form to
@code{MACROEXPAND-1} and "pretty print" the result in a temporary
buffer.

However you get to it, you can see that the result of macro expansion is
the same as the original handwritten expansion, so it seems that
@code{do-primes} works.

@node Plugging the Leaks
@section Plugging the Leaks
@anchor{#plugging-the-leaks} In his essay "The Law of Leaky
Abstractions," Joel Spolsky coined the term @emph{leaky abstraction}
to describe an abstraction that "leaks" details it's supposed to be
abstracting away. Since writing a macro is a way of creating an
abstraction, you need to make sure your macros don't leak
needlessly.@footnote{This is from @emph{Joel on Software} by Joel
Spolsky, also available at @code{http://www.joelonsoftware.com/
articles/LeakyAbstractions.html}.  Spolsky's point in the essay is
that all abstractions leak to some extent; that is, there are no
perfect abstractions. But that doesn't mean you should tolerate leaks
you can easily plug.}

As it turns out, a macro can leak details of its inner workings in three
ways. Luckily, it's pretty easy to tell whether a given macro suffers
from any of those leaks and to fix them.

The current definition suffers from one of the three possible macro
leaks: namely, it evaluates the @code{end} subform too many times.
Suppose you were to call @code{do-primes} with, instead of a literal
number such as @code{19}, an expression such as @code{(random 100)} in
the @code{end} position.

@verbatim
(do-primes (p 0 (random 100))
  (format t "~d " p))
@end verbatim

Presumably the intent here is to loop over the primes from zero to
whatever random number is returned by @code{(random 100)}. However, this
isn't what the current implementation does, as @code{MACROEXPAND-1}
shows.

@verbatim
CL-USER> (macroexpand-1 '(do-primes (p 0 (random 100)) (format t "~d " p)))
(DO ((P (NEXT-PRIME 0) (NEXT-PRIME (1+ P))))
    ((> P (RANDOM 100)))
  (FORMAT T "~d " P))
T
@end verbatim

When this expansion code is run, @code{RANDOM} will be called each time
the end test for the loop is evaluated. Thus, instead of looping until
@code{p} is greater than an initially chosen random number, this loop
will iterate until it happens to draw a random number less than or equal
to the current value of @code{p}. While the total number of iterations
will still be random, it will be drawn from a much different
distribution than the uniform distribution @code{RANDOM} returns.

This is a leak in the abstraction because, to use the macro correctly,
the caller needs to be aware that the @code{end} form is going to be
evaluated more than once. One way to plug this leak would be to simply
define this as the behavior of @code{do-primes}. But that's not very
satisfactory--you should try to observe the Principle of Least
Astonishment when implementing macros. And programmers will typically
expect the forms they pass to macros to be evaluated no more times
than absolutely necessary.@footnote{Of course, certain forms are
supposed to be evaluated more than once, such as the forms in the body
of a @code{do-primes} loop.} Furthermore, since @code{do-primes} is
built on the model of the standard macros, @code{DOTIMES} and
@code{DOLIST}, neither of which causes any of the forms except those
in the body to be evaluated more than once, most programmers will
expect @code{do-primes} to behave similarly.

You can fix the multiple evaluation easily enough; you just need to
generate code that evaluates @code{end} once and saves the value in a
variable to be used later. Recall that in a @code{DO} loop, variables
defined with an initialization form and no step form don't change from
iteration to iteration. So you can fix the multiple evaluation problem
with this definition:

@verbatim
(defmacro do-primes ((var start end) &body body)
  `(do ((ending-value ,end)
        (,var (next-prime ,start) (next-prime (1+ ,var))))
       ((> ,var ending-value))
     ,@body))
@end verbatim

Unfortunately, this fix introduces two new leaks to the macro
abstraction.

One new leak is similar to the multiple-evaluation leak you just fixed.
Because the initialization forms for variables in a @code{DO} loop are
evaluated in the order the variables are defined, when the macro
expansion is evaluated, the expression passed as @code{end} will be
evaluated before the expression passed as @code{start}, opposite to the
order they appear in the macro call. This leak doesn't cause any
problems when @code{start} and @code{end} are literal values like 0 and
19. But when they're forms that can have side effects, evaluating them
out of order can once again run afoul of the Principle of Least
Astonishment.

This leak is trivially plugged by swapping the order of the two variable
definitions.

@verbatim
(defmacro do-primes ((var start end) &body body)
  `(do ((,var (next-prime ,start) (next-prime (1+ ,var)))
        (ending-value ,end))
       ((> ,var ending-value))
     ,@body))
@end verbatim

The last leak you need to plug was created by using the variable name
@code{ending-value}. The problem is that the name, which ought to be a
purely internal detail of the macro implementation, can end up
interacting with code passed to the macro or in the context where the
macro is called. The following seemingly innocent call to
@code{do-primes} doesn't work correctly because of this leak:

@verbatim
(do-primes (ending-value 0 10)
  (print ending-value))
@end verbatim

Neither does this one:

@verbatim
(let ((ending-value 0))
  (do-primes (p 0 10)
    (incf ending-value p))
  ending-value)
@end verbatim

Again, @code{MACROEXPAND-1} can show you the problem. The first call
expands to this:

@verbatim
(do ((ending-value (next-prime 0) (next-prime (1+ ending-value)))
     (ending-value 10))
    ((> ending-value ending-value))
  (print ending-value))
@end verbatim

Some Lisps may reject this code because @code{ending-value} is used
twice as a variable name in the same @code{DO} loop. If not rejected
outright, the code will loop forever since @code{ending-value} will
never be greater than itself.

The second problem call expands to the following:

@verbatim
(let ((ending-value 0))
  (do ((p (next-prime 0) (next-prime (1+ p)))
       (ending-value 10))
      ((> p ending-value))
    (incf ending-value p))
  ending-value)
@end verbatim

In this case the generated code is perfectly legal, but the behavior
isn't at all what you want. Because the binding of @code{ending-value}
established by the @code{LET} outside the loop is shadowed by the
variable with the same name inside the @code{DO}, the form @code{(incf
ending-value p)} increments the loop variable @code{ending-value}
instead of the outer variable with the same name, creating another
infinite loop.@footnote{It may not be obvious that this loop is
necessarily infinite given the nonuniform occurrences of prime
numbers. The starting point for a proof that it is in fact infinite is
Bertrand's postulate, which says for any @emph{n} > 1, there exists a
prime @emph{p}, @emph{n} < @emph{p} < @emph{2n}. From there you can
prove that for any prime number, P less than the sum of the preceding
prime numbers, the next prime, P', is also smaller than the original
sum plus P.}

Clearly, what you need to patch this leak is a symbol that will never be
used outside the code generated by the macro. You could try using a
really unlikely name, but that's no guarantee. You could also protect
yourself to some extent by using packages, as described in Chapter 21.
But there's a better solution.

The function @code{GENSYM} returns a unique symbol each time it's
called. This is a symbol that has never been read by the Lisp reader and
never will be because it isn't interned in any package. Thus, instead of
using a literal name like @code{ending-value}, you can generate a new
symbol each time @code{do-primes} is expanded.

@verbatim
(defmacro do-primes ((var start end) &body body)
  (let ((ending-value-name (gensym)))
    `(do ((,var (next-prime ,start) (next-prime (1+ ,var)))
          (,ending-value-name ,end))
         ((> ,var ,ending-value-name))
       ,@body)))
@end verbatim

Note that the code that calls @code{GENSYM} isn't part of the expansion;
it runs as part of the macro expander and thus creates a new symbol each
time the macro is expanded. This may seem a bit strange at
first--@code{ending-value-name} is a variable whose value is the name of
another variable. But really it's no different from the parameter
@code{var} whose value is the name of a variable--the difference is the
value of @code{var} was created by the reader when the macro form was
read, and the value of @code{ending-value-name} is generated
programmatically when the macro code runs.

With this definition the two previously problematic forms expand into
code that works the way you want. The first form:

@verbatim
(do-primes (ending-value 0 10)
  (print ending-value))
@end verbatim

expands into the following:

@verbatim
(do ((ending-value (next-prime 0) (next-prime (1+ ending-value)))
     (#:g2141 10))
    ((> ending-value #:g2141))
  (print ending-value))
@end verbatim

Now the variable used to hold the ending value is the gensymed symbol,
@code{#:g2141}. The name of the symbol, @code{G2141}, was generated by
@code{GENSYM} but isn't significant; the thing that matters is the
object identity of the symbol. Gensymed symbols are printed in the
normal syntax for uninterned symbols, with a leading @code{#:}.

The other previously problematic form:

@verbatim
(let ((ending-value 0))
  (do-primes (p 0 10)
    (incf ending-value p))
  ending-value)
@end verbatim

looks like this if you replace the @code{do-primes} form with its
expansion:

@verbatim
(let ((ending-value 0))
  (do ((p (next-prime 0) (next-prime (1+ p)))
       (#:g2140 10))
      ((> p #:g2140))
    (incf ending-value p))
  ending-value)
@end verbatim

Again, there's no leak since the @code{ending-value} variable bound by
the @code{LET} surrounding the @code{do-primes} loop is no longer
shadowed by any variables introduced in the expanded code.

Not all literal names used in a macro expansion will necessarily cause a
problem--as you get more experience with the various binding forms,
you'll be able to determine whether a given name is being used in a
position that could cause a leak in a macro abstraction. But there's no
real downside to using a gensymed name just to be safe.

With that fix, you've plugged all the leaks in the implementation of
@code{do-primes}. Once you've gotten a bit of macro-writing experience
under your belt, you'll learn to write macros with these kinds of leaks
preplugged. It's actually fairly simple if you follow these rules of
thumb:

@itemize
@item
Unless there's a particular reason to do otherwise, include any subforms
in the expansion in positions that will be evaluated in the same order
as the subforms appear in the macro call.
@item
Unless there's a particular reason to do otherwise, make sure subforms
are evaluated only once by creating a variable in the expansion to hold
the value of evaluating the argument form and then using that variable
anywhere else the value is needed in the expansion.
@item
Use @code{GENSYM} at macro expansion time to create variable names used
in the expansion.
@end itemize

@node Macro-Writing Macros
@section Macro-Writing Macros
@anchor{#macro-writing-macros}
Of course, there's no reason you should be able to take advantage of
macros only when writing functions. The job of macros is to abstract
away common syntactic patterns, and certain patterns come up again and
again in writing macros that can also benefit from being abstracted
away.

In fact, you've already seen one such pattern--many macros will, like
the last version of @code{do-primes}, start with a @code{LET} that
introduces a few variables holding gensymed symbols to be used in the
macro's expansion. Since this is such a common pattern, why not abstract
it away with its own macro?

In this section you'll write a macro, @code{with-gensyms}, that does
just that. In other words, you'll write a macro-writing macro: a macro
that generates code that generates code. While complex macro-writing
macros can be a bit confusing until you get used to keeping the various
levels of code clear in your mind, @code{with-gensyms} is fairly
straightforward and will serve as a useful but not too strenuous mental
limbering exercise.

You want to be able to write something like this:

@verbatim
(defmacro do-primes ((var start end) &body body)
  (with-gensyms (ending-value-name)
    `(do ((,var (next-prime ,start) (next-prime (1+ ,var)))
          (,ending-value-name ,end))
         ((> ,var ,ending-value-name))
       ,@body)))
@end verbatim

and have it be equivalent to the previous version of @code{do-primes}.
In other words, the @code{with-gensyms} needs to expand into a
@code{LET} that binds each named variable, @code{ending-value-name} in
this case, to a gensymed symbol. That's easy enough to write with a
simple backquote template.

@verbatim
(defmacro with-gensyms ((&rest names) &body body)
  `(let ,(loop for n in names collect `(,n (gensym)))
     ,@body))
@end verbatim

Note how you can use a comma to interpolate the value of the @code{LOOP}
expression. The loop generates a list of binding forms where each
binding form consists of a list containing one of the names given to
@code{with-gensyms} and the literal code @code{(gensym)}. You can test
what code the @code{LOOP} expression would generate at the REPL by
replacing @code{names} with a list of symbols.

@verbatim
CL-USER> (loop for n in '(a b c) collect `(,n (gensym)))
((A (GENSYM)) (B (GENSYM)) (C (GENSYM)))
@end verbatim

After the list of binding forms, the body argument to
@code{with-gensyms} is spliced in as the body of the @code{LET}. Thus,
in the code you wrap in a @code{with-gensyms} you can refer to any of
the variables named in the list of variables passed to
@code{with-gensyms}.

If you macro-expand the @code{with-gensyms} form in the new definition
of @code{do-primes}, you should see something like this:

@verbatim
(let ((ending-value-name (gensym)))
  `(do ((,var (next-prime ,start) (next-prime (1+ ,var)))
        (,ending-value-name ,end))
       ((> ,var ,ending-value-name))
     ,@body))
@end verbatim

Looks good. While this macro is fairly trivial, it's important to keep
clear about when the different macros are expanded: when you compile the
@code{DEFMACRO} of @code{do-primes}, the @code{with-gensyms} form is
expanded into the code just shown and compiled. Thus, the compiled
version of @code{do-primes} is just the same as if you had written the
outer @code{LET} by hand. When you compile a function that uses
@code{do-primes}, the code @emph{generated} by @code{with-gensyms} runs
generating the @code{do-primes} expansion, but @code{with-gensyms}
itself isn't needed to compile a @code{do-primes} form since it has
already been expanded, back when @code{do-primes} was compiled.

Another classic macro-writing MACRO: ONCE-ONLY
Another classic macro-writing macro is @code{once-only}, which is used
to generate code that evaluates certain macro arguments once only and in
a particular order. Using @code{once-only}, you could write
@code{do-primes} almost as simply as the original leaky version, like
this:

@verbatim
(defmacro do-primes ((var start end) &body body)
  (once-only (start end)
    `(do ((,var (next-prime ,start) (next-prime (1+ ,var))))
         ((> ,var ,end))
       ,@body)))
@end verbatim

However, the implementation of @code{once-only} is a bit too involved
for a blow-by-blow explanation, as it relies on multiple levels of
backquoting and unquoting. If you really want to sharpen your macro
chops, you can try to figure out how it works. It looks like this:

@verbatim
(defmacro once-only ((&rest names) &body body)
  (let ((gensyms (loop for n in names collect (gensym))))
    `(let (,@(loop for g in gensyms collect `(,g (gensym))))
      `(let (,,@(loop for g in gensyms for n in names collect ``(,,g ,,n)))
        ,(let (,@(loop for n in names for g in gensyms collect `(,n ,g)))
           ,@body)))))
@end verbatim

@node Beyond Simple Macros
@section Beyond Simple Macros
@anchor{#beyond-simple-macros}
I could, of course, say a lot more about macros. All the macros you've
seen so far have been fairly simple examples that save you a bit of
typing but don't provide radical new ways of expressing things. In
upcoming chapters you'll see examples of macros that allow you to
express things in ways that would be virtually impossible without
macros. You'll start in the very next chapter, in which you'll build a
simple but effective unit test framework.

@node Practical Building a Unit Test Framework
@chapter Practical: Building a Unit Test Framework
@anchor{#practical-building-a-unit-test-framework}
In this chapter you'll return to cutting code and develop a simple unit
testing framework for Lisp. This will give you a chance to use some of
the features you've learned about since Chapter 3, including macros and
dynamic variables, in real code.

The main design goal of the test framework will be to make it as easy as
possible to add new tests, to run various suites of tests, and to track
down test failures. For now you'll focus on designing a framework you
can use during interactive development.

The key feature of an automated testing framework is that the
framework is responsible for telling you whether all the tests
passed. You don't want to spend your time slogging through test output
checking answers when the computer can do it much more quickly and
accurately.  Consequently, each test case must be an expression that
yields a boolean value--true or false, pass or fail. For instance, if
you were writing tests for the built-in @code{+} function, these might
be reasonable test cases:@footnote{This is for illustrative purposes
only--obviously, writing test cases for built-in functions such as
@code{+} is a bit silly, since if such basic things aren't working,
the chances the tests will be running the way you expect is pretty
slim. On the other hand, most Common Lisps are implemented largely in
Common Lisp, so it's not crazy to imagine writing test suites in
Common Lisp to test the standard library functions.}

@verbatim
(= (+ 1 2) 3)
(= (+ 1 2 3) 6)
(= (+ -1 -3) -4)
@end verbatim

Functions that have side effects will be tested slightly
differently--you'll have to call the function and then check for
evidence of the expected side effects.@footnote{Side effects can
include such things as signaling errors; I'll discuss Common Lisp's
error handling system in Chapter 19.  You may, after reading that
chapter, want to think about how to incorporate tests that check
whether a function does or does not signal a particular error in
certain situations.} But in the end, every test case has to boil down
to a boolean expression, thumbs up or thumbs down.
@menu
* Two First Tries::
* Refactoring::
* Fixing the Return Value::
* Better Result Reporting::
* An Abstraction Emerges::
* A Hierarchy of Tests::
* Wrapping Up The Test Framework::
@end menu

@node Two First Tries
@section Two First Tries
@anchor{#two-first-tries}
If you were doing ad hoc testing, you could enter these expressions at
the REPL and check that they return @code{T}. But you want a framework
that makes it easy to organize and run these test cases whenever you
want. If you want to start with the simplest thing that could possibly
work, you can just write a function that evaluates the test cases and
@code{AND}s the results together.

@verbatim
(defun test-+ ()
  (and
    (= (+ 1 2) 3)
    (= (+ 1 2 3) 6)
    (= (+ -1 -3) -4)))
@end verbatim

Whenever you want to run this set of test cases, you can call
@code{test-+}.

@verbatim
CL-USER> (test-+)
T
@end verbatim

As long as it returns @code{T}, you know the test cases are passing.
This way of organizing tests is also pleasantly concise--you don't have
to write a bunch of test bookkeeping code. However, as you'll discover
the first time a test case fails, the result reporting leaves something
to be desired. When @code{test-+} returns @code{NIL}, you'll know
something failed, but you'll have no idea which test case it was.

So let's try another simple--even simpleminded--approach. To find out
what happens to each test case, you could write something like this:

@verbatim
(defun test-+ ()
  (format t "~:[FAIL~;pass~] ... ~a~%" (= (+ 1 2) 3) '(= (+ 1 2) 3))
  (format t "~:[FAIL~;pass~] ... ~a~%" (= (+ 1 2 3) 6) '(= (+ 1 2 3) 6))
  (format t "~:[FAIL~;pass~] ... ~a~%" (= (+ -1 -3) -4) '(= (+ -1 -3) -4)))
@end verbatim

Now each test case will be reported individually. The
@code{~:[FAIL~;pass~]} part of the @code{FORMAT} directive causes
@code{FORMAT} to print "FAIL" if the first format argument is false
and "pass" otherwise.@footnote{I'll discuss this and other
@code{FORMAT} directives in more detail in Chapter 18.} Then you label
the result with the test expression itself. Now running @code{test-+}
shows you exactly what's going on.

@verbatim
CL-USER> (test-+)
pass ... (= (+ 1 2) 3)
pass ... (= (+ 1 2 3) 6)
pass ... (= (+ -1 -3) -4)
NIL
@end verbatim

This time the result reporting is more like what you want, but the code
itself is pretty gross. The repeated calls to @code{FORMAT} as well as
the tedious duplication of the test expression cry out to be refactored.
The duplication of the test expression is particularly grating because
if you mistype it, the test results will be mislabeled.

Another problem is that you don't get a single indicator whether all the
test cases passed. It's easy enough, with only three test cases, to scan
the output looking for "FAIL"; however, when you have hundreds of test
cases, it'll be more of a hassle.

@node Refactoring
@section Refactoring
@anchor{#refactoring}
What you'd really like is a way to write test functions as streamlined
as the first @code{test-+} that return a single @code{T} or @code{NIL}
value but that also report on the results of individual test cases like
the second version. Since the second version is close to what you want
in terms of functionality, your best bet is to see if you can factor out
some of the annoying duplication.

The simplest way to get rid of the repeated similar calls to
@code{FORMAT} is to create a new function.

@verbatim
(defun report-result (result form)
  (format t "~:[FAIL~;pass~] ... ~a~%" result form))
@end verbatim

Now you can write @code{test-+} with calls to @code{report-result}
instead of @code{FORMAT}. It's not a huge improvement, but at least now
if you decide to change the way you report results, there's only one
place you have to change.

@verbatim
(defun test-+ ()
  (report-result (= (+ 1 2) 3) '(= (+ 1 2) 3))
  (report-result (= (+ 1 2 3) 6) '(= (+ 1 2 3) 6))
  (report-result (= (+ -1 -3) -4) '(= (+ -1 -3) -4)))
@end verbatim

Next you need to get rid of the duplication of the test case expression,
with its attendant risk of mislabeling of results. What you'd really
like is to be able to treat the expression as both code (to get the
result) and data (to use as the label). Whenever you want to treat code
as data, that's a sure sign you need a macro. Or, to look at it another
way, what you need is a way to automate writing the error-prone
@code{report-result} calls. You'd like to be able to say something like
this:

@verbatim
(check (= (+ 1 2) 3))
@end verbatim

and have it mean the following:

@verbatim
(report-result (= (+ 1 2) 3) '(= (+ 1 2) 3))
@end verbatim

Writing a macro to do this translation is trivial.

@verbatim
(defmacro check (form)
  `(report-result ,form ',form))
@end verbatim

Now you can change @code{test-+} to use @code{check}.

@verbatim
(defun test-+ ()
  (check (= (+ 1 2) 3))
  (check (= (+ 1 2 3) 6))
  (check (= (+ -1 -3) -4)))
@end verbatim

Since you're on the hunt for duplication, why not get rid of those
repeated calls to @code{check}? You can define @code{check} to take an
arbitrary number of forms and wrap them each in a call to
@code{report-result}.

@verbatim
(defmacro check (&body forms)
  `(progn
     ,@(loop for f in forms collect `(report-result ,f ',f))))
@end verbatim

This definition uses a common macro idiom of wrapping a @code{PROGN}
around a series of forms in order to turn them into a single form.
Notice also how you can use @code{,@@} to splice in the result of an
expression that returns a list of expressions that are themselves
generated with a backquote template.

With the new version of @code{check} you can write a new version of
@code{test-+} like this:

@verbatim
(defun test-+ ()
  (check
    (= (+ 1 2) 3)
    (= (+ 1 2 3) 6)
    (= (+ -1 -3) -4)))
@end verbatim

that is equivalent to the following code:

@verbatim
(defun test-+ ()
  (progn
    (report-result (= (+ 1 2) 3) '(= (+ 1 2) 3))
    (report-result (= (+ 1 2 3) 6) '(= (+ 1 2 3) 6))
    (report-result (= (+ -1 -3) -4) '(= (+ -1 -3) -4))))
@end verbatim

Thanks to @code{check}, this version is as concise as the first version
of @code{test-+} but expands into code that does the same thing as the
second version. And now any changes you want to make to how
@code{test-+} behaves, you can make by changing @code{check}.

@node Fixing the Return Value
@section Fixing the Return Value
@anchor{#fixing-the-return-value}
You can start with fixing @code{test-+} so its return value indicates
whether all the test cases passed. Since @code{check} is responsible for
generating the code that ultimately runs the test cases, you just need
to change it to generate code that also keeps track of the results.

As a first step, you can make a small change to @code{report-result} so
it returns the result of the test case it's reporting.

@verbatim
(defun report-result (result form)
  (format t "~:[FAIL~;pass~] ... ~a~%" result form)
  result)
@end verbatim

Now that @code{report-result} returns the result of its test case, it
might seem you could just change the @code{PROGN} to an @code{AND} to
combine the results. Unfortunately, @code{AND} doesn't do quite what you
want in this case because of its short-circuiting behavior: as soon as
one test case fails, @code{AND} will skip the rest. On the other hand,
if you had a construct that worked like @code{AND} without the
short-circuiting, you could use it in the place of @code{PROGN}, and
you'd be done. Common Lisp doesn't provide such a construct, but that's
no reason you can't use it: it's a trivial matter to write a macro to
provide it yourself.

Leaving test cases aside for a moment, what you want is a macro--let's
call it @code{combine-results}--that will let you say this:

@verbatim
(combine-results
  (foo)
  (bar)
  (baz))
@end verbatim

and have it mean something like this:

@verbatim
(let ((result t))
  (unless (foo) (setf result nil))
  (unless (bar) (setf result nil))
  (unless (baz) (setf result nil))
  result)
@end verbatim

The only tricky bit to writing this macro is that you need to introduce
a variable--@code{result} in the previous code--in the expansion. As you
saw in the previous chapter, using a literal name for variables in macro
expansions can introduce a leak in your macro abstraction, so you'll
need to create a unique name. This is a job for @code{with-gensyms}. You
can define @code{combine-results} like this:

@verbatim
(defmacro combine-results (&body forms)
  (with-gensyms (result)
    `(let ((,result t))
      ,@(loop for f in forms collect `(unless ,f (setf ,result nil)))
      ,result)))
@end verbatim

Now you can fix @code{check} by simply changing the expansion to use
@code{combine-results} instead of @code{PROGN}.

@verbatim
(defmacro check (&body forms)
  `(combine-results
    ,@(loop for f in forms collect `(report-result ,f ',f))))
@end verbatim

With that version of @code{check}, @code{test-+} should emit the
results of its three test expressions and then return @code{T} to
indicate that everything passed.@footnote{If @code{test-+} has been
compiled--which may happen implicitly in certain Lisp
implementations--you may need to reevaluate the definition of
@code{test-+} to get the changed definition of @code{check} to affect
the behavior of @code{test-+}. Interpreted code, on the other hand,
typically expands macros anew each time the code is interpreted,
allowing the effects of macro redefinitions to be seen immediately.}

@verbatim
CL-USER> (test-+)
pass ... (= (+ 1 2) 3)
pass ... (= (+ 1 2 3) 6)
pass ... (= (+ -1 -3) -4)
T
@end verbatim

And if you change one of the test cases so it fails,@footnote{You have
to change the test to make it fail since you can't change the behavior
of @code{+}.}  the final return value changes to @code{NIL}.

@verbatim
CL-USER> (test-+)
pass ... (= (+ 1 2) 3)
pass ... (= (+ 1 2 3) 6)
FAIL ... (= (+ -1 -3) -5)
NIL
@end verbatim

@node Better Result Reporting
@section Better Result Reporting
@anchor{#better-result-reporting}
As long as you have only one test function, the current result reporting
is pretty clear. If a particular test case fails, all you have to do is
find the test case in the @code{check} form and figure out why it's
failing. But if you write a lot of tests, you'll probably want to
organize them somehow, rather than shoving them all into one function.
For instance, suppose you wanted to add some test cases for the @code{*}
function. You might write a new test function.

@verbatim
(defun test-* ()
  (check
    (= (* 2 2) 4)
    (= (* 3 5) 15)))
@end verbatim

Now that you have two test functions, you'll probably want another
function that runs all the tests. That's easy enough.

@verbatim
(defun test-arithmetic ()
  (combine-results
   (test-+)
   (test-*)))
@end verbatim

In this function you use @code{combine-results} instead of @code{check}
since both @code{test-+} and @code{test-*} will take care of reporting
their own results. When you run @code{test-arithmetic}, you'll get the
following results:

@verbatim
CL-USER> (test-arithmetic)
pass ... (= (+ 1 2) 3)
pass ... (= (+ 1 2 3) 6)
pass ... (= (+ -1 -3) -4)
pass ... (= (* 2 2) 4)
pass ... (= (* 3 5) 15)
T
@end verbatim

Now imagine that one of the test cases failed and you need to track down
the problem. With only five test cases and two test functions, it won't
be too hard to find the code of the failing test case. But suppose you
had 500 test cases spread across 20 functions. It might be nice if the
results told you what function each test case came from.

Since the code that prints the results is centralized in
@code{report-result}, you need a way to pass information about what test
function you're in to @code{report-result}. You could add a parameter to
@code{report-result} to pass this information, but @code{check}, which
generates the calls to @code{report-result}, doesn't know what function
it's being called from, which means you'd also have to change the way
you call @code{check}, passing it an argument that it simply passes onto
@code{report-result}.

This is exactly the kind of problem dynamic variables were designed to
solve. If you create a dynamic variable that each test function binds to
the name of the function before calling @code{check}, then
@code{report-result} can use it without @code{check} having to know
anything about it.

Step one is to declare the variable at the top level.

@verbatim
(defvar *test-name* nil)
@end verbatim

Now you need to make another tiny change to @code{report-result} to
include @code{*test-name*} in the @code{FORMAT} output.

@verbatim
(format t "~:[FAIL~;pass~] ... ~a: ~a~%" result *test-name* form)
@end verbatim

With those changes, the test functions will still work but will produce
the following output because @code{*test-name*} is never rebound:

@verbatim
CL-USER> (test-arithmetic)
pass ... NIL: (= (+ 1 2) 3)
pass ... NIL: (= (+ 1 2 3) 6)
pass ... NIL: (= (+ -1 -3) -4)
pass ... NIL: (= (* 2 2) 4)
pass ... NIL: (= (* 3 5) 15)
T
@end verbatim

For the name to be reported properly, you need to change the two test
functions.

@verbatim
(defun test-+ ()
  (let ((*test-name* 'test-+))
    (check
      (= (+ 1 2) 3)
      (= (+ 1 2 3) 6)
      (= (+ -1 -3) -4))))

(defun test-* ()
  (let ((*test-name* 'test-*))
    (check
      (= (* 2 2) 4)
      (= (* 3 5) 15))))
@end verbatim

Now the results are properly labeled.

@verbatim
CL-USER> (test-arithmetic)
pass ... TEST-+: (= (+ 1 2) 3)
pass ... TEST-+: (= (+ 1 2 3) 6)
pass ... TEST-+: (= (+ -1 -3) -4)
pass ... TEST-*: (= (* 2 2) 4)
pass ... TEST-*: (= (* 3 5) 15)
T
@end verbatim

@node An Abstraction Emerges
@section An Abstraction Emerges
@anchor{#an-abstraction-emerges}
In fixing the test functions, you've introduced several new bits of
duplication. Not only does each function have to include the name of the
function twice--once as the name in the @code{DEFUN} and once in the
binding of @code{*test-name*}--but the same three-line code pattern is
duplicated between the two functions. You could remove the duplication
simply on the grounds that duplication is bad. But if you look more
closely at the root cause of the duplication, you can learn an important
lesson about how to use macros.

The reason both these functions start the same way is because they're
both test functions. The duplication arises because, at the moment,
@emph{test function} is only half an abstraction. The abstraction exists
in your mind, but in the code there's no way to express "this is a test
function" other than to write code that follows a particular pattern.

Unfortunately, partial abstractions are a crummy tool for building
software. Because a half abstraction is expressed in code by a
manifestation of the pattern, you're guaranteed to have massive code
duplication with all the normal bad consequences that implies for
maintainability. More subtly, because the abstraction exists only in the
minds of programmers, there's no mechanism to make sure different
programmers (or even the same programmer working at different times)
actually understand the abstraction the same way. To make a complete
abstraction, you need a way to express "this is a test function" and
have all the code required by the pattern be generated for you. In other
words, you need a macro.

Because the pattern you're trying to capture is a @code{DEFUN} plus some
boilerplate code, you need to write a macro that will expand into a
@code{DEFUN}. You'll then use this macro, instead of a plain
@code{DEFUN} to define test functions, so it makes sense to call it
@code{deftest}.

@verbatim
(defmacro deftest (name parameters &body body)
  `(defun ,name ,parameters
    (let ((*test-name* ',name))
      ,@body)))
@end verbatim

With this macro you can rewrite @code{test-+} as follows:

@verbatim
(deftest test-+ ()
  (check
    (= (+ 1 2) 3)
    (= (+ 1 2 3) 6)
    (= (+ -1 -3) -4)))
@end verbatim

@node A Hierarchy of Tests
@section A Hierarchy of Tests
@anchor{#a-hierarchy-of-tests}
Now that you've established test functions as first-class citizens, the
question might arise, should @code{test-arithmetic} be a test function?
As things stand, it doesn't really matter--if you did define it with
@code{deftest}, its binding of @code{*test-name*} would be shadowed by
the bindings in @code{test-+} and @code{test-*} before any results are
reported.

But now imagine you've got thousands of test cases to organize. The
first level of organization is provided by test functions such as
@code{test-+} and @code{test-*} that directly call @code{check}. But
with thousands of test cases, you'll likely need other levels of
organization. Functions such as @code{test-arithmetic} can group related
test functions into test suites. Now suppose some low-level test
functions are called from multiple test suites. It's not unheard of for
a test case to pass in one context but fail in another. If that happens,
you'll probably want to know more than just what low-level test function
contains the test case.

If you define the test suite functions such as @code{test-arithmetic}
with @code{deftest} and make a small change to the @code{*test-name*}
bookkeeping, you can have results reported with a "fully qualified" path
to the test case, something like this:

@verbatim
pass ... (TEST-ARITHMETIC TEST-+): (= (+ 1 2) 3)
@end verbatim

Because you've already abstracted the process of defining a test
function, you can change the bookkeeping details without modifying the
code of the test functions.@footnote{Though, again, if the test
functions have been compiled, you'll have to recompile them after
changing the macro.} To make @code{*test-name*} hold a list of test
function names instead of just the name of the most recently entered
test function, you just need to change this binding form:

@verbatim
(let ((*test-name* ',name))
@end verbatim

to the following:

@verbatim
(let ((*test-name* (append *test-name* (list ',name))))
@end verbatim

Since @code{APPEND} returns a new list made up of the elements of its
arguments, this version will bind @code{*test-name*} to a list
containing the old contents of @code{*test-name*} with the new name
tacked onto the end.@footnote{As you'll see in Chapter 12,
@code{APPEND}ing to the end of a list isn't the most efficient way to
build a list. But for now this is sufficient--as long as the test
hierarchies aren't too deep, it should be fine. And if it becomes a
problem, all you'll have to do is change the definition of
@code{deftest}.} When each test function returns, the old value of
@code{*test-name*} will be restored.

Now you can redefine @code{test-arithmetic} with @code{deftest} instead
of @code{DEFUN}.

@verbatim
(deftest test-arithmetic ()
  (combine-results
   (test-+)
   (test-*)))
@end verbatim

The results now show exactly how you got to each test expression.

@verbatim
CL-USER> (test-arithmetic)
pass ... (TEST-ARITHMETIC TEST-+): (= (+ 1 2) 3)
pass ... (TEST-ARITHMETIC TEST-+): (= (+ 1 2 3) 6)
pass ... (TEST-ARITHMETIC TEST-+): (= (+ -1 -3) -4)
pass ... (TEST-ARITHMETIC TEST-*): (= (* 2 2) 4)
pass ... (TEST-ARITHMETIC TEST-*): (= (* 3 5) 15)
T
@end verbatim

As your test suite grows, you can add new layers of test functions; as
long as they're defined with @code{deftest}, the results will be
reported correctly. For instance, the following:

@verbatim
(deftest test-math ()
  (test-arithmetic))
@end verbatim

would generate these results:

@verbatim
CL-USER> (test-math)
pass ... (TEST-MATH TEST-ARITHMETIC TEST-+): (= (+ 1 2) 3)
pass ... (TEST-MATH TEST-ARITHMETIC TEST-+): (= (+ 1 2 3) 6)
pass ... (TEST-MATH TEST-ARITHMETIC TEST-+): (= (+ -1 -3) -4)
pass ... (TEST-MATH TEST-ARITHMETIC TEST-*): (= (* 2 2) 4)
pass ... (TEST-MATH TEST-ARITHMETIC TEST-*): (= (* 3 5) 15)
T
@end verbatim

@node Wrapping Up The Test Framework
@section Wrapping Up
@anchor{#wrapping-up-test-framework}
You could keep going, adding more features to this test framework. But
as a framework for writing tests with a minimum of busywork and easily
running them from the REPL, this is a reasonable start. Here's the
complete code, all 26 lines of it:

@verbatim
(defvar *test-name* nil)

(defmacro deftest (name parameters &body body)
  "Define a test function. Within a test function we can call
   other test functions or use 'check' to run individual test
   cases."
  `(defun ,name ,parameters
    (let ((*test-name* (append *test-name* (list ',name))))
      ,@body)))

(defmacro check (&body forms)
  "Run each expression in 'forms' as a test case."
  `(combine-results
    ,@(loop for f in forms collect `(report-result ,f ',f))))

(defmacro combine-results (&body forms)
  "Combine the results (as booleans) of evaluating 'forms' in order."
  (with-gensyms (result)
    `(let ((,result t))
      ,@(loop for f in forms collect `(unless ,f (setf ,result nil)))
      ,result)))

(defun report-result (result form)
  "Report the results of a single test case. Called by 'check'."
  (format t "~:[FAIL~;pass~] ... ~a: ~a~%" result *test-name* form)
  result)
@end verbatim

It's worth reviewing how you got here because it's illustrative of how
programming in Lisp often goes.

You started by defining a simple version of your problem--how to
evaluate a bunch of boolean expressions and find out if they all
returned true. Just @code{AND}ing them together worked and was
syntactically clean but revealed the need for better result reporting.
So you wrote some really simpleminded code, chock-full of duplication
and error-prone idioms that reported the results the way you wanted.

The next step was to see if you could refactor the second version into
something as clean as the former. You started with a standard
refactoring technique of extracting some code into a function,
@code{report-result}. Unfortunately, you could see that using
@code{report-result} was going to be tedious and error-prone since you
had to pass the test expression twice, once for the value and once as
quoted data. So you wrote the @code{check} macro to automate the details
of calling @code{report-result} correctly.

While writing @code{check}, you realized as long as you were generating
code, you could make a single call to @code{check} to generate multiple
calls to @code{report-result}, getting you back to a version of
@code{test-+} about as concise as the original @code{AND} version.

At that point you had the @code{check} API nailed down, which allowed
you to start mucking with how it worked on the inside. The next task was
to fix @code{check} so the code it generated would return a boolean
indicating whether all the test cases had passed. Rather than
immediately hacking away at @code{check}, you paused to indulge in a
little language design by fantasy. What if--you fantasized--there was
already a non-short-circuiting @code{AND} construct. Then fixing
@code{check} would be trivial. Returning from fantasyland you realized
there was no such construct but that you could write one in a few lines.
After writing @code{combine-results}, the fix to @code{check} was indeed
trivial.

At that point all that was left was to make a few more improvements to
the way you reported test results. Once you started making changes to
the test functions, you realized those functions represented a special
category of function that deserved its own abstraction. So you wrote
@code{deftest} to abstract the pattern of code that turns a regular
function into a test function.

With @code{deftest} providing an abstraction barrier between the test
definitions and the underlying machinery, you were able to enhance the
result reporting without touching the test functions.

Now, with the basics of functions, variables, and macros mastered, and a
little practical experience using them, you're ready to start exploring
Common Lisp's rich standard library of functions and data types.

@node Numbers Characters and Strings
@chapter Numbers, Characters, and Strings
@anchor{#numbers-characters-and-strings} While functions, variables,
macros, and 25 special operators provide the basic building blocks of
the language itself, the building blocks of your programs will be the
data structures you use. As Fred Brooks observed in @emph{The Mythical
Man-Month}, "Representation @emph{is} the essence of
programming."@footnote{Fred Brooks, @emph{The Mythical Man-Month},
20th Anniversary Edition (Boston: Addison-Wesley, 1995),
p. 103. Emphasis in original.}

Common Lisp provides built-in support for most of the data types
typically found in modern languages: numbers (integer, floating point,
and complex), characters, strings, arrays (including multidimensional
arrays), lists, hash tables, input and output streams, and an
abstraction for portably representing filenames. Functions are also a
first-class data type in Lisp--they can be stored in variables, passed
as arguments, returned as return values, and created at runtime.

And these built-in types are just the beginning. They're defined in the
language standard so programmers can count on them being available and
because they tend to be easier to implement efficiently when tightly
integrated with the rest of the implementation. But, as you'll see in
later chapters, Common Lisp also provides several ways for you to define
new data types, define operations on them, and integrate them with the
built-in data types.

For now, however, you can start with the built-in data types. Because
Lisp is a high-level language, the details of exactly how different data
types are implemented are largely hidden. From your point of view as a
user of the language, the built-in data types are defined by the
functions that operate on them. So to learn a data type, you just have
to learn about the functions you can use with it. Additionally, most of
the built-in data types have a special syntax that the Lisp reader
understands and that the Lisp printer uses. That's why, for instance,
you can write strings as @code{"foo"}; numbers as @code{123},
@code{1/23}, and @code{1.23}; and lists as @code{(a b c)}. I'll describe
the syntax for different kinds of objects when I describe the functions
for manipulating them.

In this chapter, I'll cover the built-in "scalar" data types: numbers,
characters, and strings. Technically, strings aren't true scalars--a
string is a sequence of characters, and you can access individual
characters and manipulate strings with a function that operates on
sequences. But I'll discuss strings here because most of the
string-specific functions manipulate them as single values and also
because of the close relation between several of the string functions
and their character counterparts.
@menu
* Numbers::
* Numeric Literals::
* Basic Math::
* Numeric Comparisons::
* Higher Math::
* Characters::
* Character Comparisons::
* Strings::
* String Comparisons::
@end menu

@node Numbers
@section Numbers
@anchor{#numbers} Math, as Barbie says, is hard.@footnote{Mattel's
Teen Talk Barbie} Common Lisp can't make the math part any easier, but
it does tend to get in the way a lot less than other programming
languages. That's not surprising given its mathematical heritage. Lisp
was originally designed by a mathematician as a tool for studying
mathematical functions. And one of the main projects of the MAC
project at MIT was the Macsyma symbolic algebra system, written in
Maclisp, one of Common Lisp's immediate predecessors.  Additionally,
Lisp has been used as a teaching language at places such as MIT where
even the computer science professors cringe at the thought of telling
their students that @emph{10/4 = 2}, leading to Lisp's support for
exact ratios. And at various times Lisp has been called upon to
compete with FORTRAN in the high-performance numeric computing arena.

One of the reasons Lisp is a nice language for math is its numbers
behave more like true mathematical numbers than the approximations of
numbers that are easy to implement in finite computer hardware. For
instance, integers in Common Lisp can be almost arbitrarily large
rather than being limited by the size of a machine
word.@footnote{Obviously, the size of a number that can be represented
on a computer with finite memory is still limited in practice;
furthermore, the actual representation of @emph{bignums} used in a
particular Common Lisp implementation may place other limits on the
size of number that can be represented. But these limits are going to
be well beyond "astronomically" large numbers. For instance, the
number of atoms in the universe is estimated to be less than 2^269;
current Common Lisp implementations can easily handle numbers up to
and beyond 2^262144.} And dividing two integers results in an exact
ratio, not a truncated value.  And since ratios are represented as
pairs of arbitrarily sized integers, ratios can represent arbitrarily
precise fractions.@footnote{Folks interested in using Common Lisp for
intensive numeric computation should note that a naive comparison of
the performance of numeric code in Common Lisp and languages such as C
or FORTRAN will probably show Common Lisp to be much slower. This is
because something as simple as @code{(+ a b)} in Common Lisp is doing
a lot more than the seemingly equivalent @code{a + b} in one of those
languages. Because of Lisp's dynamic typing and support for things
such as arbitrary precision rationals and complex numbers, a seemingly
simple addition is doing a lot more than an addition of two numbers
that are known to be represented by machine words. However, you can
use declarations to give Common Lisp information about the types of
numbers you're using that will enable it to generate code that does
only as much work as the code that would be generated by a C or
FORTRAN compiler.  Tuning numeric code for this kind of performance is
beyond the scope of this book, but it's certainly possible.}

On the other hand, for high-performance numeric programming, you may
be willing to trade the exactitude of rationals for the speed offered
by using the hardware's underlying floating-point operations. So,
Common Lisp also offers several types of floating-point numbers, which
are mapped by the implementation to the appropriate hardware-supported
floating-point representations.@footnote{While the standard doesn't
require it, many Common Lisp implementations support the IEEE standard
for floating-point arithmetic, @emph{IEEE Standard for Binary
Floating-Point Arithmetic, ANSI/ IEEE Std 754-1985} (Institute of
Electrical and Electronics Engineers, 1985).} Floats are also used to
represent the results of a computation whose true mathematical value
would be an irrational number.

Finally, Common Lisp supports complex numbers--the numbers that result
from doing things such as taking square roots and logarithms of negative
numbers. The Common Lisp standard even goes so far as to specify the
principal values and branch cuts for irrational and transcendental
functions on the complex domain.

@node Numeric Literals
@section Numeric Literals
@anchor{#numeric-literals}
You can write numeric literals in a variety of ways; you saw a few
examples in Chapter 4. However, it's important to keep in mind the
division of labor between the Lisp reader and the Lisp evaluator--the
reader is responsible for translating text into Lisp objects, and the
Lisp evaluator then deals only with those objects. For a given number of
a given type, there can be many different textual representations, all
of which will be translated to the same object representation by the
Lisp reader. For instance, you can write the integer 10 as @code{10},
@code{20/2}, @code{#xA}, or any of a number of other ways, but the
reader will translate all these to the same object. When numbers are
printed back out--say, at the REPL--they're printed in a canonical
textual syntax that may be different from the syntax used to enter the
number. For example:

@verbatim
CL-USER> 10
10
CL-USER> 20/2
10
CL-USER> #xa
10
@end verbatim

The syntax for integer values is an optional sign (@code{+} or @code{-})
followed by one or more digits. Ratios are written as an optional sign
and a sequence of digits, representing the numerator, a slash
(@code{/}), and another sequence of digits representing the denominator.
All rational numbers are "canonicalized" as they're read--that's why
@code{10} and @code{20/2} are both read as the same number, as are
@code{3/4} and @code{6/8}. Rationals are printed in "reduced"
form--integer values are printed in integer syntax and ratios with the
numerator and denominator reduced to lowest terms.

It's also possible to write rationals in bases other than 10. If
preceded by @code{#B} or @code{#b}, a rational literal is read as a
binary number with @code{0} and @code{1} as the only legal digits. An
@code{#O} or @code{#o} indicates an octal number (legal digits
@code{0}-@code{7}), and @code{#X} or @code{#x} indicates hexadecimal
(legal digits @code{0}-@code{F} or @code{0}-@code{f}). You can write
rationals in other bases from 2 to 36 with @code{#nR} where @emph{n}
is the base (always written in decimal). Additional "digits" beyond 9
are taken from the letters @code{A}-@code{Z} or
@code{a}-@code{z}. Note that these radix indicators apply to the whole
rational--it's not possible to write a ratio with the numerator in one
base and denominator in another.  Also, you can write integer values,
but not ratios, as decimal digits terminated with a decimal
point.@footnote{It's also possible to change the default base the
reader uses for numbers without a specific radix marker by changing
the value of the global variable @code{*READ-BASE*}. However, it's not
clear that's the path to anything other than complete insanity.} Some
examples of rationals, with their canonical, decimal representation
are as follows:

@verbatim
123                            ==> 123
+123                           ==> 123
-123                           ==> -123
123.                           ==> 123
2/3                            ==> 2/3
-2/3                           ==> -2/3
4/6                            ==> 2/3
6/3                            ==> 2
#b10101                        ==> 21
#b1010/1011                    ==> 10/11
#o777                          ==> 511
#xDADA                         ==> 56026
#36rABCDEFGHIJKLMNOPQRSTUVWXYZ ==> 8337503854730415241050377135811259267835
@end verbatim

You can also write floating-point numbers in a variety of ways. Unlike
rational numbers, the syntax used to notate a floating-point number
can affect the actual type of number read. Common Lisp defines four
subtypes of floating-point number: short, single, double, and
long. Each subtype can use a different number of bits in its
representation, which means each subtype can represent values spanning
a different range and with different precision. More bits gives a
wider range and more precision.@footnote{Since the purpose of
floating-point numbers is to make efficient use of floating-point
hardware, each Lisp implementation is allowed to map these four
subtypes onto the native floating-point types as appropriate. If the
hardware supports fewer than four distinct representations, one or
more of the types may be equivalent.}

The basic format for floating-point numbers is an optional sign
followed by a nonempty sequence of decimal digits possibly with an
embedded decimal point. This sequence can be followed by an exponent
marker for "computerized scientific notation."@footnote{"Computerized
scientific notation" is in scare quotes because, while commonly used
in computer languages since the days of FORTRAN, it's actually quite
different from real scientific notation. In particular, something like
@code{1.0e4} means @code{10000.0}, but in true scientific notation
that would be written as 1.0 x 10^4. And to further confuse matters,
in true scientific notation the letter @emph{e} stands for the base of
the natural logarithm, so something like 1.0 x @emph{e}^4, while
superficially similar to @code{1.0e4}, is a completely different
value, approximately 54.6.} The exponent marker consists of a single
letter followed by an optional sign and a sequence of digits, which
are interpreted as the power of ten by which the number before the
exponent marker should be multiplied. The letter does double duty: it
marks the beginning of the exponent and indicates what floating- point
representation should be used for the number. The exponent markers
@emph{s}, @emph{f}, @emph{d}, @emph{l} (and their uppercase
equivalents) indicate short, single, double, and long floats,
respectively. The letter @emph{e} indicates that the default
representation (initially single-float) should be used.

Numbers with no exponent marker are read in the default representation
and must contain a decimal point followed by at least one digit to
distinguish them from integers. The digits in a floating-point number
are always treated as base 10 digits--the @code{#B}, @code{#X},
@code{#O}, and @code{#R} syntaxes work only with rationals. The
following are some example floating-point numbers along with their
canonical representation:

@verbatim
1.0      ==> 1.0
1e0      ==> 1.0
1d0      ==> 1.0d0
123.0    ==> 123.0
123e0    ==> 123.0
0.123    ==> 0.123
.123     ==> 0.123
123e-3   ==> 0.123
123E-3   ==> 0.123
0.123e20 ==> 1.23e+19
123d23   ==> 1.23d+25
@end verbatim

Finally, complex numbers are written in their own syntax, namely,
@code{#C} or @code{#c} followed by a list of two real numbers
representing the real and imaginary part of the complex number. There
are actually five kinds of complex numbers because the real and
imaginary parts must either both be rational or both be the same kind of
floating-point number.

But you can write them however you want--if a complex is written with
one rational and one floating-point part, the rational is converted to a
float of the appropriate representation. Similarly, if the real and
imaginary parts are both floats of different representations, the one in
the smaller representation will be @emph{upgraded}.

However, no complex numbers have a rational real component and a zero
imaginary part--since such values are, mathematically speaking,
rational, they're represented by the appropriate rational value. The
same mathematical argument could be made for complex numbers with
floating-point components, but for those complex types a number with a
zero imaginary part is always a different object than the floating-point
number representing the real component. Here are some examples of
numbers written the complex number syntax:

@verbatim
#c(2      1)    ==> #c(2 1)
#c(2/3  3/4)    ==> #c(2/3 3/4)
#c(2    1.0)    ==> #c(2.0 1.0)
#c(2.0  1.0d0)  ==> #c(2.0d0 1.0d0)
#c(1/2  1.0)    ==> #c(0.5 1.0)
#c(3      0)    ==> 3
#c(3.0  0.0)    ==> #c(3.0 0.0)
#c(1/2    0)    ==> 1/2
#c(-6/3   0)    ==> -2
@end verbatim

@node Basic Math
@section Basic Math
@anchor{#basic-math} The basic arithmetic operations--addition,
subtraction, multiplication, and division--are supported for all the
different kinds of Lisp numbers with the functions @code{+}, @code{-},
@code{*}, and @code{/}. Calling any of these functions with more than
two arguments is equivalent to calling the same function on the first
two arguments and then calling it again on the resulting value and the
rest of the arguments. For example, @code{(+ 1 2 3)} is equivalent to
@code{(+ (+ 1 2) 3)}. With only one argument, @code{+} and @code{*}
return the value; @code{-} returns its negation and @code{/} its
reciprocal.@footnote{For mathematical consistency, @code{+} and
@code{*} can also be called with no arguments, in which case they
return the appropriate identity: 0 for @code{+} and 1 for @code{*}.}

@verbatim
(+ 1 2)              ==> 3
(+ 1 2 3)            ==> 6
(+ 10.0 3.0)         ==> 13.0
(+ #c(1 2) #c(3 4))  ==> #c(4 6)
(- 5 4)              ==> 1
(- 2)                ==> -2
(- 10 3 5)           ==> 2
(* 2 3)              ==> 6
(* 2 3 4)            ==> 24
(/ 10 5)             ==> 2
(/ 10 5 2)           ==> 1
(/ 2 3)              ==> 2/3
(/ 4)                ==> 1/4
@end verbatim

If all the arguments are the same type of number (rational, floating
point, or complex), the result will be the same type except in the case
where the result of an operation on complex numbers with rational
components yields a number with a zero imaginary part, in which case the
result will be a rational. However, floating-point and complex numbers
are @emph{contagious}--if all the arguments are reals but one or more
are floating-point numbers, the other arguments are converted to the
nearest floating-point value in a "largest" floating-point
representation of the actual floating-point arguments. Floating-point
numbers in a "smaller" representation are also converted to the larger
representation. Similarly, if any of the arguments are complex, any real
arguments are converted to the complex equivalents.

@verbatim
(+ 1 2.0)             ==> 3.0
(/ 2 3.0)             ==> 0.6666667
(+ #c(1 2) 3)         ==> #c(4 2)
(+ #c(1 2) 3/2)       ==> #c(5/2 2)
(+ #c(1 1) #c(2 -1))  ==> 3
@end verbatim

Because @code{/} doesn't truncate, Common Lisp provides four flavors of
truncating and rounding for converting a real number (rational or
floating point) to an integer: @code{FLOOR} truncates toward negative
infinity, returning the largest integer less than or equal to the
argument. @code{CEILING} truncates toward positive infinity, returning
the smallest integer greater than or equal to the argument.
@code{TRUNCATE} truncates toward zero, making it equivalent to
@code{FLOOR} for positive arguments and to @code{CEILING} for negative
arguments. And @code{ROUND} rounds to the nearest integer. If the
argument is exactly halfway between two integers, it rounds to the
nearest even integer.

Two related functions are @code{MOD} and @code{REM}, which return the
modulus and remainder of a truncating division on real numbers. These
two functions are related to the @code{FLOOR} and @code{TRUNCATE}
functions as follows:

@verbatim
(+ (* (floor    (/ x y)) y) (mod x y)) === x
(+ (* (truncate (/ x y)) y) (rem x y)) === x
@end verbatim

Thus, for positive quotients they're equivalent, but for negative
quotients they produce different results.@footnote{Roughly speaking,
@code{MOD} is equivalent to the @code{%} operator in Perl and Python,
and @code{REM} is equivalent to the % in C and Java. (Technically, the
exact behavior of % in C wasn't specified until the C99 standard.)}

The functions @code{1+} and @code{1-} provide a shorthand way to express
adding and subtracting one from a number. Note that these are different
from the macros @code{INCF} and @code{DECF}. @code{1+} and @code{1-} are
just functions that return a new value, but @code{INCF} and @code{DECF}
modify a place. The following equivalences show the relation between
@code{INCF}/@code{DECF}, @code{1+}/@code{1-}, and @code{+}/@code{-}:

@verbatim
(incf x)    === (setf x (1+ x)) === (setf x (+ x 1))
(decf x)    === (setf x (1- x)) === (setf x (- x 1))
(incf x 10) === (setf x (+ x 10))
(decf x 10) === (setf x (- x 10))
@end verbatim

@node Numeric Comparisons
@section Numeric Comparisons
@anchor{#numeric-comparisons}
The function @code{=} is the numeric equality predicate. It compares
numbers by mathematical value, ignoring differences in type. Thus,
@code{=} will consider mathematically equivalent values of different
types equivalent while the generic equality predicate @code{EQL} would
consider them inequivalent because of the difference in type. (The
generic equality predicate @code{EQUALP}, however, uses @code{=} to
compare numbers.) If it's called with more than two arguments, it
returns true only if they all have the same value. Thus:

@verbatim
(= 1 1)                        ==> T
(= 10 20/2)                    ==> T
(= 1 1.0 #c(1.0 0.0) #c(1 0))  ==> T
@end verbatim

The @code{/=} function, conversely, returns true only if @emph{all} its
arguments are different values.

@verbatim
(/= 1 1)        ==> NIL
(/= 1 2)        ==> T
(/= 1 2 3)      ==> T
(/= 1 2 3 1)    ==> NIL
(/= 1 2 3 1.0)  ==> NIL
@end verbatim

The functions @code{<}, @code{>}, @code{<=}, and @code{>=} order
rationals and floating-point numbers (in other words, the real numbers.)
Like @code{=} and @code{/=}, these functions can be called with more
than two arguments, in which case each argument is compared to the
argument to its right.

@verbatim
(< 2 3)       ==> T
(> 2 3)       ==> NIL
(> 3 2)       ==> T
(< 2 3 4)     ==> T
(< 2 3 3)     ==> NIL
(<= 2 3 3)    ==> T
(<= 2 3 3 4)  ==> T
(<= 2 3 4 3)  ==> NIL
@end verbatim

To pick out the smallest or largest of several numbers, you can use the
function @code{MIN} or @code{MAX}, which takes any number of real number
arguments and returns the minimum or maximum value.

@verbatim
(max 10 11)    ==> 11
(min -12 -10)  ==> -12
(max -1 2 -3)  ==> 2
@end verbatim

Some other handy functions are @code{ZEROP}, @code{MINUSP}, and
@code{PLUSP}, which test whether a single real number is equal to, less
than, or greater than zero. Two other predicates, @code{EVENP} and
@code{ODDP}, test whether a single integer argument is even or odd. The
@emph{P} suffix on the names of these functions is a standard naming
convention for predicate functions, functions that test some condition
and return a boolean.

@node Higher Math
@section Higher Math
@anchor{#higher-math}
The functions you've seen so far are the beginning of the built-in
mathematical functions. Lisp also supports logarithms: @code{LOG};
exponentiation: @code{EXP} and @code{EXPT}; the basic trigonometric
functions: @code{SIN}, @code{COS}, and @code{TAN}; their inverses:
@code{ASIN}, @code{ACOS}, and @code{ATAN}; hyperbolic functions:
@code{SINH}, @code{COSH}, and @code{TANH}; and their inverses:
@code{ASINH}, @code{ACOSH}, and @code{ATANH}. It also provides functions
to get at the individual bits of an integer and to extract the parts of
a ratio or a complex number. For a complete list, see any Common Lisp
reference.

@node Characters
@section Characters
@anchor{#characters} Common Lisp characters are a distinct type of
object from numbers.  That's as it should be--characters are
@emph{not} numbers, and languages that treat them as if they are tend
to run into problems when character encodings change, say, from 8-bit
ASCII to 21-bit Unicode.@footnote{Even Java, which was designed from
the beginning to use Unicode characters on the theory that Unicode was
the going to be @emph{the} character encoding of the future, has run
into trouble since Java characters are defined to be a 16-bit quantity
and the Unicode 3.1 standard extended the range of the Unicode
character set to require a 21-bit representation. Ooops.} Because the
Common Lisp standard didn't mandate a particular representation for
characters, today several Lisp implementations use Unicode as their
"native" character encoding despite Unicode being only a gleam in a
standards body's eye at the time Common Lisp's own standardization was
being wrapped up.

The read syntax for characters objects is simple: @code{#\} followed by
the desired character. Thus, @code{#\x} is the character @code{x}. Any
character can be used after the @code{#\}, including otherwise special
characters such as @code{"}, @code{(}, and whitespace. However, writing
whitespace characters this way isn't very (human) readable; an
alternative syntax for certain characters is @code{#\} followed by the
character's name. Exactly what names are supported depends on the
character set and on the Lisp implementation, but all implementations
support the names @emph{Space} and @emph{Newline}. Thus, you should
write @code{#\Space} instead of @code{#\ }, though the latter is
technically legal. Other semistandard names (that implementations must
use if the character set has the appropriate characters) are @emph{Tab},
@emph{Page}, @emph{Rubout}, @emph{Linefeed}, @emph{Return}, and
@emph{Backspace}.

@node Character Comparisons
@section Character Comparisons
@anchor{#character-comparisons}
The main thing you can do with characters, other than putting them into
strings (which I'll get to later in this chapter), is to compare them
with other characters. Since characters aren't numbers, you can't use
the numeric comparison functions, such as @code{<} and @code{>}.
Instead, two sets of functions provide character-specific analogs to the
numeric comparators; one set is case-sensitive and the other
case-insensitive.

The case-sensitive analog to the numeric @code{=} is the function
@code{CHAR=}. Like @code{=}, @code{CHAR=} can take any number of
arguments and returns true only if they're all the same character. The
case- insensitive version is @code{CHAR-EQUAL}.

The rest of the character comparators follow this same naming scheme:
the case-sensitive comparators are named by prepending the analogous
numeric comparator with @code{CHAR}; the case-insensitive versions spell
out the comparator name, separated from the @code{CHAR} with a hyphen.
Note, however, that @code{<=} and @code{>=} are "spelled out" with the
logical equivalents @code{NOT-GREATERP} and @code{NOT-LESSP} rather than
the more verbose @code{LESSP-OR-EQUALP} and @code{GREATERP-OR-EQUALP}.
Like their numeric counterparts, all these functions can take one or
more arguments. Table 10-1 summarizes the relation between the numeric
and character comparison functions.

Table 10-1. Character Comparison Functions
@multitable {@strong{Numeric Analog}} {@strong{Case-Sensitive}} {@strong{Case-Insensitive}}
@item
@strong{Numeric Analog}
 @tab @strong{Case-Sensitive}
 @tab @strong{Case-Insensitive}
@item
@code{=}
 @tab @code{CHAR=}
 @tab @code{CHAR-EQUAL}
@item
@code{/=}
 @tab @code{CHAR/=}
 @tab @code{CHAR-NOT-EQUAL}
@item
@code{<}
 @tab @code{CHAR<}
 @tab @code{CHAR-LESSP}
@item
@code{>}
 @tab @code{CHAR>}
 @tab @code{CHAR-GREATERP}
@item
@code{<=}
 @tab @code{CHAR<=}
 @tab @code{CHAR-NOT-GREATERP}
@item
@code{>=}
 @tab @code{CHAR>=}
 @tab @code{CHAR-NOT-LESSP}
@end multitable

Other functions that deal with characters provide functions for, among
other things, testing whether a given character is alphabetic or a digit
character, testing the case of a character, obtaining a corresponding
character in a different case, and translating between numeric values
representing character codes and actual character objects. Again, for
complete details, see your favorite Common Lisp reference.

@node Strings
@section Strings
@anchor{#strings}
As mentioned earlier, strings in Common Lisp are really a composite data
type, namely, a one-dimensional array of characters. Consequently, I'll
cover many of the things you can do with strings in the next chapter
when I discuss the many functions for manipulating sequences, of which
strings are just one type. But strings also have their own literal
syntax and a library of functions for performing string-specific
operations. I'll discuss these aspects of strings in this chapter and
leave the others for Chapter 11.

As you've seen, literal strings are written enclosed in double quotes.
You can include any character supported by the character set in a
literal string except double quote (@code{"}) and backslash (\). And you
can include these two as well if you escape them with a backslash. In
fact, backslash always escapes the next character, whatever it is,
though this isn't necessary for any character except for @code{"} and
itself. Table 10-2 shows how various literal strings will be read by the
Lisp reader.

Table 10-2. Literal Strings
@multitable {@code{"\"foobar\""}} {@strong{Contents}} {The first backslash escapes second backslash.}
@item
@strong{Literal}
 @tab @strong{Contents}
 @tab @strong{Comment}
@item
@code{"foobar"}
 @tab foobar
 @tab Plain string.
@item
@code{"foo\"bar"}
 @tab foo"bar
 @tab The backslash escapes quote.
@item
@code{"foo\\bar"}
 @tab foo\bar
 @tab The first backslash escapes second backslash.
@item
@code{"\"foobar\""}
 @tab "foobar"
 @tab The backslashes escape quotes.
@item
@code{"foo\bar"}
 @tab foobar
 @tab The backslash "escapes" @emph{b}
@end multitable

Note that the REPL will ordinarily print strings in readable form,
adding the enclosing quotation marks and any necessary escaping
backslashes, so if you want to see the actual contents of a string, you
need to use function such as @code{FORMAT} designed to print
human-readable output. For example, here's what you see if you type a
string containing an embedded quotation mark at the REPL:

@verbatim
CL-USER> "foo\"bar"
"foo\"bar"
@end verbatim

@code{FORMAT}, on the other hand, will show you the actual string
contents:@footnote{Note, however, that not all literal strings can be
printed by passing them as the second argument to @code{FORMAT} since
certain sequences of characters have a special meaning to
@code{FORMAT}.  To safely print an arbitrary string--say, the value of
a variable s--with @code{FORMAT} you should write (format t "~a" s).}

@verbatim
CL-USER> (format t "foo\"bar")
foo"bar
NIL
@end verbatim

@node String Comparisons
@section String Comparisons
@anchor{#string-comparisons}
You can compare strings using a set of functions that follow the same
naming convention as the character comparison functions except with
@code{STRING} as the prefix rather than @code{CHAR} (see Table 10-3).

Table 10-3. String Comparison Functions
@multitable {@strong{Numeric Analog}} {@strong{Case-Sensitive}} {@code{STRING-NOT-GREATERP}}
@item
@strong{Numeric Analog}
 @tab @strong{Case-Sensitive}
 @tab @strong{Case-Insensitive}
@item
@code{=}
 @tab @code{STRING=}
 @tab @code{STRING-EQUAL}
@item
@code{/=}
 @tab @code{STRING/=}
 @tab @code{STRING-NOT-EQUAL}
@item
@code{<}
 @tab @code{STRING<}
 @tab @code{STRING-LESSP}
@item
@code{>}
 @tab @code{STRING>}
 @tab @code{STRING-GREATERP}
@item
@code{<=}
 @tab @code{STRING<=}
 @tab @code{STRING-NOT-GREATERP}
@item
@code{>=}
 @tab @code{STRING>=}
 @tab @code{STRING-NOT-LESSP}
@end multitable

However, unlike the character and number comparators, the string
comparators can compare only two strings. That's because they also take
keyword arguments that allow you to restrict the comparison to a
substring of either or both strings. The arguments--@code{:start1},
@code{:end1}, @code{:start2}, and @code{:end2}--specify the starting
(inclusive) and ending (exclusive) indices of substrings in the first
and second string arguments. Thus, the following:

@verbatim
(string= "foobarbaz" "quuxbarfoo" :start1 3 :end1 6 :start2 4 :end2 7)
@end verbatim

compares the substring "bar" in the two arguments and returns true. The
@code{:end1} and @code{:end2} arguments can be @code{NIL} (or the
keyword argument omitted altogether) to indicate that the corresponding
substring extends to the end of the string.

The comparators that return true when their arguments differ--that is,
all of them except @code{STRING=} and @code{STRING-EQUAL}--return the
index in the first string where the mismatch was detected.

@verbatim
(string/= "lisp" "lissome") ==> 3
@end verbatim

If the first string is a prefix of the second, the return value will be
the length of the first string, that is, one greater than the largest
valid index into the string.

@verbatim
(string< "lisp" "lisper") ==> 4
@end verbatim

When comparing substrings, the resulting value is still an index into
the string as a whole. For instance, the following compares the
substrings "bar" and "baz" but returns 5 because that's the index of the
@emph{r} in the first string:

@verbatim
(string< "foobar" "abaz" :start1 3 :start2 1) ==> 5   ; N.B. not 2
@end verbatim

Other string functions allow you to convert the case of strings and trim
characters from one or both ends of a string. And, as I mentioned
previously, since strings are really a kind of sequence, all the
sequence functions I'll discuss in the next chapter can be used with
strings. For instance, you can discover the length of a string with the
@code{LENGTH} function and can get and set individual characters of a
string with the generic sequence element accessor function, @code{ELT},
or the generic array element accessor function, @code{AREF}. Or you can
use the string-specific accessor, @code{CHAR}. But those functions, and
others, are the topic of the next chapter, so let's move on.

@node Collections
@chapter Collections
@anchor{#collections}
Like most programming languages, Common Lisp provides standard data
types that collect multiple values into a single object. Every language
slices up the collection problem a little bit differently, but the basic
collection types usually boil down to an integer-indexed array type and
a table type that can be used to map more or less arbitrary keys to
values. The former are variously called @emph{arrays}, @emph{lists}, or
@emph{tuples}; the latter go by the names @emph{hash tables},
@emph{associative arrays}, @emph{maps}, and @emph{dictionaries}.

Lisp is, of course, famous for its list data structure, and most Lisp
books, following the ontogeny-recapitulates-phylogeny principle of
language instruction, start their discussion of Lisp's collections with
lists. However, that approach often leads readers to the mistaken
conclusion that lists are Lisp's @emph{only} collection type. To make
matters worse, because Lisp's lists are such a flexible data structure,
it @emph{is} possible to use them for many of the things arrays and hash
tables are used for in other languages. But it's a mistake to focus too
much on lists; while they're a crucial data structure for representing
Lisp code as Lisp data, in many situations other data structures are
more appropriate.

To keep lists from stealing the show, in this chapter I'll focus on
Common Lisp's other collection types: vectors and hash
tables.@footnote{Once you're familiar with all the data types Common
Lisp offers, you'll also see that lists can be useful for prototyping
data structures that will later be replaced with something more
efficient once it becomes clear how exactly the data is to be used.}
However, vectors and lists share enough characteristics that Common
Lisp treats them both as subtypes of a more general abstraction, the
sequence. Thus, you can use many of the functions I'll discuss in this
chapter with both vectors and lists.
@menu
* Vectors::
* Subtypes of Vector::
* Vectors As Sequences::
* Sequence Iterating Functions::
* Higher-Order Function Variants::
* Whole Sequence Manipulations::
* Sorting and Merging::
* Subsequence Manipulations::
* Sequence Predicates::
* Sequence Mapping Functions::
* Hash Tables::
* Hash Table Iteration::
@end menu

@node Vectors
@section Vectors
@anchor{#vectors} Vectors are Common Lisp's basic integer-indexed
collection, and they come in two flavors. Fixed-size vectors are a lot
like arrays in a language such as Java: a thin veneer over a chunk of
contiguous memory that holds the vector's elements.@footnote{Vectors
are called @emph{vectors}, not @emph{arrays} as their analogs in other
languages are, because Common Lisp supports true multidimensional
arrays. It's equally correct, though more cumbersome, to refer to them
as @emph{one-dimensional arrays}.} Resizable vectors, on the other
hand, are more like arrays in Perl or Ruby, lists in Python, or the
ArrayList class in Java: they abstract the actual storage, allowing
the vector to grow and shrink as elements are added and removed.

You can make fixed-size vectors containing specific values with the
function @code{VECTOR}, which takes any number of arguments and returns
a freshly allocated fixed-size vector containing those arguments.

@verbatim
(vector)     ==> #()
(vector 1)   ==> #(1)
(vector 1 2) ==> #(1 2)
@end verbatim

The @code{#(...)} syntax is the literal notation for vectors used by the
Lisp printer and reader. This syntax allows you to save and restore
vectors by @code{PRINT}ing them out and @code{READ}ing them back in. You
can use the @code{#(...)} syntax to include literal vectors in your
code, but as the effects of modifying literal objects aren't defined,
you should always use @code{VECTOR} or the more general function
@code{MAKE-ARRAY} to create vectors you plan to modify.

@code{MAKE-ARRAY} is more general than @code{VECTOR} since you can use
it to create arrays of any dimensionality as well as both fixed-size
and resizable vectors. The one required argument to @code{MAKE-ARRAY}
is a list containing the dimensions of the array. Since a vector is a
one-dimensional array, this list will contain one number, the size of
the vector. As a convenience, @code{MAKE-ARRAY} will also accept a
plain number in the place of a one-item list. With no other arguments,
@code{MAKE-ARRAY} will create a vector with uninitialized elements
that must be set before they can be accessed.@footnote{Array elements
"must" be set before they're accessed in the sense that the behavior
is undefined; Lisp won't necessarily stop you.} To create a vector
with the elements all set to a particular value, you can pass an
@code{:initial-element} argument. Thus, to make a five-element vector
with its elements initialized to @code{NIL}, you can write the
following:

@verbatim
(make-array 5 :initial-element nil) ==> #(NIL NIL NIL NIL NIL)
@end verbatim

@code{MAKE-ARRAY} is also the function to use to make a resizable
vector. A resizable vector is a slightly more complicated object than a
fixed-size vector; in addition to keeping track of the memory used to
hold the elements and the number of slots available, a resizable vector
also keeps track of the number of elements actually stored in the
vector. This number is stored in the vector's @emph{fill pointer}, so
called because it's the index of the next position to be filled when you
add an element to the vector.

To make a vector with a fill pointer, you pass @code{MAKE-ARRAY} a
@code{:fill-pointer} argument. For instance, the following call to
@code{MAKE-ARRAY} makes a vector with room for five elements; but it
looks empty because the fill pointer is zero:

@verbatim
(make-array 5 :fill-pointer 0) ==> #()
@end verbatim

To add an element to the end of a resizable vector, you can use the
function @code{VECTOR-PUSH}. It adds the element at the current value of
the fill pointer and then increments the fill pointer by one, returning
the index where the new element was added. The function
@code{VECTOR-POP} returns the most recently pushed item, decrementing
the fill pointer in the process.

@verbatim
(defparameter *x* (make-array 5 :fill-pointer 0))

(vector-push 'a *x*) ==> 0
*x*                  ==> #(A)
(vector-push 'b *x*) ==> 1
*x*                  ==> #(A B)
(vector-push 'c *x*) ==> 2
*x*                  ==> #(A B C)
(vector-pop *x*)     ==> C
*x*                  ==> #(A B)
(vector-pop *x*)     ==> B
*x*                  ==> #(A)
(vector-pop *x*)     ==> A
*x*                  ==> #()
@end verbatim

However, even a vector with a fill pointer isn't completely resizable.
The vector @code{*x*} can hold at most five elements. To make an
arbitrarily resizable vector, you need to pass @code{MAKE-ARRAY} another
keyword argument: @code{:adjustable}.

@verbatim
(make-array 5 :fill-pointer 0 :adjustable t) ==> #()
@end verbatim

This call makes an @emph{adjustable} vector whose underlying memory
can be resized as needed. To add elements to an adjustable vector, you
use @code{VECTOR-PUSH-EXTEND}, which works just like
@code{VECTOR-PUSH} except it will automatically expand the array if
you try to push an element onto a full vector--one whose fill pointer
is equal to the size of the underlying storage.@footnote{While
frequently used together, the @code{:fill-pointer} and
@code{:adjustable} arguments are independent--you can make an
adjustable array without a fill pointer.  However, you can use
@code{VECTOR-PUSH} and @code{VECTOR-POP} only with vectors that have a
fill pointer and @code{VECTOR-PUSH-EXTEND} only with vectors that have
a fill pointer and are adjustable. You can also use the function
@code{ADJUST-ARRAY} to modify adjustable arrays in a variety of ways
beyond just extending the length of a vector.}

@node Subtypes of Vector
@section Subtypes of Vector
@anchor{#subtypes-of-vector}
All the vectors you've dealt with so far have been @emph{general}
vectors that can hold any type of object. It's also possible to create
@emph{specialized} vectors that are restricted to holding certain types
of elements. One reason to use specialized vectors is they may be stored
more compactly and can provide slightly faster access to their elements
than general vectors. However, for the moment let's focus on a couple
kinds of specialized vectors that are important data types in their own
right.

One of these you've seen already--strings are vectors specialized to
hold characters. Strings are important enough to get their own
read/print syntax (double quotes) and the set of string-specific
functions I discussed in the previous chapter. But because they're also
vectors, all the functions I'll discuss in the next few sections that
take vector arguments can also be used with strings. These functions
will fill out the string library with functions for things such as
searching a string for a substring, finding occurrences of a character
within a string, and more.

Literal strings, such as @code{"foo"}, are like literal vectors written
with the @code{#()} syntax--their size is fixed, and they must not be
modified. However, you can use @code{MAKE-ARRAY} to make resizable
strings by adding another keyword argument, @code{:element-type}. This
argument takes a @emph{type} descriptor. I won't discuss all the
possible type descriptors you can use here; for now it's enough to know
you can create a string by passing the symbol @code{CHARACTER} as the
@code{:element-type} argument. Note that you need to quote the symbol to
prevent it from being treated as a variable name. For example, to make
an initially empty but resizable string, you can write this:

@verbatim
(make-array 5 :fill-pointer 0 :adjustable t :element-type 'character)  ""
@end verbatim

Bit vectors--vectors whose elements are all zeros or ones--also get some
special treatment. They have a special read/print syntax that looks like
@code{#*00001111} and a fairly large library of functions, which I won't
discuss, for performing bit-twiddling operations such as "anding"
together two bit arrays. The type descriptor to pass as the
@code{:element-type} to create a bit vector is the symbol @code{BIT}.

@node Vectors As Sequences
@section Vectors As Sequences
@anchor{#vectors-as-sequences}
As mentioned earlier, vectors and lists are the two concrete subtypes of
the abstract type @emph{sequence}. All the functions I'll discuss in the
next few sections are sequence functions; in addition to being
applicable to vectors--both general and specialized--they can also be
used with lists.

The two most basic sequence functions are @code{LENGTH}, which returns
the length of a sequence, and @code{ELT}, which allows you to access
individual elements via an integer index. @code{LENGTH} takes a sequence
as its only argument and returns the number of elements it contains. For
vectors with a fill pointer, this will be the value of the fill pointer.
@code{ELT}, short for @emph{element}, takes a sequence and an integer
index between zero (inclusive) and the length of the sequence
(exclusive) and returns the corresponding element. @code{ELT} will
signal an error if the index is out of bounds. Like @code{LENGTH},
@code{ELT} treats a vector with a fill pointer as having the length
specified by the fill pointer.

@verbatim
(defparameter *x* (vector 1 2 3))

(length *x*) ==> 3
(elt *x* 0)  ==> 1
(elt *x* 1)  ==> 2
(elt *x* 2)  ==> 3
(elt *x* 3)  ==> error
@end verbatim

@code{ELT} is also a @code{SETF}able place, so you can set the value of
a particular element like this:

@verbatim
(setf (elt *x* 0) 10)

*x* ==> #(10 2 3)
@end verbatim

@node Sequence Iterating Functions
@section Sequence Iterating Functions
@anchor{#sequence-iterating-functions}
While in theory all operations on sequences boil down to some
combination of @code{LENGTH}, @code{ELT}, and @code{SETF} of @code{ELT}
operations, Common Lisp provides a large library of sequence functions.

One group of sequence functions allows you to express certain operations
on sequences such as finding or filtering specific elements without
writing explicit loops. Table 11-1 summarizes them.

Table 11-1.Basic Sequence Functions
@multitable {@code{SUBSTITUTE}} {New item, item, and sequence} {Sequence with instances of item replaced with new item}
@item
Name
 @tab Required Arguments
 @tab Returns
@item
@code{COUNT}
 @tab Item and sequence
 @tab Number of times item appears in sequence
@item
@code{FIND}
 @tab Item and sequence
 @tab Item or @code{NIL}
@item
@code{POSITION}
 @tab Item and sequence
 @tab Index into sequence or @code{NIL}
@item
@code{REMOVE}
 @tab Item and sequence
 @tab Sequence with instances of item removed
@item
@code{SUBSTITUTE}
 @tab New item, item, and sequence
 @tab Sequence with instances of item replaced with new item
@end multitable

Here are some simple examples of how to use these functions:

@verbatim
(count 1 #(1 2 1 2 3 1 2 3 4))         ==> 3
(remove 1 #(1 2 1 2 3 1 2 3 4))        ==> #(2 2 3 2 3 4)
(remove 1 '(1 2 1 2 3 1 2 3 4))        ==> (2 2 3 2 3 4)
(remove #\a "foobarbaz")               ==> "foobrbz"
(substitute 10 1 #(1 2 1 2 3 1 2 3 4)) ==> #(10 2 10 2 3 10 2 3 4)
(substitute 10 1 '(1 2 1 2 3 1 2 3 4)) ==> (10 2 10 2 3 10 2 3 4)
(substitute #\x #\b "foobarbaz")       ==> "fooxarxaz"
(find 1 #(1 2 1 2 3 1 2 3 4))          ==> 1
(find 10 #(1 2 1 2 3 1 2 3 4))         ==> NIL
(position 1 #(1 2 1 2 3 1 2 3 4))      ==> 0
@end verbatim

Note how @code{REMOVE} and @code{SUBSTITUTE} always return a sequence of
the same type as their sequence argument.

You can modify the behavior of these five functions in a variety of
ways using keyword arguments. For instance, these functions, by
default, look for elements in the sequence that are the same object as
the item argument. You can change this in two ways: First, you can use
the @code{:test} keyword to pass a function that accepts two arguments
and returns a boolean. If provided, it will be used to compare
@emph{item} to each element instead of the default object equality
test, @code{EQL}.@footnote{Another parameter, @code{:test-not}
parameter, specifies a two-argument predicate to be used like a
@code{:test} argument except with the boolean result logically
reversed. This parameter is deprecated, however, in preference for
using the @code{COMPLEMENT} function. @code{COMPLEMENT} takes a
function argu-ment and returns a function that takes the same number
of arguments as the original and returns the logical complement of the
original function.  Thus, you can, and should, write this:

@verbatim
(count x sequence :test (complement #'some-test))
@end verbatim

rather than the following:

@verbatim
(count x sequence :test-not #'some-test)
@end verbatim
} Second, with the @code{:key} keyword you can pass a one-argument
function to be called on each element of the sequence to extract a
@emph{key} value, which will then be compared to the item in the place
of the element itself. Note, however, that functions such as
@code{FIND} that return elements of the sequence continue to return
the actual element, not just the extracted key.

@verbatim
(count "foo" #("foo" "bar" "baz") :test #'string=)    ==> 1
(find 'c #((a 10) (b 20) (c 30) (d 40)) :key #'first) ==> (C 30)
@end verbatim

To limit the effects of these functions to a particular subsequence of
the sequence argument, you can provide bounding indices with
@code{:start} and @code{:end} arguments. Passing @code{NIL} for
@code{:end} or omitting it is the same as specifying the length of the
sequence.@footnote{Note, however, that the effect of @code{:start} and
@code{:end} on @code{REMOVE} and @code{SUBSTITUTE} is only to limit
the elements they consider for removal or substitution; elements
before @code{:start} and after @code{:end} will be passed through
untouched.}

If a non-@code{NIL} @code{:from-end} argument is provided, then the
elements of the sequence will be examined in reverse order. By itself
@code{:from-end} can affect the results of only @code{FIND} and
@code{POSITION}. For instance:

@verbatim
(find 'a #((a 10) (b 20) (a 30) (b 40)) :key #'first)             ==> (A 10)
(find 'a #((a 10) (b 20) (a 30) (b 40)) :key #'first :from-end t) ==> (A 30)
@end verbatim

However, the @code{:from-end} argument can affect @code{REMOVE} and
@code{SUBSTITUTE} in conjunction with another keyword parameter,
@code{:count}, that's used to specify how many elements to remove or
substitute. If you specify a @code{:count} lower than the number of
matching elements, then it obviously matters which end you start from:

@verbatim
(remove #\a "foobarbaz" :count 1)             ==> "foobrbaz"
(remove #\a "foobarbaz" :count 1 :from-end t) ==> "foobarbz"
@end verbatim

And while @code{:from-end} can't change the results of the @code{COUNT}
function, it does affect the order the elements are passed to any
@code{:test} and @code{:key} functions, which could possibly have side
effects. For example:

@verbatim
CL-USER> (defparameter *v* #((a 10) (b 20) (a 30) (b 40)))
*V*
CL-USER> (defun verbose-first (x) (format t "Looking at ~s~%" x) (first x))
VERBOSE-FIRST
CL-USER> (count 'a *v* :key #'verbose-first)
Looking at (A 10)
Looking at (B 20)
Looking at (A 30)
Looking at (B 40)
2
CL-USER> (count 'a *v* :key #'verbose-first :from-end t)
Looking at (B 40)
Looking at (A 30)
Looking at (B 20)
Looking at (A 10)
2
@end verbatim

Table 11-2 summarizes these arguments.

Table 11-2. Standard Sequence Function Keyword Arguments
@multitable {@code{:from-end}} {Number indicating the number of elements to remove or substitute or @code{NIL} to indicate all (@code{REMOVE} and @code{SUBSTITUTE} only).} {@code{NIL}}
@item
Argument
 @tab Meaning
 @tab Default
@item
@code{:test}
 @tab Two-argument function used to compare item (or value extracted by
@code{:key} function) to element.
 @tab @code{EQL}
@item
@code{:key}
 @tab One-argument function to extract key value from actual sequence
element. @code{NIL} means use element as is.
 @tab @code{NIL}
@item
@code{:start}
 @tab Starting index (inclusive) of subsequence.
 @tab 0
@item
@code{:end}
 @tab Ending index (exclusive) of subsequence. @code{NIL} indicates end
of sequence.
 @tab @code{NIL}
@item
@code{:from-end}
 @tab If true, the sequence will be traversed in reverse order, from end
to start.
 @tab @code{NIL}
@item
@code{:count}
 @tab Number indicating the number of elements to remove or substitute
or @code{NIL} to indicate all (@code{REMOVE} and @code{SUBSTITUTE}
only).
 @tab @code{NIL}
@end multitable

@node Higher-Order Function Variants
@section Higher-Order Function Variants
@anchor{#higher-order-function-variants}
For each of the functions just discussed, Common Lisp provides two
@emph{higher-order function} variants that, in the place of the item
argument, take a function to be called on each element of the sequence.
One set of variants are named the same as the basic function with an
@code{-IF} appended. These functions count, find, remove, and substitute
elements of the sequence for which the function argument returns true.
The other set of variants are named with an @code{-IF-NOT} suffix and
count, find, remove, and substitute elements for which the function
argument does @emph{not} return true.

@verbatim
(count-if #'evenp #(1 2 3 4 5))         ==> 2

(count-if-not #'evenp #(1 2 3 4 5))     ==> 3

(position-if #'digit-char-p "abcd0001") ==> 4

(remove-if-not #'(lambda (x) (char= (elt x 0) #\f))
  #("foo" "bar" "baz" "foom")) ==> #("foo" "foom")
@end verbatim

According to the language standard, the @code{-IF-NOT} variants are
deprecated. However, that deprecation is generally considered to have
itself been ill-advised. If the standard is ever revised, it's more
likely the deprecation will be removed than the @code{-IF-NOT}
functions. For one thing, the @code{REMOVE-IF-NOT} variant is probably
used more often than @code{REMOVE-IF}. Despite its negative-sounding
name, @code{REMOVE-IF-NOT} is actually the positive variant--it
returns the elements that @emph{do} satisfy the
predicate. @footnote{This same functionality goes by the name
@code{grep} in Perl and @code{filter} in Python.}

The @code{-IF} and @code{-IF-NOT} variants accept all the same keyword
arguments as their vanilla counterparts except for @code{:test}, which
isn't needed since the main argument is already a
function.@footnote{The difference between the predicates passed as
@code{:test} arguments and as the function arguments to the @code{-IF}
and @code{-IF-NOT} functions is that the @code{:test} predicates are
two-argument predicates used to compare the elements of the sequence
to the specific item while the @code{-IF} and @code{-IF-NOT}
predicates are one-argument functions that simply test the individual
elements of the sequence. If the vanilla variants didn't exist, you
could implement them in terms of the -IF versions by embedding a
specific item in the test function.

@verbatim
(count char string) ===
  (count-if #'(lambda (c) (eql char c)) string)
@end verbatim

@verbatim
(count char string :test #'CHAR-EQUAL) ===
  (count-if #'(lambda (c) (char-equal char c)) string)
@end verbatim
} With a @code{:key} argument, the value
extracted by the @code{:key} function is passed to the function
instead of the actual element.

@verbatim
(count-if #'evenp #((1 a) (2 b) (3 c) (4 d) (5 e)) :key #'first)     ==> 2

(count-if-not #'evenp #((1 a) (2 b) (3 c) (4 d) (5 e)) :key #'first) ==> 3

(remove-if-not #'alpha-char-p
  #("foo" "bar" "1baz") :key #'(lambda (x) (elt x 0))) ==> #("foo" "bar")
@end verbatim

The @code{REMOVE} family of functions also support a fourth variant,
@code{REMOVE-DUPLICATES}, that has only one required argument, a
sequence, from which it removes all but one instance of each duplicated
element. It takes the same keyword arguments as @code{REMOVE}, except
for @code{:count}, since it always removes all duplicates.

@verbatim
(remove-duplicates #(1 2 1 2 3 1 2 3 4)) ==> #(1 2 3 4)
@end verbatim

@node Whole Sequence Manipulations
@section Whole Sequence Manipulations
@anchor{#whole-sequence-manipulations}
A handful of functions perform operations on a whole sequence (or
sequences) at a time. These tend to be simpler than the other functions
I've described so far. For instance, @code{COPY-SEQ} and @code{REVERSE}
each take a single argument, a sequence, and each returns a new sequence
of the same type. The sequence returned by @code{COPY-SEQ} contains the
same elements as its argument while the sequence returned by
@code{REVERSE} contains the same elements but in reverse order. Note
that neither function copies the elements themselves--only the returned
sequence is a new object.

The @code{CONCATENATE} function creates a new sequence containing the
concatenation of any number of sequences. However, unlike
@code{REVERSE} and @code{COPY-SEQ}, which simply return a sequence of
the same type as their single argument, @code{CONCATENATE} must be
told explicitly what kind of sequence to produce in case the arguments
are of different types. Its first argument is a type descriptor, like
the @code{:element-type} argument to @code{MAKE-ARRAY}. In this case,
the type descriptors you'll most likely use are the symbols
@code{VECTOR}, @code{LIST}, or @code{STRING}.@footnote{If you tell
@code{CONCATENATE} to return a specialized vector, such as a string,
all the elements of the argument sequences must be instances of the
vector's element type.} For example:

@verbatim
(concatenate 'vector #(1 2 3) '(4 5 6))    ==> #(1 2 3 4 5 6)
(concatenate 'list #(1 2 3) '(4 5 6))      ==> (1 2 3 4 5 6)
(concatenate 'string "abc" '(#\d #\e #\f)) ==> "abcdef"
@end verbatim

@node Sorting and Merging
@section Sorting and Merging
@anchor{#sorting-and-merging}
The functions @code{SORT} and @code{STABLE-SORT} provide two ways of
sorting a sequence. They both take a sequence and a two-argument
predicate and return a sorted version of the sequence.

@verbatim
(sort (vector "foo" "bar" "baz") #'string<) ==> #("bar" "baz" "foo")
@end verbatim

The difference is that @code{STABLE-SORT} is guaranteed to not reorder
any elements considered equivalent by the predicate while @code{SORT}
guarantees only that the result is sorted and may reorder equivalent
elements.

Both these functions are examples of what are called @emph{destructive}
functions. Destructive functions are allowed--typically for reasons of
efficiency--to modify their arguments in more or less arbitrary ways.
This has two implications: one, you should always do something with the
return value of these functions (such as assign it to a variable or pass
it to another function), and, two, unless you're done with the object
you're passing to the destructive function, you should pass a copy
instead. I'll say more about destructive functions in the next chapter.

Typically you won't care about the unsorted version of a sequence
after you've sorted it, so it makes sense to allow @code{SORT} and
@code{STABLE-SORT} to destroy the sequence in the course of sorting
it.  But it does mean you need to remember to write the
following:@footnote{When the sequence passed to the sorting functions
is a vector, the "destruction" is actually guaranteed to entail
permuting the elements in place, so you could get away without saving
the returned value. However, it's good style to always do something
with the return value since the sorting functions can modify lists in
much more arbitrary ways.}

@verbatim
(setf my-sequence (sort my-sequence #'string<))
@end verbatim

rather than just this:

@verbatim
(sort my-sequence #'string<)
@end verbatim

Both these functions also take a keyword argument, @code{:key}, which,
like the @code{:key} argument in other sequence functions, should be a
function and will be used to extract the values to be passed to the
sorting predicate in the place of the actual elements. The extracted
keys are used only to determine the ordering of elements; the sequence
returned will contain the actual elements of the argument sequence.

The @code{MERGE} function takes two sequences and a predicate and
returns a sequence produced by merging the two sequences, according to
the predicate. It's related to the two sorting functions in that if each
sequence is already sorted by the same predicate, then the sequence
returned by @code{MERGE} will also be sorted. Like the sorting
functions, @code{MERGE} takes a @code{:key} argument. Like
@code{CONCATENATE}, and for the same reason, the first argument to
@code{MERGE} must be a type descriptor specifying the type of sequence
to produce.

@verbatim
(merge 'vector #(1 3 5) #(2 4 6) #'<) ==> #(1 2 3 4 5 6)
(merge 'list #(1 3 5) #(2 4 6) #'<)   ==> (1 2 3 4 5 6)
@end verbatim

@node Subsequence Manipulations
@section Subsequence Manipulations
@anchor{#subsequence-manipulations}
Another set of functions allows you to manipulate subsequences of
existing sequences. The most basic of these is @code{SUBSEQ}, which
extracts a subsequence starting at a particular index and continuing to
a particular ending index or the end of the sequence. For instance:

@verbatim
(subseq "foobarbaz" 3)   ==> "barbaz"
(subseq "foobarbaz" 3 6) ==> "bar"
@end verbatim

@code{SUBSEQ} is also @code{SETF}able, but it won't extend or shrink a
sequence; if the new value and the subsequence to be replaced are
different lengths, the shorter of the two determines how many characters
are actually changed.

@verbatim
(defparameter *x* (copy-seq "foobarbaz"))

(setf (subseq *x* 3 6) "xxx")  ; subsequence and new value are same length
*x* ==> "fooxxxbaz"

(setf (subseq *x* 3 6) "abcd") ; new value too long, extra character ignored.
*x* ==> "fooabcbaz"

(setf (subseq *x* 3 6) "xx")   ; new value too short, only two characters changed
*x* ==> "fooxxcbaz"
@end verbatim

You can use the @code{FILL} function to set multiple elements of a
sequence to a single value. The required arguments are a sequence and
the value with which to fill it. By default every element of the
sequence is set to the value; @code{:start} and @code{:end} keyword
arguments can limit the effects to a given subsequence.

If you need to find a subsequence within a sequence, the @code{SEARCH}
function works like @code{POSITION} except the first argument is a
sequence rather than a single item.

@verbatim
(position #\b "foobarbaz") ==> 3
(search "bar" "foobarbaz") ==> 3
@end verbatim

On the other hand, to find where two sequences with a common prefix
first diverge, you can use the @code{MISMATCH} function. It takes two
sequences and returns the index of the first pair of mismatched
elements.

@verbatim
(mismatch "foobarbaz" "foom") ==> 3
@end verbatim

It returns @code{NIL} if the strings match. @code{MISMATCH} also takes
many of the standard keyword arguments: a @code{:key} argument for
specifying a function to use to extract the values to be compared; a
@code{:test} argument to specify the comparison function; and
@code{:start1}, @code{:end1}, @code{:start2}, and @code{:end2} arguments
to specify subsequences within the two sequences. And a @code{:from-end}
argument of @code{T} specifies the sequences should be searched in
reverse order, causing @code{MISMATCH} to return the index, in the first
sequence, where whatever common suffix the two sequences share begins.

@verbatim
(mismatch "foobar" "bar" :from-end t) ==> 3
@end verbatim

@node Sequence Predicates
@section Sequence Predicates
@anchor{#sequence-predicates}
Four other handy functions are @code{EVERY}, @code{SOME}, @code{NOTANY},
and @code{NOTEVERY}, which iterate over sequences testing a boolean
predicate. The first argument to all these functions is the predicate,
and the remaining arguments are sequences. The predicate should take as
many arguments as the number of sequences passed. The elements of the
sequences are passed to the predicate--one element from each
sequence--until one of the sequences runs out of elements or the overall
termination test is met: @code{EVERY} terminates, returning false, as
soon as the predicate fails. If the predicate is always satisfied, it
returns true. @code{SOME} returns the first non-@code{NIL} value
returned by the predicate or returns false if the predicate is never
satisfied. @code{NOTANY} returns false as soon as the predicate is
satisfied or true if it never is. And @code{NOTEVERY} returns true as
soon as the predicate fails or false if the predicate is always
satisfied. Here are some examples of testing just one sequence:

@verbatim
(every #'evenp #(1 2 3 4 5))    ==> NIL
(some #'evenp #(1 2 3 4 5))     ==> T
(notany #'evenp #(1 2 3 4 5))   ==> NIL
(notevery #'evenp #(1 2 3 4 5)) ==> T
@end verbatim

These calls compare elements of two sequences pairwise:

@verbatim
(every #'> #(1 2 3 4) #(5 4 3 2))    ==> NIL
(some #'> #(1 2 3 4) #(5 4 3 2))     ==> T
(notany #'> #(1 2 3 4) #(5 4 3 2))   ==> NIL
(notevery #'> #(1 2 3 4) #(5 4 3 2)) ==> T
@end verbatim

@node Sequence Mapping Functions
@section Sequence Mapping Functions
@anchor{#sequence-mapping-functions}
Finally, the last of the sequence functions are the generic mapping
functions. @code{MAP}, like the sequence predicate functions, takes a
@emph{n}-argument function and @emph{n} sequences. But instead of a
boolean value, @code{MAP} returns a new sequence containing the result
of applying the function to subsequent elements of the sequences. Like
@code{CONCATENATE} and @code{MERGE}, @code{MAP} needs to be told what
kind of sequence to create.

@verbatim
(map 'vector #'* #(1 2 3 4 5) #(10 9 8 7 6)) ==> #(10 18 24 28 30)
@end verbatim

@code{MAP-INTO} is like @code{MAP} except instead of producing a new
sequence of a given type, it places the results into a sequence passed
as the first argument. This sequence can be the same as one of the
sequences providing values for the function. For instance, to sum
several vectors--@code{a}, @code{b}, and @code{c}--into one, you could
write this:

@verbatim
(map-into a #'+ a b c)
@end verbatim

If the sequences are different lengths, @code{MAP-INTO} affects only as
many elements as are present in the shortest sequence, including the
sequence being mapped into. However, if the sequence being mapped into
is a vector with a fill pointer, the number of elements affected isn't
limited by the fill pointer but rather by the actual size of the vector.
After a call to @code{MAP-INTO}, the fill pointer will be set to the
number of elements mapped. @code{MAP-INTO} won't, however, extend an
adjustable vector.

The last sequence function is @code{REDUCE}, which does another kind of
mapping: it maps over a single sequence, applying a two-argument
function first to the first two elements of the sequence and then to the
value returned by the function and subsequent elements of the sequence.
Thus, the following expression sums the numbers from one to ten:

@verbatim
(reduce #'+ #(1 2 3 4 5 6 7 8 9 10)) ==> 55
@end verbatim

@code{REDUCE} is a surprisingly useful function--whenever you need to
distill a sequence down to a single value, chances are you can write it
with @code{REDUCE}, and it will often be quite a concise way to express
what you want. For instance, to find the maximum value in a sequence of
numbers, you can write @code{(reduce #'max numbers)}. @code{REDUCE} also
takes a full complement of keyword arguments (@code{:key},
@code{:from-end}, @code{:start}, and @code{:end}) and one unique to
@code{REDUCE} (@code{:initial-value}). The latter specifies a value
that's logically placed before the first element of the sequence (or
after the last if you also specify a true @code{:from-end} argument).

@node Hash Tables
@section Hash Tables
@anchor{#hash-tables}
The other general-purpose collection provided by Common Lisp is the hash
table. Where vectors provide an integer-indexed data structure, hash
tables allow you to use arbitrary objects as the indexes, or keys. When
you add a value to a hash table, you store it under a particular key.
Later you can use the same key to retrieve the value. Or you can
associate a new value with the same key--each key maps to a single
value.

With no arguments @code{MAKE-HASH-TABLE} makes a hash table that
considers two keys equivalent if they're the same object according to
@code{EQL}. This is a good default unless you want to use strings as
keys, since two strings with the same contents aren't necessarily
@code{EQL}. In that case you'll want a so-called @code{EQUAL} hash
table, which you can get by passing the symbol @code{EQUAL} as the
@code{:test} keyword argument to @code{MAKE-HASH-TABLE}. Two other
possible values for the @code{:test} argument are the symbols @code{EQ}
and @code{EQUALP}. These are, of course, the names of the standard
object comparison functions, which I discussed in Chapter 4. However,
unlike the @code{:test} argument passed to sequence functions,
@code{MAKE-HASH-TABLE}'s @code{:test} can't be used to specify an
arbitrary function--only the values @code{EQ}, @code{EQL}, @code{EQUAL},
and @code{EQUALP}. This is because hash tables actually need two
functions, an equivalence function and a @emph{hash} function that
computes a numerical hash code from the key in a way compatible with how
the equivalence function will ultimately compare two keys. However,
although the language standard provides only for hash tables that use
the standard equivalence functions, most implementations provide some
mechanism for defining custom hash tables.

The @code{GETHASH} function provides access to the elements of a hash
table. It takes two arguments--a key and the hash table--and returns
the value, if any, stored in the hash table under that key or
@code{NIL}.@footnote{By an accident of history, the order of arguments
to @code{GETHASH} is the opposite of @code{ELT}--@code{ELT} takes the
collection first and then the index while @code{GETHASH} takes the key
first and then the collection.} For example:

@verbatim
(defparameter *h* (make-hash-table))

(gethash 'foo *h*) ==> NIL

(setf (gethash 'foo *h*) 'quux)

(gethash 'foo *h*) ==> QUUX
@end verbatim

Since @code{GETHASH} returns @code{NIL} if the key isn't present in the
table, there's no way to tell from the return value the difference
between a key not being in a hash table at all and being in the table
with the value @code{NIL}. @code{GETHASH} solves this problem with a
feature I haven't discussed yet--multiple return values. @code{GETHASH}
actually returns two values; the primary value is the value stored under
the given key or @code{NIL}. The secondary value is a boolean indicating
whether the key is present in the hash table. Because of the way
multiple values work, the extra return value is silently discarded
unless the caller explicitly handles it with a form that can "see"
multiple values.

I'll discuss multiple return values in greater detail in Chapter 20, but
for now I'll give you a sneak preview of how to use the
@code{MULTIPLE-VALUE-BIND} macro to take advantage of @code{GETHASH}'s
extra return value. @code{MULTIPLE-VALUE-BIND} creates variable bindings
like @code{LET} does, filling them with the multiple values returned by
a form.

The following function shows how you might use
@code{MULTIPLE-VALUE-BIND}; the variables it binds are @code{value} and
@code{present}:

@verbatim
(defun show-value (key hash-table)
  (multiple-value-bind (value present) (gethash key hash-table)
    (if present
      (format nil "Value ~a actually present." value)
      (format nil "Value ~a because key not found." value))))

(setf (gethash 'bar *h*) nil) ; provide an explicit value of NIL

(show-value 'foo *h*) ==> "Value QUUX actually present."
(show-value 'bar *h*) ==> "Value NIL actually present."
(show-value 'baz *h*) ==> "Value NIL because key not found."
@end verbatim

Since setting the value under a key to @code{NIL} leaves the key in the
table, you'll need another function to completely remove a key/value
pair. @code{REMHASH} takes the same arguments as @code{GETHASH} and
removes the specified entry. You can also completely clear a hash table
of all its key/value pairs with @code{CLRHASH}.

@node Hash Table Iteration
@section Hash Table Iteration
@anchor{#hash-table-iteration}
Common Lisp provides a couple ways to iterate over the entries in a hash
table. The simplest of these is via the function @code{MAPHASH}.
Analogous to the @code{MAP} function, @code{MAPHASH} takes a
two-argument function and a hash table and invokes the function once for
each key/value pair in the hash table. For instance, to print all the
key/value pairs in a hash table, you could use @code{MAPHASH} like this:

@verbatim
(maphash #'(lambda (k v) (format t "~a => ~a~%" k v)) *h*)
@end verbatim

The consequences of adding or removing elements from a hash table while
iterating over it aren't specified (and are likely to be bad) with two
exceptions: you can use @code{SETF} with @code{GETHASH} to change the
value of the current entry, and you can use @code{REMHASH} to remove the
current entry. For instance, to remove all the entries whose value is
less than ten, you could write this:

@verbatim
(maphash #'(lambda (k v) (when (< v 10) (remhash k *h*))) *h*)
@end verbatim

The other way to iterate over a hash table is with the extended
@code{LOOP} macro, which I'll discuss in Chapter
22.@footnote{@code{LOOP}'s hash table iteration is typically
implemented on top of a more primitive form,
@code{WITH-HASH-TABLE-ITERATOR}, that you don't need to worry about;
it was added to the language specifically to support implementing
things such as @code{LOOP} and is of little use unless you need to
write completely new control constructs for iterating over hash
tables.}  The @code{LOOP} equivalent of the first @code{MAPHASH}
expression would look like this:

@verbatim
(loop for k being the hash-keys in *h* using (hash-value v)
  do (format t "~a => ~a~%" k v))
@end verbatim

I could say a lot more about the nonlist collections supported by Common
Lisp. For instance, I haven't discussed multidimensional arrays at all
or the library of functions for manipulating bit arrays. However, what
I've covered in this chapter should suffice for most of your
general-purpose programming needs. Now it's finally time to look at
Lisp's eponymous data structure: lists.

@node They Called It LISP for a Reason List Processing
@chapter They Called It LISP for a Reason: List Processing
@anchor{#they-called-it-lisp-for-a-reason-list-processing}
Lists play an important role in Lisp--for reasons both historical and
practical. Historically, lists were Lisp's original composite data type,
though it has been decades since they were its @emph{only} such data
type. These days, a Common Lisp programmer is as likely to use a vector,
a hash table, or a user-defined class or structure as to use a list.

Practically speaking, lists remain in the language because they're an
excellent solution to certain problems. One such problem--how to
represent code as data in order to support code-transforming and
code-generating macros--is particular to Lisp, which may explain why
other languages don't feel the lack of Lisp-style lists. More generally,
lists are an excellent data structure for representing any kind of
heterogeneous and/or hierarchical data. They're also quite lightweight
and support a functional style of programming that's another important
part of Lisp's heritage.

Thus, you need to understand lists on their own terms; as you gain a
better understanding of how lists work, you'll be in a better position
to appreciate when you should and shouldn't use them.
@menu
* "There Is No List"::
* Functional Programming and Lists::
* "Destructive" Operations::
* Combining Recycling with Shared Structure::
* List-Manipulation Functions::
* Mapping::
* Other Structures::
@end menu

@node "There Is No List"
@section "There Is No List"
@anchor{#there-is-no-list}
@quotation
@strong{Spoon Boy}: Do not try and bend the list. That's impossible.
Instead . . . only try to realize the truth.
@end quotation
@quotation
@strong{Neo}: What truth?
@end quotation
@quotation
@strong{Spoon Boy}: There is no list.
@end quotation
@quotation
@strong{Neo}: There is no list?
@end quotation
@quotation
@strong{Spoon Boy}: Then you'll see that it is not the list that
bends; it is only yourself.@footnote{Adapted from @emph{The Matrix}
(@code{http://us.imdb.com/Quotes?0133093})}
@end quotation
The key to understanding lists is to understand that they're largely an
illusion built on top of objects that are instances of a more primitive
data type. Those simpler objects are pairs of values called @emph{cons
cells}, after the function @code{CONS} used to create them.

@code{CONS} takes two arguments and returns a new cons cell containing
the two values.@footnote{@code{CONS} was originally short for the verb
@emph{construct}.} These values can be references to any kind of
object. Unless the second value is @code{NIL} or another cons cell, a
cons is printed as the two values in parentheses separated by a dot, a
so-called dotted pair.

@verbatim
(cons 1 2) ==> (1 . 2)
@end verbatim

The two values in a cons cell are called the @code{CAR} and the
@code{CDR} after the names of the functions used to access them. At the
dawn of time, these names were mnemonic, at least to the folks
implementing the first Lisp on an IBM 704. But even then they were just
lifted from the assembly mnemonics used to implement the operations.
However, it's not all bad that these names are somewhat
meaningless--when considering individual cons cells, it's best to think
of them simply as an arbitrary pair of values without any particular
semantics. Thus:

@verbatim
(car (cons 1 2)) ==> 1
(cdr (cons 1 2)) ==> 2
@end verbatim

Both @code{CAR} and @code{CDR} are also @code{SETF}able places--given
an existing cons cell, it's possible to assign a new value to either
of its values.@footnote{When the place given to @code{SETF} is a
@code{CAR} or @code{CDR}, it expands into a call to the function
@code{RPLACA} or @code{RPLACD}; some old-school Lispers--the same ones
who still use @code{SETQ}--will still use @code{RPLACA} and
@code{RPLACD} directly, but modern style is to use @code{SETF} of
@code{CAR} or @code{CDR}.}

@verbatim
(defparameter *cons* (cons 1 2))
*cons*                 ==> (1 . 2)
(setf (car *cons*) 10) ==> 10
*cons*                 ==> (10 . 2)
(setf (cdr *cons*) 20) ==> 20
*cons*                 ==> (10 . 20)
@end verbatim

Because the values in a cons cell can be references to any kind of
object, you can build larger structures out of cons cells by linking
them together. Lists are built by linking together cons cells in a
chain. The elements of the list are held in the @code{CAR}s of the cons
cells while the links to subsequent cons cells are held in the
@code{CDR}s. The last cell in the chain has a @code{CDR} of @code{NIL},
which--as I mentioned in Chapter 4--represents the empty list as well as
the boolean value false.

This arrangement is by no means unique to Lisp; it's called a
@emph{singly linked list}. However, few languages outside the Lisp
family provide such extensive support for this humble data type.

So when I say a particular value is a list, what I really mean is it's
either @code{NIL} or a reference to a cons cell. The @code{CAR} of the
cons cell is the first item of the list, and the @code{CDR} is a
reference to another list, that is, another cons cell or @code{NIL},
containing the remaining elements. The Lisp printer understands this
convention and prints such chains of cons cells as parenthesized lists
rather than as dotted pairs.

@verbatim
(cons 1 nil)                   ==> (1)
(cons 1 (cons 2 nil))          ==> (1 2)
(cons 1 (cons 2 (cons 3 nil))) ==> (1 2 3)
@end verbatim

When talking about structures built out of cons cells, a few diagrams
can be a big help. Box-and-arrow diagrams represent cons cells as a pair
of boxes like this:

@image{figures/one-cons-cell,,,,png}

The box on the left represents the @code{CAR}, and the box on the
right is the @code{CDR}. The values stored in a particular cons cell
are either drawn in the appropriate box or represented by an arrow
from the box to a representation of the referenced
value.@footnote{Typically, simple objects such as numbers are drawn
within the appropriate box, and more complex objects will be drawn
outside the box with an arrow from the box indicating the reference.
This actually corresponds well with how many Common Lisp
implementations work--although all objects are conceptually stored by
reference, certain simple immutable objects can be stored directly in
a cons cell.} For instance, the list @code{(1 2 3)}, which consists of
three cons cells linked together by their @code{CDR}s, would be
diagrammed like this:

@image{figures/list-1-2-3,,,,png}

However, most of the time you work with lists you won't have to deal
with individual cons cells--the functions that create and manipulate
lists take care of that for you. For example, the @code{LIST} function
builds a cons cells under the covers for you and links them together;
the following @code{LIST} expressions are equivalent to the previous
@code{CONS} expressions:

@verbatim
(list 1)     ==> (1)
(list 1 2)   ==> (1 2)
(list 1 2 3) ==> (1 2 3)
@end verbatim

Similarly, when you're thinking in terms of lists, you don't have to use
the meaningless names @code{CAR} and @code{CDR}; @code{FIRST} and
@code{REST} are synonyms for @code{CAR} and @code{CDR} that you should
use when you're dealing with cons cells as lists.

@verbatim
(defparameter *list* (list 1 2 3 4))
(first *list*)        ==> 1
(rest *list*)         ==> (2 3 4)
(first (rest *list*)) ==> 2
@end verbatim

Because cons cells can hold any kind of values, so can lists. And a
single list can hold objects of different types.

@verbatim
(list "foo" (list 1 2) 10) ==> ("foo" (1 2) 10)
@end verbatim

The structure of that list would look like this:

@image{figures/mixed-list,,,,png}

Because lists can have other lists as elements, you can also use them to
represent trees of arbitrary depth and complexity. As such, they make
excellent representations for any heterogeneous, hierarchical data.
Lisp-based XML processors, for instance, usually represent XML documents
internally as lists. Another obvious example of tree-structured data is
Lisp code itself. In Chapters 30 and 31 you'll write an HTML generation
library that uses lists of lists to represent the HTML to be generated.
I'll talk more next chapter about using cons cells to represent other
data structures.

Common Lisp provides quite a large library of functions for manipulating
lists. In the sections "List-Manipulation Functions" and "Mapping,"
you'll look at some of the more important of these functions. However,
they will be easier to understand in the context of a few ideas borrowed
from functional programming.

@node Functional Programming and Lists
@section Functional Programming and Lists
@anchor{#functional-programming-and-lists}
The essence of functional programming is that programs are built
entirely of functions with no side effects that compute their results
based solely on the values of their arguments. The advantage of the
functional style is that it makes programs easier to understand.
Eliminating side effects eliminates almost all possibilities for action
at a distance. And since the result of a function is determined only by
the values of its arguments, its behavior is easier to understand and
test. For instance, when you see an expression such as @code{(+ 3 4)},
you know the result is uniquely determined by the definition of the
@code{+} function and the values @code{3} and @code{4}. You don't have
to worry about what may have happened earlier in the execution of the
program since there's nothing that can change the result of evaluating
that expression.

Functions that deal with numbers are naturally functional since numbers
are immutable. A list, on the other hand, can be mutated, as you've just
seen, by @code{SETF}ing the @code{CAR}s and @code{CDR}s of the cons
cells that make up its backbone. However, lists can be treated as a
functional data type if you consider their value to be determined by the
elements they contain. Thus, any list of the form @code{(1 2 3 4)} is
functionally equivalent to any other list containing those four values,
regardless of what cons cells are actually used to represent the list.
And any function that takes a list as an argument and returns a value
based solely on the contents of the list can likewise be considered
functional. For instance, the @code{REVERSE} sequence function, given
the list @code{(1 2 3 4)}, always returns a list @code{(4 3 2 1)}.
Different calls to @code{REVERSE} with functionally equivalent lists as
the argument will return functionally equivalent result lists. Another
aspect of functional programming, which I'll discuss in the section
"Mapping," is the use of higher-order functions: functions that treat
other functions as data, taking them as arguments or returning them as
results.

Most of Common Lisp's list-manipulation functions are written in a
functional style. I'll discuss later how to mix functional and other
coding styles, but first you should understand a few subtleties of the
functional style as applied to lists.

The reason most list functions are written functionally is it allows
them to return results that share cons cells with their arguments. To
take a concrete example, the function @code{APPEND} takes any number of
list arguments and returns a new list containing the elements of all its
arguments. For instance:

@verbatim
(append (list 1 2) (list 3 4)) ==> (1 2 3 4)
@end verbatim

From a functional point of view, @code{APPEND}'s job is to return the
list @code{(1 2 3 4)} without modifying any of the cons cells in the
lists @code{(1 2)} and @code{(3 4)}. One obvious way to achieve that
goal is to create a completely new list consisting of four new cons
cells. However, that's more work than is necessary. Instead,
@code{APPEND} actually makes only two new cons cells to hold the values
@code{1} and @code{2}, linking them together and pointing the @code{CDR}
of the second cons cell at the head of the last argument, the list
@code{(3 4)}. It then returns the cons cell containing the @code{1}.
None of the original cons cells has been modified, and the result is
indeed the list @code{(1 2 3 4)}. The only wrinkle is that the list
returned by @code{APPEND} shares some cons cells with the list
@code{(3 4)}. The resulting structure looks like this:

@image{figures/after-append,,,,png}

In general, @code{APPEND} must copy all but its last argument, but it
can always return a result that @emph{shares structure} with the last
argument.

Other functions take similar advantage of lists' ability to share
structure. Some, like @code{APPEND}, are specified to always return
results that share structure in a particular way. Others are simply
allowed to return shared structure at the discretion of the
implementation.

@node "Destructive" Operations
@section "Destructive" Operations
@anchor{#destructive-operations}
If Common Lisp were a purely functional language, that would be the end
of the story. However, because it's possible to modify a cons cell after
it has been created by @code{SETF}ing its @code{CAR} or @code{CDR}, you
need to think a bit about how side effects and structure sharing mix.

Because of Lisp's functional heritage, operations that modify existing
objects are called @emph{destructive--}in functional programming,
changing an object's state "destroys" it since it no longer represents
the same value. However, using the same term to describe all
state-modifying operations leads to a certain amount of confusion
since there are two very different kinds of destructive operations,
@emph{for-side-effect} operations and @emph{recycling}
operations.@footnote{The phrase @emph{for-side-effect} is used in the
language standard, but @emph{recycling} is my own invention; most Lisp
literature simply uses the term @emph{destructive} for both kinds of
operations, leading to the confusion I'm trying to dispel.}

For-side-effect operations are those used specifically for their side
effects. All uses of @code{SETF} are destructive in this sense, as are
functions that use @code{SETF} under the covers to change the state of
an existing object such as @code{VECTOR-PUSH} or @code{VECTOR-POP}. But
it's a bit unfair to describe these operations as destructive--they're
not intended to be used in code written in a functional style, so they
shouldn't be described using functional terminology. However, if you mix
nonfunctional, for-side-effect operations with functions that return
structure-sharing results, then you need to be careful not to
inadvertently modify the shared structure. For instance, consider these
three definitions:

@verbatim
(defparameter *list-1* (list 1 2))
(defparameter *list-2* (list 3 4))
(defparameter *list-3* (append *list-1* *list-2*))
@end verbatim

After evaluating these forms, you have three lists, but @code{*list-3*}
and @code{*list-2*} share structure just like the lists in the previous
diagram.

@verbatim
*list-1*                  ==> (1 2)
*list-2*                  ==> (3 4)
*list-3*                  ==> (1 2 3 4)
@end verbatim

Now consider what happens when you modify @code{*list-2*}.

@verbatim
(setf (first *list-2*) 0) ==> 0
*list-2*                  ==> (0 4)     ; as expected
*list-3*                  ==> (1 2 0 4) ; maybe not what you wanted
@end verbatim

The change to @code{*list-2*} also changes @code{*list-3*} because of
the shared structure: the first cons cell in @code{*list-2*} is also the
third cons cell in @code{*list-3*}. @code{SETF}ing the @code{FIRST} of
@code{*list-2*} changes the value in the @code{CAR} of that cons cell,
affecting both lists.

On the other hand, the other kind of destructive operations, recycling
operations, @emph{are} intended to be used in functional code. They use
side effects only as an optimization. In particular, they reuse certain
cons cells from their arguments when building their result. However,
unlike functions such as @code{APPEND} that reuse cons cells by
including them, unmodified, in the list they return, recycling functions
reuse cons cells as raw material, modifying the @code{CAR} and
@code{CDR} as necessary to build the desired result. Thus, recycling
functions can be used safely only when the original lists aren't going
to be needed after the call to the recycling function.

To see how a recycling function works, let's compare @code{REVERSE}, the
nondestructive function that returns a reversed version of a sequence,
to @code{NREVERSE}, a recycling version of the same function. Because
@code{REVERSE} doesn't modify its argument, it must allocate a new cons
cell for each element in the list being reversed. But suppose you write
something like this:

@verbatim
(setf *list* (reverse *list*))
@end verbatim

By assigning the result of @code{REVERSE} back to @code{*list*}, you've
removed the reference to the original value of @code{*list*}. Assuming
the cons cells in the original list aren't referenced anywhere else,
they're now eligible to be garbage collected. However, in many Lisp
implementations it'd be more efficient to immediately reuse the existing
cons cells rather than allocating new ones and letting the old ones
become garbage.

@code{NREVERSE} allows you to do exactly that. The @emph{N} stands for
@emph{non-consing}, meaning it doesn't need to allocate any new cons
cells. The exact side effects of @code{NREVERSE} are intentionally not
specified--it's allowed to modify any @code{CAR} or @code{CDR} of any
cons cell in the list--but a typical implementation might walk down the
list changing the @code{CDR} of each cons cell to point to the previous
cons cell, eventually returning the cons cell that was previously the
last cons cell in the old list and is now the head of the reversed list.
No new cons cells need to be allocated, and no garbage is created.

Most recycling functions, like @code{NREVERSE}, have nondestructive
counterparts that compute the same result. In general, the recycling
functions have names that are the same as their non-destructive
counterparts except with a leading @emph{N}. However, not all do,
including several of the more commonly used recycling functions such as
@code{NCONC}, the recycling version of @code{APPEND}, and @code{DELETE},
@code{DELETE-IF}, @code{DELETE-IF-NOT}, and @code{DELETE-DUPLICATES},
the recycling versions of the @code{REMOVE} family of sequence
functions.

In general, you use recycling functions in the same way you use their
nondestructive counterparts except it's safe to use them only when you
know the arguments aren't going to be used after the function returns.
The side effects of most recycling functions aren't specified tightly
enough to be relied upon.

However, the waters are further muddied by a handful of recycling
functions with specified side effects that @emph{can} be relied upon.
They are @code{NCONC}, the recycling version of @code{APPEND}, and
@code{NSUBSTITUTE} and its @code{-IF} and @code{-IF-NOT} variants, the
recycling versions of the sequence functions @code{SUBSTITUTE} and
friends.

Like @code{APPEND}, @code{NCONC} returns a concatenation of its list
arguments, but it builds its result in the following way: for each
nonempty list it's passed, @code{NCONC} sets the @code{CDR} of the
list's last cons cell to point to the first cons cell of the next
nonempty list. It then returns the first list, which is now the head of
the spliced-together result. Thus:

@verbatim
(defparameter *x* (list 1 2 3))

(nconc *x* (list 4 5 6)) ==> (1 2 3 4 5 6)

*x* ==> (1 2 3 4 5 6)
@end verbatim

@code{NSUBSTITUTE} and variants can be relied on to walk down the list
structure of the list argument and to @code{SETF} the @code{CAR}s of
any cons cells holding the old value to the new value and to otherwise
leave the list intact. It then returns the original list, which now
has the same value as would've been computed by @code{SUBSTITUTE}.
@footnote{The string functions @code{NSTRING-CAPITALIZE},
@code{NSTRING-DOWNCASE}, and @code{NSTRING-UPCASE} are similar--they
return the same results as their N-less counterparts but are specified
to modify their string argument in place.}

The key thing to remember about @code{NCONC} and @code{NSUBSTITUTE} is
that they're the exceptions to the rule that you can't rely on the side
effects of recycling functions. It's perfectly acceptable--and arguably
good style--to ignore the reliability of their side effects and use
them, like any other recycling function, only for the value they return.

@node Combining Recycling with Shared Structure
@section Combining Recycling with Shared Structure
@anchor{#combining-recycling-with-shared-structure}
Although you can use recycling functions whenever the arguments to the
recycling function won't be used after the function call, it's worth
noting that each recycling function is a loaded gun pointed footward: if
you accidentally use a recycling function on an argument that @emph{is}
used later, you're liable to lose some toes.

To make matters worse, shared structure and recycling functions tend to
work at cross-purposes. Nondestructive list functions return lists that
share structure under the assumption that cons cells are never modified,
but recycling functions work by violating that assumption. Or, put
another way, sharing structure is based on the premise that you don't
care exactly what cons cells make up a list while using recycling
functions requires that you know exactly what cons cells are referenced
from where.

In practice, recycling functions tend to be used in a few idiomatic
ways. By far the most common recycling idiom is to build up a list to
be returned from a function by "consing" onto the front of a list,
usually by @code{PUSH}ing elements onto a list stored in a local
variable and then returning the result of @code{NREVERSE}ing
it.@footnote{For example, in an examination of all uses of recycling
functions in the Common Lisp Open Code Collection (CLOCC), a diverse
set of libraries written by various authors, instances of the
@code{PUSH}/@code{NREVERSE} idiom accounted for nearly half of all
uses of recycling functions.}

This is an efficient way to build a list because each @code{PUSH} has
to create only one cons cell and modify a local variable and the
@code{NREVERSE} just has to zip down the list reassigning the
@code{CDR}s. Because the list is created entirely within the function,
there's no danger any code outside the function has a reference to any
of its cons cells. Here's a function that uses this idiom to build a
list of the first @emph{n} numbers, starting at zero:@footnote{There
are, of course, other ways to do this same thing. The extended
@code{LOOP} macro, for instance, makes it particularly easy and likely
generates code that's even more efficient than the @code{PUSH}/
@code{NREVERSE} version.}

@verbatim
(defun upto (max)
  (let ((result nil))
    (dotimes (i max)
      (push i result))
    (nreverse result)))

(upto 10) ==> (0 1 2 3 4 5 6 7 8 9)
@end verbatim

The next most common recycling idiom@footnote{This idiom accounts for
30 percent of uses of recycling in the CLOCC code base.} is to
immediately reassign the value returned by the recycling function back
to the place containing the potentially recycled value. For instance,
you'll often see expressions like the following, using @code{DELETE},
the recycling version of @code{REMOVE}:

@verbatim
(setf foo (delete nil foo))
@end verbatim

This sets the value of @code{foo} to its old value except with all the
@code{NIL}s removed. However, even this idiom must be used with some
care--if @code{foo} shares structure with lists referenced elsewhere,
using @code{DELETE} instead of @code{REMOVE} can destroy the structure
of those other lists. For example, consider the two lists
@code{*list-2*} and @code{*list-3*} from earlier that share their last
two cons cells.

@verbatim
*list-2* ==> (0 4)
*list-3* ==> (1 2 0 4)
@end verbatim

You can delete @code{4} from @code{*list-3*} like this:

@verbatim
(setf *list-3* (delete 4 *list-3*)) ==> (1 2 0)
@end verbatim

However, @code{DELETE} will likely perform the necessary deletion by
setting the @code{CDR} of the third cons cell to @code{NIL},
disconnecting the fourth cons cell, the one holding the @code{4}, from
the list. Because the third cons cell of @code{*list-3*} is also the
first cons cell in @code{*list-2*}, the following modifies
@code{*list-2*} as well:

@verbatim
*list-2* ==> (0)
@end verbatim

If you had used @code{REMOVE} instead of @code{DELETE}, it would've
built a list containing the values @code{1}, @code{2}, and @code{0},
creating new cons cells as necessary rather than modifying any of the
cons cells in @code{*list-3*}. In that case, @code{*list-2*} wouldn't
have been affected.

The @code{PUSH}/@code{NREVERSE} and @code{SETF}/@code{DELETE} idioms
probably account for 80 percent of the uses of recycling functions.
Other uses are possible but require keeping careful track of which
functions return shared structure and which do not.

In general, when manipulating lists, it's best to write your own code in
a functional style--your functions should depend only on the contents of
their list arguments and shouldn't modify them. Following that rule
will, of course, rule out using any destructive functions, recycling or
otherwise. Once you have your code working, if profiling shows you need
to optimize, you can replace nondestructive list operations with their
recycling counterparts but only if you're certain the argument lists
aren't referenced from anywhere else.

One last gotcha to watch out for is that the sorting functions
@code{SORT}, @code{STABLE-SORT}, and @code{MERGE} mentioned in Chapter
11 are also recycling functions when applied to
lists.@footnote{@code{SORT} and @code{STABLE-SORT} can be used as
for-side-effect operations on vectors, but since they still return the
sorted vector, you should ignore that fact and use them for return
values for the sake of consistency.} However, these functions don't
have nondestructive counterparts, so if you need to sort a list
without destroying it, you need to pass the sorting function a copy
made with @code{COPY-LIST}. In either case you need to be sure to save
the result of the sorting function because the original argument is
likely to be in tatters. For instance:

@verbatim
CL-USER> (defparameter *list* (list 4 3 2 1))
*LIST*
CL-USER> (sort *list* #'<)
(1 2 3 4)                      ; looks good
CL-USER> *list*
(4)                            ; whoops!
@end verbatim

@node List-Manipulation Functions
@section List-Manipulation Functions
@anchor{#list-manipulation-functions}
With that background out of the way, you're ready to look at the library
of functions Common Lisp provides for manipulating lists.

You've already seen the basic functions for getting at the elements of
a list: @code{FIRST} and @code{REST}. Although you can get at any
element of a list by combining enough calls to @code{REST} (to move
down the list) with a @code{FIRST} (to extract the element), that can
be a bit tedious. So Common Lisp provides functions named for the
other ordinals from @code{SECOND} to @code{TENTH} that return the
appropriate element.  More generally, the function @code{NTH} takes
two arguments, an index and a list, and returns the @emph{n}th
(zero-based) element of the list.  Similarly, @code{NTHCDR} takes an
index and a list and returns the result of calling @code{CDR} @emph{n}
times. (Thus, @code{(nthcdr 0 ...)} simply returns the original list,
and @code{(nthcdr 1 ...)} is equivalent to @code{REST}.) Note,
however, that none of these functions is any more efficient, in terms
of work done by the computer, than the equivalent combinations of
@code{FIRST}s and @code{REST}s--there's no way to get to the
@emph{n}th element of a list without following @emph{n} @code{CDR}
references.@footnote{@code{NTH} is roughly equivalent to the sequence
function @code{ELT} but works only with lists. Also, confusingly,
@code{NTH} takes the index as the first argument, the opposite of
@code{ELT}. Another difference is that @code{ELT} will signal an error
if you try to access an element at an index greater than or equal to
the length of the list, but @code{NTH} will return @code{NIL}.}

The 28 composite @code{CAR}/@code{CDR} functions are another family of
functions you may see used from time to time. Each function is named by
placing a sequence of up to four @code{A}s and @code{D}s between a
@code{C} and @code{R}, with each @code{A} representing a call to
@code{CAR} and each @code{D} a call to @code{CDR}. Thus:

@verbatim
(caar list) === (car (car list))
(cadr list) === (car (cdr list))
(cadadr list) === (car (cdr (car (cdr list))))
@end verbatim

Note, however, that many of these functions make sense only when applied
to lists that contain other lists. For instance, @code{CAAR} extracts
the @code{CAR} of the @code{CAR} of the list it's given; thus, the list
it's passed must contain another list as its first element. In other
words, these are really functions on trees rather than lists:

@verbatim
(caar (list 1 2 3))                  ==> error
(caar (list (list 1 2) 3))           ==> 1
(cadr (list (list 1 2) (list 3 4)))  ==> (3 4)
(caadr (list (list 1 2) (list 3 4))) ==> 3
@end verbatim

These functions aren't used as often now as in the old days. And even
the most die-hard old-school Lisp hackers tend to avoid the longer
combinations. However, they're used quite a bit in older Lisp code, so
it's worth at least understanding how they work.@footnote{In
particular, they used to be used to extract the various parts of
expressions passed to macros before the invention of destructuring
parameter lists. For example, you could take apart the following
expression:

@verbatim
(when (> x 10) (print x))
@end verbatim

Like this:

@verbatim
;; the condition
(cadr '(when (> x 10) (print x))) ==> (> X 10)
@end verbatim

@verbatim
;; the body, as a list
(cddr '(when (> x 10) (print x))) ==> ((PRINT X))
@end verbatim
}

The @code{FIRST}-@code{TENTH} and @code{CAR}, @code{CADR}, and so on,
functions can also be used as @code{SETF}able places if you're using
lists nonfunctionally.

Table 12-1 summarizes some other list functions that I won't cover in
detail.

Table 12-1. Other List Functions
@multitable {@code{REVAPPEND}} {Builds a list to hold all but the last of its arguments and then makes the last argument the @code{CDR} of the last cell in the list. In other words, a cross between @code{LIST} and @code{APPEND}.}
@item
Function
 @tab Description
@item
@code{LAST}
 @tab Returns the last cons cell in a list. With an integer, argument
returns the last @emph{n} cons cells.
@item
@code{BUTLAST}
 @tab Returns a copy of the list, excluding the last cons cell. With an
integer argument, excludes the last @emph{n} cells.
@item
@code{NBUTLAST}
 @tab The recycling version of @code{BUTLAST}; may modify and return the
argument list but has no reliable side effects.
@item
@code{LDIFF}
 @tab Returns a copy of a list up to a given cons cell.
@item
@code{TAILP}
 @tab Returns true if a given object is a cons cell that's part of the
structure of a list.
@item
@code{LIST*}
 @tab Builds a list to hold all but the last of its arguments and then
makes the last argument the @code{CDR} of the last cell in the list. In
other words, a cross between @code{LIST} and @code{APPEND}.
@item
@code{MAKE-LIST}
 @tab Builds an @emph{n} item list. The initial elements of the list are
@code{NIL} or the value specified with the @code{:initial-element}
keyword argument.
@item
@code{REVAPPEND}
 @tab Combination of @code{REVERSE} and @code{APPEND}; reverses first
argument as with @code{REVERSE} and then appends the second argument.
@item
@code{NRECONC}
 @tab Recycling version of @code{REVAPPEND}; reverses first argument as
if by @code{NREVERSE} and then appends the second argument. No reliable
side effects.
@item
@code{CONSP}
 @tab Predicate to test whether an object is a cons cell.
@item
@code{ATOM}
 @tab Predicate to test whether an object is @emph{not} a cons cell.
@item
@code{LISTP}
 @tab Predicate to test whether an object is either a cons cell or
@code{NIL}.
@item
@code{NULL}
 @tab Predicate to test whether an object is @code{NIL}. Functionally
equivalent to @code{NOT} but stylistically preferable when testing for
an empty list as opposed to boolean false.
@end multitable

@node Mapping
@section Mapping
@anchor{#mapping}
Another important aspect of the functional style is the use of
higher-order functions, functions that take other functions as arguments
or return functions as values. You saw several examples of higher-order
functions, such as @code{MAP}, in the previous chapter. Although
@code{MAP} can be used with both lists and vectors (that is, with any
kind of sequence), Common Lisp also provides six mapping functions
specifically for lists. The differences between the six functions have
to do with how they build up their result and whether they apply the
function to the elements of the list or to the cons cells of the list
structure.

@code{MAPCAR} is the function most like @code{MAP}. Because it always
returns a list, it doesn't require the result-type argument @code{MAP}
does. Instead, its first argument is the function to apply, and
subsequent arguments are the lists whose elements will provide the
arguments to the function. Otherwise, it behaves like @code{MAP}: the
function is applied to successive elements of the list arguments, taking
one element from each list per application of the function. The results
of each function call are collected into a new list. For example:

@verbatim
(mapcar #'(lambda (x) (* 2 x)) (list 1 2 3)) ==> (2 4 6)
(mapcar #'+ (list 1 2 3) (list 10 20 30)) ==> (11 22 33)
@end verbatim

@code{MAPLIST} is just like @code{MAPCAR} except instead of passing
the elements of the list to the function, it passes the actual cons
cells.@footnote{Thus, @code{MAPLIST} is the more primitive of the two
functions--if you had only @code{MAPLIST}, you could build
@code{MAPCAR} on top of it, but you couldn't build @code{MAPLIST} on
top of @code{MAPCAR}.} Thus, the function has access not only to the
value of each element of the list (via the @code{CAR} of the cons
cell) but also to the rest of the list (via the @code{CDR}).

@code{MAPCAN} and @code{MAPCON} work like @code{MAPCAR} and
@code{MAPLIST} except for the way they build up their result. While
@code{MAPCAR} and @code{MAPLIST} build a completely new list to hold
the results of the function calls, @code{MAPCAN} and @code{MAPCON}
build their result by splicing together the results--which must be
lists--as if by @code{NCONC}. Thus, each function invocation can
provide any number of elements to be included in the
result.@footnote{In Lisp dialects that didn't have filtering functions
like @code{REMOVE}, the idiomatic way to filter a list was with
@code{MAPCAN}.

@verbatim
(mapcan #'(lambda (x) (if (= x 10) nil (list x)))  list) === (remove 10 list)
@end verbatim
}
@code{MAPCAN}, like @code{MAPCAR}, passes the elements of the list to
the mapped function while @code{MAPCON}, like @code{MAPLIST}, passes
the cons cells.

Finally, the functions @code{MAPC} and @code{MAPL} are control
constructs disguised as functions--they simply return their first list
argument, so they're useful only when the side effects of the mapped
function do something interesting. @code{MAPC} is the cousin of
@code{MAPCAR} and @code{MAPCAN} while @code{MAPL} is in the
@code{MAPLIST}/@code{MAPCON} family.

@node Other Structures
@section Other Structures
@anchor{#other-structures}
While cons cells and lists are typically considered to be synonymous,
that's not quite right--as I mentioned earlier, you can use lists of
lists to represent trees. Just as the functions discussed in this
chapter allow you to treat structures built out of cons cells as lists,
other functions allow you to use cons cells to represent trees, sets,
and two kinds of key/value maps. I'll discuss some of those functions in
the next chapter.

@node Beyond Lists Other Uses for Cons Cells
@chapter Beyond Lists: Other Uses for Cons Cells
@anchor{#beyond-lists-other-uses-for-cons-cells}
As you saw in the previous chapter, the list data type is an illusion
created by a set of functions that manipulate cons cells. Common Lisp
also provides functions that let you treat data structures built out of
cons cells as trees, sets, and lookup tables. In this chapter I'll give
you a quick tour of some of these other data structures and the
functions for manipulating them. As with the list-manipulation
functions, many of these functions will be useful when you start writing
more complicated macros and need to manipulate Lisp code as data.
@menu
* Trees::
* Sets::
* Lookup Tables Alists and Plists::
* DESTRUCTURING-BIND::
@end menu

@node Trees
@section Trees
@anchor{#trees} Treating structures built from cons cells as trees is
just about as natural as treating them as lists. What is a list of
lists, after all, but another way of thinking of a tree? The
difference between a function that treats a bunch of cons cells as a
list and a function that treats the same bunch of cons cells as a tree
has to do with which cons cells the functions traverse to find the
values of the list or tree. The cons cells traversed by a list
function, called the @emph{list structure}, are found by starting at
the first cons cell and following @code{CDR} references until reaching
a @code{NIL}. The elements of the list are the objects referenced by
the @code{CAR}s of the cons cells in the list structure. If a cons
cell in the list structure has a @code{CAR} that references another
cons cell, the referenced cons cell is considered to be the head of a
list that's an element of the outer list.@footnote{It's possible to
build a chain of cons cells where the @code{CDR} of the last cons cell
isn't @code{NIL} but some other atom. This is called a @emph{dotted}
list because the last cons is a dotted pair.} @emph{Tree structure},
on the other hand, is traversed by following both @code{CAR} and
@code{CDR} references for as long as they point to other cons
cells. The values in a tree are thus the atomic--non-cons-cell-values
referenced by either the @code{CAR}s or the @code{CDR}s of the cons
cells in the tree structure.

For instance, the following box-and-arrow diagram shows the cons cells
that make up the list of lists: @code{((1 2) (3 4) (5 6))}. The list
structure includes only the three cons cells inside the dashed box while
the tree structure includes all the cons cells.

@image{figures/list-or-tree,,,,png}

To see the difference between a list function and a tree function, you
can consider how the functions @code{COPY-LIST} and @code{COPY-TREE}
will copy this bunch of cons cells. @code{COPY-LIST}, as a list
function, copies the cons cells that make up the list structure. That
is, it makes a new cons cell corresponding to each of the cons cells
inside the dashed box. The @code{CAR}s of each of these new cons cells
reference the same object as the @code{CAR}s of the original cons cells
in the list structure. Thus, @code{COPY-LIST} doesn't copy the sublists
@code{(1 2)}, @code{(3 4)}, or @code{(5 6)}, as shown in this diagram:

@image{figures/copy-list-list-or-tree,,,,png}

@code{COPY-TREE}, on the other hand, makes a new cons cell for each of
the cons cells in the diagram and links them together in the same
structure, as shown in this diagram:

@image{figures/copy-tree-list-or-tree,,,,png}

Where a cons cell in the original referenced an atomic value, the
corresponding cons cell in the copy will reference the same value. Thus,
the only objects referenced in common by the original tree and the copy
produced by @code{COPY-TREE} are the numbers 1-6, and the symbol
@code{NIL}.

Another function that walks both the @code{CAR}s and the @code{CDR}s of
a tree of cons cells is @code{TREE-EQUAL}, which compares two trees,
considering them equal if the tree structure is the same shape and if
the leaves are @code{EQL} (or if they satisfy the test supplied with the
@code{:test} keyword argument).

Some other tree-centric functions are the tree analogs to the
@code{SUBSTITUTE} and @code{NSUBSTITUTE} sequence functions and their
@code{-IF} and @code{-IF-NOT} variants. The function @code{SUBST}, like
@code{SUBSTITUTE}, takes a new item, an old item, and a tree (as opposed
to a sequence), along with @code{:key} and @code{:test} keyword
arguments, and it returns a new tree with the same shape as the original
tree but with all instances of the old item replaced with the new item.
For example:

@verbatim
CL-USER> (subst 10 1 '(1 2 (3 2 1) ((1 1) (2 2))))
(10 2 (3 2 10) ((10 10) (2 2)))
@end verbatim

@code{SUBST-IF} is analogous to @code{SUBSTITUTE-IF}. Instead of an
old item, it takes a one-argument function--the function is called
with each atomic value in the tree, and whenever it returns true, the
position in the new tree is filled with the new
value. @code{SUBST-IF-NOT} is the same except the values where the
test returns @code{NIL} are replaced.  @code{NSUBST},
@code{NSUBST-IF}, and @code{NSUBST-IF-NOT} are the recycling versions
of the @code{SUBST} functions. As with most other recycling functions,
you should use these functions only as drop-in replacements for their
nondestructive counterparts in situations where you know there's no
danger of modifying a shared structure. In particular, you must
continue to save the return value of these functions since you have no
guarantee that the result will be @code{EQ} to the original
tree.@footnote{It may seem that the @code{NSUBST} family of functions
can and in fact does modify the tree in place. However, there's one
edge case: when the "tree" passed is, in fact, an atom, it can't be
modified in place, so the result of @code{NSUBST} will be a different
object than the argument: @code{(nsubst 'x 'y 'y) X}.}

@node Sets
@section Sets
@anchor{#sets}
Sets can also be implemented in terms of cons cells. In fact, you can
treat any list as a set--Common Lisp provides several functions for
performing set-theoretic operations on lists. However, you should bear
in mind that because of the way lists are structured, these operations
get less and less efficient the bigger the sets get.

That said, using the built-in set functions makes it easy to write
set-manipulation code. And for small sets they may well be more
efficient than the alternatives. If profiling shows you that these
functions are a performance bottleneck in your code, you can always
replace the lists with sets built on top of hash tables or bit vectors.

To build up a set, you can use the function @code{ADJOIN}. @code{ADJOIN}
takes an item and a list representing a set and returns a list
representing the set containing the item and all the items in the
original set. To determine whether the item is present, it must scan the
list; if the item isn't found, @code{ADJOIN} creates a new cons cell
holding the item and pointing to the original list and returns it.
Otherwise, it returns the original list.

@code{ADJOIN} also takes @code{:key} and @code{:test} keyword arguments,
which are used when determining whether the item is present in the
original list. Like @code{CONS}, @code{ADJOIN} has no effect on the
original list--if you want to modify a particular list, you need to
assign the value returned by @code{ADJOIN} to the place where the list
came from. The modify macro @code{PUSHNEW} does this for you
automatically.

@verbatim
CL-USER> (defparameter *set* ())
*SET*
CL-USER> (adjoin 1 *set*)
(1)
CL-USER> *set*
NIL
CL-USER> (setf *set* (adjoin 1 *set*))
(1)
CL-USER> (pushnew 2 *set*)
(2 1)
CL-USER> *set*
(2 1)
CL-USER> (pushnew 2 *set*)
(2 1)
@end verbatim

You can test whether a given item is in a set with @code{MEMBER} and the
related functions @code{MEMBER-IF} and @code{MEMBER-IF-NOT}. These
functions are similar to the sequence functions @code{FIND},
@code{FIND-IF}, and @code{FIND-IF-NOT} except they can be used only with
lists. And instead of returning the item when it's present, they return
the cons cell containing the item--in other words, the sublist starting
with the desired item. When the desired item isn't present in the list,
all three functions return @code{NIL}.

The remaining set-theoretic functions provide bulk operations:
@code{INTERSECTION}, @code{UNION}, @code{SET-DIFFERENCE}, and
@code{SET-EXCLUSIVE-OR}. Each of these functions takes two lists and
@code{:key} and @code{:test} keyword arguments and returns a new list
representing the set resulting from performing the appropriate
set-theoretic operation on the two lists: @code{INTERSECTION} returns
a list containing all the elements found in both
arguments. @code{UNION} returns a list containing one instance of each
unique element from the two arguments.@footnote{@code{UNION} takes
only one element from each list, but if either list contains duplicate
elements, the result may also contain duplicates.}
@code{SET-DIFFERENCE} returns a list containing all the elements from
the first argument that don't appear in the second argument. And
@code{SET-EXCLUSIVE-OR} returns a list containing those elements
appearing in only one or the other of the two argument lists but not
in both. Each of these functions also has a recycling counterpart
whose name is the same except with an @emph{N} prefix.

Finally, the function @code{SUBSETP} takes two lists and the usual
@code{:key} and @code{:test} keyword arguments and returns true if the
first list is a subset of the second--if every element in the first list
is also present in the second list. The order of the elements in the
lists doesn't matter.

@verbatim
CL-USER> (subsetp '(3 2 1) '(1 2 3 4))
T
CL-USER> (subsetp '(1 2 3 4) '(3 2 1))
NIL
@end verbatim

@node Lookup Tables Alists and Plists
@section Lookup Tables: Alists and Plists
@anchor{#lookup-tables-alists-and-plists}
In addition to trees and sets, you can build tables that map keys to
values out of cons cells. Two flavors of cons-based lookup tables are
commonly used, both of which I've mentioned in passing in previous
chapters. They're @emph{association lists}, also called @emph{alists},
and @emph{property lists}, also known as @emph{plists}. While you
wouldn't use either alists or plists for large tables--for that you'd
use a hash table--it's worth knowing how to work with them both because
for small tables they can be more efficient than hash tables and because
they have some useful properties of their own.

An alist is a data structure that maps keys to values and also supports
reverse lookups, finding the key when given a value. Alists also support
adding key/value mappings that shadow existing mappings in such a way
that the shadowing mapping can later be removed and the original
mappings exposed again.

Under the covers, an alist is essentially a list whose elements are
themselves cons cells. Each element can be thought of as a key/value
pair with the key in the cons cell's @code{CAR} and the value in the
@code{CDR}. For instance, the following is a box-and-arrow diagram of an
alist mapping the symbol @code{A} to the number 1, @code{B} to 2, and
@code{C} to 3:

@image{figures/alist-abc-123,,,,png}

Unless the value in the @code{CDR} is a list, cons cells representing
the key/value pairs will be @emph{dotted pairs} in s-expression
notation. The alist diagramed in the previous figure, for instance, is
printed like this:

@verbatim
((A . 1) (B . 2) (C . 3))
@end verbatim

The main lookup function for alists is @code{ASSOC}, which takes a key
and an alist and returns the first cons cell whose @code{CAR} matches
the key or @code{NIL} if no match is found.

@verbatim
CL-USER> (assoc 'a '((a . 1) (b . 2) (c . 3)))
(A . 1)
CL-USER> (assoc 'c '((a . 1) (b . 2) (c . 3)))
(C . 3)
CL-USER> (assoc 'd '((a . 1) (b . 2) (c . 3)))
NIL
@end verbatim

To get the value corresponding to a given key, you simply pass the
result of @code{ASSOC} to @code{CDR}.

@verbatim
CL-USER> (cdr (assoc 'a '((a . 1) (b . 2) (c . 3))))
1
@end verbatim

By default the key given is compared to the keys in the alist using
@code{EQL}, but you can change that with the standard combination of
@code{:key} and @code{:test} keyword arguments. For instance, if you
wanted to use string keys, you might write this:

@verbatim
CL-USER> (assoc "a" '(("a" . 1) ("b" . 2) ("c" . 3)) :test #'string=)
("a" . 1)
@end verbatim

Without specifying @code{:test} to be @code{STRING=}, that @code{ASSOC}
would probably return @code{NIL} because two strings with the same
contents aren't necessarily @code{EQL}.

@verbatim
CL-USER> (assoc "a" '(("a" . 1) ("b" . 2) ("c" . 3)))
NIL
@end verbatim

Because @code{ASSOC} searches the list by scanning from the front of the
list, one key/value pair in an alist can shadow other pairs with the
same key later in the list.

@verbatim
CL-USER> (assoc 'a '((a . 10) (a . 1) (b . 2) (c . 3)))
(A . 10)
@end verbatim

You can add a pair to the front of an alist with @code{CONS} like this:

@verbatim
(cons (cons 'new-key 'new-value) alist)
@end verbatim

However, as a convenience, Common Lisp provides the function
@code{ACONS}, which lets you write this:

@verbatim
(acons 'new-key 'new-value alist)
@end verbatim

Like @code{CONS}, @code{ACONS} is a function and thus can't modify the
place holding the alist it's passed. If you want to modify an alist, you
need to write either this:

@verbatim
(setf alist (acons 'new-key 'new-value alist))
@end verbatim

or this:

@verbatim
(push (cons 'new-key 'new-value) alist)
@end verbatim

Obviously, the time it takes to search an alist with @code{ASSOC} is a
function of how deep in the list the matching pair is found. In the
worst case, determining that no pair matches requires @code{ASSOC} to
scan every element of the alist. However, since the basic mechanism for
alists is so lightweight, for small tables an alist can outperform a
hash table. Also, alists give you more flexibility in how you do the
lookup. I already mentioned that @code{ASSOC} takes @code{:key} and
@code{:test} keyword arguments. When those don't suit your needs, you
may be able to use the @code{ASSOC-IF} and @code{ASSOC-IF-NOT}
functions, which return the first key/value pair whose @code{CAR}
satisfies (or not, in the case of @code{ASSOC-IF-NOT}) the test function
passed in the place of a specific item. And three
functions--@code{RASSOC}, @code{RASSOC-IF}, and
@code{RASSOC-IF-NOT}--work just like the corresponding @code{ASSOC}
functions except they use the value in the @code{CDR} of each element as
the key, performing a reverse lookup.

The function @code{COPY-ALIST} is similar to @code{COPY-TREE} except,
instead of copying the whole tree structure, it copies only the cons
cells that make up the list structure, plus the cons cells directly
referenced from the @code{CAR}s of those cells. In other words, the
original alist and the copy will both contain the same objects as the
keys and values, even if those keys or values happen to be made up of
cons cells.

Finally, you can build an alist from two separate lists of keys and
values with the function @code{PAIRLIS}. The resulting alist may contain
the pairs either in the same order as the original lists or in reverse
order. For example, you may get this result:

@verbatim
CL-USER> (pairlis '(a b c) '(1 2 3))
((C . 3) (B . 2) (A . 1))
@end verbatim

Or you could just as well get this:

@verbatim
CL-USER> (pairlis '(a b c) '(1 2 3))
((A . 1) (B . 2) (C . 3))
@end verbatim

The other kind of lookup table is the property list, or plist, which you
used to represent the rows in the database in Chapter 3. Structurally a
plist is just a regular list with the keys and values as alternating
values. For instance, a plist mapping @code{A}, @code{B}, and @code{C},
to 1, 2, and 3 is simply the list @code{(A 1 B 2 C 3)}. In
boxes-and-arrows form, it looks like this:

@image{figures/plist-abc-123,,,,png}

However, plists are less flexible than alists. In fact, plists support
only one fundamental lookup operation, the function @code{GETF}, which
takes a plist and a key and returns the associated value or @code{NIL}
if the key isn't found. @code{GETF} also takes an optional third
argument, which will be returned in place of @code{NIL} if the key isn't
found.

Unlike @code{ASSOC}, which uses @code{EQL} as its default test and
allows a different test function to be supplied with a @code{:test}
argument, @code{GETF} always uses @code{EQ} to test whether the provided
key matches the keys in the plist. Consequently, you should never use
numbers or characters as keys in a plist; as you saw in Chapter 4, the
behavior of @code{EQ} for those types is essentially undefined.
Practically speaking, the keys in a plist are almost always symbols,
which makes sense since plists were first invented to implement symbolic
"properties," arbitrary mappings between names and values.

You can use @code{SETF} with @code{GETF} to set the value associated
with a given key. @code{SETF} also treats @code{GETF} a bit specially in
that the first argument to @code{GETF} is treated as the place to
modify. Thus, you can use @code{SETF} of @code{GETF} to add a new
key/value pair to an existing plist.

@verbatim
CL-USER> (defparameter *plist* ())
*PLIST*
CL-USER> *plist*
NIL
CL-USER> (setf (getf *plist* :a) 1)
1
CL-USER> *plist*
(:A 1)
CL-USER> (setf (getf *plist* :a) 2)
2
CL-USER> *plist*
(:A 2)
@end verbatim

To remove a key/value pair from a plist, you use the macro @code{REMF},
which sets the place given as its first argument to a plist containing
all the key/value pairs except the one specified. It returns true if the
given key was actually found.

@verbatim
CL-USER> (remf *plist* :a)
T
CL-USER> *plist*
NIL
@end verbatim

Like @code{GETF}, @code{REMF} always uses @code{EQ} to compare the given
key to the keys in the plist.

Since plists are often used in situations where you want to extract
several properties from the same plist, Common Lisp provides a function,
@code{GET-PROPERTIES}, that makes it more efficient to extract multiple
values from a single plist. It takes a plist and a list of keys to
search for and returns, as multiple values, the first key found, the
corresponding value, and the head of the list starting with the found
key. This allows you to process a property list, extracting the desired
properties, without continually rescanning from the front of the list.
For instance, the following function efficiently processes--using the
hypothetical function @code{process-property}--all the key/value pairs
in a plist for a given list of keys:

@verbatim
(defun process-properties (plist keys)
  (loop while plist do
       (multiple-value-bind (key value tail) (get-properties plist keys)
         (when key (process-property key value))
         (setf plist (cddr tail)))))
@end verbatim

The last special thing about plists is the relationship they have with
symbols: every symbol object has an associated plist that can be used to
store information about the symbol. The plist can be obtained via the
function @code{SYMBOL-PLIST}. However, you rarely care about the whole
plist; more often you'll use the functions @code{GET}, which takes a
symbol and a key and is shorthand for a @code{GETF} of the same key in
the symbols @code{SYMBOL-PLIST}.

@verbatim
(get 'symbol 'key) === (getf (symbol-plist 'symbol) 'key)
@end verbatim

Like @code{GETF}, @code{GET} is @code{SETF}able, so you can attach
arbitrary information to a symbol like this:

@verbatim
(setf (get 'some-symbol 'my-key) "information")
@end verbatim

To remove a property from a symbol's plist, you can use either
@code{REMF} of @code{SYMBOL-PLIST} or the convenience function
@code{REMPROP}.@footnote{It's also possible to directly @code{SETF
SYMBOL-PLIST}. However, that's a bad idea, as different code may have
added different properties to the symbol's plist for different
reasons. If one piece of code clobbers the symbol's whole plist, it
may break other code that added its own properties to the plist.}

@verbatim
(remprop 'symbol 'key) === (remf (symbol-plist 'symbol key))
@end verbatim

Being able to attach arbitrary information to names is quite handy when
doing any kind of symbolic programming. For instance, one of the macros
you'll write in Chapter 24 will attach information to names that other
instances of the same macros will extract and use when generating their
expansions.

@node DESTRUCTURING-BIND
@section DESTRUCTURING-BIND
@anchor{#destructuring-bind}
One last tool for slicing and dicing lists that I need to cover since
you'll need it in later chapters is the @code{DESTRUCTURING-BIND} macro.
This macro provides a way to @emph{destructure} arbitrary lists, similar
to the way macro parameter lists can take apart their argument list. The
basic skeleton of a @code{DESTRUCTURING-BIND} is as follows:

@verbatim
(destructuring-bind (parameter*) list
  body-form*)
@end verbatim

The parameter list can include any of the types of parameters
supported in macro parameter lists such as @code{&optional},
@code{&rest}, and @code{&key} parameters.@footnote{Macro parameter
lists do support one parameter type, @code{&environment} parameters,
which @code{DESTRUCTURING-BIND} doesn't.  However, I didn't discuss
that parameter type in Chapter 8, and you don't need to worry about it
now either.} And, as in macro parameter lists, any parameter can be
replaced with a nested destructuring parameter list, which takes apart
the list that would otherwise have been bound to the replaced
parameter. The @emph{list} form is evaluated once and should return a
list, which is then destructured and the appropriate values are bound
to the variables in the parameter list.  Then the @emph{body-forms}
are evaluated in order with those bindings in effect. Some simple
examples follow:

@verbatim
(destructuring-bind (x y z) (list 1 2 3)
  (list :x x :y y :z z)) ==> (:X 1 :Y 2 :Z 3)

(destructuring-bind (x y z) (list 1 (list 2 20) 3)
  (list :x x :y y :z z)) ==> (:X 1 :Y (2 20) :Z 3)

(destructuring-bind (x (y1 y2) z) (list 1 (list 2 20) 3)
  (list :x x :y1 y1 :y2 y2 :z z)) ==> (:X 1 :Y1 2 :Y2 20 :Z 3)

(destructuring-bind (x (y1 &optional y2) z) (list 1 (list 2 20) 3)
  (list :x x :y1 y1 :y2 y2 :z z)) ==> (:X 1 :Y1 2 :Y2 20 :Z 3)

(destructuring-bind (x (y1 &optional y2) z) (list 1 (list 2) 3)
  (list :x x :y1 y1 :y2 y2 :z z)) ==> (:X 1 :Y1 2 :Y2 NIL :Z 3)

(destructuring-bind (&key x y z) (list :x 1 :y 2 :z 3)
  (list :x x :y y :z z)) ==> (:X 1 :Y 2 :Z 3)

(destructuring-bind (&key x y z) (list :z 1 :y 2 :x 3)
  (list :x x :y y :z z)) ==> (:X 3 :Y 2 :Z 1)
@end verbatim

One kind of parameter you can use with @code{DESTRUCTURING-BIND} and
also in macro parameter lists, though I didn't mention it in Chapter
8, is a @code{&whole} parameter. If specified, it must be the first
parameter in a parameter list, and it's bound to the whole list
form.@footnote{When a @code{&whole} parameter is used in a macro
parameter list, the form it's bound to is the whole macro form,
including the name of the macro.} After a @code{&whole} parameter,
other parameters can appear as usual and will extract specific parts
of the list just as they would if the @code{&whole} parameter weren't
there. An example of using @code{&whole} with
@code{DESTRUCTURING-BIND} looks like this:

@verbatim
(destructuring-bind (&whole whole &key x y z) (list :z 1 :y 2 :x 3)
  (list :x x :y y :z z :whole whole))
==> (:X 3 :Y 2 :Z 1 :WHOLE (:Z 1 :Y 2 :X 3))
@end verbatim

You'll use a @code{&whole} parameter in one of the macros that's part of
the HTML generation library you'll develop in Chapter 31. However, I
have a few more topics to cover before you can get to that. After two
chapters on the rather Lispy topic of cons cells, you can now turn to
the more prosaic matter of how to deal with files and filenames.

@node Files and File I/O
@chapter Files and File I/O
@anchor{#files-and-file-io}
Common Lisp provides a rich library of functionality for dealing with
files. In this chapter I'll focus on a few basic file-related tasks:
reading and writing files and listing files in the file system. For
these basic tasks, Common Lisp's I/O facilities are similar to those in
other languages. Common Lisp provides a stream abstraction for reading
and writing data and an abstraction, called @emph{pathnames}, for
manipulating filenames in an operating system-independent way.
Additionally, Common Lisp provides other bits of functionality unique to
Lisp such as the ability to read and write s-expressions.
@menu
* Reading File Data::
* Reading Binary Data::
* Bulk Reads::
* File Output::
* Closing Files::
* Filenames::
* How Pathnames Represent Filenames::
* Constructing New Pathnames::
* Two Representations of Directory Names::
* Interacting with the File System::
* Other Kinds of I/O::
@end menu

@node Reading File Data
@section Reading File Data
@anchor{#reading-file-data}
The most basic file I/O task is to read the contents of a file. You
obtain a stream from which you can read a file's contents with the
@code{OPEN} function. By default @code{OPEN} returns a character-based
input stream you can pass to a variety of functions that read one or
more characters of text: @code{READ-CHAR} reads a single character;
@code{READ-LINE} reads a line of text, returning it as a string with the
end-of-line character(s) removed; and @code{READ} reads a single
s-expression, returning a Lisp object. When you're done with the stream,
you can close it with the @code{CLOSE} function.

The only required argument to @code{OPEN} is the name of the file to
read. As you'll see in the section "Filenames," Common Lisp provides a
couple of ways to represent a filename, but the simplest is to use a
string containing the name in the local file-naming syntax. So assuming
that @code{/some/file/name.txt} is a file, you can open it like this:

@verbatim
(open "/some/file/name.txt")
@end verbatim

You can use the object returned as the first argument to any of the read
functions. For instance, to print the first line of the file, you can
combine @code{OPEN}, @code{READ-LINE}, and @code{CLOSE} as follows:

@verbatim
(let ((in (open "/some/file/name.txt")))
  (format t "~a~%" (read-line in))
  (close in))
@end verbatim

Of course, a number of things can go wrong while trying to open and read
from a file. The file may not exist. Or you may unexpectedly hit the end
of the file while reading. By default @code{OPEN} and the @code{READ-*}
functions will signal an error in these situations. In Chapter 19, I'll
discuss how to recover from such errors. For now, however, there's a
lighter-weight solution: each of these functions accepts arguments that
modify its behavior in these exceptional situations.

If you want to open a possibly nonexistent file without @code{OPEN}
signaling an error, you can use the keyword argument
@code{:if-does-not-exist} to specify a different behavior. The three
possible values are @code{:error}, the default; @code{:create}, which
tells it to go ahead and create the file and then proceed as if it had
already existed; and @code{NIL}, which tells it to return @code{NIL}
instead of a stream. Thus, you can change the previous example to deal
with the possibility that the file may not exist.

@verbatim
(let ((in (open "/some/file/name.txt" :if-does-not-exist nil)))
  (when in
    (format t "~a~%" (read-line in))
    (close in)))
@end verbatim

The reading functions--@code{READ-CHAR}, @code{READ-LINE}, and
@code{READ}--all take an optional argument, which defaults to true, that
specifies whether they should signal an error if they're called at the
end of the file. If that argument is @code{NIL}, they instead return the
value of their third argument, which defaults to @code{NIL}. Thus, you
could print all the lines in a file like this:

@verbatim
(let ((in (open "/some/file/name.txt" :if-does-not-exist nil)))
  (when in
    (loop for line = (read-line in nil)
         while line do (format t "~a~%" line))
    (close in)))
@end verbatim

Of the three text-reading functions, @code{READ} is unique to Lisp. This
is the same function that provides the @emph{R} in the REPL and that's
used to read Lisp source code. Each time it's called, it reads a single
s-expression, skipping whitespace and comments, and returns the Lisp
object denoted by the s-expression. For instance, suppose
@code{/some/file/name.txt} has the following contents:

@verbatim
(1 2 3)
456
"a string" ; this is a comment
((a b)
 (c d))
@end verbatim

In other words, it contains four s-expressions: a list of numbers, a
number, a string, and a list of lists. You can read those expressions
like this:

@verbatim
CL-USER> (defparameter *s* (open "/some/file/name.txt"))
*S*
CL-USER> (read *s*)
(1 2 3)
CL-USER> (read *s*)
456
CL-USER> (read *s*)
"a string"
CL-USER> (read *s*)
((A B) (C D))
CL-USER> (close *s*)
T
@end verbatim

As you saw in Chapter 3, you can use @code{PRINT} to print Lisp
objects in "readable" form. Thus, whenever you need to store a bit of
data in a file, @code{PRINT} and @code{READ} provide an easy way to do
it without having to design a data format or write a parser. They
even--as the previous example demonstrated--give you comments for
free. And because s-expressions were designed to be human editable,
it's also a fine format for things like configuration
files.@footnote{Note, however, that while the Lisp reader knows how to
skip comments, it completely skips them. Thus, if you use @code{READ}
to read in a configuration file containing comments and then use
@code{PRINT} to save changes to the data, you'll lose the comments.}

@node Reading Binary Data
@section Reading Binary Data
@anchor{#reading-binary-data} By default @code{OPEN} returns character
streams, which translate the underlying bytes to characters according
to a particular character-encoding scheme.@footnote{By default
@code{OPEN} uses the default character encoding for the operating
system, but it also accepts a keyword parameter,
@code{:external-format}, that can pass implementation-defined values
that specify a different encoding. Character streams also translate
the platform-specific end-of-line sequence to the single character
@code{#\Newline}.} To read the raw bytes, you need to pass @code{OPEN}
an @code{:element-type} argument of @code{'(unsigned-byte
8)}.@footnote{The type @code{(unsigned-byte 8)} indicates an 8-bit
byte; Common Lisp "byte" types aren't a fixed size since Lisp has run
at various times on architectures with byte sizes from 6 to 9 bits, to
say nothing of the PDP-10, which had individually addressable
variable-length bit fields of 1 to 36 bits.} You can pass the
resulting stream to the function @code{READ-BYTE}, which will return
an integer between 0 and 255 each time it's called. @code{READ-BYTE},
like the character-reading functions, also accepts optional arguments
to specify whether it should signal an error if called at the end of
the file and what value to return if not. In Chapter 24 you'll build a
library that allows you to conveniently read structured binary data
using @code{READ-BYTE}.@footnote{In general, a stream is either a
character stream or a binary stream, so you can't mix calls to
@code{READ-BYTE} and @code{READ-CHAR} or other character-based read
functions. However, some implementations, such as Allegro, support
so-called bivalent streams, which support both character and binary
I/O.}

@node Bulk Reads
@section Bulk Reads
@anchor{#bulk-reads}
One last reading function, @code{READ-SEQUENCE}, works with both
character and binary streams. You pass it a sequence (typically a
vector) and a stream, and it attempts to fill the sequence with data
from the stream. It returns the index of the first element of the
sequence that wasn't filled or the length of the sequence if it was able
to completely fill it. You can also pass @code{:start} and @code{:end}
keyword arguments to specify a subsequence that should be filled
instead. The sequence argument must be a type that can hold elements of
the stream's element type. Since most operating systems support some
form of block I/O, @code{READ-SEQUENCE} is likely to be quite a bit more
efficient than filling a sequence by repeatedly calling @code{READ-BYTE}
or @code{READ-CHAR}.

@node File Output
@section File Output
@anchor{#file-output}
To write data to a file, you need an output stream, which you obtain by
calling @code{OPEN} with a @code{:direction} keyword argument of
@code{:output}. When opening a file for output, @code{OPEN} assumes the
file shouldn't already exist and will signal an error if it does.
However, you can change that behavior with the @code{:if-exists} keyword
argument. Passing the value @code{:supersede} tells @code{OPEN} to
replace the existing file. Passing @code{:append} causes @code{OPEN} to
open the existing file such that new data will be written at the end of
the file, while @code{:overwrite} returns a stream that will overwrite
existing data starting from the beginning of the file. And passing
@code{NIL} will cause @code{OPEN} to return @code{NIL} instead of a
stream if the file already exists. A typical use of @code{OPEN} for
output looks like this:

@verbatim
(open "/some/file/name.txt" :direction :output :if-exists :supersede)
@end verbatim

Common Lisp also provides several functions for writing data:
@code{WRITE-CHAR} writes a single character to the stream.
@code{WRITE-LINE} writes a string followed by a newline, which will be
output as the appropriate end-of-line character or characters for the
platform. Another function, @code{WRITE-STRING}, writes a string without
adding any end-of-line characters. Two different functions can print
just a newline: @code{TERPRI}--short for "terminate
print"--unconditionally prints a newline character, and
@code{FRESH-LINE} prints a newline character unless the stream is at the
beginning of a line. @code{FRESH-LINE} is handy when you want to avoid
spurious blank lines in textual output generated by different functions
called in sequence. For example, suppose you have one function that
generates output that should always be followed by a line break and
another that should start on a new line. But assume that if the
functions are called one after the other, you don't want a blank line
between the two bits of output. If you use @code{FRESH-LINE} at the
beginning of the second function, its output will always start on a new
line, but if it's called right after the first, it won't emit an extra
line break.

Several functions output Lisp data as s-expressions: @code{PRINT} prints
an s-expression preceded by an end-of-line and followed by a space.
@code{PRIN1} prints just the s-expression. And the function
@code{PPRINT} prints s-expressions like @code{PRINT} and @code{PRIN1}
but using the "pretty printer," which tries to print its output in an
aesthetically pleasing way.

However, not all objects can be printed in a form that @code{READ} will
understand. The variable @code{*PRINT-READABLY*} controls what happens
if you try to print such an object with @code{PRINT}, @code{PRIN1}, or
@code{PPRINT}. When it's @code{NIL}, these functions will print the
object in a special syntax that's guaranteed to cause @code{READ} to
signal an error if it tries to read it; otherwise they will signal an
error rather than print the object.

Another function, @code{PRINC}, also prints Lisp objects, but in a way
designed for human consumption. For instance, @code{PRINC} prints
strings without quotation marks. You can generate more elaborate text
output with the incredibly flexible if somewhat arcane @code{FORMAT}
function. I'll discuss some of the more important details of
@code{FORMAT}, which essentially defines a mini-language for emitting
formatted output, in Chapter 18.

To write binary data to a file, you have to @code{OPEN} the file with
the same @code{:element-type} argument as you did to read it:
@code{'(unsigned-byte 8)}. You can then write individual bytes to the
stream with @code{WRITE-BYTE}.

The bulk output function @code{WRITE-SEQUENCE} accepts both binary and
character streams as long as all the elements of the sequence are of an
appropriate type for the stream, either characters or bytes. As with
@code{READ-SEQUENCE}, this function is likely to be quite a bit more
efficient than writing the elements of the sequence one at a time.

@node Closing Files
@section Closing Files
@anchor{#closing-files} As anyone who has written code that deals with
lots of files knows, it's important to close files when you're done
with them, because file handles tend to be a scarce resource. If you
open files and don't close them, you'll soon discover you can't open
any more files.@footnote{Some folks expect this wouldn't be a problem
in a garbage-collected language such as Lisp. It is the case in most
Lisp implementations that a stream that becomes garbage will
automatically be closed. However, this isn't something to rely on--the
problem is that garbage collectors usually run only when memory is
low; they don't know about other scarce resources such as file
handles. If there's plenty of memory available, it's easy to run out
of file handles long before the garbage collector runs.} It might seem
straightforward enough to just be sure every @code{OPEN} has a
matching @code{CLOSE}. For instance, you could always structure your
file using code like this:

@verbatim
(let ((stream (open "/some/file/name.txt")))
  ;; do stuff with stream
  (close stream))
@end verbatim

However, this approach suffers from two problems. One is simply that
it's error prone--if you forget the @code{CLOSE}, the code will leak a
file handle every time it runs. The other--and more significant--problem
is that there's no guarantee you'll get to the @code{CLOSE}. For
instance, if the code prior to the @code{CLOSE} contains a @code{RETURN}
or @code{RETURN-FROM}, you could leave the @code{LET} without closing
the stream. Or, as you'll see in Chapter 19, if any of the code before
the @code{CLOSE} signals an error, control may jump out of the
@code{LET} to an error handler and never come back to close the stream.

Common Lisp provides a general solution to the problem of how to ensure
that certain code always runs: the special operator
@code{UNWIND-PROTECT}, which I'll discuss in Chapter 20. However,
because the pattern of opening a file, doing something with the
resulting stream, and then closing the stream is so common, Common Lisp
provides a macro, @code{WITH-OPEN-FILE}, built on top of
@code{UNWIND-PROTECT}, to encapsulate this pattern. This is the basic
form:

@verbatim
(with-open-file (stream-var open-argument*)
  body-form*)
@end verbatim

The forms in @emph{body-forms} are evaluated with @emph{stream-var}
bound to a file stream opened by a call to @code{OPEN} with
@emph{open-arguments} as its arguments. @code{WITH-OPEN-FILE} then
ensures the stream in @emph{stream-var} is closed before the
@code{WITH-OPEN-FILE} form returns. Thus, you can write this to read a
line from a file:

@verbatim
(with-open-file (stream "/some/file/name.txt")
  (format t "~a~%" (read-line stream)))
@end verbatim

To create a new file, you can write something like this:

@verbatim
(with-open-file (stream "/some/file/name.txt" :direction :output)
  (format stream "Some text."))
@end verbatim

You'll probably use @code{WITH-OPEN-FILE} for 90-99 percent of the file
I/O you do--the only time you need to use raw @code{OPEN} and
@code{CLOSE} calls is if you need to open a file in a function and keep
the stream around after the function returns. In that case, you must
take care to eventually close the stream yourself, or you'll leak file
descriptors and may eventually end up unable to open any more files.

@node Filenames
@section Filenames
@anchor{#filenames}
So far you've used strings to represent filenames. However, using
strings as filenames ties your code to a particular operating system and
file system. Likewise, if you programmatically construct names according
to the rules of a particular naming scheme (separating directories with
/, say), you also tie your code to a particular file system.

To avoid this kind of nonportability, Common Lisp provides another
representation of filenames: pathname objects. Pathnames represent
filenames in a structured way that makes them easy to manipulate without
tying them to a particular filename syntax. And the burden of
translating back and forth between strings in the local syntax--called
@emph{namestrings}--and pathnames is placed on the Lisp implementation.

Unfortunately, as with many abstractions designed to hide the details
of fundamentally different underlying systems, the pathname
abstraction introduces its own complications. When pathnames were
designed, the set of file systems in general use was quite a bit more
variegated than those in common use today. Consequently, some nooks
and crannies of the pathname abstraction make little sense if all
you're concerned about is representing Unix or Windows
filenames. However, once you understand which parts of the pathname
abstraction you can ignore as artifacts of pathnames' evolutionary
history, they do provide a convenient way to manipulate
filenames.@footnote{Another reason the pathname system is considered
somewhat baroque is because of the inclusion of @emph{logical
pathnames}. However, you can use the rest of the pathname system
perfectly well without knowing anything more about logical pathnames
than that you can safely ignore them. Briefly, logical pathnames allow
Common Lisp programs to contain references to pathnames without naming
specific files. Logical pathnames could then be mapped to specific
locations in an actual file system when the program was installed by
defining a "logical pathname translation" that translates logical
pathnames matching certain wildcards to pathnames representing files
in the file system, so-called physical pathnames. They have their uses
in certain situations, but you can get pretty far without worrying
about them.}

Most places a filename is called for, you can use either a namestring or
a pathname. Which to use depends mostly on where the name originated.
Filenames provided by the user--for example, as arguments or as values
in configuration files--will typically be namestrings, since the user
knows what operating system they're running on and shouldn't be expected
to care about the details of how Lisp represents filenames. But
programmatically generated filenames will be pathnames because you can
create them portably. A stream returned by @code{OPEN} also represents a
filename, namely, the filename that was originally used to open the
stream. Together these three types are collectively referred to as
@emph{pathname designators}. All the built-in functions that expect a
filename argument accept all three types of pathname designator. For
instance, all the places in the previous section where you used a string
to represent a filename, you could also have passed a pathname object or
a stream.

How We Got Here
The historical diversity of file systems in existence during the 70s and
80s can be easy to forget. Kent Pitman, one of the principal technical
editors of the Common Lisp standard, described the situation once in
comp.lang.lisp (Message-ID: @code{sfwzo74np6w.fsf@@world.std.com})
thusly:

@quotation
The dominant file systems at the time the design [of Common Lisp] was
done were TOPS-10, TENEX, TOPS-20, VAX VMS, AT&T Unix, MIT Multics, MIT
ITS, not to mention a bunch of mainframe [OSs]. Some were uppercase
only, some mixed, some were case-sensitive but case- translating (like
CL). Some had dirs as files, some not. Some had quote chars for funny
file chars, some not. Some had wildcards, some didn't. Some had :up in
relative pathnames, some didn't. Some had namable root dirs, some
didn't. There were file systems with no directories, file systems with
non-hierarchical directories, file systems with no file types, file
systems with no versions, file systems with no devices, and so on.
@end quotation
If you look at the pathname abstraction from the point of view of any
single file system, it seems baroque. However, if you take even two such
similar file systems as Windows and Unix, you can already begin to see
differences the pathname system can help abstract away--Windows
filenames contain a drive letter, for instance, while Unix filenames
don't. The other advantage of having the pathname abstraction designed
to handle the wide variety of file systems that existed in the past is
that it's more likely to be able to handle file systems that may exist
in the future. If, say, versioning file systems come back into vogue,
Common Lisp will be ready.

@node How Pathnames Represent Filenames
@section How Pathnames Represent Filenames
@anchor{#how-pathnames-represent-filenames}
A pathname is a structured object that represents a filename using six
components: host, device, directory, name, type, and version. Most of
these components take on atomic values, usually strings; only the
directory component is further structured, containing a list of
directory names (as strings) prefaced with the keyword @code{:absolute}
or @code{:relative}. However, not all pathname components are needed on
all platforms--this is one of the reasons pathnames strike many new
Lispers as gratuitously complex. On the other hand, you don't really
need to worry about which components may or may not be used to represent
names on a particular file system unless you need to create a new
pathname object from scratch, which you'll almost never need to do.
Instead, you'll usually get hold of pathname objects either by letting
the implementation parse a file system-specific namestring into a
pathname object or by creating a new pathname that takes most of its
components from an existing pathname.

For instance, to translate a namestring to a pathname, you use the
@code{PATHNAME} function. It takes a pathname designator and returns an
equivalent pathname object. When the designator is already a pathname,
it's simply returned. When it's a stream, the original filename is
extracted and returned. When the designator is a namestring, however,
it's parsed according to the local filename syntax. The language
standard, as a platform-neutral document, doesn't specify any particular
mapping from namestring to pathname, but most implementations follow the
same conventions on a given operating system.

On Unix file systems, only the directory, name, and type components
are typically used. On Windows, one more component--usually the device
or host--holds the drive letter. On these platforms, a namestring is
parsed by first splitting it into elements on the path separator--a
slash on Unix and a slash or backslash on Windows. The drive letter on
Windows will be placed into either the device or the host
component. All but the last of the other name elements are placed in a
list starting with @code{:absolute} or @code{:relative} depending on
whether the name (ignoring the drive letter, if any) began with a path
separator. This list becomes the directory component of the
pathname. The last element is then split on the rightmost dot, if any,
and the two parts put into the name and type components of the
pathname.@footnote{Many Unix-based implementations treat filenames
whose last element starts with a dot and don't contain any other dots
specially, putting the whole element, with the dot, in the name
component and leaving the type component @code{NIL}.

@verbatim
(pathname-name (pathname "/foo/.emacs")) ==> ".emacs"
(pathname-type (pathname "/foo/.emacs")) ==> NIL
@end verbatim

However, not all implementations follow this convention; some will
create a pathname with "" as the name and @code{emacs} as the type.}

You can examine these individual components of a pathname with the
functions @code{PATHNAME-DIRECTORY}, @code{PATHNAME-NAME}, and
@code{PATHNAME-TYPE}.

@verbatim
(pathname-directory (pathname "/foo/bar/baz.txt")) ==> (:ABSOLUTE "foo" "bar")
(pathname-name (pathname "/foo/bar/baz.txt"))      ==> "baz"
(pathname-type (pathname "/foo/bar/baz.txt"))      ==> "txt"
@end verbatim

Three other functions--@code{PATHNAME-HOST}, @code{PATHNAME-DEVICE}, and
@code{PATHNAME-VERSION}--allow you to get at the other three pathname
components, though they're unlikely to have interesting values on Unix.
On Windows either @code{PATHNAME-HOST} or @code{PATHNAME-DEVICE} will
return the drive letter.

Like many other built-in objects, pathnames have their own read syntax,
@code{#p} followed by a double-quoted string. This allows you to print
and read back s-expressions containing pathname objects, but because the
syntax depends on the namestring parsing algorithm, such data isn't
necessarily portable between operating systems.

@verbatim
(pathname "/foo/bar/baz.txt") ==> #p"/foo/bar/baz.txt"
@end verbatim

To translate a pathname back to a namestring--for instance, to present
to the user--you can use the function @code{NAMESTRING}, which takes a
pathname designator and returns a namestring. Two other functions,
@code{DIRECTORY-NAMESTRING} and @code{FILE-NAMESTRING}, return a
partial namestring. @code{DIRECTORY-NAMESTRING} combines the elements
of the directory component into a local directory name, and
@code{FILE-NAMESTRING} combines the name and type
components.@footnote{The name returned by @code{FILE-NAMESTRING} also
includes the version component on file systems that use it.}

@verbatim
(namestring #p"/foo/bar/baz.txt")           ==> "/foo/bar/baz.txt"
(directory-namestring #p"/foo/bar/baz.txt") ==> "/foo/bar/"
(file-namestring #p"/foo/bar/baz.txt")      ==> "baz.txt"
@end verbatim

@node Constructing New Pathnames
@section Constructing New Pathnames
@anchor{#constructing-new-pathnames} You can construct arbitrary
pathnames using the @code{MAKE-PATHNAME} function. It takes one
keyword argument for each pathname component and returns a pathname
with any supplied components filled in and the rest
@code{NIL}.@footnote{The host component may not default to @code{NIL},
but if not, it will be an opaque implementation-defined value.}

@verbatim
(make-pathname
  :directory '(:absolute "foo" "bar")
  :name "baz"
  :type "txt") ==> #p"/foo/bar/baz.txt"
@end verbatim

However, if you want your programs to be portable, you probably don't
want to make pathnames completely from scratch: even though the pathname
abstraction protects you from unportable filename syntax, filenames can
be unportable in other ways. For instance, the filename
@code{/home/peter/foo.txt} is no good on an OS X box where @code{/home/}
is called @code{/Users/}.

Another reason not to make pathnames completely from scratch is that
different implementations use the pathname components slightly
differently. For instance, as mentioned previously, some Windows-based
Lisp implementations store the drive letter in the device component
while others store it in the host component. If you write code like
this:

@verbatim
(make-pathname :device "c" :directory '(:absolute "foo" "bar") :name "baz")
@end verbatim

it will be correct on some implementations but not on others.

Rather than making names from scratch, you can build a new pathname
based on an existing pathname with @code{MAKE-PATHNAME}'s keyword
parameter @code{:defaults}. With this parameter you can provide a
pathname designator, which will supply the values for any components not
specified by other arguments. For example, the following expression
creates a pathname with an @code{.html} extension and all other
components the same as the pathname in the variable @code{input-file}:

@verbatim
(make-pathname :type "html" :defaults input-file)
@end verbatim

Assuming the value in @code{input-file} was a user-provided name, this
code will be robust in the face of operating system and implementation
differences such as whether filenames have drive letters in them and
where they're stored in a pathname if they do.@footnote{For absolutely
maximum portability, you should really write this:

@verbatim
(make-pathname :type "html" :version :newest :defaults input-file)
@end verbatim

Without the @code{:version} argument, on a file system with built-in
versioning, the output pathname would inherit its version number from
the input file which isn't likely to be right--if the input file has
been saved many times it will have a much higher version number than
the generated HTML file. On implementations without file versioning,
the @code{:version} argument should be ignored. It's up to you if you
care that much about portability.}

You can use the same technique to create a pathname with a different
directory component.

@verbatim
(make-pathname :directory '(:relative "backups") :defaults input-file)
@end verbatim

However, this will create a pathname whose whole directory component is
the relative directory @code{backups/}, regardless of any directory
component @code{input-file} may have had. For example:

@verbatim
(make-pathname :directory '(:relative "backups")
               :defaults #p"/foo/bar/baz.txt") ==> #p"backups/baz.txt"
@end verbatim

Sometimes, though, you want to combine two pathnames, at least one of
which has a relative directory component, by combining their directory
components. For instance, suppose you have a relative pathname such as
@code{#p"foo/bar.html"} that you want to combine with an absolute
pathname such as @code{#p"/www/html/"} to get
@code{#p"/www/html/foo/bar.html"}. In that case, @code{MAKE-PATHNAME}
won't do; instead, you want @code{MERGE-PATHNAMES}.

@code{MERGE-PATHNAMES} takes two pathnames and merges them, filling in
any @code{NIL} components in the first pathname with the corresponding
value from the second pathname, much like @code{MAKE-PATHNAME} fills in
any unspecified components with components from the @code{:defaults}
argument. However, @code{MERGE-PATHNAMES} treats the directory component
specially: if the first pathname's directory is relative, the directory
component of the resulting pathname will be the first pathname's
directory relative to the second pathname's directory. Thus:

@verbatim
(merge-pathnames #p"foo/bar.html" #p"/www/html/") ==> #p"/www/html/foo/bar.html"
@end verbatim

The second pathname can also be relative, in which case the resulting
pathname will also be relative.

@verbatim
(merge-pathnames #p"foo/bar.html" #p"html/") ==> #p"html/foo/bar.html"
@end verbatim

To reverse this process and obtain a filename relative to a particular
root directory, you can use the handy function @code{ENOUGH-NAMESTRING}.

@verbatim
(enough-namestring #p"/www/html/foo/bar.html" #p"/www/") ==> "html/foo/bar.html"
@end verbatim

You can then combine @code{ENOUGH-NAMESTRING} with
@code{MERGE-PATHNAMES} to create a pathname representing the same name
but in a different root.

@verbatim
(merge-pathnames
  (enough-namestring #p"/www/html/foo/bar/baz.html" #p"/www/")
  #p"/www-backups/") ==> #p"/www-backups/html/foo/bar/baz.html"
@end verbatim

@code{MERGE-PATHNAMES} is also used internally by the standard functions
that actually access files in the file system to fill in incomplete
pathnames. For instance, suppose you make a pathname with just a name
and a type.

@verbatim
(make-pathname :name "foo" :type "txt") ==> #p"foo.txt"
@end verbatim

If you try to use this pathname as an argument to @code{OPEN}, the
missing components, such as the directory, must be filled in before Lisp
will be able to translate the pathname to an actual filename. Common
Lisp will obtain values for the missing components by merging the given
pathname with the value of the variable
@code{*DEFAULT-PATHNAME-DEFAULTS*}. The initial value of this variable
is determined by the implementation but is usually a pathname with a
directory component representing the directory where Lisp was started
and appropriate values for the host and device components, if needed. If
invoked with just one argument, @code{MERGE-PATHNAMES} will merge the
argument with the value of @code{*DEFAULT-PATHNAME-DEFAULTS*}. For
instance, if @code{*DEFAULT-PATHNAME-DEFAULTS*} is
@code{#p"/home/peter/"}, then you'd get the following:

@verbatim
(merge-pathnames #p"foo.txt") ==> #p"/home/peter/foo.txt"
@end verbatim

@node Two Representations of Directory Names
@section Two Representations of Directory Names
@anchor{#two-representations-of-directory-names}
When dealing with pathnames that name directories, you need to be aware
of one wrinkle. Pathnames separate the directory and name components,
but Unix and Windows consider directories just another kind of file.
Thus, on those systems, every directory has two different pathname
representations.

One representation, which I'll call @emph{file form}, treats a directory
like any other file and puts the last element of the namestring into the
name and type components. The other representation, @emph{directory
form}, places all the elements of the name in the directory component,
leaving the name and type components @code{NIL}. If @code{/foo/bar/} is
a directory, then both of the following pathnames name it.

@verbatim
(make-pathname :directory '(:absolute "foo") :name "bar") ; file form
(make-pathname :directory '(:absolute "foo" "bar"))       ; directory form
@end verbatim

When you create pathnames with @code{MAKE-PATHNAME}, you can control
which form you get, but you need to be careful when dealing with
namestrings. All current implementations create file form pathnames
unless the namestring ends with a path separator. But you can't rely on
user-supplied namestrings necessarily being in one form or another. For
instance, suppose you've prompted the user for a directory to save a
file in and they entered @code{"/home/peter"}. If you pass that value as
the @code{:defaults} argument of @code{MAKE-PATHNAME} like this:

@verbatim
(make-pathname :name "foo" :type "txt" :defaults user-supplied-name)
@end verbatim

you'll end up saving the file in @code{/home/foo.txt} rather than the
intended @code{/home/peter/foo.txt} because the @code{"peter"} in the
namestring will be placed in the name component when
@code{user-supplied-name} is converted to a pathname. In the pathname
portability library I'll discuss in the next chapter, you'll write a
function called @code{pathname-as-directory} that converts a pathname to
directory form. With that function you can reliably save the file in the
directory indicated by the user.

@verbatim
(make-pathname
  :name "foo" :type "txt" :defaults (pathname-as-directory user-supplied-name))
@end verbatim

@node Interacting with the File System
@section Interacting with the File System
@anchor{#interacting-with-the-file-system}
While the most common interaction with the file system is probably
@code{OPEN}ing files for reading and writing, you'll also occasionally
want to test whether a file exists, list the contents of a directory,
delete and rename files, create directories, and get information about a
file such as who owns it, when it was last modified, and its length.
This is where the generality of the pathname abstraction begins to cause
a bit of pain: because the language standard doesn't specify how
functions that interact with the file system map to any specific file
system, implementers are left with a fair bit of leeway.

That said, most of the functions that interact with the file system are
still pretty straightforward. I'll discuss the standard functions here
and point out the ones that suffer from nonportability between
implementations. In the next chapter you'll develop a pathname
portability library to smooth over some of those nonportability issues.

To test whether a file exists in the file system corresponding to a
pathname designator--a pathname, namestring, or file stream--you can use
the function @code{PROBE-FILE}. If the file named by the pathname
designator exists, @code{PROBE-FILE} returns the file's @emph{truename},
a pathname with any file system-level translations such as resolving
symbolic links performed. Otherwise, it returns @code{NIL}. However, not
all implementations support using this function to test whether a
directory exists. Also, Common Lisp doesn't provide a portable way to
test whether a given file that exists is a regular file or a directory.
In the next chapter you'll wrap @code{PROBE-FILE} with a new function,
@code{file-exists-p}, that can both test whether a directory exists and
tell you whether a given name is the name of a file or directory.

Similarly, the standard function for listing files in the file system,
@code{DIRECTORY}, works fine for simple cases, but the differences
between implementations make it tricky to use portably. In the next
chapter you'll define a @code{list-directory} function that smoothes
over some of these differences.

@code{DELETE-FILE} and @code{RENAME-FILE} do what their names suggest.
@code{DELETE-FILE} takes a pathname designator and deletes the named
file, returning true if it succeeds. Otherwise it signals a
@code{FILE-ERROR}.@footnote{See Chapter 19 for more on handling
errors.}

@code{RENAME-FILE} takes two pathname designators and renames the file
named by the first name to the second name.

You can create directories with the function
@code{ENSURE-DIRECTORIES-EXIST}. It takes a pathname designator and
ensures that all the elements of the directory component exist and are
directories, creating them as necessary. It returns the pathname it was
passed, which makes it convenient to use inline.

@verbatim
(with-open-file (out (ensure-directories-exist name) :direction :output)
   ...
   )
@end verbatim

Note that if you pass @code{ENSURE-DIRECTORIES-EXIST} a directory name,
it should be in directory form, or the leaf directory won't be created.

The functions @code{FILE-WRITE-DATE} and @code{FILE-AUTHOR} both take
a pathname designator. @code{FILE-WRITE-DATE} returns the time in
number of seconds since midnight January 1, 1900, Greenwich mean time
(GMT), that the file was last written, and @code{FILE-AUTHOR} returns,
on Unix and Windows, the file owner.@footnote{For applications that
need access to other file attributes on a particular operating system
or file system, libraries provide bindings to underlying C system
calls. The Osicat library at
@code{http://common-lisp.net/project/osicat/} provides a simple API
built using the Universal Foreign Function Interface (UFFI), which
should run on most Common Lisps that run on a POSIX operating system.}

To find the length of a file, you can use the function
@code{FILE-LENGTH}. For historical reasons @code{FILE-LENGTH} takes a
stream as an argument rather than a pathname. In theory this allows
@code{FILE-LENGTH} to return the length in terms of the element type
of the stream. However, since on most present-day operating systems,
the only information available about the length of a file, short of
actually reading the whole file to measure it, is its length in bytes,
that's what most implementations return, even when @code{FILE-LENGTH}
is passed a character stream. However, the standard doesn't require
this behavior, so for predictable results, the best way to get the
length of a file is to use a binary stream.@footnote{The number of
bytes and characters in a file can differ even if you're not using a
multibyte character encoding. Because character streams also translate
platform-specific line endings to a single @code{#\Newline} character,
on Windows (which uses CRLF as its line ending) the number of
characters will typically be smaller than the number of bytes. If you
really have to know the number of characters in a file, you have to
bite the bullet and write something like this:

@verbatim
(with-open-file (in filename)
  (loop while (read-char in nil) count t))
@end verbatim

or maybe something more efficient like this:

@verbatim
(with-open-file (in filename)
  (let ((scratch (make-string 4096)))
    (loop for read = (read-sequence scratch in)
          while (plusp read) sum read)))
@end verbatim
}

@verbatim
(with-open-file (in filename :element-type '(unsigned-byte 8))
  (file-length in))
@end verbatim

A related function that also takes an open file stream as its argument
is @code{FILE-POSITION}. When called with just a stream, this function
returns the current position in the file--the number of elements that
have been read from or written to the stream. When called with two
arguments, the stream and a position designator, it sets the position of
the stream to the designated position. The position designator must be
the keyword @code{:start}, the keyword @code{:end}, or a non-negative
integer. The two keywords set the position of the stream to the start or
end of the file while an integer moves to the indicated position in the
file. With a binary stream the position is simply a byte offset into the
file. However, for character streams things are a bit more complicated
because of character-encoding issues. Your best bet, if you need to jump
around within a file of textual data, is to only ever pass, as a second
argument to the two-argument version of @code{FILE-POSITION}, a value
previously returned by the one-argument version of @code{FILE-POSITION}
with the same stream argument.

@node Other Kinds of I/O
@section Other Kinds of I/O
@anchor{#other-kinds-of-io}
In addition to file streams, Common Lisp supports other kinds of
streams, which can also be used with the various reading, writing, and
printing I/O functions. For instance, you can read data from, or write
data to, a string using @code{STRING-STREAM}s, which you can create with
the functions @code{MAKE-STRING-INPUT-STREAM} and
@code{MAKE-STRING-OUTPUT-STREAM}.

@code{MAKE-STRING-INPUT-STREAM} takes a string and optional start and
end indices to bound the area of the string from which data should be
read and returns a character stream that you can pass to any of the
character-based input functions such as @code{READ-CHAR},
@code{READ-LINE}, or @code{READ}. For example, if you have a string
containing a floating-point literal in Common Lisp's syntax, you can
convert it to a float like this:

@verbatim
(let ((s (make-string-input-stream "1.23")))
  (unwind-protect (read s)
    (close s)))
@end verbatim

Similarly, @code{MAKE-STRING-OUTPUT-STREAM} creates a stream you can use
with @code{FORMAT}, @code{PRINT}, @code{WRITE-CHAR}, @code{WRITE-LINE},
and so on. It takes no arguments. Whatever you write, a string output
stream will be accumulated into a string that can then be obtained with
the function @code{GET-OUTPUT-STREAM-STRING}. Each time you call
@code{GET-OUTPUT-STREAM-STRING}, the stream's internal string is cleared
so you can reuse an existing string output stream.

However, you'll rarely use these functions directly, because the macros
@code{WITH-INPUT-FROM-STRING} and @code{WITH-OUTPUT-TO-STRING} provide a
more convenient interface. @code{WITH-INPUT-FROM-STRING} is similar to
@code{WITH-OPEN-FILE}--it creates a string input stream from a given
string and then executes the forms in its body with the stream bound to
the variable you provide. For instance, instead of the @code{LET} form
with the explicit @code{UNWIND-PROTECT}, you'd probably write this:

@verbatim
(with-input-from-string (s "1.23")
  (read s))
@end verbatim

The @code{WITH-OUTPUT-TO-STRING} macro is similar: it binds a newly
created string output stream to a variable you name and then executes
its body. After all the body forms have been executed,
@code{WITH-OUTPUT-TO-STRING} returns the value that would be returned by
@code{GET-OUTPUT-STREAM-STRING}.

@verbatim
CL-USER> (with-output-to-string (out)
            (format out "hello, world ")
            (format out "~s" (list 1 2 3)))
"hello, world (1 2 3)"
@end verbatim

The other kinds of streams defined in the language standard provide
various kinds of stream "plumbing," allowing you to plug together
streams in almost any configuration. A @code{BROADCAST-STREAM} is an
output stream that sends any data written to it to a set of output
streams provided as arguments to its constructor function,
@code{MAKE-BROADCAST-STREAM}.@footnote{@code{MAKE-BROADCAST-STREAM}
can make a data black hole by calling it with no arguments.}
Conversely, a @code{CONCATENATED-STREAM} is an input stream that takes
its input from a set of input streams, moving from stream to stream as
it hits the end of each stream. @code{CONCATENATED-STREAM}s are
constructed with the function @code{MAKE-CONCATENATED-STREAM}, which
takes any number of input streams as arguments.

Two kinds of bidirectional streams that can plug together streams in a
couple ways are @code{TWO-WAY-STREAM} and @code{ECHO-STREAM}. Their
constructor functions, @code{MAKE-TWO-WAY-STREAM} and
@code{MAKE-ECHO-STREAM}, both take two arguments, an input stream and an
output stream, and return a stream of the appropriate type, which you
can use with both input and output functions.

In a @code{TWO-WAY-STREAM} every read you perform will return data read
from the underlying input stream, and every write will send data to the
underlying output stream. An @code{ECHO-STREAM} works essentially the
same way except that all the data read from the underlying input stream
is also echoed to the output stream. Thus, the output stream of an
@code{ECHO-STREAM} stream will contain a transcript of both sides of the
conversation.

Using these five kinds of streams, you can build almost any topology of
stream plumbing you want.

Finally, although the Common Lisp standard doesn't say anything about
networking APIs, most implementations support socket programming and
typically implement sockets as another kind of stream, so you can use
all the regular I/O functions with them.@footnote{The biggest missing
piece in Common Lisp's standard I/O facilities is a way for users to
define new stream classes. There are, however, two de facto standards
for user-defined streams. During the Common Lisp standardization,
David Gray of Texas Instruments wrote a draft proposal for an API to
allow users to define new stream classes.  Unfortunately, there wasn't
time to work out all the issues raised by his draft to include it in
the language standard. However, many implementations support some form
of so-called Gray Streams, basing their API on Gray's draft
proposal. Another, newer API, called Simple Streams, has been
developed by Franz and included in Allegro Common Lisp. It was
designed to improve the performance of user-defined streams relative
to Gray Streams and has been adopted by some of the open-source Common
Lisp implementations.}

Now you're ready to move on to building a library that smoothes over
some of the differences between how the basic pathname functions behave
in different Common Lisp implementations.

@node Practical A Portable Pathname Library
@chapter Practical: A Portable Pathname Library
@anchor{#practical-a-portable-pathname-library}
As I discussed in the previous chapter, Common Lisp provides an
abstraction, the pathname, that's supposed to insulate you from the
details of how different operating systems and file systems name files.
Pathnames provide a useful API for manipulating names as names, but when
it comes to the functions that actually interact with the file system,
things get a bit hairy.

The root of the problem, as I mentioned, is that the pathname
abstraction was designed to represent filenames on a much wider variety
of file systems than are commonly used now. Unfortunately, by making
pathnames abstract enough to account for a wide variety of file systems,
Common Lisp's designers left implementers with a fair number of choices
to make about how exactly to map the pathname abstraction onto any
particular file system. Consequently, different implementers, each
implementing the pathname abstraction for the same file system, just by
making different choices at a few key junctions, could end up with
conforming implementations that nonetheless provide different behavior
for several of the main pathname-related functions.

However, one way or another, all implementations provide the same basic
functionality, so it's not too hard to write a library that provides a
consistent interface for the most common operations across different
implementations. That's your task for this chapter. In addition to
giving you several useful functions that you'll use in future chapters,
writing this library will give you a chance to learn how to write code
that deals with differences between implementations.
@menu
* The API::
* *FEATURES* and Read-Time Conditionalization::
* Listing a Directory::
* Testing a File's Existence::
* Walking a Directory Tree::
@end menu

@node The API
@section The API
@anchor{#the-api}
The basic operations the library will support will be getting a list of
files in a directory and determining whether a file or directory with a
given name exists. You'll also write a function for recursively walking
a directory hierarchy, calling a given function for each pathname in the
tree.

In theory, these directory listing and file existence operations are
already provided by the standard functions @code{DIRECTORY} and
@code{PROBE-FILE}. However, as you'll see, there are enough different
ways to implement these functions--all within the bounds of valid
interpretations of the language standard--that you'll want to write new
functions that provide a consistent behavior across implementations.

@node *FEATURES* and Read-Time Conditionalization
@section *FEATURES* and Read-Time Conditionalization
@anchor{#features-and-read-time-conditionalization}
Before you can implement this API in a library that will run correctly
on multiple Common Lisp implementations, I need to show you the
mechanism for writing implementation-specific code.

While most of the code you write can be "portable" in the sense that it
will run the same on any conforming Common Lisp implementation, you may
occasionally need to rely on implementation-specific functionality or to
write slightly different bits of code for different implementations. To
allow you to do so without totally destroying the portability of your
code, Common Lisp provides a mechanism, called @emph{read-time
conditionalization}, that allows you to conditionally include code based
on various features such as what implementation it's being run in.

The mechanism consists of a variable @code{*FEATURES*} and two extra
bits of syntax understood by the Lisp reader. @code{*FEATURES*} is a
list of symbols; each symbol represents a "feature" that's present in
the implementation or on the underlying platform. These symbols are then
used in @emph{feature expressions} that evaluate to true or false
depending on whether the symbols in the expression are present in
@code{*FEATURES*}. The simplest feature expression is a single symbol;
the expression is true if the symbol is in @code{*FEATURES*} and false
if it isn't. Other feature expressions are boolean expressions built out
of @code{NOT}, @code{AND}, and @code{OR} operators. For instance, if you
wanted to conditionalize some code to be included only if the features
@code{foo} and @code{bar} were present, you could write the feature
expression @code{(and foo bar)}.

The reader uses feature expressions in conjunction with two bits of
syntax, @code{#+} and @code{#-}. When the reader sees either of these
bits of syntax, it first reads a feature expression and then evaluates
it as I just described. When a feature expression following a @code{#+}
is true, the reader reads the next expression normally. Otherwise it
skips the next expression, treating it as whitespace. @code{#-} works
the same way except it reads the form if the feature expression is false
and skips it if it's true.

The initial value of @code{*FEATURES*} is implementation dependent, and
what functionality is implied by the presence of any given symbol is
likewise defined by the implementation. However, all implementations
include at least one symbol that indicates what implementation it is.
For instance, Allegro Common Lisp includes the symbol @code{:allegro},
CLISP includes @code{:clisp}, SBCL includes @code{:sbcl}, and CMUCL
includes @code{:cmu}. To avoid dependencies on packages that may or may
not exist in different implementations, the symbols in @code{*FEATURES*}
are usually keywords, and the reader binds @code{*PACKAGE*} to the
@code{KEYWORD} package while reading feature expressions. Thus, a name
with no package qualification will be read as a keyword symbol. So, you
could write a function that behaves slightly differently in each of the
implementations just mentioned like this:

@verbatim
(defun foo ()
  #+allegro (do-one-thing)
  #+sbcl (do-another-thing)
  #+clisp (something-else)
  #+cmu (yet-another-version)
  #-(or allegro sbcl clisp cmu) (error "Not implemented"))
@end verbatim

In Allegro that code will be read as if it had been written like this:

@verbatim
(defun foo ()
  (do-one-thing))
@end verbatim

while in SBCL the reader will read this:

@verbatim
(defun foo ()
  (do-another-thing))
@end verbatim

while in an implementation other than one of the ones specifically
conditionalized, it will read this:

@verbatim
(defun foo ()
  (error "Not implemented"))
@end verbatim

Because the conditionalization happens in the reader, the compiler
doesn't even see expressions that are skipped.@footnote{One slightly
annoying consequence of the way read-time conditionalization works is
that there's no easy way to write a fall-through case. For example, if
you add support for another implementation to @code{foo} by adding
another expression guarded with @code{#+}, you need to remember to
also add the same feature to the @code{or} feature expression after
the @code{#-} or the @code{ERROR} form will be evaluated after your
new code runs.} This means you pay no runtime cost for having
different versions for different implementations. Also, when the
reader skips conditionalized expressions, it doesn't bother interning
symbols, so the skipped expressions can safely contain symbols from
packages that may not exist in other implementations.

Packaging the Library
Speaking of packages, if you download the complete code for this
library, you'll see that it's defined in a new package,
@code{com.gigamonkeys.pathnames}. I'll discuss the details of defining
and using packages in Chapter 21. For now you should note that some
implementations provide their own packages that contain functions with
some of the same names as the ones you'll define in this chapter and
make those names available in the CL-USER package. Thus, if you try to
define the functions from this library while in the CL-USER package, you
may get errors or warnings about clobbering existing definitions. To
avoid this possibility, you can create a file called
@code{packages.lisp} with the following contents:

@verbatim
(in-package :cl-user)
@end verbatim

@verbatim
(defpackage :com.gigamonkeys.pathnames
  (:use :common-lisp)
  (:export
   :list-directory
   :file-exists-p
   :directory-pathname-p
   :file-pathname-p
   :pathname-as-directory
   :pathname-as-file
   :walk-directory
   :directory-p
   :file-p))
@end verbatim

and @code{LOAD} it. Then at the REPL or at the top of the file where you
type the definitions from this chapter, type the following expression:

@verbatim
(in-package :com.gigamonkeys.pathnames)
@end verbatim

In addition to avoiding name conflicts with symbols already available in
@code{CL-USER}, packaging the library this way also makes it easier to
use in other code, as you'll see in several future chapters.

@node Listing a Directory
@section Listing a Directory
@anchor{#listing-a-directory} You can implement the function for
listing a single directory, @code{list-directory}, as a thin wrapper
around the standard function @code{DIRECTORY}. @code{DIRECTORY} takes
a special kind of pathname, called a @emph{wild pathname}, that has
one or more components containing the special value @code{:wild} and
returns a list of pathnames representing files in the file system that
match the wild pathname.@footnote{Another special value,
@code{:wild-inferiors}, can appear as part of the directory component
of a wild pathname, but you won't need it in this chapter.} The
matching algorithm--like most things having to do with the interaction
between Lisp and a particular file system--isn't defined by the
language standard, but most implementations on Unix and Windows follow
the same basic scheme.

The @code{DIRECTORY} function has two problems that you need to address
with @code{list-directory}. The main one is that certain aspects of its
behavior differ fairly significantly between different Common Lisp
implementations, even on the same operating system. The other is that
while @code{DIRECTORY} provides a powerful interface for listing files,
to use it properly requires understanding some rather subtle points
about the pathname abstraction. Between these subtleties and the
idiosyncrasies of different implementations, actually writing portable
code that uses @code{DIRECTORY} to do something as simple as listing all
the files and subdirectories in a single directory can be a frustrating
experience. You can deal with those subtleties and idiosyncrasies once
and for all, by writing @code{list-directory}, and forget them
thereafter.

One subtlety I discussed in Chapter 14 is the two ways to represent the
name of a directory as a pathname: directory form and file form.

To get @code{DIRECTORY} to return a list of files in
@code{/home/peter/}, you need to pass it a wild pathname whose directory
component is the directory you want to list and whose name and type
components are @code{:wild}. Thus, to get a listing of the files in
@code{/home/peter/}, it might seem you could write this:

@verbatim
(directory (make-pathname :name :wild :type :wild :defaults home-dir))
@end verbatim

where @code{home-dir} is a pathname representing @code{/home/peter/}.
This would work if @code{home-dir} were in directory form. But if it
were in file form--for example, if it had been created by parsing the
namestring @code{"/home/peter"}--then that same expression would list
all the files in @code{/home} since the name component @code{"peter"}
would be replaced with @code{:wild}.

To avoid having to worry about explicitly converting between
representations, you can define @code{list-directory} to accept a
nonwild pathname in either form, which it will then convert to the
appropriate wild pathname.

To help with this, you should define a few helper functions. One,
@code{component-present-p}, will test whether a given component of a
pathname is "present," meaning neither @code{NIL} nor the special
value @code{:unspecific}.@footnote{Implementations are allowed to
return @code{:unspecific} instead of @code{NIL} as the value of
pathname components in certain situations such as when the component
isn't used by that implementation.} Another,
@code{directory-pathname-p}, tests whether a pathname is already in
directory form, and the third, @code{pathname-as-directory}, converts
any pathname to a directory form pathname.

@verbatim
(defun component-present-p (value)
  (and value (not (eql value :unspecific))))

(defun directory-pathname-p  (p)
  (and
   (not (component-present-p (pathname-name p)))
   (not (component-present-p (pathname-type p)))
   p))

(defun pathname-as-directory (name)
  (let ((pathname (pathname name)))
    (when (wild-pathname-p pathname)
      (error "Can't reliably convert wild pathnames."))
    (if (not (directory-pathname-p name))
      (make-pathname
       :directory (append (or (pathname-directory pathname) (list :relative))
                          (list (file-namestring pathname)))
       :name      nil
       :type      nil
       :defaults pathname)
      pathname)))
@end verbatim

Now it seems you could generate a wild pathname to pass to
@code{DIRECTORY} by calling @code{MAKE-PATHNAME} with a directory form
name returned by @code{pathname-as-directory}. Unfortunately, it's not
quite that simple, thanks to a quirk in CLISP's implementation of
@code{DIRECTORY}. In CLISP, @code{DIRECTORY} won't return files with no
extension unless the type component of the wildcard is @code{NIL} rather
than @code{:wild}. So you can define a function,
@code{directory-wildcard}, that takes a pathname in either directory or
file form and returns a proper wildcard for the given implementation
using read-time conditionalization to make a pathname with a
@code{:wild} type component in all implementations except for CLISP and
@code{NIL} in CLISP.

@verbatim
(defun directory-wildcard (dirname)
  (make-pathname
   :name :wild
   :type #-clisp :wild #+clisp nil
   :defaults (pathname-as-directory dirname)))
@end verbatim

Note how each read-time conditional operates at the level of a single
expression After @code{#-clisp}, the expression @code{:wild} is either
read or skipped; likewise, after @code{#+clisp}, the @code{NIL} is read
or skipped.

Now you can take a first crack at the @code{list-directory} function.

@verbatim
(defun list-directory (dirname)
  (when (wild-pathname-p dirname)
    (error "Can only list concrete directory names."))
  (directory (directory-wildcard dirname)))
@end verbatim

As it stands, this function would work in SBCL, CMUCL, and LispWorks.
Unfortunately, a couple more implementation differences remain to be
smoothed over. One is that not all implementations will return
subdirectories of the given directory. Allegro, SBCL, CMUCL, and
LispWorks do. OpenMCL doesn't by default but will if you pass
@code{DIRECTORY} a true value via the implementation-specific keyword
argument @code{:directories}. CLISP's @code{DIRECTORY} returns
subdirectories only when it's passed a wildcard pathname with
@code{:wild} as the last element of the directory component and
@code{NIL} name and type components. In this case, it returns
@emph{only} subdirectories, so you'll need to call @code{DIRECTORY}
twice with different wildcards and combine the results.

Once you get all the implementations returning directories, you'll
discover they can also differ in whether they return the names of
directories in directory or file form. You want @code{list-directory} to
always return directory names in directory form so you can differentiate
subdirectories from regular files based on just the name. Except for
Allegro, all the implementations this library will support do that.
Allegro, on the other hand, requires you to pass @code{DIRECTORY} the
implementation-specific keyword argument @code{:directories-are-files}
@code{NIL} to get it to return directories in file form.

Once you know how to make each implementation do what you want, actually
writing @code{list-directory} is simply a matter of combining the
different versions using read-time conditionals.

@verbatim
(defun list-directory (dirname)
  (when (wild-pathname-p dirname)
    (error "Can only list concrete directory names."))
  (let ((wildcard (directory-wildcard dirname)))

    #+(or sbcl cmu lispworks)
    (directory wildcard)

    #+openmcl
    (directory wildcard :directories t)

    #+allegro
    (directory wildcard :directories-are-files nil)

    #+clisp
    (nconc
     (directory wildcard)
     (directory (clisp-subdirectories-wildcard wildcard)))

    #-(or sbcl cmu lispworks openmcl allegro clisp)
    (error "list-directory not implemented")))
@end verbatim

The function @code{clisp-subdirectories-wildcard} isn't actually
specific to CLISP, but since it isn't needed by any other
implementation, you can guard its definition with a read-time
conditional. In this case, since the expression following the @code{#+}
is the whole @code{DEFUN}, the whole function definition will be
included or not, depending on whether @code{clisp} is present in
@code{*FEATURES*}.

@verbatim
#+clisp
(defun clisp-subdirectories-wildcard (wildcard)
  (make-pathname
   :directory (append (pathname-directory wildcard) (list :wild))
   :name nil
   :type nil
   :defaults wildcard))
@end verbatim

@node Testing a File's Existence
@section Testing a File's Existence
@anchor{#testing-a-files-existence}
To replace @code{PROBE-FILE}, you can define a function called
@code{file-exists-p}. It should accept a pathname and return an
equivalent pathname if the file exists and @code{NIL} if it doesn't. It
should be able to accept the name of a directory in either directory or
file form but should always return a directory form pathname if the file
exists and is a directory. This will allow you to use
@code{file-exists-p}, along with @code{directory-pathname-p}, to test
whether an arbitrary name is the name of a file or directory.

In theory, @code{file-exists-p} is quite similar to the standard
function @code{PROBE-FILE}; indeed, in several implementations--SBCL,
LispWorks, and OpenMCL--@code{PROBE-FILE} already gives you the behavior
you want for @code{file-exists-p}. But not all implementations of
@code{PROBE-FILE} behave quite the same.

Allegro and CMUCL's @code{PROBE-FILE} functions are close to what you
need--they will accept the name of a directory in either form but,
instead of returning a directory form name, simply return the name in
the same form as the argument it was passed. Luckily, if passed the name
of a nondirectory in directory form, they return @code{NIL}. So with
those implementations you can get the behavior you want by first passing
the name to @code{PROBE-FILE} in directory form--if the file exists and
is a directory, it will return the directory form name. If that call
returns @code{NIL}, then you try again with a file form name.

CLISP, on the other hand, once again has its own way of doing things.
Its @code{PROBE-FILE} immediately signals an error if passed a name in
directory form, regardless of whether a file or directory exists with
that name. It also signals an error if passed a name in file form that's
actually the name of a directory. For testing whether a directory
exists, CLISP provides its own function: @code{probe-directory} (in the
@code{ext} package). This is almost the mirror image of
@code{PROBE-FILE}: it signals an error if passed a name in file form or
if passed a name in directory form that happens to name a file. The only
difference is it returns @code{T} rather than a pathname when the named
directory exists.

But even in CLISP you can implement the desired semantics by wrapping
the calls to @code{PROBE-FILE} and @code{probe-directory} in
@code{IGNORE-ERRORS}.@footnote{This is slightly broken in the sense
that if @code{PROBE-FILE} signals an error for some other reason, this
code will interpret it incorrectly. Unfortunately, the CLISP
documentation doesn't specify what errors might be signaled by
@code{PROBE-FILE} and @code{probe-directory}, and experimentation
seems to show that they signal @code{simple-file-error}s in most
erroneous situations.}

@verbatim
(defun file-exists-p (pathname)
  #+(or sbcl lispworks openmcl)
  (probe-file pathname)

  #+(or allegro cmu)
  (or (probe-file (pathname-as-directory pathname))
      (probe-file pathname))

  #+clisp
  (or (ignore-errors
        (probe-file (pathname-as-file pathname)))
      (ignore-errors
        (let ((directory-form (pathname-as-directory pathname)))
          (when (ext:probe-directory directory-form)
            directory-form))))

  #-(or sbcl cmu lispworks openmcl allegro clisp)
  (error "file-exists-p not implemented"))
@end verbatim

The function @code{pathname-as-file} that you need for the CLISP
implementation of @code{file-exists-p} is the inverse of the previously
defined @code{pathname-as-directory}, returning a pathname that's the
file form equivalent of its argument. This function, despite being
needed here only by CLISP, is generally useful, so define it for all
implementations and make it part of the library.

@verbatim
(defun pathname-as-file (name)
  (let ((pathname (pathname name)))
    (when (wild-pathname-p pathname)
      (error "Can't reliably convert wild pathnames."))
    (if (directory-pathname-p name)
      (let* ((directory (pathname-directory pathname))
             (name-and-type (pathname (first (last directory)))))
        (make-pathname
         :directory (butlast directory)
         :name (pathname-name name-and-type)
         :type (pathname-type name-and-type)
         :defaults pathname))
      pathname)))
@end verbatim

@node Walking a Directory Tree
@section Walking a Directory Tree
@anchor{#walking-a-directory-tree}
Finally, to round out this library, you can implement a function called
@code{walk-directory}. Unlike the functions defined previously, this
function doesn't need to do much of anything to smooth over
implementation differences; it just needs to use the functions you've
already defined. However, it's quite handy, and you'll use it several
times in subsequent chapters. It will take the name of a directory and a
function and call the function on the pathnames of all the files under
the directory, recursively. It will also take two keyword arguments:
@code{:directories} and @code{:test}. When @code{:directories} is true,
it will call the function on the pathnames of directories as well as
regular files. The @code{:test} argument, if provided, specifies another
function that's invoked on each pathname before the main function is;
the main function will be called only if the test function returns true.

@verbatim
(defun walk-directory (dirname fn &key directories (test (constantly t)))
  (labels
      ((walk (name)
         (cond
           ((directory-pathname-p name)
            (when (and directories (funcall test name))
              (funcall fn name))
            (dolist (x (list-directory name)) (walk x)))
           ((funcall test name) (funcall fn name)))))
    (walk (pathname-as-directory dirname))))
@end verbatim

Now you have a useful library of functions for dealing with pathnames.
As I mentioned, these functions will come in handy in later chapters,
particularly Chapters 23 and 27, where you'll use @code{walk-directory}
to crawl through directory trees containing spam messages and MP3 files.
But before we get to that, though, I need to talk about object
orientation, the topic of the next two chapters.

@node Object Reorientation Generic Functions
@chapter Object Reorientation: Generic Functions
@anchor{#object-reorientation-generic-functions} Because the invention
of Lisp predated the rise of object-oriented programming by a couple
decades,@footnote{The language now generally considered the first
object-oriented language, Simula, was invented in the early 1960s,
only a few years after McCarthy's first Lisp. However, object
orientation didn't really take off until the 1980s when the first
widely available version of Smalltalk was released, followed by the
release of C++ a few years later. Smalltalk took quite a bit of
inspiration from Lisp and combined it with ideas from Simula to
produce a dynamic object-oriented language, while C++ combined Simula
with C, another fairly static language, to yield a static
object-oriented language. This early split has led to much confusion
in the definition of object orientation. Folks who come from the C++
tradition tend to consider certain aspects of C++, such as strict data
encapsulation, to be key characteristics of object orientation. Folks
from the Smalltalk tradition, however, consider many features of C++
to be just that, features of C++, and not core to object
orientation. Indeed, Alan Kay, the inventor of Smalltalk, is reported
to have said, "I invented the term @emph{object oriented}, and I can
tell you that C++ wasn't what I had in mind."} new Lispers are
sometimes surprised to discover what a thoroughly object-oriented
language Common Lisp is. Common Lisp's immediate predecessors were
developed at a time when object orientation was an exciting new idea
and there were many experiments with ways to incorporate the ideas of
object orientation, especially as manifested in Smalltalk, into
Lisp. As part of the Common Lisp standardization, a synthesis of
several of these experiments emerged under the name Common Lisp Object
System, or CLOS.  The ANSI standard incorporated CLOS into the
language, so it no longer really makes sense to speak of CLOS as a
separate entity.

The features CLOS contributed to Common Lisp range from those that can
hardly be avoided to relatively esoteric manifestations of Lisp's
language-as-language-building-tool philosophy. Complete coverage of all
these features is beyond the scope of this book, but in this chapter and
the next I'll describe the bread-and-butter features and give an
overview of Common Lisp's approach to objects.

You should note at the outset that Common Lisp's object system offers
a fairly different embodiment of the principles of object orientation
than many other languages. If you have a deep understanding of the
fundamental ideas behind object orientation, you'll likely appreciate
the particularly powerful and general way Common Lisp manifests those
ideas. On the other hand, if your experience with object orientation
has been largely with a single language, you may find Common Lisp's
approach somewhat foreign; you should try to avoid assuming that
there's only one way for a language to support object
orientation.@footnote{There are those who reject the notion that
Common Lisp is in fact object oriented at all. In particular, folks
who consider strict data encapsulation a key characteristic of object
orientation--usually advocates of relatively static languages such as
C++, Eiffel, or Java--don't consider Common Lisp to be properly object
oriented. Of course, by that definition, Smalltalk, arguably one of
the original and purest object-oriented languages, isn't object
oriented either. On the other hand, folks who consider message passing
to be the key to object orientation will also not be happy with the
claim that Common Lisp is object oriented since Common Lisp's generic
function orientation provides degrees of freedom not offered by pure
message passing.} If you have little object-oriented programming
experience, you should have no trouble understanding the explanations
here, though it may help to ignore the occasional comparisons to the
way other languages do things.
@menu
* Generic Functions and Classes::
* Generic Functions and Methods::
* DEFGENERIC::
* DEFMETHOD::
* Method Combination::
* The Standard Method Combination::
* Other Method Combinations::
* Multimethods::
* To Be Continued   ::
@end menu

@node Generic Functions and Classes
@section Generic Functions and Classes
@anchor{#generic-functions-and-classes}
The fundamental idea of object orientation is that a powerful way to
organize a program is to define data types and then associate operations
with those data types. In particular, you want to be able to invoke an
operation and have the exact behavior determined by the type of the
object or objects on which the operation was invoked. The classic
example used, seemingly by all introductions to object orientation, is
an operation @code{draw} that can be applied to objects representing
various geometric shapes. Different implementations of the @code{draw}
operation can be provided for drawing circles, triangles, and squares,
and a call to @code{draw} will actually result in drawing a circle,
triangle, or square, depending on the type of the object to which the
@code{draw} operation is applied. The different implementations of
@code{draw} are defined separately, and new versions can be defined that
draw other shapes without having to change the code of either the caller
or any of the other @code{draw} implementations. This feature of object
orientation goes by the fancy Greek name @emph{polymorphism}, meaning
"many forms," because a single conceptual operation, such as drawing an
object, can take many different concrete forms.

Common Lisp, like most object-oriented languages today, is
class-based; all objects are @emph{instances} of a particular
class.@footnote{Prototype-based languages are the other style of
object-oriented language. In these languages, JavaScript being perhaps
the most famous example, objects are created by cloning a prototypical
object. The clone can then be modified and used as a prototype for
other objects.} The class of an object determines its
representation--built-in classes such as @code{NUMBER} and
@code{STRING} have opaque representations accessible only via the
standard functions for manipulating those types, while instances of
user-defined classes, as you'll see in the next chapter, consist of
named parts called @emph{slots}.

Classes are arranged in a hierarchy, a taxonomy for all objects. A
class can be defined as a @emph{subclass} of other classes, called its
@emph{superclasses}. A class @emph{inherits} part of its definition
from its superclasses and instances of a class are also considered
instances of the superclasses. In Common Lisp, the hierarchy of
classes has a single root, the class @code{T}, which is a direct or
indirect superclass of every other class. Thus, every datum in Common
Lisp is an instance of @code{T}.@footnote{@code{T} the constant value
and @code{T} the class have no particular relationship except they
happen to have the same name. @code{T} the value is a direct instance
of the class @code{SYMBOL} and only indirectly an instance of @code{T}
the class.} Common Lisp also supports @emph{multiple inheritance}--a
single class can have multiple direct superclasses.

Outside the Lisp family, almost all object-oriented languages follow the
basic pattern established by Simula of having behavior associated with
classes through @emph{methods} or @emph{member functions} that belong to
a particular class. In these languages, a method is invoked on a
particular object, and the class of that object determines what code
runs. This model of method invocation is called--after the Smalltalk
terminology--@emph{message passing}. Conceptually, method invocation in
a message-passing system starts by sending a @emph{message} containing
the name of the method to run and any arguments to the object on which
the method is being invoked. The object then uses its class to look up
the method associated with the name in the message and runs it. Because
each class can have its own method for a given name, the same message,
sent to different objects, can invoke different methods.

Early Lisp object systems worked in a similar way, providing a special
function @code{SEND} that could be used to send a message to a
particular object. However, this wasn't entirely satisfactory, as it
made method invocations different from normal function calls.
Syntactically method invocations were written like this:

@verbatim
(send object 'foo)
@end verbatim

rather than like this:

@verbatim
(foo object)
@end verbatim

More significantly, because methods weren't functions, they couldn't be
passed as arguments to higher-order functions such as @code{MAPCAR}; if
one wanted to call a method on all the elements of a list with
@code{MAPCAR}, one had to write this:

@verbatim
(mapcar #'(lambda (object) (send object 'foo)) objects)
@end verbatim

rather than this:

@verbatim
(mapcar #'foo objects)
@end verbatim

Eventually the folks working on Lisp object systems unified methods with
functions by creating a new kind of function called a @emph{generic
function}. In addition to solving the problems just described, generic
functions opened up new possibilities for the object system, including
many features that simply don't make sense in a message-passing object
system.

Generic functions are the heart of Common Lisp's object system and the
topic of the rest of this chapter. While I can't talk about generic
functions without some mention of classes, for now I'll focus on how to
define and use generic functions. In the next chapter I'll show you how
to define your own classes.

@node Generic Functions and Methods
@section Generic Functions and Methods
@anchor{#generic-functions-and-methods}
A generic function defines an abstract operation, specifying its name
and a parameter list but no implementation. Here, for example, is how
you might define a generic function, @code{draw}, that will be used to
draw different kinds of shapes on the screen:

@verbatim
(defgeneric draw (shape)
  (:documentation "Draw the given shape on the screen."))
@end verbatim

I'll discuss the syntax of @code{DEFGENERIC} in the next section; for
now just note that this definition doesn't contain any actual code.

A generic function is generic in the sense that it can--at least in
theory--accept any objects as arguments.@footnote{Here, as elsewhere,
@emph{object} means any Lisp datum--Common Lisp doesn't distinguish,
as some languages do, between objects and "primitive" data types; all
data in Common Lisp are objects, and every object is an instance of a
class.} However, by itself a generic function can't actually do
anything; if you just define a generic function, no matter what
arguments you call it with, it will signal an error. The actual
implementation of a generic function is provided by
@emph{methods}. Each method provides an implementation of the generic
function for particular classes of arguments. Perhaps the biggest
difference between a generic function-based system and a
message-passing system is that methods don't belong to classes; they
belong to the generic function, which is responsible for determining
what method or methods to run in response to a particular invocation.

Methods indicate what kinds of arguments they can handle by
@emph{specializing} the required parameters defined by the generic
function. For instance, on the generic function @code{draw}, you might
define one method that specializes the @code{shape} parameter for
objects that are instances of the class @code{circle} while another
method specializes @code{shape} for objects that are instances of the
class @code{triangle}. They would look like this, eliding the actual
drawing code:

@verbatim
(defmethod draw ((shape circle))
  ...)

(defmethod draw ((shape triangle))
  ...)
@end verbatim

When a generic function is invoked, it compares the actual arguments it
was passed with the specializers of each of its methods to find the
@emph{applicable} methods--those methods whose specializers are
compatible with the actual arguments. If you invoke @code{draw}, passing
an instance of @code{circle}, the method that specialized @code{shape}
on the class @code{circle} is applicable, while if you pass it a
@code{triangle}, then the method that specializes @code{shape} on the
class @code{triangle} applies. In simple cases, only one method will be
applicable, and it will handle the invocation. In more complex cases,
there may be multiple methods that apply; they're then combined, as I'll
discuss in the section "Method Combination," into a single
@emph{effective method} that handles the invocation.

You can specialize a parameter in two ways--usually you'll specify a
class that the argument must be an instance of. Because instances of a
class are also considered instances of that class's superclasses, a
method with a parameter specialized on a particular class can be
applicable whenever the corresponding argument is a direct instance of
the specializing class or of any of its subclasses. The other kind of
specializer is a so-called @code{EQL} specializer, which specifies a
particular object to which the method applies.

When a generic function has only methods specialized on a single
parameter and all the specializers are class specializers, the result of
invoking a generic function is quite similar to the result of invoking a
method in a message-passing system--the combination of the name of the
operation and the class of the object on which it's invoked determines
what method to run.

However, reversing the order of lookup opens up possibilities not found
in message-passing systems. Generic functions support methods that
specialize on multiple parameters, provide a framework that makes
multiple inheritance much more manageable, and let you use declarative
constructs to control how methods are combined into an effective method,
supporting several common usage patterns without a lot of boilerplate
code. I'll discuss those topics in a moment. But first you need to look
at the basics of the two macros used to define the generic functions
@code{DEFGENERIC} and @code{DEFMETHOD}.

@node DEFGENERIC
@section DEFGENERIC
@anchor{#defgeneric}
To give you a feel for these macros and the various facilities they
support, I'll show you some code you might write as part of a banking
application--or, rather, a toy banking application; the point is to look
at a few language features, not to learn how to really write banking
software. For instance, this code doesn't even pretend to deal with such
issues as multiple currencies let alone audit trails and transactional
integrity.

Because I'm not going to discuss how to define new classes until the
next chapter, for now you can just assume that certain classes already
exist: for starters, assume there's a class @code{bank-account} and that
it has two subclasses, @code{checking-account} and
@code{savings-account}. The class hierarchy looks like this:

@image{figures/account-hierarchy,,,,png}

The first generic function will be @code{withdraw}, which decreases the
account balance by a specified amount. If the balance is less than the
amount, it should signal an error and leave the balance unchanged. You
can start by defining the generic function with @code{DEFGENERIC}.

The basic form of @code{DEFGENERIC} is similar to @code{DEFUN} except
with no body. The parameter list of @code{DEFGENERIC} specifies the
parameters that must be accepted by all the methods that will be defined
on the generic function. In the place of the body, a @code{DEFGENERIC}
can contain various options. One option you should always include is
@code{:documentation}, which you use to provide a string describing the
purpose of the generic function. Because a generic function is purely
abstract, it's important to be clear to both users and implementers what
it's for. Thus, you might define @code{withdraw} like this:

@verbatim
(defgeneric withdraw (account amount)
  (:documentation "Withdraw the specified amount from the account.
Signal an error if the current balance is less than amount."))
@end verbatim

@node DEFMETHOD
@section DEFMETHOD
@anchor{#defmethod} Now you're ready to use @code{DEFMETHOD} to define
methods that implement @code{withdraw}.@footnote{Technically you could
skip the @code{DEFGENERIC} altogether--if you define a method with
@code{DEFMETHOD} and no such generic function has been defined, one is
automatically created. But it's good form to define generic functions
explicitly, if only because it gives you a good place to document the
intended behavior.}

A method's parameter list must be @emph{congruent} with its generic
function's. In this case, that means all methods defined on
@code{withdraw} must have exactly two required parameters. More
generally, methods must have the same number of required and optional
parameters and must be capable of accepting any arguments
corresponding to any @code{&rest} or @code{&key} parameters specified
by the generic function.@footnote{A method can "accept" @code{&key}
and @code{&rest} arguments defined in its generic function by having a
@code{&rest} parameter, by having the same @code{&key} parameters, or
by specifying @code{&allow-other-keys} along with @code{&key}. A
method can also specify @code{&key} parameters not found in the
generic function's parameter list--when the generic function is
called, any @code{&key} parameter specified by the generic function or
any applicable method will be accepted.}

Since the basics of withdrawing are the same for all accounts, you can
define a method that specializes the @code{account} parameter on the
@code{bank-account} class. You can assume the function @code{balance}
returns the current balance of the account and can be used with
@code{SETF}--and thus with @code{DECF}--to set the balance. The function
@code{ERROR} is a standard function used to signal an error, which I'll
discuss in greater detail in Chapter 19. Using those two functions, you
can define a basic @code{withdraw} method that looks like this:

@verbatim
(defmethod withdraw ((account bank-account) amount)
  (when (< (balance account) amount)
    (error "Account overdrawn."))
  (decf (balance account) amount))
@end verbatim

As this code suggests, the form of @code{DEFMETHOD} is even more like
that of @code{DEFUN} than @code{DEFGENERIC}'s is. The only difference is
that the required parameters can be specialized by replacing the
parameter name with a two-element list. The first element is the name of
the parameter, and the second element is the specializer, either the
name of a class or an @code{EQL} specializer, the form of which I'll
discuss in a moment. The parameter name can be anything--it doesn't have
to match the name used in the generic function, though it often will.

This method will apply whenever the first argument to @code{withdraw} is
an instance of @code{bank-account}. The second parameter, @code{amount},
is implicitly specialized on @code{T}, and since all objects are
instances of @code{T}, it doesn't affect the applicability of the
method.

Now suppose all checking accounts have overdraft protection. That is,
each checking account is linked to another bank account that's drawn
upon when the balance of the checking account itself can't cover a
withdrawal. You can assume that the function @code{overdraft-account}
takes a @code{checking-account} object and returns a @code{bank-account}
object representing the linked account.

Thus, withdrawing from a @code{checking-account} object requires a few
extra steps compared to withdrawing from a standard @code{bank-account}
object. You must first check whether the amount being withdrawn is
greater than the account's current balance and, if it is, transfer the
difference from the overdraft account. Then you can proceed as with a
standard @code{bank-account} object.

So what you'd like to do is define a method on @code{withdraw} that
specializes on @code{checking-account} to handle the transfer and then
lets the method specialized on @code{bank-account} take control. Such a
method might look like this:

@verbatim
(defmethod withdraw ((account checking-account) amount)
  (let ((overdraft (- amount (balance account))))
    (when (plusp overdraft)
      (withdraw (overdraft-account account) overdraft)
      (incf (balance account) overdraft)))
  (call-next-method))
@end verbatim

The function @code{CALL-NEXT-METHOD} is part of the generic function
machinery used to combine applicable methods. It indicates that
control should be passed from this method to the method specialized on
@code{bank-account}.@footnote{@code{CALL-NEXT-METHOD} is roughly
analogous to invoking a method on @code{super} in Java or using an
explicitly class-qualified method or function name in Python or C++.}
When it's called with no arguments, as it is here, the next method is
invoked with whatever arguments were originally passed to the generic
function. It can also be called with arguments, which will then be
passed onto the next method.

You aren't required to invoke @code{CALL-NEXT-METHOD} in every method.
However, if you don't, the new method is then responsible for completely
implementing the desired behavior of the generic function. For example,
if you had a subclass of @code{bank-account}, @code{proxy-account}, that
didn't actually keep track of its own balance but instead delegated
withdrawals to another account, you might write a method like this
(assuming a function, @code{proxied-account}, that returns the proxied
account):

@verbatim
(defmethod withdraw ((proxy proxy-account) amount)
  (withdraw (proxied-account proxy) amount))
@end verbatim

Finally, @code{DEFMETHOD} also allows you to create methods specialized
on a particular object with an @code{EQL} specializer. For example,
suppose the banking app is going to be deployed in a particularly
corrupt bank. Suppose the variable @code{*account-of-bank-president*}
holds a reference to a particular bank account that belongs--as the name
suggests--to the bank's president. Further suppose the variable
@code{*bank*} represents the bank as a whole, and the function
@code{embezzle} steals money from the bank. The bank president might ask
you to "fix" @code{withdraw} to handle his account specially.

@verbatim
(defmethod withdraw ((account (eql *account-of-bank-president*)) amount)
  (let ((overdraft (- amount (balance account))))
    (when (plusp overdraft)
      (incf (balance account) (embezzle *bank* overdraft)))
  (call-next-method)))
@end verbatim

Note, however, that the form in the @code{EQL} specializer that provides
the object to specialize on--@code{*account-of-bank-president*} in this
case--is evaluated once, when the @code{DEFMETHOD} is evaluated. This
method will be specialized on the value of
@code{*account-of-bank-president*} at the time the method is defined;
changing the variable later won't change the method.

@node Method Combination
@section Method Combination
@anchor{#method-combination}
Outside the body of a method, @code{CALL-NEXT-METHOD} has no meaning.
Within a method, it's given a meaning by the generic function machinery
that builds an @emph{effective method} each time the generic function is
invoked using all the methods applicable to that particular invocation.
This notion of building an effective method by combining applicable
methods is the heart of the generic function concept and is the thing
that allows generic functions to support facilities not found in
message-passing systems. So it's worth taking a closer look at what's
really happening. Folks with the message-passing model deeply ingrained
in their consciousness should pay particular attention because generic
functions turn method dispatching inside out compared to message
passing, making the generic function, rather than the class, the prime
mover.

Conceptually, the effective method is built in three steps: First, the
generic function builds a list of applicable methods based on the
actual arguments it was passed. Second, the list of applicable methods
is sorted according to the @emph{specificity} of their parameter
specializers. Finally, methods are taken in order from the sorted list
and their code combined to produce the effective
method.@footnote{While building the effective method sounds
time-consuming, quite a bit of the effort in developing fast Common
Lisp implementations has gone into making it efficient. One strategy
is to cache the effective method so future calls with the same
argument types will be able to proceed directly.}

To find applicable methods, the generic function compares the actual
arguments with the corresponding parameter specializers in each of its
methods. A method is applicable if, and only if, all the specializers
are compatible with the corresponding arguments.

When the specializer is the name of a class, it's compatible if it names
the actual class of the argument or one of its superclasses. (Recall
that parameters without explicit specializers are implicitly specialized
on the class @code{T} so will be compatible with any argument.) An
@code{EQL} specializer is compatible only when the argument is the same
object as was specified in the specializer.

Because @emph{all} the arguments are checked against the corresponding
specializers, they all affect whether a method is applicable. Methods
that explicitly specialize more than one parameter are called
@emph{multimethods}; I'll discuss them in the section "Multimethods."

After the applicable methods have been found, the generic function
machinery needs to sort them before it can combine them into an
effective method. To order two applicable methods, the generic
function compares their parameter specializers from left to
right,@footnote{Actually, the order in which specializers are compared
is customizable via the @code{DEFGENERIC} option
@code{:argument-precedence-order}, though that option is rarely used.}
and the first specializer that's different between the two methods
determines their ordering, with the method with the more specific
specializer coming first.

Because only applicable methods are being sorted, you know all class
specializers will name classes that the corresponding argument is
actually an instance of. In the typical case, if two class specializers
differ, one will be a subclass of the other. In that case, the
specializer naming the subclass is considered more specific. This is why
the method that specialized @code{account} on @code{checking-account}
was considered more specific than the method that specialized it on
@code{bank-account}.

Multiple inheritance slightly complicates the notion of specificity
since the actual argument may be an instance of two classes, neither of
which is a subclass of the other. If such classes are used as parameter
specializers, the generic function can't order them using only the rule
that subclasses are more specific than their superclasses. In the next
chapter I'll discuss how the notion of specificity is extended to deal
with multiple inheritance. For now, suffice it to say that there's a
deterministic algorithm for ordering class specializers.

Finally, an @code{EQL} specializer is always more specific than any
class specializer, and because only applicable methods are being
considered, if more than one method has an @code{EQL} specializer for a
particular parameter, they must all have the same @code{EQL}
specializer. The comparison of those methods will thus be decided based
on other parameters.

@node The Standard Method Combination
@section The Standard Method Combination
@anchor{#the-standard-method-combination}
Now that you understand how the applicable methods are found and sorted,
you're ready to take a closer look at the last step--how the sorted list
of methods is combined into a single effective method. By default,
generic functions use what's called the @emph{standard method
combination}. The standard method combination combines methods so that
@code{CALL-NEXT-METHOD} works as you've already seen--the most specific
method runs first, and each method can pass control to the next most
specific method via @code{CALL-NEXT-METHOD}.

However, there's a bit more to it than that. The methods I've been
discussing so far are called @emph{primary methods}. Primary methods, as
their name suggests, are responsible for providing the primary
implementation of a generic function. The standard method combination
also supports three kinds of @emph{auxiliary} methods: @code{:before},
@code{:after}, and @code{:around} methods. An auxiliary method
definition is written with @code{DEFMETHOD} like a primary method but
with a @emph{method qualifier,} which names the type of method, between
the name of the method and the parameter list. For instance, a
@code{:before} method on @code{withdraw} that specializes the
@code{account} parameter on the class @code{bank-account} would start
like this:

@verbatim
(defmethod withdraw :before ((account bank-account) amount) ...)
@end verbatim

Each kind of auxiliary method is combined into the effective method in a
different way. All the applicable @code{:before} methods--not just the
most specific--are run as part of the effective method. They run, as
their name suggests, before the most specific primary method and are run
in most-specific-first order. Thus, @code{:before} methods can be used
to do any preparation needed to ensure that the primary method can run.
For instance, you could've used a @code{:before} method specialized on
@code{checking-account} to implement the overdraft protection on
checking accounts like this:

@verbatim
(defmethod withdraw :before ((account checking-account) amount)
  (let ((overdraft (- amount (balance account))))
    (when (plusp overdraft)
      (withdraw (overdraft-account account) overdraft)
      (incf (balance account) overdraft))))
@end verbatim

This @code{:before} method has three advantages over a primary method.
One is that it makes it immediately obvious how the method changes the
overall behavior of the @code{withdraw} function--it's not going to
interfere with the main behavior or change the result returned.

The next advantage is that a primary method specialized on a class more
specific than @code{checking-account} won't interfere with this
@code{:before} method, making it easier for an author of a subclass of
@code{checking-account} to extend the behavior of @code{withdraw} while
keeping part of the old behavior.

Lastly, since a @code{:before} method doesn't have to call
@code{CALL-NEXT-METHOD} to pass control to the remaining methods, it's
impossible to introduce a bug by forgetting to.

The other auxiliary methods also fit into the effective method in ways
suggested by their names. All the @code{:after} methods run after the
primary methods in most-specific-last order, that is, the reverse of the
@code{:before} methods. Thus, the @code{:before} and @code{:after}
methods combine to create a sort of nested wrapping around the core
functionality provided by the primary methods--each more-specific
@code{:before} method will get a chance to set things up so the
less-specific @code{:before} methods and primary methods can run
successfully, and each more-specific @code{:after} method will get a
chance to clean up after all the primary methods and less-specific
@code{:after} methods.

Finally, @code{:around} methods are combined much like primary methods
except they're run "around" all the other methods. That is, the code
from the most specific @code{:around} method is run before anything
else. Within the body of an @code{:around} method,
@code{CALL-NEXT-METHOD} will lead to the code of the next most specific
@code{:around} method or, in the least specific @code{:around} method,
to the complex of @code{:before}, primary, and @code{:after} methods.
Almost all @code{:around} methods will contain such a call to
@code{CALL-NEXT-METHOD} because an @code{:around} method that doesn't
will completely hijack the implementation of the generic function from
all the methods except for more-specific @code{:around} methods.

Occasionally that kind of hijacking is called for, but typically
@code{:around} methods are used to establish some dynamic context in
which the rest of the methods will run--to bind a dynamic variable, for
example, or to establish an error handler (as I'll discuss in Chapter
19). About the only time it's appropriate for an @code{:around} method
to not call @code{CALL-NEXT-METHOD} is when it returns a result cached
from a previous call to @code{CALL-NEXT-METHOD}. At any rate, an
@code{:around} method that doesn't call @code{CALL-NEXT-METHOD} is
responsible for correctly implementing the semantics of the generic
function for all classes of arguments to which the method may apply,
including future subclasses.

Auxiliary methods are just a convenient way to express certain common
patterns more concisely and concretely. They don't actually allow you to
do anything you couldn't do by combining primary methods with diligent
adherence to a few coding conventions and some extra typing. Perhaps
their biggest benefit is that they provide a uniform framework for
extending generic functions. Often a library will define a generic
function and provide a default primary method, allowing users of the
library to customize its behavior by defining appropriate auxiliary
methods.

@node Other Method Combinations
@section Other Method Combinations
@anchor{#other-method-combinations}
In addition to the standard method combination, the language specifies
nine other built-in method combinations known as the @emph{simple}
built-in method combinations. You can also define custom method
combinations, though that's a fairly esoteric feature and beyond the
scope of this book. I'll briefly cover how to use the simple built-in
combinations to give you a sense of the possibilities.

All the simple combinations follow the same pattern: instead of invoking
the most specific primary method and letting it invoke less-specific
primary methods via @code{CALL-NEXT-METHOD}, the simple method
combinations produce an effective method that contains the code of all
the primary methods, one after another, all wrapped in a call to the
function, macro, or special operator that gives the method combination
its name. The nine combinations are named for the operators: @code{+},
@code{AND}, @code{OR}, @code{LIST}, @code{APPEND}, @code{NCONC},
@code{MIN}, @code{MAX}, and @code{PROGN}. The simple combinations also
support only two kinds of methods, primary methods, which are combined
as just described, and @code{:around} methods, which work like
@code{:around} methods in the standard method combination.

For example, a generic function that uses the @code{+} method
combination will return the sum of all the results returned by its
primary methods. Note that the @code{AND} and @code{OR} method
combinations won't necessarily run all the primary methods because of
those macros' short-circuiting behavior--a generic function using the
@code{AND} combination will return @code{NIL} as soon as one of the
methods does and will return the value of the last method otherwise.
Similarly, the @code{OR} combination will return the first
non-@code{NIL} value returned by any of the methods.

To define a generic function that uses a particular method combination,
you include a @code{:method-combination} option in the @code{DEFGENERIC}
form. The value supplied with this option is the name of the method
combination you want to use. For example, to define a generic function,
@code{priority}, that returns the sum of values returned by individual
methods using the @code{+} method combination, you might write this:

@verbatim
(defgeneric priority (job)
  (:documentation "Return the priority at which the job should be run.")
  (:method-combination +))
@end verbatim

By default all these method combinations combine the primary methods in
most-specific-first order. However, you can reverse the order by
including the keyword @code{:most-specific-last} after the name of the
method combination in the @code{DEFGENERIC} form. The order probably
doesn't matter if you're using the @code{+} combination unless the
methods have side effects, but for demonstration purposes you can change
@code{priority} to use most-specific-last order like this:

@verbatim
(defgeneric priority (job)
  (:documentation "Return the priority at which the job should be run.")
  (:method-combination + :most-specific-last))
@end verbatim

The primary methods on a generic function that uses one of these
combinations must be qualified with the name of the method combination.
Thus, a primary method defined on @code{priority} might look like this:

@verbatim
(defmethod priority + ((job express-job)) 10)
@end verbatim

This makes it obvious when you see a method definition that it's part of
a particular kind of generic function.

All the simple built-in method combinations also support @code{:around}
methods that work like @code{:around} methods in the standard method
combination: the most specific @code{:around} method runs before any
other methods, and @code{CALL-NEXT-METHOD} is used to pass control to
less-and-less-specific @code{:around} methods until it reaches the
combined primary methods. The @code{:most-specific-last} option doesn't
affect the order of @code{:around} methods. And, as I mentioned before,
the built-in method combinations don't support @code{:before} or
@code{:after} methods.

Like the standard method combination, these method combinations don't
allow you to do anything you couldn't do "by hand." Rather, they allow
you to express @emph{what} you want and let the language take care of
wiring everything together for you, making your code both more concise
and more expressive.

That said, probably 99 percent of the time, the standard method
combination will be exactly what you want. Of the remaining 1 percent,
probably 99 percent of them will be handled by one of the simple
built-in method combinations. If you run into one of the 1 percent of 1
percent of cases where none of the built-in combinations suffices, you
can look up @code{DEFINE-METHOD-COMBINATION} in your favorite Common
Lisp reference.

@node Multimethods
@section Multimethods
@anchor{#multimethods}
Methods that explicitly specialize more than one of the generic
function's required parameters are called @emph{multimethods}.
Multimethods are where generic functions and message passing really part
ways. Multimethods don't fit into message-passing languages because they
don't belong to a particular class; instead, each multimethod defines a
part of the implementations of a given generic function that applies
when the generic function is invoked with arguments that match
@emph{all} the method's specialized parameters.

Multimethods vs. Method Overloading
Programmers used to statically typed message-passing languages such as
Java and C++ may think multimethods sound similar to a feature of those
languages called @emph{method overloading}. However, these two language
features are actually quite different since overloaded methods are
chosen at compile time, based on the compile-time type of the arguments,
not at runtime. To see how this works, consider the following two Java
classes:

@verbatim
public class A {
  public void foo(A a) { System.out.println("A/A"); }
  public void foo(B b) { System.out.println("A/B"); }
}
@end verbatim

@verbatim
public class B extends A {
  public void foo(A a) { System.out.println("B/A"); }
  public void foo(B b) { System.out.println("B/B"); }
}
@end verbatim

Now consider what happens when you run the @code{main} method from this
class.

@verbatim
public class Main {
  public static void main(String[] argv) {
    A obj = argv[0].equals("A") ? new A() : new B();
    obj.foo(obj);
  }
}
@end verbatim

When you tell @code{Main} to instantiate an @code{A}, it prints "A/A" as
you'd probably expect.

@verbatim
bash$ java com.gigamonkeys.Main A
A/A
@end verbatim

However, if you tell @code{Main} to instantiate a @code{B}, then the
true type of @code{obj} is taken into account for only half the
dispatching.

@verbatim
bash$ java com.gigamonkeys.Main B
B/A
@end verbatim

If overloaded methods worked like Common Lisp's multimethods, then that
would print "B/B" instead. It is possible to implement multiple dispatch
by hand in message-passing languages, but this runs against the grain of
the message-passing model since the code in a multiply dispatched method
doesn't belong to any one class.
Multimethods are perfect for all those situations where, in a
message-passing language, you struggle to decide to which class a
certain behavior ought to belong. Is the sound a drum makes when it's
hit with a drumstick a function of what kind of drum it is or what kind
of stick you use to hit it? Both, of course. To model this situation in
Common Lisp, you simply define a generic function @code{beat} that takes
two arguments.

@verbatim
(defgeneric beat (drum stick)
  (:documentation
   "Produce a sound by hitting the given drum with the given stick."))
@end verbatim

Then you can define various multimethods to implement @code{beat} for
the combinations you care about. For example:

@verbatim
(defmethod beat ((drum snare-drum) (stick wooden-drumstick)) ...)
(defmethod beat ((drum snare-drum) (stick brush)) ...)
(defmethod beat ((drum snare-drum) (stick soft-mallet)) ...)
(defmethod beat ((drum tom-tom) (stick wooden-drumstick)) ...)
(defmethod beat ((drum tom-tom) (stick brush)) ...)
(defmethod beat ((drum tom-tom) (stick soft-mallet)) ...)
@end verbatim

Multimethods don't help with the combinatorial explosion--if you need
to model five kinds of drums and six kinds of sticks, and every
combination makes a different sound, there's no way around it; you
need thirty different methods to implement all the combinations, with
or without multimethods. What multimethods do save you from is having
to write a bunch of dispatching code by letting you use the same
built-in polymorphic dispatching that's so useful when dealing with
methods specialized on a single parameter.@footnote{In languages
without multimethods, you must write dispatching code yourself to
implement behavior that depends on the class of more than one
object. The purpose of the popular Visitor design pattern is to
structure a series of singly dispatched method calls so as to provide
multiple dispatch. However, it requires one set of classes to know
about the other. The Visitor pattern also quickly bogs down in a
combinatorial explosion of dispatching methods if it's used to
dispatch on more than two objects.}

Multimethods also save you from having to tightly couple one set of
classes with the other. In the drum/stick example, nothing requires the
implementation of the drum classes to know about the various classes of
drumstick, and nothing requires the drumstick classes to know anything
about the various classes of drum. The multimethods connect the
otherwise independent classes to describe their joint behavior without
requiring any cooperation from the classes themselves.

@node To Be Continued
@section To Be Continued . . .
@anchor{#to-be-continued-.-.-.}
I've covered the basics--and a bit beyond--of generic functions, the
verbs of Common Lisp's object system. In the next chapter I'll show you
how to define your own classes.

@node Object Reorientation Classes
@chapter Object Reorientation: Classes
@anchor{#object-reorientation-classes}
If generic functions are the verbs of the object system, classes are the
nouns. As I mentioned in the previous chapter, all values in a Common
Lisp program are instances of some class. Furthermore, all classes are
organized into a single hierarchy rooted at the class @code{T}.

The class hierarchy consists of two major families of classes,
built-in and user-defined classes. Classes that represent the data
types you've been learning about up until now, classes such as
@code{INTEGER}, @code{STRING}, and @code{LIST}, are all built-in. They
live in their own section of the class hierarchy, arranged into
appropriate sub- and superclass relationships, and are manipulated by
the functions I've been discussing for much of the book up until
now. You can't subclass these classes, but, as you saw in the previous
chapter, you can define methods that specialize on them, effectively
extending the behavior of those classes.@footnote{Defining new methods
for an existing class may seem strange to folks used to statically
typed languages such as C++ and Java in which all the methods of a
class must be defined as part of the class definition. But programmers
with experience in dynamically typed object-oriented languages such as
Smalltalk and Objective C will find nothing strange about adding new
behaviors to existing classes.}

But when you want to create new nouns--for instance, the classes used in
the previous chapter for representing bank accounts--you need to define
your own classes. That's the subject of this chapter.
@menu
* DEFCLASS::
* Slot Specifiers::
* Object Initialization::
* Accessor Functions::
* WITH-SLOTS and WITH-ACCESSORS::
* Class-Allocated Slots::
* Slots and Inheritance::
* Multiple Inheritance::
* Good Object-Oriented Design::
@end menu

@node DEFCLASS
@section DEFCLASS
@anchor{#defclass}
You create user-defined classes with the @code{DEFCLASS} macro. Because
behaviors are associated with a class by defining generic functions and
methods specialized on the class, @code{DEFCLASS} is responsible only
for defining the class as a data type.

The three facets of the class as a data type are its name, its
relation to other classes, and the names of the slots that make up
instances of the class.@footnote{In other object-oriented languages,
slots might be called @emph{fields}, @emph{member variables}, or
@emph{attributes}.} The basic form of a @code{DEFCLASS} is quite
simple.

@verbatim
(defclass name (direct-superclass-name*)
  (slot-specifier*))
@end verbatim

What Are "User-Defined Classes"?  The term @emph{user-defined classes}
isn't a term from the language standard--technically what I'm talking
about when I say @emph{user-defined classes} are classes that subclass
@code{STANDARD-OBJECT} and whose metaclass is
@code{STANDARD-CLASS}. But since I'm not going to talk about the ways
you can define classes that don't subclass @code{STANDARD-OBJECT} and
whose metaclass isn't @code{STANDARD-CLASS}, you don't really have to
worry about that.  @emph{User-defined} isn't a perfect term for these
classes since the implementation may define certain classes the same
way. However, to call them @emph{standard} classes would be even more
confusing since the built-in classes, such as @code{INTEGER} and
@code{STRING}, are just as standard, if not more so, because they're
defined by the language standard but they don't extend
@code{STANDARD-OBJECT}. To further complicate matters, it's also
possible for users to define new classes that @emph{don't} subclass
@code{STANDARD-OBJECT}. In particular, the macro @code{DEFSTRUCT} also
defines new classes. But that's largely for backward
compatibility--@code{DEFSTRUCT} predated CLOS and was retrofitted to
define classes when CLOS was integrated into the language. But the
classes it creates are fairly limited compared to @code{DEFCLASS}ed
classes. So in this chapter I'll be discussing only classes defined
with @code{DEFCLASS} that use the default metaclass of
@code{STANDARD-CLASS}, and I'll refer to them as @emph{user-defined}
for lack of a better term.  As with functions and variables, you can
use any symbol as the name of a new class.@footnote{As when naming
functions and variables, it's not quite true that you can use
@emph{any} symbol as a class name--you can't use names defined by the
language standard. You'll see in Chapter 21 how to avoid such name
conflicts.} Class names are in a separate namespace from both
functions and variables, so you can have a class, function, and
variable all with the same name. You'll use the class name as the
argument to @code{MAKE-INSTANCE}, the function that creates new
instances of user-defined classes.

The @emph{direct-superclass-names} specify the classes of which the new
class is a subclass. If no superclasses are listed, the new class will
directly subclass @code{STANDARD-OBJECT}. Any classes listed must be
other user-defined classes, which ensures that each new class is
ultimately descended from @code{STANDARD-OBJECT}. @code{STANDARD-OBJECT}
in turn subclasses @code{T}, so all user-defined classes are part of the
single class hierarchy that also contains all the built-in classes.

Eliding the slot specifiers for a moment, the @code{DEFCLASS} forms of
some of the classes you used in the previous chapter might look like
this:

@verbatim
(defclass bank-account () ...)

(defclass checking-account (bank-account) ...)

(defclass savings-account (bank-account) ...)
@end verbatim

I'll discuss in the section "Multiple Inheritance" what it means to list
more than one direct superclass in @emph{direct-superclass-names}.

@node Slot Specifiers
@section Slot Specifiers
@anchor{#slot-specifiers}
The bulk of a @code{DEFCLASS} form consists of the list of slot
specifiers. Each slot specifier defines a slot that will be part of each
instance of the class. Each slot in an instance is a place that can hold
a value, which can be accessed using the @code{SLOT-VALUE} function.
@code{SLOT-VALUE} takes an object and the name of a slot as arguments
and returns the value of the named slot in the given object. It can be
used with @code{SETF} to set the value of a slot in an object.

A class also inherits slot specifiers from its superclasses, so the set
of slots actually present in any object is the union of all the slots
specified in a class's @code{DEFCLASS} form and those specified in all
its superclasses.

At the minimum, a slot specifier names the slot, in which case the slot
specifier can be just a name. For instance, you could define a
@code{bank-account} class with two slots, @code{customer-name} and
@code{balance}, like this:

@verbatim
(defclass bank-account ()
  (customer-name
   balance))
@end verbatim

Each instance of this class will contain two slots, one to hold the name
of the customer the account belongs to and another to hold the current
balance. With this definition, you can create new @code{bank-account}
objects using @code{MAKE-INSTANCE}.

@verbatim
(make-instance 'bank-account) ==> #<BANK-ACCOUNT @ #x724b93ba>
@end verbatim

The argument to @code{MAKE-INSTANCE} is the name of the class to
instantiate, and the value returned is the new object.@footnote{The
argument to @code{MAKE-INSTANCE} can actually be either the name of
the class or a class object returned by the function @code{CLASS-OF}
or @code{FIND-CLASS}.} The printed representation of an object is
determined by the generic function @code{PRINT-OBJECT}. In this case,
the applicable method will be one provided by the implementation,
specialized on @code{STANDARD-OBJECT}. Since not every object can be
printed so that it can be read back, the @code{STANDARD-OBJECT} print
method uses the @code{#<>} syntax, which will cause the reader to
signal an error if it tries to read it. The rest of the representation
is implementation-defined but will typically be something like the
output just shown, including the name of the class and some
distinguishing value such as the address of the object in memory. In
Chapter 23 you'll see an example of how to define a method on
@code{PRINT-OBJECT} to make objects of a certain class be printed in a
more informative form.

Using the definition of @code{bank-account} just given, new objects will
be created with their slots @emph{unbound}. Any attempt to get the value
of an unbound slot signals an error, so you must set a slot before you
can read it.

@verbatim
(defparameter *account* (make-instance 'bank-account))  ==> *ACCOUNT*
(setf (slot-value *account* 'customer-name) "John Doe") ==> "John Doe"
(setf (slot-value *account* 'balance) 1000)             ==> 1000
@end verbatim

Now you can access the value of the slots.

@verbatim
(slot-value *account* 'customer-name) ==> "John Doe"
(slot-value *account* 'balance)       ==> 1000
@end verbatim

@node Object Initialization
@section Object Initialization
@anchor{#object-initialization} Since you can't do much with an object
with unbound slots, it'd be nice to be able to create objects with
their slots already initialized.  Common Lisp provides three ways to
control the initial value of slots.  The first two involve adding
options to the slot specifier in the @code{DEFCLASS} form: with the
@code{:initarg} option, you can specify a name that can then be used
as a keyword parameter to @code{MAKE-INSTANCE} and whose argument will
be stored in the slot. A second option, @code{:initform}, lets you
specify a Lisp expression that will be used to compute a value for the
slot if no @code{:initarg} argument is passed to
@code{MAKE-INSTANCE}. Finally, for complete control over the
initialization, you can define a method on the generic function
@code{INITIALIZE-INSTANCE}, which is called by
@code{MAKE-INSTANCE}.@footnote{Another way to affect the values of
slots is with the @code{:default-initargs} option to
@code{DEFCLASS}. This option is used to specify forms that will be
evaluated to provide arguments for specific initialization parameters
that aren't given a value in a particular call to
@code{MAKE-INSTANCE}. You don't need to worry about
@code{:default-initargs} for now.}

A slot specifier that includes options such as @code{:initarg} or
@code{:initform} is written as a list starting with the name of the slot
followed by the options. For example, if you want to modify the
definition of @code{bank-account} to allow callers of
@code{MAKE-INSTANCE} to pass the customer name and the initial balance
and to provide a default value of zero dollars for the balance, you'd
write this:

@verbatim
(defclass bank-account ()
  ((customer-name
    :initarg :customer-name)
   (balance
    :initarg :balance
    :initform 0)))
@end verbatim

Now you can create an account and specify the slot values at the same
time.

@verbatim
(defparameter *account*
  (make-instance 'bank-account :customer-name "John Doe" :balance 1000))

(slot-value *account* 'customer-name) ==> "John Doe"
(slot-value *account* 'balance)       ==> 1000
@end verbatim

If you don't supply a @code{:balance} argument to @code{MAKE-INSTANCE},
the @code{SLOT-VALUE} of @code{balance} will be computed by evaluating
the form specified with the @code{:initform} option. But if you don't
supply a @code{:customer-name} argument, the @code{customer-name} slot
will be unbound, and an attempt to read it before you set it will signal
an error.

@verbatim
(slot-value (make-instance 'bank-account) 'balance)       ==> 0
(slot-value (make-instance 'bank-account) 'customer-name) ==> error
@end verbatim

If you want to ensure that the customer name is supplied when the
account is created, you can signal an error in the initform since it
will be evaluated only if an initarg isn't supplied. You can also use
initforms that generate a different value each time they're
evaluated--the initform is evaluated anew for each object. To experiment
with these techniques, you can modify the @code{customer-name} slot
specifier and add a new slot, @code{account-number}, that's initialized
with the value of an ever-increasing counter.

@verbatim
(defvar *account-numbers* 0)

(defclass bank-account ()
  ((customer-name
    :initarg :customer-name
    :initform (error "Must supply a customer name."))
   (balance
    :initarg :balance
    :initform 0)
   (account-number
    :initform (incf *account-numbers*))))
@end verbatim

Most of the time the combination of @code{:initarg} and @code{:initform}
options will be sufficient to properly initialize an object. However,
while an initform can be any Lisp expression, it has no access to the
object being initialized, so it can't initialize one slot based on the
value of another. For that you need to define a method on the generic
function @code{INITIALIZE-INSTANCE}.

The primary method on @code{INITIALIZE-INSTANCE} specialized on
@code{STANDARD-OBJECT} takes care of initializing slots based on their
@code{:initarg} and @code{:initform} options. Since you don't want to
disturb that, the most common way to add custom initialization code is
to define an @code{:after} method specialized on your
class.@footnote{Adding an @code{:after} method to
@code{INITIALIZE-INSTANCE} is the Common Lisp analog to defining a
constructor in Java or C++ or an @code{__init__} method in Python.}
For instance, suppose you want to add a slot @code{account-type} that
needs to be set to one of the values @code{:gold}, @code{:silver}, or
@code{:bronze} based on the account's initial balance. You might
change your class definition to this, adding the @code{account-type}
slot with no options:

@verbatim
(defclass bank-account ()
  ((customer-name
    :initarg :customer-name
    :initform (error "Must supply a customer name."))
   (balance
    :initarg :balance
    :initform 0)
   (account-number
    :initform (incf *account-numbers*))
   account-type))
@end verbatim

Then you can define an @code{:after} method on
@code{INITIALIZE-INSTANCE} that sets the @code{account-type} slot
based on the value that has been stored in the @code{balance}
slot.@footnote{One mistake you might make until you get used to using
auxiliary methods is to define a method on @code{INITIALIZE-INSTANCE}
but without the @code{:after} qualifier. If you do that, you'll get a
new primary method that shadows the default one. You can remove the
unwanted primary method using the functions @code{REMOVE-METHOD} and
@code{FIND-METHOD}. Certain development environments may provide a
graphical user interface to do the same thing.

@verbatim
(remove-method #'initialize-instance
  (find-method #'initialize-instance () (list (find-class 'bank-account))))
@end verbatim
}

@verbatim
(defmethod initialize-instance :after ((account bank-account) &key)
  (let ((balance (slot-value account 'balance))) (setf (slot-value
  account 'account-type) (cond ((>= balance 100000) :gold) ((>=
  balance 50000) :silver) (t :bronze)))))
@end verbatim

The @code{&key} in the parameter list is required to keep the method's
parameter list congruent with the generic function's--the parameter list
specified for the @code{INITIALIZE-INSTANCE} generic function includes
@code{&key} in order to allow individual methods to supply their own
keyword parameters but doesn't require any particular ones. Thus, every
method must specify @code{&key} even if it doesn't specify any
@code{&key} parameters.

On the other hand, if an @code{INITIALIZE-INSTANCE} method specialized
on a particular class does specify a @code{&key} parameter, that
parameter becomes a legal parameter to @code{MAKE-INSTANCE} when
creating an instance of that class. For instance, if the bank sometimes
pays a percentage of the initial balance as a bonus when an account is
opened, you could implement that using a method on
@code{INITIALIZE-INSTANCE} that takes a keyword argument to specify the
percentage of the bonus like this:

@verbatim
(defmethod initialize-instance :after ((account bank-account)
                                       &key opening-bonus-percentage)
  (when opening-bonus-percentage
    (incf (slot-value account 'balance)
          (* (slot-value account 'balance) (/ opening-bonus-percentage 100)))))
@end verbatim

By defining this @code{INITIALIZE-INSTANCE} method, you make
@code{:opening-bonus-percentage} a legal argument to
@code{MAKE-INSTANCE} when creating a @code{bank-account} object.

@verbatim
CL-USER> (defparameter *acct* (make-instance
                                'bank-account
                                 :customer-name "Sally Sue"
                                 :balance 1000
                                 :opening-bonus-percentage 5))
*ACCT*
CL-USER> (slot-value *acct* 'balance)
1050
@end verbatim

@node Accessor Functions
@section Accessor Functions
@anchor{#accessor-functions}
Between @code{MAKE-INSTANCE} and @code{SLOT-VALUE}, you have all the
tools you need for creating and manipulating instances of your classes.
Everything else you might want to do can be implemented in terms of
those two functions. However, as anyone familiar with the principles of
good object-oriented programming practices knows, directly accessing the
slots (or fields or member variables) of an object can lead to fragile
code. The problem is that directly accessing slots ties your code too
tightly to the concrete structure of your class. For example, suppose
you decide to change the definition of @code{bank-account} so that,
instead of storing the current balance as a number, you store a list of
time-stamped withdrawals and deposits. Code that directly accesses the
@code{balance} slot will likely break if you change the class definition
to remove the slot or to store the new list in the old slot. On the
other hand, if you define a function, @code{balance}, that accesses the
slot, you can redefine it later to preserve its behavior even if the
internal representation changes. And code that uses such a function will
continue to work without modification.

Another advantage to using accessor functions rather than direct
access to slots via @code{SLOT-VALUE} is that they let you limit the
ways outside code can modify a slot.@footnote{Of course, providing an
accessor function doesn't really limit anything since other code can
still use @code{SLOT-VALUE} to get at slots directly. Common Lisp
doesn't provide strict encapsulation of slots the way some languages
such as C++ and Java do; however, if the author of a class provides
accessor functions and you ignore them, using @code{SLOT-VALUE}
instead, you had better know what you're doing. It's also possible to
use the package system, which I'll discuss in Chapter 21, to make it
even more obvious that certain slots aren't to be accessed directly,
by not exporting the names of the slots.} It may be fine for users of
the @code{bank-account} class to get the current balance, but you may
want all modifications to the balance to go through other functions
you'll provide, such as @code{deposit} and @code{withdraw}. If clients
know they're supposed to manipulate objects only through the published
functional API, you can provide a @code{balance} function but not make
it @code{SETF}able if you want the balance to be read-only.

Finally, using accessor functions makes your code tidier since it helps
you avoid lots of uses of the rather verbose @code{SLOT-VALUE} function.

It's trivial to define a function that reads the value of the
@code{balance} slot.

@verbatim
(defun balance (account)
  (slot-value account 'balance))
@end verbatim

However, if you know you're going to define subclasses of
@code{bank-account}, it might be a good idea to define @code{balance} as
a generic function. That way, you can provide different methods on
@code{balance} for those subclasses or extend its definition with
auxiliary methods. So you might write this instead:

@verbatim
(defgeneric balance (account))

(defmethod balance ((account bank-account))
  (slot-value account 'balance))
@end verbatim

As I just discussed, you don't want callers to be able to directly set
the balance, but for other slots, such as @code{customer-name}, you may
also want to provide a function to set them. The cleanest way to define
such a function is as a @code{SETF} function.

A @code{SETF} function is a way to extend @code{SETF}, defining a new
kind of place that it knows how to set. The name of a @code{SETF}
function is a two-item list whose first element is the symbol
@code{setf} and whose second element is a symbol, typically the name
of a function used to access the place the @code{SETF} function will
set. A @code{SETF} function can take any number of arguments, but the
first argument is always the value to be assigned to the
place.@footnote{One consequence of defining a @code{SETF}
function--say, @code{(setf foo)}--is that if you also define the
corresponding accessor function, @code{foo} in this case, you can use
all the modify macros built upon @code{SETF}, such as @code{INCF},
@code{DECF}, @code{PUSH}, and @code{POP}, on the new kind of place.}
You could, for instance, define a @code{SETF} function to set the
@code{customer-name} slot in a @code{bank-account} like this:

@verbatim
(defun (setf customer-name) (name account)
  (setf (slot-value account 'customer-name) name))
@end verbatim

After evaluating that definition, an expression like the following one:

@verbatim
(setf (customer-name my-account) "Sally Sue")
@end verbatim

will be compiled as a call to the @code{SETF} function you just defined
with "Sally Sue" as the first argument and the value of
@code{my-account} as the second argument.

Of course, as with reader functions, you'll probably want your
@code{SETF} function to be generic, so you'd actually define it like
this:

@verbatim
(defgeneric (setf customer-name) (value account))

(defmethod (setf customer-name) (value (account bank-account))
  (setf (slot-value account 'customer-name) value))
@end verbatim

And of course you'll also want to define a reader function for
@code{customer-name}.

@verbatim
(defgeneric customer-name (account))

(defmethod customer-name ((account bank-account))
  (slot-value account 'customer-name))
@end verbatim

This allows you to write the following:

@verbatim
(setf (customer-name *account*) "Sally Sue") ==> "Sally Sue"

(customer-name *account*)                    ==> "Sally Sue"
@end verbatim

There's nothing hard about writing these accessor functions, but it
wouldn't be in keeping with The Lisp Way to have to write them all by
hand. Thus, @code{DEFCLASS} supports three slot options that allow you
to automatically create reader and writer functions for a specific slot.

The @code{:reader} option specifies a name to be used as the name of a
generic function that accepts an object as its single argument. When the
@code{DEFCLASS} is evaluated, the generic function is created, if it
doesn't already exist. Then a method specializing its single argument on
the new class and returning the value of the slot is added to the
generic function. The name can be anything, but it's typical to name it
the same as the slot itself. Thus, instead of explicitly writing the
@code{balance} generic function and method as shown previously, you
could change the slot specifier for the @code{balance} slot in the
definition of @code{bank-account} to this:

@verbatim
(balance
 :initarg :balance
 :initform 0
 :reader balance)
@end verbatim

The @code{:writer} option is used to create a generic function and
method for setting the value of a slot. The function and method created
follow the requirements for a @code{SETF} function, taking the new value
as the first argument and returning it as the result, so you can define
a @code{SETF} function by providing a name such as
@code{(setf customer-name)}. For instance, you could provide reader and
writer methods for @code{customer-name} equivalent to the ones you just
wrote by changing the slot specifier to this:

@verbatim
(customer-name
 :initarg :customer-name
 :initform (error "Must supply a customer name.")
 :reader customer-name
 :writer (setf customer-name))
@end verbatim

Since it's quite common to want both reader and writer functions,
@code{DEFCLASS} also provides an option, @code{:accessor}, that creates
both a reader function and the corresponding @code{SETF} function. So
instead of the slot specifier just shown, you'd typically write this:

@verbatim
(customer-name
 :initarg :customer-name
 :initform (error "Must supply a customer name.")
 :accessor customer-name)
@end verbatim

Finally, one last slot option you should know about is the
@code{:documentation} option, which you can use to provide a string that
documents the purpose of the slot. Putting it all together and adding a
reader method for the @code{account-number} and @code{account-type}
slots, the @code{DEFCLASS} form for the @code{bank-account} class would
look like this:

@verbatim
(defclass bank-account ()
  ((customer-name
    :initarg :customer-name
    :initform (error "Must supply a customer name.")
    :accessor customer-name
    :documentation "Customer's name")
   (balance
    :initarg :balance
    :initform 0
    :reader balance
    :documentation "Current account balance")
   (account-number
    :initform (incf *account-numbers*)
    :reader account-number
    :documentation "Account number, unique within a bank.")
   (account-type
    :reader account-type
    :documentation "Type of account, one of :gold, :silver, or :bronze.")))
@end verbatim

@node WITH-SLOTS and WITH-ACCESSORS
@section WITH-SLOTS and WITH-ACCESSORS
@anchor{#with-slots-and-with-accessors}
While using accessor functions will make your code easier to maintain,
they can still be a bit verbose. And there will be times, when writing
methods that implement the low-level behaviors of a class, that you may
specifically want to access slots directly to set a slot that has no
writer function or to get at the slot value without causing any
auxiliary methods defined on the reader function to run.

This is what @code{SLOT-VALUE} is for; however, it's still quite
verbose. To make matters worse, a function or method that accesses the
same slot several times can become clogged with calls to accessor
functions and @code{SLOT-VALUE}. For example, even a fairly simple
method such as the following, which assesses a penalty on a
@code{bank-account} if its balance falls below a certain minimum, is
cluttered with calls to @code{balance} and @code{SLOT-VALUE}:

@verbatim
(defmethod assess-low-balance-penalty ((account bank-account))
  (when (< (balance account) *minimum-balance*)
    (decf (slot-value account 'balance) (* (balance account) .01))))
@end verbatim

And if you decide you want to directly access the slot value in order to
avoid running auxiliary methods, it gets even more cluttered.

@verbatim
(defmethod assess-low-balance-penalty ((account bank-account))
  (when (< (slot-value account 'balance) *minimum-balance*)
    (decf (slot-value account 'balance) (* (slot-value account 'balance) .01))))
@end verbatim

Two standard macros, @code{WITH-SLOTS} and @code{WITH-ACCESSORS}, can
help tidy up this clutter. Both macros create a block of code in which
simple variable names can be used to refer to slots on a particular
object. @code{WITH-SLOTS} provides direct access to the slots, as if by
@code{SLOT-VALUE}, while @code{WITH-ACCESSORS} provides a shorthand for
accessor methods.

The basic form of @code{WITH-SLOTS} is as follows:

@verbatim
(with-slots (slot*) instance-form
  body-form*)
@end verbatim

Each element of @emph{slots} can be either the name of a slot, which
is also used as a variable name, or a two-item list where the first
item is a name to use as a variable and the second is the name of the
slot. The @emph{instance-form} is evaluated once to produce the object
whose slots will be accessed. Within the body, each occurrence of one
of the variable names is translated to a call to @code{SLOT-VALUE}
with the object and the appropriate slot name as
arguments.@footnote{The "variable" names provided by @code{WITH-SLOTS}
and @code{WITH-ACCESSORS} aren't true variables; they're implemented
using a special kind of macro, called a @emph{symbol macro}, that
allows a simple name to expand into arbitrary code. Symbol macros were
introduced into the language to support @code{WITH-SLOTS} and
@code{WITH-ACCESSORS}, but you can also use them for your own
purposes.  I'll discuss them in a bit more detail in Chapter 20.}
Thus, you can write @code{assess-low-balance-penalty} like this:

@verbatim
(defmethod assess-low-balance-penalty ((account bank-account))
  (with-slots (balance) account
    (when (< balance *minimum-balance*)
      (decf balance (* balance .01)))))
@end verbatim

or, using the two-item list form, like this:

@verbatim
(defmethod assess-low-balance-penalty ((account bank-account))
  (with-slots ((bal balance)) account
    (when (< bal *minimum-balance*)
      (decf bal (* bal .01)))))
@end verbatim

If you had defined @code{balance} with an @code{:accessor} rather than
just a @code{:reader}, then you could also use @code{WITH-ACCESSORS}.
The form of @code{WITH-ACCESSORS} is the same as @code{WITH-SLOTS}
except each element of the slot list is a two-item list containing a
variable name and the name of an accessor function. Within the body of
@code{WITH-ACCESSORS}, a reference to one of the variables is equivalent
to a call to the corresponding accessor function. If the accessor
function is @code{SETF}able, then so is the variable.

@verbatim
(defmethod assess-low-balance-penalty ((account bank-account))
  (with-accessors ((balance balance)) account
    (when (< balance *minimum-balance*)
      (decf balance (* balance .01)))))
@end verbatim

The first @code{balance} is the name of the variable, and the second is
the name of the accessor function; they don't have to be the same. You
could, for instance, write a method to merge two accounts using two
calls to @code{WITH-ACCESSORS}, one for each account.

@verbatim
(defmethod merge-accounts ((account1 bank-account) (account2 bank-account))
  (with-accessors ((balance1 balance)) account1
    (with-accessors ((balance2 balance)) account2
      (incf balance1 balance2)
      (setf balance2 0))))
@end verbatim

The choice of whether to use @code{WITH-SLOTS} versus
@code{WITH-ACCESSORS} is the same as the choice between
@code{SLOT-VALUE} and an accessor function: low-level code that provides
the basic functionality of a class may use @code{SLOT-VALUE} or
@code{WITH-SLOTS} to directly manipulate slots in ways not supported by
accessor functions or to explicitly avoid the effects of auxiliary
methods that may have been defined on the accessor functions. But you
should generally use accessor functions or @code{WITH-ACCESSORS} unless
you have a specific reason not to.

@node Class-Allocated Slots
@section Class-Allocated Slots
@anchor{#class-allocated-slots}
The last slot option you need to know about is @code{:allocation}. The
value of @code{:allocation} can be either @code{:instance} or
@code{:class} and defaults to @code{:instance} if not specified. When a
slot has @code{:class} allocation, the slot has only a single value,
which is stored in the class and shared by all instances.

However, @code{:class} slots are accessed the same as @code{:instance}
slots--they're accessed with @code{SLOT-VALUE} or an accessor function,
which means you can access the slot value only through an instance of
the class even though it isn't actually stored in the instance. The
@code{:initform} and @code{:initarg} options have essentially the same
effect except the initform is evaluated once when the class is defined
rather than each time an instance is created. On the other hand, passing
an initarg to @code{MAKE-INSTANCE} will set the value, affecting all
instances of the class.

Because you can't get at a class-allocated slot without an instance of
the class, class-allocated slots aren't really equivalent to
@emph{static} or @emph{class} fields in languages such as Java, C++,
and Python.@footnote{The Meta Object Protocol (MOP), which isn't part
of the language standard but is supported by most Common Lisp
implementations, provides a function, @code{class-prototype}, that
returns an instance of a class that can be used to access class slots.
If you're using an implementation that supports the MOP and happen to
be translating some code from another language that makes heavy use of
static or class fields, this may give you a way to ease the
translation.  But it's not all that idiomatic.} Rather,
class-allocated slots are used primarily to save space; if you're
going to create many instances of a class and all instances are going
to have a reference to the same object--say, a pool of shared
resources--you can save the cost of each instance having its own
reference by making the slot class-allocated.

@node Slots and Inheritance
@section Slots and Inheritance
@anchor{#slots-and-inheritance}
As I discussed in the previous chapter, classes inherit behavior from
their superclasses thanks to the generic function machinery--a method
specialized on class @code{A} is applicable not only to direct instances
of @code{A} but also to instances of @code{A}'s subclasses. Classes also
inherit slots from their superclasses, but the mechanism is slightly
different.

In Common Lisp a given object can have only one slot with a particular
name. However, it's possible that more than one class in the inheritance
hierarchy of a given class will specify a slot with a particular name.
This can happen either because a subclass includes a slot specifier with
the same name as a slot specified in a superclass or because multiple
superclasses specify slots with the same name.

Common Lisp resolves these situations by merging all the specifiers with
the same name from the new class and all its superclasses to create a
single specifier for each unique slot name. When merging specifiers,
different slot options are treated differently. For instance, since a
slot can have only a single default value, if multiple classes specify
an @code{:initform}, the new class uses the one from the most specific
class. This allows a subclass to specify a different default value than
the one it would otherwise inherit.

On the other hand, @code{:initarg}s needn't be exclusive--each
@code{:initarg} option in a slot specifier creates a keyword parameter
that can be used to initialize the slot; multiple parameters don't
create a conflict, so the new slot specifier contains all the
@code{:initarg}s. Callers of @code{MAKE-INSTANCE} can use any of the
@code{:initarg}s to initialize the slot. If a caller passes multiple
keyword arguments that initialize the same slot, then the leftmost
argument in the call to @code{MAKE-INSTANCE} is used.

Inherited @code{:reader}, @code{:writer}, and @code{:accessor} options
aren't included in the merged slot specifier since the methods created
by the superclass's @code{DEFCLASS} will already apply to the new class.
The new class can, however, create its own accessor functions by
supplying its own @code{:reader}, @code{:writer}, or @code{:accessor}
options.

Finally, the @code{:allocation} option is, like @code{:initform},
determined by the most specific class that specifies the slot. Thus,
it's possible for all instances of one class to share a @code{:class}
slot while instances of a subclass may each have their own
@code{:instance} slot of the same name. And a sub-subclass may then
redefine it back to @code{:class} slot, so all instances of @emph{that}
class will again share a single slot. In the latter case, the slot
shared by instances of the sub-subclass is different than the slot
shared by the original superclass.

For instance, suppose you have these classes:

@verbatim
(defclass foo ()
  ((a :initarg :a :initform "A" :accessor a)
   (b :initarg :b :initform "B" :accessor b)))

(defclass bar (foo)
  ((a :initform (error "Must supply a value for a"))
   (b :initarg :the-b :accessor the-b :allocation :class)))
@end verbatim

When instantiating the class @code{bar}, you can use the inherited
initarg, @code{:a}, to specify a value for the slot @code{a} and, in
fact, must do so to avoid an error, since the @code{:initform} supplied
by @code{bar} supersedes the one inherited from @code{foo}. To
initialize the @code{b} slot, you can use either the inherited initarg
:@code{b} or the new initarg @code{:the-b}. However, because of the
@code{:allocation} option on the @code{b} slot in @code{bar}, the value
specified will be stored in the slot shared by all instances of
@code{bar}. That same slot can be accessed either with the method on the
generic function @code{b} that specializes on @code{foo} or with the new
method on the generic function @code{the-b} that specializes directly on
@code{bar}. To access the @code{a} slot on either a @code{foo} or a
@code{bar}, you'll continue to use the generic function @code{a}.

Usually merging slot definitions works quite nicely. However, it's
important to be aware when using multiple inheritance that two unrelated
slots that happen to have the same name can be merged into a single slot
in the new class. Thus, methods specialized on different classes could
end up manipulating the same slot when applied to a class that extends
those classes. This isn't much of a problem in practice since, as you'll
see in Chapter 21, you can use the package system to avoid collisions
between names in independently developed pieces of code.

@node Multiple Inheritance
@section Multiple Inheritance
@anchor{#multiple-inheritance}
All the classes you've seen so far have had only a single direct
superclass. Common Lisp also supports multiple inheritance--a class can
have multiple direct superclasses, inheriting applicable methods and
slot specifiers from all of them.

Multiple inheritance doesn't dramatically change any of the mechanisms
of inheritance I've discussed so far--every user-defined class already
has multiple superclasses since they all extend @code{STANDARD-OBJECT},
which extends @code{T}, and so have at least two superclasses. The
wrinkle that multiple inheritance adds is that a class can have more
than one @emph{direct} superclass. This complicates the notion of class
specificity that's used both when building the effective methods for a
generic function and when merging inherited slot specifiers.

That is, if classes could have only a single direct superclass, ordering
classes by specificity would be trivial--a class and all its
superclasses could be ordered in a straight line starting from the class
itself, followed by its single direct superclass, followed by @emph{its}
direct superclass, all the way up to @code{T}. But when a class has
multiple direct superclasses, those superclasses are typically not
related to each other--indeed, if one was a subclass of another, you
wouldn't need to subclass both directly. In that case, the rule that
subclasses are more specific than their superclasses isn't enough to
order all the superclasses. So Common Lisp uses a second rule that sorts
unrelated superclasses according to the order they're listed in the
@code{DEFCLASS}'s direct superclass list--classes earlier in the list
are considered more specific than classes later in the list. This rule
is admittedly somewhat arbitrary but does allow every class to have a
linear @emph{class precedence list}, which can be used to determine
which superclasses should be considered more specific than others. Note,
however, there's no global ordering of classes--each class has its own
class precedence list, and the same classes can appear in different
orders in different classes' class precedence lists.

To see how this works, let's add a class to the banking app:
@code{money-market-account}. A money market account combines the
characteristics of a checking account and a savings account: a customer
can write checks against it, but it also earns interest. You might
define it like this:

@verbatim
(defclass money-market-account (checking-account savings-account) ())
@end verbatim

The class precedence list for @code{money-market-account} will be as
follows:

@verbatim
(money-market-account
 checking-account
 savings-account
 bank-account
 standard-object
 t)
@end verbatim

Note how this list satisfies both rules: every class appears before all
its superclasses, and @code{checking-account} and @code{savings-account}
appear in the order specified in @code{DEFCLASS}.

This class defines no slots of its own but will inherit slots from
both of its direct superclasses, including the slots they inherit from
their superclasses. Likewise, any method that's applicable to any
class in the class precedence list will be applicable to a
@code{money-market-account} object. Because all slot specifiers for
the same slot are merged, it doesn't matter that
@code{money-market-account} inherits the same slot specifiers from
@code{bank-account} twice.  @footnote{In other words, Common Lisp
doesn't suffer from the @emph{diamond inheritance} problem the way,
say, C++ does. In C++, when one class subclasses two classes that both
inherit a member variable from a common superclass, the bottom class
inherits the member variable twice, leading to no end of confusion.}

Multiple inheritance is easiest to understand when the different
superclasses provide completely independent slots and behaviors. For
instance, @code{money-market-account} will inherit slots and behaviors
for dealing with checks from @code{checking-account} and slots and
behaviors for computing interest from @code{savings-account}. You don't
have to worry about the class precedence list for methods and slots
inherited from only one superclass or another.

However, it's also possible to inherit different methods for the same
generic function from different superclasses. In that case, the class
precedence list does come into play. For instance, suppose the banking
application defined a generic function @code{print-statement} used to
generate monthly statements. Presumably there would already be methods
for @code{print-statement} specialized on both @code{checking-account}
and @code{savings-account}. Both of these methods will be applicable to
instances of @code{money-market-account}, but the one specialized on
@code{checking-account} will be considered more specific than the one on
@code{savings-account} because @code{checking-account} precedes
@code{savings-account} in @code{money-market-account}'s class precedence
list.

Assuming the inherited methods are all primary methods and you haven't
defined any other methods, the method specialized on
@code{checking-account} will be used if you invoke
@code{print-statement} on @code{money-market-account}. However, that
won't necessarily give you the behavior you want since you probably want
a money market account's statement to contain elements of both a
checking account and a savings account statement.

You can modify the behavior of @code{print-statement} for
@code{money-market-account}s in a couple ways. One straightforward way
is to define a new primary method specialized on
@code{money-market-account}. This gives you the most control over the
new behavior but will probably require more new code than some other
options I'll discuss in a moment. The problem is that while you can use
@code{CALL-NEXT-METHOD} to call "up" to the next most specific method,
namely, the one specialized on @code{checking-account}, there's no way
to invoke a particular less-specific method, such as the one specialized
on @code{savings-account}. Thus, if you want to be able to reuse the
code that prints the @code{savings-account} part of the statement,
you'll need to break that code into a separate function, which you can
then call directly from both the @code{money-market-account} and
@code{savings-account} @code{print-statement} methods.

Another possibility is to write the primary methods of all three classes
to call @code{CALL-NEXT-METHOD}. Then the method specialized on
@code{money-market-account} will use @code{CALL-NEXT-METHOD} to invoke
the method specialized on @code{checking-account}. When that method
calls @code{CALL-NEXT-METHOD}, it will result in running the
@code{savings-account} method since it will be the next most specific
method according to @code{money-market-account}'s class precedence list.

Of course, if you're going to rely on a coding convention--that every
method calls @code{CALL-NEXT-METHOD}--to ensure all the applicable
methods run at some point, you should think about using auxiliary
methods instead. In this case, instead of defining primary methods on
@code{print-statement} for @code{checking-account} and
@code{savings-account}, you can define those methods as @code{:after}
methods, defining a single primary method on @code{bank-account}. Then,
@code{print-statement}, called on a @code{money-market-account}, will
print a basic account statement, output by the primary method
specialized on @code{bank-account}, followed by details output by the
@code{:after} methods specialized on @code{savings-account} and
@code{checking-account}. And if you want to add details specific to
@code{money-market-account}s, you can define an @code{:after} method
specialized on @code{money-market-account}, which will run last of all.

The advantage of using auxiliary methods is that it makes it quite clear
which methods are primarily responsible for implementing the generic
function and which ones are only contributing additional bits of
functionality. The disadvantage is that you don't get fine-grained
control over the order in which the auxiliary methods run--if you wanted
the @code{checking-account} part of the statement to print before the
@code{savings-account} part, you'd have to change the order in which the
@code{money-market-account} subclasses those classes. But that's a
fairly dramatic change that could affect other methods and inherited
slots. In general, if you find yourself twiddling the order of the
direct superclass list as a way of fine-tuning the behavior of specific
methods, you probably need to step back and rethink your approach.

On the other hand, if you don't care exactly what the order is but want
it to be consistent across several generic functions, then using
auxiliary methods may be just the thing. For example, if in addition to
@code{print-statement} you have a @code{print-detailed-statement}
generic function, you can implement both functions using @code{:after}
methods on the various subclasses of @code{bank-account}, and the order
of the parts of both a regular and a detailed statement will be the
same.

@node Good Object-Oriented Design
@section Good Object-Oriented Design
@anchor{#good-object-oriented-design}
That's about it for the main features of Common Lisp's object system. If
you have lots of experience with object-oriented programming, you can
probably see how Common Lisp's features can be used to implement good
object-oriented designs. However, if you have less experience with
object orientation, you may need to spend some time absorbing the
object-oriented way of thinking. Unfortunately, that's a fairly large
topic and beyond the scope of this book. Or, as the man page for Perl's
object system puts it, "Now you need just to go off and buy a book about
object-oriented design methodology and bang your forehead with it for
the next six months or so." Or you can wait for some of the practical
chapters, later in this book, where you'll see several examples of how
these features are used in practice. For now, however, you're ready to
take a break from all this theory of object orientation and turn to the
rather different topic of how to make good use of Common Lisp's
powerful, but sometimes cryptic, @code{FORMAT} function.

@node A Few FORMAT Recipes
@chapter A Few FORMAT Recipes
@anchor{#a-few-format-recipes} Common Lisp's @code{FORMAT} function
is--along with the extended @code{LOOP} macro--one of the two Common
Lisp features that inspires a strong emotional response in a lot of
Common Lisp users. Some love it; others hate it.@footnote{Of course,
most folks realize it's not worth getting that worked up over
@emph{anything} in a programming language and use it or not without a
lot of angst. On the other hand, it's interesting that these two
features are the two features in Common Lisp that implement what are
essentially domain-specific languages using a syntax not based on
s-expressions. The syntax of @code{FORMAT}'s control strings is
character based, while the extended @code{LOOP} macro can be
understood only in terms of the grammar of the @code{LOOP}
keywords. That one of the common knocks on both @code{FORMAT} and
@code{LOOP} is that they "aren't Lispy enough" is evidence that
Lispers really do like the s-expression syntax.}

@code{FORMAT}'s fans love it for its great power and concision, while
its detractors hate it because of the potential for misuse and its
opacity. Complex @code{FORMAT} control strings sometimes bear a
suspicious resemblance to line noise, but @code{FORMAT} remains popular
with Common Lispers who like to be able to generate little bits of
human-readable output without having to clutter their code with lots of
output-generating code. While @code{FORMAT}'s control strings can be
cryptic, at least a single @code{FORMAT} expression doesn't clutter
things up too badly. For instance, suppose you want to print the values
in a list delimited with commas. You could write this:

@verbatim
(loop for cons on list
    do (format t "~a" (car cons))
    when (cdr cons) do (format t ", "))
@end verbatim

That's not too bad, but anyone reading this code has to mentally parse
it just to figure out that all it's doing is printing the contents of
@code{list} to standard output. On the other hand, you can tell at a
glance that the following expression is printing @code{list}, in some
form, to standard output:

@verbatim
(format t "~{~a~^, ~}" list)
@end verbatim

If you care exactly what form the output will take, then you'll have to
examine the control string, but if all you want is a first-order
approximation of what this line of code is doing, that's immediately
available.

At any rate, you should have at least a reading knowledge of
@code{FORMAT}, and it's worth getting a sense of what it can do before
you affiliate yourself with the pro- or anti-@code{FORMAT} camp. It's
also important to understand at least the basics of @code{FORMAT}
because other standard functions, such as the condition-signaling
functions discussed in the next chapter, use @code{FORMAT}-style control
strings to generate output.

To further complicate matters, @code{FORMAT} supports three quite
different kinds of formatting: printing tables of data,
@emph{pretty-printing} s-expressions, and generating human-readable
messages with interpolated values. Printing tables of data as text is a
bit passe these days; it's one of those reminders that Lisp is nearly as
old as FORTRAN. In fact, several of the directives you can use to print
floating-point values in fixed-width fields were based quite directly on
FORTRAN @emph{edit descriptors}, which are used in FORTRAN to read and
print columns of data arranged in fixed-width fields. However, using
Common Lisp as a FORTRAN replacement is beyond the scope of this book,
so I won't discuss those aspects of @code{FORMAT}.

Pretty-printing is likewise beyond the scope of this book--not because
it's passe but just because it's too big a topic. Briefly, the Common
Lisp pretty printer is a customizable system for printing
block-structured data such as--but not limited to--s-expressions while
varying indentation and dynamically adding line breaks as needed. It's
a great thing when you need it, but it's not often needed in
day-to-day programming.@footnote{Readers interested in the pretty
printer may want to read the paper "XP: A Common Lisp Pretty Printing
System" by Richard Waters. It's a description of the pretty printer
that was eventually incorporated into Common Lisp. You can download it
from
@code{ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1102a.pdf}.}

Instead, I'll focus on the parts of @code{FORMAT} you can use to
generate human-readable strings with interpolated values. Even limiting
the scope in that way, there's still a fair bit to cover. You shouldn't
feel obliged to remember every detail described in this chapter. You can
get quite far with just a few @code{FORMAT} idioms. I'll describe the
most important features of @code{FORMAT} first; it's up to you how much
of a @code{FORMAT} wizard you want to become.
@menu
* The FORMAT Function::
* FORMAT Directives::
* Basic Formatting::
* Character and Integer Directives::
* Floating-Point Directives::
* English-Language Directives::
* Conditional Formatting::
* Iteration::
* Hop Skip Jump::
* And More   ::
@end menu

@node The FORMAT Function
@section The FORMAT Function
@anchor{#the-format-function}
As you've seen in previous chapters, the @code{FORMAT} function takes
two required arguments: a destination for its output and a control
string that contains literal text and embedded @emph{directives}. Any
additional arguments provide the values used by the directives in the
control string that interpolate values into the output. I'll refer to
these arguments as @emph{format arguments}.

The first argument to @code{FORMAT}, the destination for the output,
can be @code{T}, @code{NIL}, a stream, or a string with a fill
pointer.  @code{T} is shorthand for the stream
@code{*STANDARD-OUTPUT*}, while @code{NIL} causes @code{FORMAT} to
generate its output to a string, which it then returns.@footnote{To
slightly confuse matters, most other I/O functions also accept
@code{T} and @code{NIL} as @emph{stream designators} but with a
different meaning: as a stream designator, @code{T} designates the
bidirectional stream @code{*TERMINAL-IO*}, while @code{NIL} designates
@code{*STANDARD-OUTPUT*} as an output stream and
@code{*STANDARD-INPUT*} as an input stream.} If the destination is a
stream, the output is written to the stream. And if the destination is
a string with a fill pointer, the formatted output is added to the end
of the string and the fill pointer is adjusted appropriately. Except
when the destination is @code{NIL} and it returns a string,
@code{FORMAT} returns @code{NIL}.

The second argument, the control string, is, in essence, a program in
the @code{FORMAT} language. The @code{FORMAT} language isn't Lispy at
all--its basic syntax is based on characters, not s-expressions, and
it's optimized for compactness rather than easy comprehension. This is
why a complex @code{FORMAT} control string can end up looking like line
noise.

Most of @code{FORMAT}'s directives simply interpolate an argument into
the output in one form or another. Some directives, such as @code{~%},
which causes @code{FORMAT} to emit a newline, don't consume any
arguments. And others, as you'll see, can consume more than one
argument. One directive even allows you to jump around in the list of
arguments in order to process the same argument more than once or to
skip certain arguments in certain situations. But before I discuss
specific directives, let's look at the general syntax of a directive.

@node FORMAT Directives
@section FORMAT Directives
@anchor{#format-directives}
All directives start with a tilde (@code{~}) and end with a single
character that identifies the directive. You can write the character in
either upper- or lowercase. Some directives take @emph{prefix
parameters}, which are written immediately following the tilde,
separated by commas, and used to control things such as how many digits
to print after the decimal point when printing a floating-point number.
For example, the @code{~$} directive, one of the directives used to
print floating-point values, by default prints two digits following the
decimal point.

@verbatim
CL-USER> (format t "~$" pi)
3.14
NIL
@end verbatim

However, with a prefix parameter, you can specify that it should print
its argument to, say, five decimal places like this:

@verbatim
CL-USER> (format t "~5$" pi)
3.14159
NIL
@end verbatim

The values of prefix parameters are either numbers, written in decimal,
or characters, written as a single quote followed by the desired
character. The value of a prefix parameter can also be derived from the
format arguments in two ways: A prefix parameter of @code{v} causes
@code{FORMAT} to consume one format argument and use its value for the
prefix parameter. And a prefix parameter of @code{#} will be evaluated
as the number of remaining format arguments. For example:

@verbatim
CL-USER> (format t "~v$" 3 pi)
3.142
NIL
CL-USER> (format t "~#$" pi)
3.1
NIL
@end verbatim

I'll give some more realistic examples of how you can use the @code{#}
argument in the section "Conditional Formatting."

You can also omit prefix parameters altogether. However, if you want to
specify one parameter but not the ones before it, you must include a
comma for each unspecified parameter. For instance, the @code{~F}
directive, another directive for printing floating-point values, also
takes a parameter to control the number of decimal places to print, but
it's the second parameter rather than the first. If you want to use
@code{~F} to print a number to five decimal places, you can write this:

@verbatim
CL-USER> (format t "~,5f" pi)
3.14159
NIL
@end verbatim

You can also modify the behavior of some directives with colon and
at-sign @emph{modifiers}, which are placed after any prefix parameters
and before the directive's identifying character. These modifiers change
the behavior of the directive in small ways. For instance, with a colon
modifier, the @code{~D} directive used to output integers in decimal
emits the number with commas separating every three digits, while the
at-sign modifier causes @code{~D} to include a plus sign when the number
is positive.

@verbatim
CL-USER> (format t "~d" 1000000)
1000000
NIL
CL-USER> (format t "~:d" 1000000)
1,000,000
NIL
CL-USER> (format t "~@d" 1000000)
+1000000
NIL
@end verbatim

When it makes sense, you can combine the colon and at-sign modifiers to
get both modifications.

@verbatim
CL-USER> (format t "~:@d" 1000000)
+1,000,000
NIL
@end verbatim

In directives where the two modified behaviors can't be meaningfully
combined, using both modifiers is either undefined or given a third
meaning.

@node Basic Formatting
@section Basic Formatting
@anchor{#basic-formatting}
Now you're ready to look at specific directives. I'll start with several
of the most commonly used directives, including some you've seen in
previous chapters.

The most general-purpose directive is @code{~A}, which consumes one
format argument of any type and outputs it in @emph{aesthetic}
(human-readable) form. For example, strings are output without quotation
marks or escape characters, and numbers are output in a natural way for
the type of number. If you just want to emit a value for human
consumption, this directive is your best bet.

@verbatim
(format nil "The value is: ~a" 10)           ==> "The value is: 10"
(format nil "The value is: ~a" "foo")        ==> "The value is: foo"
(format nil "The value is: ~a" (list 1 2 3)) ==> "The value is: (1 2 3)"
@end verbatim

A closely related directive, @code{~S}, likewise consumes one format
argument of any type and outputs it. However, @code{~S} tries to
generate output that can be read back in with @code{READ}. Thus, strings
will be enclosed in quotation marks, symbols will be package-qualified
when necessary, and so on. Objects that don't have a @code{READ}able
representation are printed with the unreadable object syntax,
@code{#<>}. With a colon modifier, both the @code{~A} and @code{~S}
directives emit @code{NIL} as @code{()} rather than @code{NIL}. Both the
@code{~A} and @code{~S} directives also take up to four prefix
parameters, which can be used to control whether padding is added after
(or before with the at-sign modifier) the value, but those parameters
are only really useful for generating tabular data.

The other two most frequently used directives are @code{~%}, which emits
a newline, and @code{~&}, which emits a @emph{fresh line}. The
difference between the two is that @code{~%} always emits a newline,
while @code{~&} emits one only if it's not already at the beginning of a
line. This is handy when writing loosely coupled functions that each
generate a piece of output and that need to be combined in different
ways. For instance, if one function generates output that ends with a
newline (@code{~%}) and another function generates some output that
starts with a fresh line (@code{~&}), you don't have to worry about
getting an extra blank line if you call them one after the other. Both
of these directives can take a single prefix parameter that specifies
the number of newlines to emit. The @code{~%} directive will simply emit
that many newline characters, while the @code{~&} directive will emit
either @emph{n} - 1 or @emph{n} newlines, depending on whether it starts
at the beginning of a line.

Less frequently used is the related @code{~~} directive, which causes
@code{FORMAT} to emit a literal tilde. Like the @code{~%} and @code{~&}
directives, it can be parameterized with a number that controls how many
tildes to emit.

@node Character and Integer Directives
@section Character and Integer Directives
@anchor{#character-and-integer-directives}
In addition to the general-purpose directives, @code{~A} and @code{~S},
@code{FORMAT} supports several directives that can be used to emit
values of specific types in particular ways. One of the simplest of
these is the @code{~C} directive, which is used to emit characters. It
takes no prefix arguments but can be modified with the colon and at-sign
modifiers. Unmodified, its behavior is no different from @code{~A}
except that it works only with characters. The modified versions are
more useful. With a colon modifier, @code{~:C} outputs
@emph{nonprinting} characters such as space, tab, and newline by name.
This is useful if you want to emit a message to the user about some
character. For instance, the following:

@verbatim
(format t "Syntax error. Unexpected character: ~:c" char)
@end verbatim

can emit messages like this:

@verbatim
Syntax error. Unexpected character: a
@end verbatim

but also like the following:

@verbatim
Syntax error. Unexpected character: Space
@end verbatim

With the at-sign modifier, @code{~@@C} will emit the character in Lisp's
literal character syntax.

@verbatim
CL-USER> (format t "~@c~%" #\a)
#\a
NIL
@end verbatim

With both the colon and at-sign modifiers, the @code{~C} directive can
print extra information about how to enter the character at the keyboard
if it requires special key combinations. For instance, on the Macintosh,
in certain applications you can enter a null character (character code 0
in ASCII or in any ASCII superset such as ISO-8859-1 or Unicode) by
pressing the Control key and typing @@. In OpenMCL, if you print the
null character with the @code{~:C} directive, it tells you this:

@verbatim
(format nil "~:@c" (code-char 0)) ==> "^@ (Control @)"
@end verbatim

However, not all Lisps implement this aspect of the @code{~C}
directive.  And even if they do, it may or may not be accurate--for
instance, if you're running OpenMCL in SLIME, the @code{C-@@} key
chord is intercepted by Emacs, invoking
@code{set-mark-command}.@footnote{This variant on the @code{~C}
directive makes more sense on platforms like the Lisp Machines where
key press events were represented by Lisp characters.}

Format directives dedicated to emitting numbers are another important
category. While you can use the @code{~A} and @code{~S} directives to
emit numbers, if you want fine control over how they're printed, you
need to use one of the number-specific directives. The numeric
directives can be divided into two subcategories: directives for
formatting integer values and directives for formatting floating-point
values.

Five closely related directives format integer values: @code{~D},
@code{~X}, @code{~O}, @code{~B}, and @code{~R}. The most frequently used
is the @code{~D} directive, which outputs integers in base 10.

@verbatim
(format nil "~d" 1000000) ==> "1000000"
@end verbatim

As I mentioned previously, with a colon modifier it adds commas.

@verbatim
(format nil "~:d" 1000000) ==> "1,000,000"
@end verbatim

And with an at-sign modifier, it always prints a sign.

@verbatim
(format nil "~@d" 1000000) ==> "+1000000"
@end verbatim

And the two modifiers can be combined.

@verbatim
(format nil "~:@d" 1000000) ==> "+1,000,000"
@end verbatim

The first prefix parameter can specify a minimum width for the output,
and the second parameter can specify a padding character to use. The
default padding character is space, and padding is always inserted
before the number itself.

@verbatim
(format nil "~12d" 1000000)    ==> "     1000000"
(format nil "~12,'0d" 1000000) ==> "000001000000"
@end verbatim

These parameters are handy for formatting things such as dates in a
fixed-width format.

@verbatim
(format nil "~4,'0d-~2,'0d-~2,'0d" 2005 6 10) ==> "2005-06-10"
@end verbatim

The third and fourth parameters are used in conjunction with the colon
modifier: the third parameter specifies the character to use as the
separator between groups and digits, and the fourth parameter specifies
the number of digits per group. These parameters default to a comma and
the number 3. Thus, you can use the directive @code{~:D} without
parameters to output large integers in standard format for the United
States but can change the comma to a period and the grouping from 3 to 4
with @code{~,,'.,4D}.

@verbatim
(format nil "~:d" 100000000)       ==> "100,000,000"
(format nil "~,,'.,4:d" 100000000) ==> "1.0000.0000"
@end verbatim

Note that you must use commas to hold the places of the unspecified
width and padding character parameters, allowing them to keep their
default values.

The @code{~X}, @code{~O}, and @code{~B} directives work just like the
@code{~D} directive except they emit numbers in hexadecimal (base 16),
octal (base 8), and binary (base 2).

@verbatim
(format nil "~x" 1000000) ==> "f4240"
(format nil "~o" 1000000) ==> "3641100"
(format nil "~b" 1000000) ==> "11110100001001000000"
@end verbatim

Finally, the @code{~R} directive is the general @emph{radix} directive.
Its first parameter is a number between 2 and 36 (inclusive) that
indicates what base to use. The remaining parameters are the same as the
four parameters accepted by the @code{~D}, @code{~X}, @code{~O}, and
@code{~B} directives, and the colon and at-sign modifiers modify its
behavior in the same way. The @code{~R} directive also has some special
behavior when used with no prefix parameters, which I'll discuss in the
section "English-Language Directives."

@node Floating-Point Directives
@section Floating-Point Directives
@anchor{#floating-point-directives}
Four directives format floating-point values: @code{~F}, @code{~E},
@code{~G}, and @code{~$}. The first three of these are the directives
based on FORTRAN's edit descriptors. I'll skip most of the details of
those directives since they mostly have to do with formatting
floating-point values for use in tabular form. However, you can use the
@code{~F}, @code{~E}, and @code{~$} directives to interpolate
floating-point values into text. The @code{~G}, or @emph{general,}
floating-point directive, on the other hand, combines aspects of the
@code{~F} and @code{~E} directives in a way that only really makes sense
for generating tabular output.

The @code{~F} directive emits its argument, which should be a
number,@footnote{Technically, if the argument isn't a real number,
@code{~F} is supposed to format it as if by the @code{~D} directive,
which in turn behaves like the @code{~A} directive if the argument
isn't a number, but not all implementations get this right.} in
decimal format, possibly controlling the number of digits after the
decimal point. The @code{~F} directive is, however, allowed to use
computerized scientific notation if the number is sufficiently large
or small. The @code{~E} directive, on the other hand, always emits
numbers in computerized scientific notation. Both of these directives
take a number of prefix parameters, but you need to worry only about
the second, which controls the number of digits to print after the
decimal point.

@verbatim
(format nil "~f" pi)   ==> "3.141592653589793d0"
(format nil "~,4f" pi) ==> "3.1416"
(format nil "~e" pi)   ==> "3.141592653589793d+0"
(format nil "~,4e" pi) ==> "3.1416d+0"
@end verbatim

The @code{~$}, or monetary, directive is similar to @code{~F} but a bit
simpler. As its name suggests, it's intended for emitting monetary
units. With no parameters, it's basically equivalent to @code{~,2F}. To
modify the number of digits printed after the decimal point, you use the
@emph{first} parameter, while the second parameter controls the minimum
number of digits to print before the decimal point.

@verbatim
(format nil "~$" pi)    ==> "3.14"
(format nil "~2,4$" pi) ==> "0003.14"
@end verbatim

All three directives, @code{~F}, @code{~E}, and @code{~$}, can be made
to always print a sign, plus or minus, with the at-sign
modifier.@footnote{Well, that's what the language standard says. For
some reason, perhaps rooted in a common ancestral code base, several
Common Lisp implementations don't implement this aspect of the
@code{~F} directive correctly.}

@node English-Language Directives
@section English-Language Directives
@anchor{#english-language-directives}
Some of the handiest @code{FORMAT} directives for generating
human-readable messages are the ones for emitting English text. These
directives allow you to emit numbers as English words, to emit plural
markers based on the value of a format argument, and to apply case
conversions to sections of @code{FORMAT}'s output.

The @code{~R} directive, which I discussed in "Character and Integer
Directives," when used with no base specified, prints numbers as English
words or Roman numerals. When used with no prefix parameter and no
modifiers, it emits the number in words as a cardinal number.

@verbatim
(format nil "~r" 1234) ==> "one thousand two hundred thirty-four"
@end verbatim

With the colon modifier, it emits the number as an ordinal.

@verbatim
(format nil "~:r" 1234) ==> "one thousand two hundred thirty-fourth"
@end verbatim

And with an at-sign modifier, it emits the number as a Roman numeral;
with both an at-sign and a colon, it emits "old-style" Roman numerals in
which fours and nines are written as IIII and VIIII instead of IV and
IX.

@verbatim
(format nil "~@r" 1234)  ==> "MCCXXXIV"
(format nil "~:@r" 1234) ==> "MCCXXXIIII"
@end verbatim

For numbers too large to be represented in the given form, @code{~R}
behaves like @code{~D}.

To help you generate messages with words properly pluralized,
@code{FORMAT} provides the @code{~P} directive, which simply emits an
@emph{s} unless the corresponding argument is @code{1}.

@verbatim
(format nil "file~p" 1)  ==> "file"
(format nil "file~p" 10) ==> "files"
(format nil "file~p" 0)  ==> "files"
@end verbatim

Typically, however, you'll use @code{~P} with the colon modifier, which
causes it to reprocess the previous format argument.

@verbatim
(format nil "~r file~:p" 1)  ==> "one file"
(format nil "~r file~:p" 10) ==> "ten files"
(format nil "~r file~:p" 0)  ==> "zero files"
@end verbatim

With the at-sign modifier, which can be combined with the colon
modifier, @code{~P} emits either @emph{y} or @emph{ies}.

@verbatim
(format nil "~r famil~:@p" 1)  ==> "one family"
(format nil "~r famil~:@p" 10) ==> "ten families"
(format nil "~r famil~:@p" 0)  ==> "zero families"
@end verbatim

Obviously, @code{~P} can't solve all pluralization problems and is no
help for generating messages in other languages, but it's handy for the
cases it does handle. And the @code{~[} directive, which I'll discuss in
a moment, gives you a more flexible way to conditionalize parts of
@code{FORMAT}'s output.

The last directive for dealing with emitting English text is @code{~(},
which allows you to control the case of text in the output. Each
@code{~(} is paired with a @code{~)}, and all the output generated by
the portion of the control string between the two markers will be
converted to all lowercase.

@verbatim
(format nil "~(~a~)" "FOO") ==> "foo"
(format nil "~(~@r~)" 124)  ==> "cxxiv"
@end verbatim

You can modify @code{~(} with an at sign to make it capitalize the first
word in a section of text, with a colon to make it to capitalize all
words, and with both modifiers to convert all text to uppercase. (A
@emph{word} for the purpose of this directive is a sequence of
alphanumeric characters delimited by nonalphanumeric characters or the
ends of the text.)

@verbatim
(format nil "~(~a~)" "tHe Quick BROWN foX")   ==> "the quick brown fox"
(format nil "~@(~a~)" "tHe Quick BROWN foX")  ==> "The quick brown fox"
(format nil "~:(~a~)" "tHe Quick BROWN foX")  ==> "The Quick Brown Fox"
(format nil "~:@(~a~)" "tHe Quick BROWN foX") ==> "THE QUICK BROWN FOX"
@end verbatim

@node Conditional Formatting
@section Conditional Formatting
@anchor{#conditional-formatting}
In addition to directives that interpolate arguments and modify other
output, @code{FORMAT} provides several directives that implement simple
control constructs within the control string. One of these, which you
used in Chapter 9, is the @emph{conditional} directive @code{~[.} This
directive is closed by a corresponding @code{~]}, and in between are a
number of clauses separated by @code{~;}. The job of the @code{~[}
directive is to pick one of the clauses, which is then processed by
@code{FORMAT}. With no modifiers or parameters, the clause is selected
by numeric index; the @code{~[} directive consumes a format argument,
which should be a number, and takes the @emph{nth} (zero-based) clause
where @emph{N} is the value of the argument.

@verbatim
(format nil "~[cero~;uno~;dos~]" 0) ==> "cero"
(format nil "~[cero~;uno~;dos~]" 1) ==> "uno"
(format nil "~[cero~;uno~;dos~]" 2) ==> "dos"
@end verbatim

If the value of the argument is greater than the number of clauses,
nothing is printed.

@verbatim
(format nil "~[cero~;uno~;dos~]" 3) ==> ""
@end verbatim

However, if the last clause separator is @code{~:;} instead of
@code{~;}, then the last clause serves as a default clause.

@verbatim
(format nil "~[cero~;uno~;dos~:;mucho~]" 3)   ==> "mucho"
(format nil "~[cero~;uno~;dos~:;mucho~]" 100) ==> "mucho"
@end verbatim

It's also possible to specify the clause to be selected using a prefix
parameter. While it'd be silly to use a literal value in the control
string, recall that @code{#} used as a prefix parameter means the number
of arguments remaining to be processed. Thus, you can define a format
string such as the following:

@verbatim
(defparameter *list-etc*
  "~#[NONE~;~a~;~a and ~a~:;~a, ~a~]~#[~; and ~a~:;, ~a, etc~].")
@end verbatim

and then use it like this:

@verbatim
(format nil *list-etc*)                ==> "NONE."
(format nil *list-etc* 'a)             ==> "A."
(format nil *list-etc* 'a 'b)          ==> "A and B."
(format nil *list-etc* 'a 'b 'c)       ==> "A, B and C."
(format nil *list-etc* 'a 'b 'c 'd)    ==> "A, B, C, etc."
(format nil *list-etc* 'a 'b 'c 'd 'e) ==> "A, B, C, etc."
@end verbatim

Note that the control string actually contains two @code{~[~]}
directives--both of which use @code{#} to select the clause to use. The
first consumes between zero and two arguments, while the second consumes
one more, if available. @code{FORMAT} will silently ignore any arguments
not consumed while processing the control string.

With a colon modifier, the @code{~[} can contain only two clauses; the
directive consumes a single argument and processes the first clause if
the argument is @code{NIL} and the second clause is otherwise. You used
this variant of @code{~[} in Chapter 9 to generate pass/fail messages,
like this:

@verbatim
(format t "~:[FAIL~;pass~]" test-result)
@end verbatim

Note that either clause can be empty, but the directive must contain a
@code{~;}.

Finally, with an at-sign modifier, the @code{~[} directive can have only
one clause. The directive consumes one argument and, if it's
non-@code{NIL}, processes the clause after backing up to make the
argument available to be consumed again.

@verbatim
(format nil "~@[x = ~a ~]~@[y = ~a~]" 10 20)   ==> "x = 10 y = 20"
(format nil "~@[x = ~a ~]~@[y = ~a~]" 10 nil)  ==> "x = 10 "
(format nil "~@[x = ~a ~]~@[y = ~a~]" nil 20)  ==> "y = 20"
(format nil "~@[x = ~a ~]~@[y = ~a~]" nil nil) ==> ""
@end verbatim

@node Iteration
@section Iteration
@anchor{#iteration}
Another @code{FORMAT} directive that you've seen already, in passing, is
the iteration directive @code{~@{}. This directive tells @code{FORMAT}
to iterate over the elements of a list or over the implicit list of the
format arguments.

With no modifiers, @code{~@{} consumes one format argument, which must
be a list. Like the @code{~[} directive, which is always paired with a
@code{~]} directive, the @code{~@{} directive is always paired with a
closing @code{~}@}. The text between the two markers is processed as a
control string, which draws its arguments from the list consumed by the
@code{~@{} directive. @code{FORMAT} will repeatedly process this control
string for as long as the list being iterated over has elements left. In
the following example, the @code{~@{} consumes the single format
argument, the list @code{(1 2 3)}, and then processes the control string
@code{"~a, "}, repeating until all the elements of the list have been
consumed.

@verbatim
(format nil "~{~a, ~}" (list 1 2 3)) ==> "1, 2, 3, "
@end verbatim

However, it's annoying that in the output the last element of the list
is followed by a comma and a space. You can fix that with the @code{~^}
directive; within the body of a @code{~@{} directive, the @code{~^}
causes the iteration to stop immediately, without processing the rest of
the control string, when no elements remain in the list. Thus, to avoid
printing the comma and space after the last element of a list, you can
precede them with a @code{~^}.

@verbatim
(format nil "~{~a~^, ~}" (list 1 2 3)) ==> "1, 2, 3"
@end verbatim

The first two times through the iteration, there are still unprocessed
elements in the list when the @code{~^} is processed. The third time
through, however, after the @code{~a} directive consumes the @code{3},
the @code{~^} will cause @code{FORMAT} to break out of the iteration
without printing the comma and space.

With an at-sign modifier, @code{~@{} processes the remaining format
arguments as a list.

@verbatim
(format nil "~@{~a~^, ~}" 1 2 3) ==> "1, 2, 3"
@end verbatim

Within the body of a @code{~@{...~}@}, the special prefix parameter
@code{#} refers to the number of items remaining to be processed in the
list rather than the number of remaining format arguments. You can use
that, along with the @code{~[} directive, to print a comma-separated
list with an "and" before the last item like this:

@verbatim
(format nil "~{~a~#[~;, and ~:;, ~]~}" (list 1 2 3)) ==> "1, 2, and 3"
@end verbatim

However, that doesn't really work right if the list is two items long
because it adds an extra comma.

@verbatim
(format nil "~{~a~#[~;, and ~:;, ~]~}" (list 1 2)) ==> "1, and 2"
@end verbatim

You could fix that in a bunch of ways. The following takes advantage of
the behavior of @code{~@@@{} when nested inside another @code{~@{} or
@code{~@@@{} directive--it iterates over whatever items remain in the
list being iterated over by the outer @code{~@{}. You can combine that
with a @code{~#[} directive to make the following control string for
formatting lists according to English grammar:

@verbatim
(defparameter *english-list*
  "~{~#[~;~a~;~a and ~a~:;~@{~a~#[~;, and ~:;, ~]~}~]~}")

(format nil *english-list* '())        ==> ""
(format nil *english-list* '(1))       ==> "1"
(format nil *english-list* '(1 2))     ==> "1 and 2"
(format nil *english-list* '(1 2 3))   ==> "1, 2, and 3"
(format nil *english-list* '(1 2 3 4)) ==> "1, 2, 3, and 4"
@end verbatim

While that control string verges on being "write-only" code, it's not
too hard to understand if you take it a bit at a time. The outer
@code{~@{...~}@} will consume and iterate over a list. The whole body of
the iteration then consists of a @code{~#[...~]}; the output generated
each time through the iteration will thus depend on the number of items
left to be processed from the list. Splitting apart the @code{~#[...~]}
directive on the @code{~;} clause separators, you can see that it's made
up of four clauses, the last of which is a default clause because it's
preceded by a @code{~:;} rather than a plain @code{~;}. The first
clause, for when there are zero elements to be processed, is empty,
which makes sense--if there are no more elements to be processed, the
iteration would've stopped already. The second clause handles the case
of one element with a simple @code{~a} directive. Two elements are
handled with @code{"~a and ~a"}. And the default clause, which handles
three or more elements, consists of another iteration directive, this
time using @code{~@@@{} to iterate over the remaining elements of the
list being processed by the outer @code{~@{}. And the body of that
iteration is the control string that can handle a list of three or more
elements correctly, which is fine in this context. Because the
@code{~@@@{} loop consumes all the remaining list items, the outer loop
iterates only once.

If you wanted to print something special such as "<empty>" when the list
was empty, you have a couple ways to do it. Perhaps the easiest is to
put the text you want into the first (zeroth) clause of the outer
@code{~#[} and then add a colon modifier to the closing @code{~}@} of
the outer iteration--the colon forces the iteration to be run at least
once, even if the list is empty, at which point @code{FORMAT} processes
the zeroth clause of the conditional directive.

@verbatim
(defparameter *english-list*
  "~{~#[<empty>~;~a~;~a and ~a~:;~@{~a~#[~;, and ~:;, ~]~}~]~:}")

(format nil *english-list* '()) ==> "<empty>"
@end verbatim

Amazingly, the @code{~@{} directive provides even more variations with
different combinations of prefix parameters and modifiers. I won't
discuss them other than to say you can use an integer prefix parameter
to limit the maximum number of iterations and that, with a colon
modifier, each element of the list (either an actual list or the list
constructed by the @code{~@@@{} directive) must itself be a list whose
elements will then be used as arguments to the control string in the
@code{~:@{...~}@} directive.

@node Hop Skip Jump
@section Hop, Skip, Jump
@anchor{#hop-skip-jump}
A much simpler directive is the @code{~*} directive, which allows you to
jump around in the list of format arguments. In its basic form, without
modifiers, it simply skips the next argument, consuming it without
emitting anything. More often, however, it's used with a colon modifier,
which causes it to move backward, allowing the same argument to be used
a second time. For instance, you can use @code{~:*} to print a numeric
argument once as a word and once in numerals like this:

@verbatim
(format nil "~r ~:*(~d)" 1) ==> "one (1)"
@end verbatim

Or you could implement a directive similar to @code{~:P} for an
irregular plural by combing @code{~:*} with @code{~[}.

@verbatim
(format nil "I saw ~r el~:*~[ves~;f~:;ves~]." 0) ==> "I saw zero elves."
(format nil "I saw ~r el~:*~[ves~;f~:;ves~]." 1) ==> "I saw one elf."
(format nil "I saw ~r el~:*~[ves~;f~:;ves~]." 2) ==> "I saw two elves."
@end verbatim

In this control string, the @code{~R} prints the format argument as a
cardinal number. Then the @code{~:*} directive backs up so the number
is also used as the argument to the @code{~[} directive, selecting
between the clauses for when the number is zero, one, or anything
else.@footnote{If you find "I saw zero elves" to be a bit clunky, you
could use a slightly more elaborate format string that makes another
use of @code{~:*} like this:

@verbatim
(format nil "I saw ~[no~:;~:*~r~] el~:*~[ves~;f~:;ves~]." 0) ==> "I saw no elves."
(format nil "I saw ~[no~:;~:*~r~] el~:*~[ves~;f~:;ves~]." 1) ==> "I saw one elf."
(format nil "I saw ~[no~:;~:*~r~] el~:*~[ves~;f~:;ves~]." 2) ==> "I saw two elves."
@end verbatim
}

Within an @code{~@{} directive, @code{~*} skips or backs up over the
items in the list. For instance, you could print only the keys of a
plist like this:

@verbatim
(format nil "~{~s~*~^ ~}" '(:a 10 :b 20)) ==> ":A :B"
@end verbatim

The @code{~*} directive can also be given a prefix parameter. With no
modifiers or with the colon modifier, this parameter specifies the
number of arguments to move forward or backward and defaults to one.
With an at-sign modifier, the prefix parameter specifies an absolute,
zero-based index of the argument to jump to, defaulting to zero. The
at-sign variant of @code{~*} can be useful if you want to use
different control strings to generate different messages for the same
arguments and if different messages need to use the arguments in
different orders.@footnote{This kind of problem can arise when trying
to localize an application and translate human-readable messages into
different languages. @code{FORMAT} can help with some of these
problems but is by no means a full-blown localization system.}

@node And More
@section And More . . .
@anchor{#and-more-.-.-.}
And there's more--I haven't mentioned the @code{~?} directive, which can
take snippets of control strings from the format arguments or the
@code{~/} directive, which allows you to call an arbitrary function to
handle the next format argument. And then there are all the directives
for generating tabular and pretty-printed output. But the directives
discussed in this chapter should be plenty for the time being.

In the next chapter, you'll move onto Common Lisp's condition system,
the Common Lisp analog to other languages' exception and error handling
systems.

@node Beyond Exception Handling Conditions and Restarts
@chapter  Beyond Exception Handling: Conditions and Restarts
@anchor{#beyond-exception-handling-conditions-and-restarts}
One of Lisp's great features is its @emph{condition} system. It serves a
similar purpose to the exception handling systems in Java, Python, and
C++ but is more flexible. In fact, its flexibility extends beyond error
handling--conditions are more general than exceptions in that a
condition can represent any occurrence during a program's execution that
may be of interest to code at different levels on the call stack. For
example, in the section "Other Uses for Conditions," you'll see that
conditions can be used to emit warnings without disrupting execution of
the code that emits the warning while allowing code higher on the call
stack to control whether the warning message is printed. For the time
being, however, I'll focus on error handling.

The condition system is more flexible than exception systems because
instead of providing a two-part division between the code that signals
an error@footnote{@emph{Throws} or @emph{raises} an exception in
Java/Python terms} and the code that handles
it,@footnote{@emph{Catches} the exception in Java/Python terms} the
condition system splits the responsibilities into three
parts--@emph{signaling} a condition, @emph{handling} it, and
@emph{restarting}. In this chapter, I'll describe how you could use
conditions in part of a hypothetical application for analyzing log
files. You'll see how you could use the condition system to allow a
low-level function to detect a problem while parsing a log file and
signal an error, to allow mid-level code to provide several possible
ways of recovering from such an error, and to allow code at the
highest level of the application to define a policy for choosing which
recovery strategy to use.

To start, I'll introduce some terminology: @emph{errors}, as I'll use
the term, are the consequences of Murphy's law. If something can go
wrong, it will: a file that your program needs to read will be missing,
a disk that you need to write to will be full, the server you're talking
to will crash, or the network will go down. If any of these things
happen, it may stop a piece of code from doing what you want. But
there's no bug; there's no place in the code that you can fix to make
the nonexistent file exist or the disk not be full. However, if the rest
of the program is depending on the actions that were going to be taken,
then you'd better deal with the error somehow or you @emph{will} have
introduced a bug. So, errors aren't caused by bugs, but neglecting to
handle an error is almost certainly a bug.

So, what does it mean to handle an error? In a well-written program,
each function is a black box hiding its inner workings. Programs are
then built out of layers of functions: high-level functions are built on
top of the lower-level functions, and so on. This hierarchy of
functionality manifests itself at runtime in the form of the call stack:
if @code{high} calls @code{medium}, which calls @code{low}, when the
flow of control is in @code{low}, it's also still in @code{medium} and
@code{high}, that is, they're still on the call stack.

Because each function is a black box, function boundaries are an
excellent place to deal with errors. Each function--@code{low}, for
example--has a job to do. Its direct caller--@code{medium} in this
case--is counting on it to do its job. However, an error that prevents
it from doing its job puts all its callers at risk: @code{medium} called
@code{low} because it needs the work done that @code{low} does; if that
work doesn't get done, @code{medium} is in trouble. But this means that
@code{medium}'s caller, @code{high}, is also in trouble--and so on up
the call stack to the very top of the program. On the other hand,
because each function is a black box, if any of the functions in the
call stack can somehow do their job despite underlying errors, then none
of the functions above it needs to know there was a problem--all those
functions care about is that the function they called somehow did the
work expected of it.

In most languages, errors are handled by returning from a failing
function and giving the caller the choice of either recovering or
failing itself. Some languages use the normal function return mechanism,
while languages with exceptions return control by @emph{throwing} or
@emph{raising} an exception. Exceptions are a vast improvement over
using normal function returns, but both schemes suffer from a common
flaw: while searching for a function that can recover, the stack
unwinds, which means code that might recover has to do so without the
context of what the lower-level code was trying to do when the error
actually occurred.

Consider the hypothetical call chain of @code{high}, @code{medium},
@code{low}. If @code{low} fails and @code{medium} can't recover, the
ball is in @code{high}'s court. For @code{high} to handle the error, it
must either do its job without any help from @code{medium} or somehow
change things so calling @code{medium} will work and call it again. The
first option is theoretically clean but implies a lot of extra code--a
whole extra implementation of whatever it was @code{medium} was supposed
to do. And the further the stack unwinds, the more work that needs to be
redone. The second option--patching things up and retrying--is tricky;
for @code{high} to be able to change the state of the world so a second
call into @code{medium} won't end up causing an error in @code{low},
it'd need an unseemly knowledge of the inner workings of both
@code{medium} and @code{low}, contrary to the notion that each function
is a black box.
@menu
* The Lisp Way::
* Conditions::
* Condition Handlers::
* Restarts::
* Providing Multiple Restarts::
* Other Uses for Conditions::
@end menu

@node The Lisp Way
@section The Lisp Way
@anchor{#the-lisp-way}
Common Lisp's error handling system gives you a way out of this
conundrum by letting you separate the code that actually recovers from
an error from the code that decides how to recover. Thus, you can put
recovery code in low-level functions without committing to actually
using any particular recovery strategy, leaving that decision to code in
high-level functions.

To get a sense of how this works, let's suppose you're writing an
application that reads some sort of textual log file, such as a Web
server's log. Somewhere in your application you'll have a function to
parse the individual log entries. Let's assume you'll write a function,
@code{parse-log-entry}, that will be passed a string containing the text
of a single log entry and that is supposed to return a @code{log-entry}
object representing the entry. This function will be called from a
function, @code{parse-log-file}, that reads a complete log file and
returns a list of objects representing all the entries in the file.

To keep things simple, the @code{parse-log-entry} function will not be
required to parse incorrectly formatted entries. It will, however, be
able to detect when its input is malformed. But what should it do when
it detects bad input? In C you'd return a special value to indicate
there was a problem. In Java or Python you'd throw or raise an
exception. In Common Lisp, you signal a condition.

@node Conditions
@section Conditions
@anchor{#conditions} A @emph{condition} is an object whose class
indicates the general nature of the condition and whose instance data
carries information about the details of the particular circumstances
that lead to the condition being signaled.@footnote{In this respect, a
condition is a lot like an exception in Java or Python except not all
conditions represent an error or @emph{exceptional} situation.} In
this hypothetical log analysis program, you might define a condition
class, @code{malformed-log-entry-error}, that @code{parse-log-entry}
will signal if it's given data it can't parse.

Condition classes are defined with the @code{DEFINE-CONDITION} macro,
which works essentially the same as @code{DEFCLASS} except that the
default superclass of classes defined with @code{DEFINE-CONDITION} is
@code{CONDITION} rather than @code{STANDARD-OBJECT}. Slots are
specified in the same way, and condition classes can singly and
multiply inherit from other classes that descend from
@code{CONDITION}. But for historical reasons, condition classes aren't
required to be instances of @code{STANDARD-OBJECT}, so some of the
functions you use with @code{DEFCLASS}ed classes aren't required to
work with conditions. In particular, a condition's slots can't be
accessed using @code{SLOT-VALUE}; you must specify either a
@code{:reader} option or an @code{:accessor} option for any slot whose
value you intend to use.  Likewise, new condition objects are created
with @code{MAKE-CONDITION} rather than
@code{MAKE-INSTANCE}. @code{MAKE-CONDITION} initializes the slots of
the new condition based on the @code{:initarg}s it's passed, but
there's no way to further customize a condition's initialization,
equivalent to @code{INITIALIZE-INSTANCE}.@footnote{In some Common Lisp
implementations, conditions are defined as subclasses of
@code{STANDARD-OBJECT}, in which case @code{SLOT-VALUE},
@code{MAKE-INSTANCE}, and @code{INITIALIZE-INSTANCE} will work, but
it's not portable to rely on it.}

When using the condition system for error handling, you should define
your conditions as subclasses of @code{ERROR}, a subclass of
@code{CONDITION}. Thus, you might define
@code{malformed-log-entry-error}, with a slot to hold the argument that
was passed to @code{parse-log-entry}, like this:

@verbatim
(define-condition malformed-log-entry-error (error)
  ((text :initarg :text :reader text)))
@end verbatim

@node Condition Handlers
@section Condition Handlers
@anchor{#condition-handlers}
In @code{parse-log-entry} you'll signal a
@code{malformed-log-entry-error} if you can't parse the log entry. You
signal errors with the function @code{ERROR}, which calls the
lower-level function @code{SIGNAL} and drops into the debugger if the
condition isn't handled. You can call @code{ERROR} two ways: you can
pass it an already instantiated condition object, or you can pass it the
name of the condition class and any initargs needed to construct a new
condition, and it will instantiate the condition for you. The former is
occasionally useful for resignaling an existing condition object, but
the latter is more concise. Thus, you could write @code{parse-log-entry}
like this, eliding the details of actually parsing a log entry:

@verbatim
(defun parse-log-entry (text)
  (if (well-formed-log-entry-p text)
    (make-instance 'log-entry ...)
    (error 'malformed-log-entry-error :text text)))
@end verbatim

What happens when the error is signaled depends on the code above
@code{parse-log-entry} on the call stack. To avoid landing in the
debugger, you must establish a @emph{condition handler} in one of the
functions leading to the call to @code{parse-log-entry}. When a
condition is signaled, the signaling machinery looks through a list of
active condition handlers, looking for a handler that can handle the
condition being signaled based on the condition's class. Each condition
handler consists of a type specifier indicating what types of conditions
it can handle and a function that takes a single argument, the
condition. At any given moment there can be many active condition
handlers established at various levels of the call stack. When a
condition is signaled, the signaling machinery finds the most recently
established handler whose type specifier is compatible with the
condition being signaled and calls its function, passing it the
condition object.

The handler function can then choose whether to handle the condition.
The function can decline to handle the condition by simply returning
normally, in which case control returns to the @code{SIGNAL} function,
which will search for the next most recently established handler with a
compatible type specifier. To handle the condition, the function must
transfer control out of @code{SIGNAL} via a @emph{nonlocal exit}. In the
next section, you'll see how a handler can choose where to transfer
control. However, many condition handlers simply want to unwind the
stack to the place where they were established and then run some code.
The macro @code{HANDLER-CASE} establishes this kind of condition
handler. The basic form of a @code{HANDLER-CASE} is as follows:

@verbatim
(handler-case expression
  error-clause*)
@end verbatim

where each @emph{error-clause} is of the following form:

@verbatim
(condition-type ([var]) code)
@end verbatim

If the @emph{expression} returns normally, then its value is returned by
the @code{HANDLER-CASE}. The body of a @code{HANDLER-CASE} must be a
single expression; you can use @code{PROGN} to combine several
expressions into a single form. If, however, the expression signals a
condition that's an instance of any of the @emph{condition-type}s
specified in any @emph{error-clause}, then the code in the appropriate
error clause is executed and its value returned by the
@code{HANDLER-CASE}. The @emph{var}, if included, is the name of the
variable that will hold the condition object when the handler code is
executed. If the code doesn't need to access the condition object, you
can omit the variable name.

For instance, one way to handle the @code{malformed-log-entry-error}
signaled by @code{parse-log-entry} in its caller, @code{parse-log-file},
would be to skip the malformed entry. In the following function, the
@code{HANDLER-CASE} expression will either return the value returned by
@code{parse-log-entry} or return @code{NIL} if a
@code{malformed-log-entry-error} is signaled. (The @code{it} in the
@code{LOOP} clause @code{collect it} is another @code{LOOP} keyword,
which refers to the value of the most recently evaluated conditional
test, in this case the value of @code{entry}.)

@verbatim
(defun parse-log-file (file)
  (with-open-file (in file :direction :input)
    (loop for text = (read-line in nil nil) while text
       for entry = (handler-case (parse-log-entry text)
                     (malformed-log-entry-error () nil))
       when entry collect it)))
@end verbatim

When @code{parse-log-entry} returns normally, its value will be assigned
to @code{entry} and collected by the @code{LOOP}. But if
@code{parse-log-entry} signals a @code{malformed-log-entry-error}, then
the error clause will return @code{NIL}, which won't be collected.

JAVA-STYLE EXCEPTON HANDLING
@code{HANDLER-CASE} is the nearest analog in Common Lisp to Java- or
Python-style exception handling. Where you might write this in Java:

@verbatim
try {
  doStuff();
  doMoreStuff();
} catch (SomeException se) {
  recover(se);
}
@end verbatim

or this in Python:

@verbatim
try:
  doStuff()
  doMoreStuff()
except SomeException, se:
  recover(se)
@end verbatim

in Common Lisp you'd write this:

@verbatim
(handler-case
    (progn
      (do-stuff)
      (do-more-stuff))
  (some-exception (se) (recover se)))
@end verbatim

This version of @code{parse-log-file} has one serious deficiency: it's
doing too much. As its name suggests, the job of @code{parse-log-file}
is to parse the file and produce a list of @code{log-entry} objects; if
it can't, it's not its place to decide what to do instead. What if you
want to use @code{parse-log-file} in an application that wants to tell
the user that the log file is corrupted or one that wants to recover
from malformed entries by fixing them up and re-parsing them? Or maybe
an application is fine with skipping them but only until a certain
number of corrupted entries have been seen.

You could try to fix this problem by moving the @code{HANDLER-CASE} to a
higher-level function. However, then you'd have no way to implement the
current policy of skipping individual entries--when the error was
signaled, the stack would be unwound all the way to the higher-level
function, abandoning the parsing of the log file altogether. What you
want is a way to provide the current recovery strategy without requiring
that it always be used.

@node Restarts
@section Restarts
@anchor{#restarts}
The condition system lets you do this by splitting the error handling
code into two parts. You place code that actually recovers from errors
into @emph{restarts}, and condition handlers can then handle a condition
by invoking an appropriate restart. You can place restart code in mid-
or low-level functions, such as @code{parse-log-file} or
@code{parse-log-entry}, while moving the condition handlers into the
upper levels of the application.

To change @code{parse-log-file} so it establishes a restart instead of a
condition handler, you can change the @code{HANDLER-CASE} to a
@code{RESTART-CASE}. The form of @code{RESTART-CASE} is quite similar to
a @code{HANDLER-CASE} except the names of restarts are just names, not
necessarily the names of condition types. In general, a restart name
should describe the action the restart takes. In @code{parse-log-file},
you can call the restart @code{skip-log-entry} since that's what it
does. The new version will look like this:

@verbatim
(defun parse-log-file (file)
  (with-open-file (in file :direction :input)
    (loop for text = (read-line in nil nil) while text
       for entry = (restart-case (parse-log-entry text)
                     (skip-log-entry () nil))
       when entry collect it)))
@end verbatim

If you invoke this version of @code{parse-log-file} on a log file
containing corrupted entries, it won't handle the error directly; you'll
end up in the debugger. However, there among the various restarts
presented by the debugger will be one called @code{skip-log-entry},
which, if you choose it, will cause @code{parse-log-file} to continue on
its way as before. To avoid ending up in the debugger, you can establish
a condition handler that invokes the @code{skip-log-entry} restart
automatically.

The advantage of establishing a restart rather than having
@code{parse-log-file} handle the error directly is it makes
@code{parse-log-file} usable in more situations. The higher-level code
that invokes @code{parse-log-file} doesn't have to invoke the
@code{skip-log-entry} restart. It can choose to handle the error at a
higher level. Or, as I'll show in the next section, you can add restarts
to @code{parse-log-entry} to provide other recovery strategies, and then
condition handlers can choose which strategy they want to use.

But before I can talk about that, you need to see how to set up a
condition handler that will invoke the @code{skip-log-entry} restart.
You can set up the handler anywhere in the chain of calls leading to
@code{parse-log-file}. This may be quite high up in your application,
not necessarily in @code{parse-log-file}'s direct caller. For instance,
suppose the main entry point to your application is a function,
@code{log-analyzer}, that finds a bunch of logs and analyzes them with
the function @code{analyze-log}, which eventually leads to a call to
@code{parse-log-file}. Without any error handling, it might look like
this:

@verbatim
(defun log-analyzer ()
  (dolist (log (find-all-logs))
    (analyze-log log)))
@end verbatim

The job of @code{analyze-log} is to call, directly or indirectly,
@code{parse-log-file} and then do something with the list of log entries
returned. An extremely simple version might look like this:

@verbatim
(defun analyze-log (log)
  (dolist (entry (parse-log-file log))
    (analyze-entry entry)))
@end verbatim

where the function @code{analyze-entry} is presumably responsible for
extracting whatever information you care about from each log entry and
stashing it away somewhere.

Thus, the path from the top-level function, @code{log-analyzer}, to
@code{parse-log-entry}, which actually signals an error, is as follows:

@image{figures/restart-call-stack,,,,png}

Assuming you always want to skip malformed log entries, you could change
this function to establish a condition handler that invokes the
@code{skip-log-entry} restart for you. However, you can't use
@code{HANDLER-CASE} to establish the condition handler because then the
stack would be unwound to the function where the @code{HANDLER-CASE}
appears. Instead, you need to use the lower-level macro
@code{HANDLER-BIND}. The basic form of @code{HANDLER-BIND} is as
follows:

@verbatim
(handler-bind (binding*) form*)
@end verbatim

where each binding is a list of a condition type and a handler
function of one argument. After the handler bindings, the body of the
@code{HANDLER-BIND} can contain any number of forms. Unlike the
handler code in @code{HANDLER-CASE}, the handler code must be a
function object, and it must accept a single argument. A more
important difference between @code{HANDLER-BIND} and
@code{HANDLER-CASE} is that the handler function bound by
@code{HANDLER-BIND} will be run without unwinding the stack--the flow
of control will still be in the call to @code{parse-log-entry} when
this function is called. The call to @code{INVOKE-RESTART} will find
and invoke the most recently bound restart with the given name. So you
can add a handler to @code{log-analyzer} that will invoke the
@code{skip-log-entry} restart established in @code{parse-log-file}
like this:@footnote{The compiler may complain if the parameter is
never used. You can silence that warning by adding a declaration
@code{(declare (ignore c))} as the first expression in the
@code{LAMBDA} body.}

@verbatim
(defun log-analyzer ()
  (handler-bind ((malformed-log-entry-error
                  #'(lambda (c)
                      (invoke-restart 'skip-log-entry))))
    (dolist (log (find-all-logs))
      (analyze-log log))))
@end verbatim

In this @code{HANDLER-BIND}, the handler function is an anonymous
function that invokes the restart @code{skip-log-entry}. You could also
define a named function that does the same thing and bind it instead. In
fact, a common practice when defining a restart is to define a function,
with the same name and taking a single argument, the condition, that
invokes the eponymous restart. Such functions are called @emph{restart
functions}. You could define a restart function for
@code{skip-log-entry} like this:

@verbatim
(defun skip-log-entry (c)
  (invoke-restart 'skip-log-entry))
@end verbatim

Then you could change the definition of @code{log-analyzer} to this:

@verbatim
(defun log-analyzer ()
  (handler-bind ((malformed-log-entry-error #'skip-log-entry))
    (dolist (log (find-all-logs))
      (analyze-log log))))
@end verbatim

As written, the @code{skip-log-entry} restart function assumes that a
@code{skip-log-entry} restart has been established. If a
@code{malformed-log-entry-error} is ever signaled by code called from
@code{log-analyzer} without a @code{skip-log-entry} having been
established, the call to @code{INVOKE-RESTART} will signal a
@code{CONTROL-ERROR} when it fails to find the @code{skip-log-entry}
restart. If you want to allow for the possibility that a
@code{malformed-log-entry-error} might be signaled from code that
doesn't have a @code{skip-log-entry} restart established, you could
change the @code{skip-log-entry} function to this:

@verbatim
(defun skip-log-entry (c)
  (let ((restart (find-restart 'skip-log-entry)))
    (when restart (invoke-restart restart))))
@end verbatim

@code{FIND-RESTART} looks for a restart with a given name and returns an
object representing the restart if the restart is found and @code{NIL}
if not. You can invoke the restart by passing the restart object to
@code{INVOKE-RESTART}. Thus, when @code{skip-log-entry} is bound with
@code{HANDLER-BIND}, it will handle the condition by invoking the
@code{skip-log-entry} restart if one is available and otherwise will
return normally, giving other condition handlers, bound higher on the
stack, a chance to handle the condition.

@node Providing Multiple Restarts
@section Providing Multiple Restarts
@anchor{#providing-multiple-restarts}
Since restarts must be explicitly invoked to have any effect, you can
define multiple restarts, each providing a different recovery strategy.
As I mentioned earlier, not all log-parsing applications will
necessarily want to skip malformed entries. Some applications might want
@code{parse-log-file} to include a special kind of object representing
malformed entries in the list of @code{log-entry} objects; other
applications may have some way to repair a malformed entry and may want
a way to pass the fixed entry back to @code{parse-log-entry}.

To allow more complex recovery protocols, restarts can take arbitrary
arguments, which are passed in the call to @code{INVOKE-RESTART}. You
can provide support for both the recovery strategies I just mentioned by
adding two restarts to @code{parse-log-entry}, each of which takes a
single argument. One simply returns the value it's passed as the return
value of @code{parse-log-entry}, while the other tries to parse its
argument in the place of the original log entry.

@verbatim
(defun parse-log-entry (text)
  (if (well-formed-log-entry-p text)
    (make-instance 'log-entry ...)
    (restart-case (error 'malformed-log-entry-error :text text)
      (use-value (value) value)
      (reparse-entry (fixed-text) (parse-log-entry fixed-text)))))
@end verbatim

The name @code{USE-VALUE} is a standard name for this kind of restart.
Common Lisp defines a restart function for @code{USE-VALUE} similar to
the @code{skip-log-entry} function you just defined. So, if you wanted
to change the policy on malformed entries to one that created an
instance of @code{malformed-log-entry}, you could change
@code{log-analyzer} to this (assuming the existence of a
@code{malformed-log-entry} class with a @code{:text} initarg):

@verbatim
(defun log-analyzer ()
  (handler-bind ((malformed-log-entry-error
                  #'(lambda (c)
                      (use-value
                       (make-instance 'malformed-log-entry :text (text c))))))
    (dolist (log (find-all-logs))
      (analyze-log log))))
@end verbatim

You could also have put these new restarts into @code{parse-log-file}
instead of @code{parse-log-entry}. However, you generally want to put
restarts in the lowest-level code possible. It wouldn't, though, be
appropriate to move the @code{skip-log-entry} restart into
@code{parse-log-entry} since that would cause @code{parse-log-entry} to
sometimes return normally with @code{NIL}, the very thing you started
out trying to avoid. And it'd be an equally bad idea to remove the
@code{skip-log-entry} restart on the theory that the condition handler
could get the same effect by invoking the @code{use-value} restart with
@code{NIL} as the argument; that would require the condition handler to
have intimate knowledge of how the @code{parse-log-file} works. As it
stands, the @code{skip-log-entry} is a properly abstracted part of the
log-parsing API.

@node Other Uses for Conditions
@section Other Uses for Conditions
@anchor{#other-uses-for-conditions}
While conditions are mainly used for error handling, they can be used
for other purposes--you can use conditions, condition handlers, and
restarts to build a variety of protocols between low- and high-level
code. The key to understanding the potential of conditions is to
understand that merely signaling a condition has no effect on the flow
of control.

The primitive signaling function @code{SIGNAL} implements the mechanism
of searching for an applicable condition handler and invoking its
handler function. The reason a handler can decline to handle a condition
by returning normally is because the call to the handler function is
just a regular function call--when the handler returns, control passes
back to @code{SIGNAL}, which then looks for another, less recently bound
handler that can handle the condition. If @code{SIGNAL} runs out of
condition handlers before the condition is handled, it also returns
normally.

The @code{ERROR} function you've been using calls @code{SIGNAL}. If the
error is handled by a condition handler that transfers control via
@code{HANDLER-CASE} or by invoking a restart, then the call to
@code{SIGNAL} never returns. But if @code{SIGNAL} returns, @code{ERROR}
invokes the debugger by calling the function stored in
@code{*DEBUGGER-HOOK*}. Thus, a call to @code{ERROR} can never return
normally; the condition must be handled either by a condition handler or
in the debugger.

Another condition signaling function, @code{WARN}, provides an example
of a different kind of protocol built on the condition system. Like
@code{ERROR}, @code{WARN} calls @code{SIGNAL} to signal a condition. But
if @code{SIGNAL} returns, @code{WARN} doesn't invoke the debugger--it
prints the condition to @code{*ERROR-OUTPUT*} and returns @code{NIL},
allowing its caller to proceed. @code{WARN} also establishes a restart,
@code{MUFFLE-WARNING}, around the call to @code{SIGNAL} that can be used
by a condition handler to make @code{WARN} return without printing
anything. The restart function @code{MUFFLE-WARNING} finds and invokes
its eponymous restart, signaling a @code{CONTROL-ERROR} if no such
restart is available. Of course, a condition signaled with @code{WARN}
could also be handled in some other way--a condition handler could
"promote" a warning to an error by handling it as if it were an error.

For instance, in the log-parsing application, if there were ways a log
entry could be slightly malformed but still parsable, you could write
@code{parse-log-entry} to go ahead and parse the slightly defective
entries but to signal a condition with @code{WARN} when it did. Then the
larger application could choose to let the warning print, to muffle the
warning, or to treat the warning like an error, recovering the same way
it would from a @code{malformed-log-entry-error}.

A third error-signaling function, @code{CERROR}, provides yet another
protocol. Like @code{ERROR}, @code{CERROR} will drop you into the
debugger if the condition it signals isn't handled. But like
@code{WARN}, it establishes a restart before it signals the condition.
The restart, @code{CONTINUE}, causes @code{CERROR} to return
normally--if the restart is invoked by a condition handler, it will keep
you out of the debugger altogether. Otherwise, you can use the restart
once you're in the debugger to resume the computation immediately after
the call to @code{CERROR}. The function @code{CONTINUE} finds and
invokes the @code{CONTINUE} restart if it's available and returns
@code{NIL} otherwise.

You can also build your own protocols on @code{SIGNAL}--whenever
low-level code needs to communicate information back up the call stack
to higher-level code, the condition mechanism is a reasonable mechanism
to use. But for most purposes, one of the standard error or warning
protocols should suffice.

You'll use the condition system in future practical chapters, both for
regular error handling and, in Chapter 25, to help in handling a tricky
corner case of parsing ID3 files. Unfortunately, it's the fate of error
handling to always get short shrift in programming texts--proper error
handling, or lack thereof, is often the biggest difference between
illustrative code and hardened, production-quality code. The trick to
writing the latter has more to do with adopting a particularly rigorous
way of thinking about software than with the details of any particular
programming language constructs. That said, if your goal is to write
that kind of software, you'll find the Common Lisp condition system is
an excellent tool for writing robust code and one that fits quite nicely
into Common Lisp's incremental development style.

Writing Robust Software
For information on writing robust software, you could do worse than to
start by finding a copy of @emph{Software Reliability} (John Wiley &
Sons, 1976) by Glenford J. Meyers. Bertrand Meyer's writings on Design
By Contract also provide a useful way of thinking about software
correctness. For instance, see Chapters 11 and 12 of his
@emph{Object-Oriented Software Construction} (Prentice Hall, 1997). Keep
in mind, however, that Bertrand Meyer is the inventor of Eiffel, a
statically typed bondage and discipline language in the Algol/Ada
school. While he has a lot of smart things to say about object
orientation and software reliability, there's a fairly wide gap between
his view of programming and The Lisp Way. Finally, for an excellent
overview of the larger issues surrounding building fault-tolerant
systems, see Chapter 3 of the classic @emph{Transaction Processing:
Concepts and Techniques} (Morgan Kaufmann, 1993) by Jim Gray and Andreas
Reuter.
In the next chapter I'll give a quick overview of some of the 25 special
operators you haven't had a chance to use yet, at least not directly.

@node The Special Operators
@chapter The Special Operators
@anchor{#the-special-operators}
In a way, the most impressive aspect of the condition system covered in
the previous chapter is that if it wasn't already part of the language,
it could be written entirely as a user-level library. This is possible
because Common Lisp's special operators--while none touches directly on
signaling or handling conditions--provide enough access to the
underlying machinery of the language to be able to do things such as
control the unwinding of the stack.

In previous chapters I've discussed the most frequently used special
operators, but it's worth being familiar with the others for two
reasons. First, some of the infrequently used special operators are used
infrequently simply because whatever need they address doesn't arise
that often. It's good to be familiar with these special operators so
when one of them is called for, you'll at least know it exists. Second,
because the 25 special operators--along with the basic rule for
evaluating function calls and the built-in data types--provide the
foundation for the rest of the language, a passing familiarity with them
will help you understand how the language works.

In this chapter, I'll discuss all the special operators, some briefly
and some at length, so you can see how they fit together. I'll point out
which ones you can expect to use directly in your own code, which ones
serve as the basis for other constructs that you use all the time, and
which ones you'll rarely use directly but which can be handy in
macro-generated code.
@menu
* Controlling Evaluation::
* Manipulating the Lexical Environment::
* Local Flow of Control::
* Unwinding the Stack::
* Multiple Values::
* EVAL-WHEN::
* Other Special Operators::
@end menu

@node Controlling Evaluation
@section Controlling Evaluation
@anchor{#controlling-evaluation} The first category of special
operators contains the three operators that provide basic control over
the evaluation of forms. They're @code{QUOTE}, @code{IF}, and
@code{PROGN}, and I've discussed them all already. However, it's worth
noting how each of these special operators provides one fundamental
kind of control over the evaluation of one or more forms. @code{QUOTE}
prevents evaluation altogether and allows you to get at s-expressions
as data. @code{IF} provides the fundamental boolean choice operation
from which all other conditional execution constructs can be
built.@footnote{Of course, if @code{IF} wasn't a special operator but
some other conditional form, such as @code{COND}, was, you could build
@code{IF} as a macro. Indeed, in many Lisp dialects, starting with
McCarthy's original Lisp, @code{COND} was the primitive conditional
evaluation operator.} And @code{PROGN} provides the ability to
sequence a number of forms.

@node Manipulating the Lexical Environment
@section Manipulating the Lexical Environment
@anchor{#manipulating-the-lexical-environment} The largest class of
special operators contains the operators that manipulate and access
the @emph{lexical environment}. @code{LET} and @code{LET*}, which I've
already discussed, are examples of special operators that manipulate
the lexical environment since they can introduce new lexical bindings
for variables. Any construct, such as a @code{DO} or @code{DOTIMES},
that binds lexical variables will have to expand into a @code{LET} or
@code{LET*}.@footnote{Well, technically those constructs could also
expand into a @code{LAMBDA} expression since, as I mentioned in
Chapter 6, @code{LET} could be defined--and was in some earlier
Lisps--as a macro that expands into an invocation of an anonymous
function.} The @code{SETQ} special operator is one that accesses the
lexical environment since it can be used to set variables whose
bindings were created by @code{LET} and @code{LET*}.

Variables, however, aren't the only thing that can be named within a
lexical scope. While most functions are defined globally with
@code{DEFUN}, it's also possible to create local functions with the
special operators @code{FLET} and @code{LABELS}, local macros with
@code{MACROLET}, and a special kind of macro, called a @emph{symbol
macro}, with @code{SYMBOL-MACROLET}.

Much like @code{LET} allows you to introduce a lexical variable whose
scope is the body of the @code{LET}, @code{FLET} and @code{LABELS} let
you define a function that can be referred to only within the scope of
the @code{FLET} or @code{LABELS} form. These special operators are handy
when you need a local function that's a bit too complex to define inline
as a @code{LAMBDA} expression or that you need to use more than once.
Both have the same basic form, which looks like this:

@verbatim
(flet (function-definition*)
  body-form*)
@end verbatim

and like this:

@verbatim
(labels (function-definition*)
  body-form*)
@end verbatim

where each @emph{function-definition} has the following form:

@verbatim
(name (parameter*) form*)
@end verbatim

The difference between @code{FLET} and @code{LABELS} is that the names
of the functions defined with @code{FLET} can be used only in the body
of the @code{FLET}, while the names introduced by @code{LABELS} can be
used immediately, including in the bodies of the functions defined by
the @code{LABELS}. Thus, @code{LABELS} can define recursive functions,
while @code{FLET} can't. It might seem limiting that @code{FLET} can't
be used to define recursive functions, but Common Lisp provides both
@code{FLET} and @code{LABELS} because sometimes it's useful to be able
to write local functions that can call another function of the same
name, either a globally defined function or a local function from an
enclosing scope.

Within the body of a @code{FLET} or @code{LABELS}, you can use the names
of the functions defined just like any other function, including with
the @code{FUNCTION} special operator. Since you can use @code{FUNCTION}
to get the function object representing a function defined with
@code{FLET} or @code{LABELS}, and since a @code{FLET} or @code{LABELS}
can be in the scope of other binding forms such as @code{LET}s, these
functions can be closures.

Because the local functions can refer to variables from the enclosing
scope, they can often be written to take fewer parameters than the
equivalent helper functions. This is particularly handy when you need to
pass a function that takes a single argument as a functional parameter.
For example, in the following function, which you'll see again in
Chapter 25, the @code{FLET}ed function, @code{count-version}, takes a
single argument, as required by @code{walk-directory}, but can also use
the variable @code{versions}, introduced by the enclosing @code{LET}:

@verbatim
(defun count-versions (dir)
  (let ((versions (mapcar #'(lambda (x) (cons x 0)) '(2 3 4))))
    (flet ((count-version (file)
             (incf (cdr (assoc (major-version (read-id3 file)) versions)))))
      (walk-directory dir #'count-version :test #'mp3-p))
    versions))
@end verbatim

This function could also be written using an anonymous function in the
place of the @code{FLET}ed @code{count-version}, but giving the function
a meaningful name makes it a bit easier to read.

And when a helper function needs to recurse, an anonymous function
just won't do.@footnote{Surprising as it may seem, it actually is
possible to make anonymous functions recurse. However, you must use a
rather esoteric mechanism known as the @emph{Y combinator}. But the Y
combinator is an interesting theoretical result, not a practical
programming tool, so is well outside the scope of this book.} When you
don't want to define a recursive helper function as a global function,
you can use @code{LABELS}. For example, the following function,
@code{collect-leaves}, uses the recursive helper function @code{walk}
to walk a tree and gather all the atoms in the tree into a list, which
@code{collect-leaves} then returns (after reversing it):

@verbatim
(defun collect-leaves (tree)
  (let ((leaves ()))
    (labels ((walk (tree)
               (cond
                 ((null tree))
                 ((atom tree) (push tree leaves))
                 (t (walk (car tree))
                    (walk (cdr tree))))))
      (walk tree))
    (nreverse leaves)))
@end verbatim

Notice again how, within the @code{walk} function, you can refer to the
variable, @code{leaves}, introduced by the enclosing @code{LET}.

@code{FLET} and @code{LABELS} are also useful operations to use in macro
expansions--a macro can expand into code that contains a @code{FLET} or
@code{LABELS} to create functions that can be used within the body of
the macro. This technique can be used either to introduce functions that
the user of the macro will call or simply as a way of organizing the
code generated by the macro. This, for instance, is how a function such
as @code{CALL-NEXT-METHOD}, which can be used only within a method
definition, might be defined.

A near relative to @code{FLET} and @code{LABELS} is the special operator
@code{MACROLET}, which you can use to define local macros. Local macros
work just like global macros defined with @code{DEFMACRO} except without
cluttering the global namespace. When a @code{MACROLET} form is
evaluated, the body forms are evaluated with the local macro definitions
in effect and possibly shadowing global function and macro definitions
or local definitions from enclosing forms. Like @code{FLET} and
@code{LABELS}, @code{MACROLET} can be used directly, but it's also a
handy target for macro-generated code--by wrapping some user-supplied
code in a @code{MACROLET}, a macro can provide constructs that can be
used only within that code or can shadow a globally defined macro.
You'll see an example of this latter use of @code{MACROLET} in Chapter
31.

Finally, one last macro-defining special operator is
@code{SYMBOL-MACROLET}, which defines a special kind of macro called,
appropriately enough, a @emph{symbol macro}. Symbol macros are like
regular macros except they can't take arguments and are referred to with
a plain symbol rather than a list form. In other words, after you've
defined a symbol macro with a particular name, any use of that symbol in
a value position will be expanded and the resulting form evaluated in
its place. This is how macros such as @code{WITH-SLOTS} and
@code{WITH-ACCESSORS} are able to define "variables" that access the
state of a particular object under the covers. For instance, the
following @code{WITH-SLOTS} form:

@verbatim
(with-slots (x y z) foo (list x y z)))
@end verbatim

might expand into this code that uses @code{SYMBOL-MACROLET}:

@verbatim
(let ((#:g149 foo))
  (symbol-macrolet
      ((x (slot-value #:g149 'x))
       (y (slot-value #:g149 'y))
       (z (slot-value #:g149 'z)))
    (list x y z)))
@end verbatim

When the expression @code{(list x y z)} is evaluated, the symbols
@code{x}, @code{y}, and @code{z} will be replaced with their
expansions, such as @code{(slot-value #:g149 'x)}.@footnote{It's not
required that @code{WITH-SLOTS} be implemented with
@code{SYMBOL-MACROLET}--in some implementations, @code{WITH-SLOTS} may
walk the code provided and generate an expansion with @code{x},
@code{y}, and @code{z} already replaced with the appropriate
@code{SLOT-VALUE} forms. You can see how your implementation does it
by evaluating this form:

@verbatim
(macroexpand-1 '(with-slots (x y z) obj (list x y z)))
@end verbatim

However, walking the body is much easier for the Lisp implementation
to do than for user code; to replace @code{x}, @code{y}, and @code{z}
only when they appear in value positions requires a code walker that
understands the syntax of all special operators and that recursively
expands all macro forms in order to determine whether their expansions
include the symbols in value positions. The Lisp implementation
obviously has such a code walker at its disposal, but it's one of the
few parts of Lisp that's not exposed to users of the language.}

Symbol macros are most often local, defined with @code{SYMBOL-MACROLET},
but Common Lisp also provides a macro @code{DEFINE-SYMBOL-MACRO} that
defines a global symbol macro. A symbol macro defined with
@code{SYMBOL-MACROLET} shadows other symbol macros of the same name
defined with @code{DEFINE-SYMBOL-MACRO} or enclosing
@code{SYMBOL-MACROLET} forms.

@node Local Flow of Control
@section Local Flow of Control
@anchor{#local-flow-of-control}
The next four special operators I'll discuss also create and use names
in the lexical environment but for the purposes of altering the flow of
control rather than defining new functions and macros. I've mentioned
all four of these special operators in passing because they provide the
underlying mechanisms used by other language features. They're
@code{BLOCK}, @code{RETURN-FROM}, @code{TAGBODY}, and @code{GO}. The
first two, @code{BLOCK} and @code{RETURN-FROM}, are used together to
write code that returns immediately from a section of code--I discussed
@code{RETURN-FROM} in Chapter 5 as a way to return immediately from a
function, but it's more general than that. The other two, @code{TAGBODY}
and @code{GO}, provide a quite low-level goto construct that's the basis
for all the higher-level looping constructs you've already seen.

The basic skeleton of a @code{BLOCK} form is this:

@verbatim
(block name
  form*)
@end verbatim

The @emph{name} is a symbol, and the @emph{forms} are Lisp forms. The
forms are evaluated in order, and the value of the last form is returned
as the value of the @code{BLOCK} unless a @code{RETURN-FROM} is used to
return from the block early. A @code{RETURN-FROM} form, as you saw in
Chapter 5, consists of the name of the block to return from and,
optionally, a form that provides a value to return. When a
@code{RETURN-FROM} is evaluated, it causes the named @code{BLOCK} to
return immediately. If @code{RETURN-FROM} is called with a return value
form, the @code{BLOCK} will return the resulting value; otherwise, the
@code{BLOCK} evaluates to @code{NIL}.

A @code{BLOCK} name can be any symbol, which includes @code{NIL}. Many
of the standard control construct macros, such as @code{DO},
@code{DOTIMES}, and @code{DOLIST}, generate an expansion consisting of a
@code{BLOCK} named @code{NIL}. This allows you to use the @code{RETURN}
macro, which is a bit of syntactic sugar for
@code{(return-from nil ...)}, to break out of such loops. Thus, the
following loop will print at most ten random numbers, stopping as soon
as it gets a number greater than 50:

@verbatim
(dotimes (i 10)
  (let ((answer (random 100)))
    (print answer)
    (if (> answer 50) (return))))
@end verbatim

Function-defining macros such as @code{DEFUN}, @code{FLET}, and
@code{LABELS}, on the other hand, wrap their bodies in a @code{BLOCK}
with the same name as the function. That's why you can use
@code{RETURN-FROM} to return from a function.

@code{TAGBODY} and @code{GO} have a similar relationship to each other
as @code{BLOCK} and @code{RETURN-FROM}: a @code{TAGBODY} form defines a
context in which names are defined that can be used by @code{GO}. The
skeleton of a @code{TAGBODY} is as follows:

@verbatim
(tagbody
  tag-or-compound-form*)
@end verbatim

where each @emph{tag-or-compound-form} is either a symbol, called a
@emph{tag}, or a nonempty list form. The list forms are evaluated in
order and the tags ignored, except as I'll discuss in a moment. After
the last form of the @code{TAGBODY} is evaluated, the @code{TAGBODY}
returns @code{NIL}. Anywhere within the lexical scope of the
@code{TAGBODY} you can use the @code{GO} special operator to jump
immediately to any of the tags, and evaluation will resume with the form
following the tag. For instance, you can write a trivial infinite loop
with @code{TAGBODY} and @code{GO} like this:

@verbatim
(tagbody
 top
   (print 'hello)
   (go top))
@end verbatim

Note that while the tag names must appear at the top level of the
@code{TAGBODY}, not nested within other forms, the @code{GO} special
operator can appear anywhere within the scope of the @code{TAGBODY}.
This means you could write a loop that loops a random number of times
like this:

@verbatim
(tagbody
 top
   (print 'hello)
   (when (plusp (random 10)) (go top)))
@end verbatim

An even sillier example of @code{TAGBODY}, which shows you can have
multiple tags in a single @code{TAGBODY}, looks like this:

@verbatim
(tagbody
 a (print 'a) (if (zerop (random 2)) (go c))
 b (print 'b) (if (zerop (random 2)) (go a))
 c (print 'c) (if (zerop (random 2)) (go b)))
@end verbatim

This form will jump around randomly printing @emph{a}s, @emph{b}s, and
@emph{c}s until eventually the last @code{RANDOM} expression returns 1
and the control falls off the end of the @code{TAGBODY}.

@code{TAGBODY} is rarely used directly since it's almost always easier
to write iterative constructs in terms of the existing looping macros.
It's handy, however, for translating algorithms written in other
languages into Common Lisp, either automatically or manually. An
example of an automatic translation tool is the FORTRAN-to-Common Lisp
translator, f2cl, that translates FORTRAN source code into Common Lisp
in order to make various FORTRAN libraries available to Common Lisp
programmers. Since many FORTRAN libraries were written before the
structured programming revolution, they're full of gotos. The f2cl
compiler can simply translate those gotos to @code{GO}s within
appropriate @code{TAGBODY}s.@footnote{One version of f2cl is available
as part of the Common Lisp Open Code Collection (CLOCC):
@code{http://clocc.sourceforge.net/}. By contrast, consider the tricks
the authors of f2j, a FORTRAN-to-Java translator, have to
play. Although the Java Virtual Machine (JVM) has a goto instruction,
it's not directly exposed in Java. So to compile FORTRAN gotos, they
first compile the FORTRAN code into legal Java source with calls to a
dummy class to represent the labels and gotos. Then they compile the
source with a regular Java compiler and postprocess the byte codes to
translate the dummy calls into JVM-level byte codes. Clever, but what
a pain.}

Similarly, @code{TAGBODY} and @code{GO} can be handy when translating
algorithms described in prose or by flowcharts--for instance, in Donald
Knuth's classic series @emph{The Art of Computer Programming}, he
describes algorithms using a "recipe" format: step 1, do this; step 2,
do that; step 3, go back to step 2; and so on. For example, on page 142
of @emph{The Art of Computer Programming, Volume 2: Seminumerical
Algorithms}, Third Edition (Addison-Wesley, 1998), he describes
Algorithm S, which you'll use in Chapter 27, in this form:

@quotation
Algorithm S (Selection sampling technique). To select n records at
random from a set of N, where 0 < n <= N.
@end quotation
@quotation
S1. [Initialize.] Set t <-- 0, m <-- 0. (During this algorithm, m
represents the number of records selected so far, and t is the total
number of input records that we have dealt with.)
@end quotation
@quotation
S2. [Generate U.] Generate a random number U, uniformly distributed
between zero and one.
@end quotation
@quotation
S3. [Test.] If (N - t)U >= n - m, go to step S5.
@end quotation
@quotation
S4. [Select.] Select the next record for the sample, and increase m and
t by 1. If m < n, go to step S2; otherwise the sample is complete and
the algorithm terminates.
@end quotation
@quotation
S5. [Skip.] Skip the next record (do not include it in the sample),
increase t by 1, and go back to step S2.
@end quotation
This description can be easily translated into a Common Lisp function,
after renaming a few variables, as follows:

@verbatim
(defun algorithm-s (n max) ; max is N in Knuth's algorithm
  (let (seen               ; t in Knuth's algorithm
        selected           ; m in Knuth's algorithm
        u                  ; U in Knuth's algorithm
        (records ()))      ; the list where we save the records selected
    (tagbody
     s1
       (setf seen 0)
       (setf selected 0)
     s2
       (setf u (random 1.0))
     s3
       (when (>= (* (- max seen) u) (- n selected)) (go s5))
     s4
       (push seen records)
       (incf selected)
       (incf seen)
       (if (< selected n)
           (go s2)
           (return-from algorithm-s (nreverse records)))
     s5
       (incf seen)
       (go s2))))
@end verbatim

It's not the prettiest code, but it's easy to verify that it's a
faithful translation of Knuth's algorithm. But, this code, unlike
Knuth's prose description, can be run and tested. Then you can start
refactoring, checking after each change that the function still
works.@footnote{Since this algorithm depends on values returned by
@code{RANDOM}, you may want to test it with a consistent random seed,
which you can get by binding @code{*RANDOM-STATE*} to the value of
@code{(make-random-state nil)} around each call to @code{algorithm-s}.
For instance, you can do a basic sanity check of @code{algorithm-s} by
evaluating this:

@verbatim
(let ((*random-state* (make-random-state nil))) (algorithm-s 10 200))
@end verbatim

If your refactorings are all valid, this expression should evaluate to
the same list each time.}

After pushing the pieces around a bit, you might end up with something
like this:

@verbatim
(defun algorithm-s (n max)
  (loop for seen from 0
     when (< (* (- max seen) (random 1.0)) n)
     collect seen and do (decf n)
     until (zerop n)))
@end verbatim

While it may not be immediately obvious that this code correctly
implements Algorithm S, if you got here via a series of functions that
all behave identically to the original literal translation of Knuth's
recipe, you'd have good reason to believe it's correct.

@node Unwinding the Stack
@section Unwinding the Stack
@anchor{#unwinding-the-stack}
Another aspect of the language that special operators give you control
over is the behavior of the call stack. For instance, while you normally
use @code{BLOCK} and @code{TAGBODY} to manage the flow of control within
a single function, you can also use them, in conjunction with closures,
to force an immediate nonlocal return from a function further down on
the stack. That's because @code{BLOCK} names and @code{TAGBODY} tags can
be closed over by any code within the lexical scope of the @code{BLOCK}
or @code{TAGBODY}. For example, consider this function:

@verbatim
(defun foo ()
  (format t "Entering foo~%")
  (block a
    (format t " Entering BLOCK~%")
    (bar #'(lambda () (return-from a)))
    (format t " Leaving BLOCK~%"))
  (format t "Leaving foo~%"))
@end verbatim

The anonymous function passed to @code{bar} uses @code{RETURN-FROM} to
return from the @code{BLOCK}. But that @code{RETURN-FROM} doesn't get
evaluated until the anonymous function is invoked with @code{FUNCALL} or
@code{APPLY}. Now suppose @code{bar} looks like this:

@verbatim
(defun bar (fn)
  (format t "  Entering bar~%")
  (baz fn)
  (format t "  Leaving bar~%"))
@end verbatim

Still, the anonymous function isn't invoked. Now look at @code{baz}.

@verbatim
(defun baz (fn)
  (format t "   Entering baz~%")
  (funcall fn)
  (format t "   Leaving baz~%"))
@end verbatim

Finally the function is invoked. But what does it mean to
@code{RETURN-FROM} a block that's several layers up on the call stack?
Turns out it works fine--the stack is unwound back to the frame where
the @code{BLOCK} was established and control returns from the
@code{BLOCK}. The @code{FORMAT} expressions in @code{foo}, @code{bar},
and @code{baz} show this:

@verbatim
CL-USER> (foo)
Entering foo
 Entering BLOCK
  Entering bar
   Entering baz
Leaving foo
NIL
@end verbatim

Note that the only "Leaving . . ." message that prints is the one that
appears after the @code{BLOCK} in @code{foo}.

Because the names of blocks are lexically scoped, a @code{RETURN-FROM}
always returns from the smallest enclosing @code{BLOCK} in the lexical
environment where the @code{RETURN-FROM} form appears even if the
@code{RETURN-FROM} is executed in a different dynamic context. For
instance, @code{bar} could also contain a @code{BLOCK} named @code{a},
like this:

@verbatim
(defun bar (fn)
  (format t "  Entering bar~%")
  (block a (baz fn))
  (format t "  Leaving bar~%"))
@end verbatim

This extra @code{BLOCK} won't change the behavior of @code{foo} at
all--the name @code{a} is resolved lexically, at compile time, not
dynamically, so the intervening block has no effect on the
@code{RETURN-FROM}. Conversely, the name of a @code{BLOCK} can be used
only by @code{RETURN-FROM}s appearing within the lexical scope of the
@code{BLOCK}; there's no way for code outside the block to return from
the block except by invoking a closure that closes over a
@code{RETURN-FROM} from the lexical scope of the @code{BLOCK}.

@code{TAGBODY} and @code{GO} work the same way, in this regard, as
@code{BLOCK} and @code{RETURN-FROM}. When you invoke a closure that
contains a @code{GO} form, if the @code{GO} is evaluated, the stack will
unwind back to the appropriate @code{TAGBODY} and then jump to the
specified tag.

@code{BLOCK} names and @code{TAGBODY} tags, however, differ from
lexical variable bindings in one important way. As I discussed in
Chapter 6, lexical bindings have indefinite extent, meaning the
bindings can stick around even after the binding form has
returned. @code{BLOCK}s and @code{TAGBODY}s, on the other hand, have
dynamic extent--you can @code{RETURN-FROM} a @code{BLOCK} or @code{GO}
to a @code{TAGBODY} tag only while the @code{BLOCK} or @code{TAGBODY}
is on the call stack. In other words, a closure that captures a block
name or @code{TAGBODY} tag can be passed @emph{down} the stack to be
invoked later, but it can't be returned @emph{up} the stack. If you
invoke a closure that tries to @code{RETURN-FROM} a @code{BLOCK},
after the @code{BLOCK} itself has returned, you'll get an
error. Likewise, trying to @code{GO} to a @code{TAGBODY} that no
longer exists will cause an error.@footnote{This is a pretty
reasonable restriction--it's not entirely clear what it'd mean to
return from a form that has already returned--unless, of course,
you're a Scheme programmer. Scheme supports @emph{continuations}, a
language construct that makes it possible to return from the same
function call more than once. But for a variety of reasons, few, if
any, languages other than Scheme support this kind of continuation.}

It's unlikely you'll need to use @code{BLOCK} and @code{TAGBODY}
yourself for this kind of stack unwinding. But you'll likely be using
them indirectly whenever you use the condition system, so
understanding how they work should help you understand better what
exactly, for instance, invoking a restart is doing.@footnote{If you're
the kind of person who likes to know how things work all the way down
to the bits, it may be instructive to think about how you might
implement the condition system's macros using @code{BLOCK},
@code{TAGBODY}, closures, and dynamic variables.}

@code{CATCH} and @code{THROW} are another pair of special operators that
can force the stack to unwind. You'll use these operators even less
often than the others mentioned so far--they're holdovers from earlier
Lisp dialects that didn't have Common Lisp's condition system. They
definitely shouldn't be confused with @code{try}/@code{catch} and
@code{try}/@code{except} constructs from languages such as Java and
Python.

@code{CATCH} and @code{THROW} are the dynamic counterparts of
@code{BLOCK} and @code{RETURN-FROM}. That is, you wrap @code{CATCH}
around a body of code and then use @code{THROW} to cause the
@code{CATCH} form to return immediately with a specified value. The
difference is that the association between a @code{CATCH} and
@code{THROW} is established dynamically--instead of a lexically scoped
name, the label for a @code{CATCH} is an object, called a @emph{catch
tag}, and any @code{THROW} evaluated within the dynamic extent of the
@code{CATCH} that throws that object will unwind the stack back to the
@code{CATCH} form and cause it to return immediately. Thus, you can
write a version of the @code{foo}, @code{bar}, and @code{baz} functions
from before using @code{CATCH} and @code{THROW} instead of @code{BLOCK}
and @code{RETURN-FROM} like this:

@verbatim
(defparameter *obj* (cons nil nil)) ; i.e. some arbitrary object

(defun foo ()
  (format t "Entering foo~%")
  (catch *obj*
    (format t " Entering CATCH~%")
    (bar)
    (format t " Leaving CATCH~%"))
  (format t "Leaving foo~%"))

(defun bar ()
  (format t "  Entering bar~%")
  (baz)
  (format t "  Leaving bar~%"))

(defun baz ()
  (format t "   Entering baz~%")
  (throw *obj* nil)
  (format t "   Leaving baz~%"))
@end verbatim

Notice how it isn't necessary to pass a closure down the
stack--@code{baz} can call @code{THROW} directly. The result is quite
similar to the earlier version.

@verbatim
CL-USER> (foo)
Entering foo
 Entering CATCH
  Entering bar
   Entering baz
Leaving foo
NIL
@end verbatim

However, @code{CATCH} and @code{THROW} are almost @emph{too} dynamic. In
both the @code{CATCH} and the @code{THROW}, the tag form is evaluated,
which means their values are both determined at runtime. Thus, if some
code in @code{bar} reassigned or rebound @code{*obj*}, the @code{THROW}
in @code{baz} wouldn't throw to the same @code{CATCH}. This makes
@code{CATCH} and @code{THROW} much harder to reason about than
@code{BLOCK} and @code{RETURN-FROM}. The only advantage, which the
version of @code{foo}, @code{bar}, and @code{baz} that use @code{CATCH}
and @code{THROW} demonstrates, is there's no need to pass down a closure
in order for low-level code to return from a @code{CATCH}--any code that
runs within the dynamic extent of a @code{CATCH} can cause it to return
by throwing the right object.

In older Lisp dialects that didn't have anything like Common Lisp's
condition system, @code{CATCH} and @code{THROW} were used for error
handling. However, to keep them manageable, the catch tags were usually
just quoted symbols, so you @emph{could} tell by looking at a
@code{CATCH} and a @code{THROW} whether they would hook up at runtime.
In Common Lisp you'll rarely have any call to use @code{CATCH} and
@code{THROW} since the condition system is so much more flexible.

The last special operator related to controlling the stack is another
one I've mentioned in passing before--@code{UNWIND-PROTECT}.
@code{UNWIND-PROTECT} lets you control what happens as the stack
unwinds--to make sure that certain code always runs regardless of how
control leaves the scope of the @code{UNWIND-PROTECT}, whether by a
normal return, by a restart being invoked, or by any of the ways
discussed in this section.@footnote{@code{UNWIND-PROTECT} is
essentially equivalent to @code{try/finally} constructs in Java and
Python.} The basic skeleton of @code{UNWIND-PROTECT} looks like this:

@verbatim
(unwind-protect protected-form
  cleanup-form*)
@end verbatim

The single @emph{protected-form} is evaluated, and then, regardless of
how it returns, the @emph{cleanup-forms} are evaluated. If the
@emph{protected-form} returns normally, then whatever it returns is
returned from the @code{UNWIND-PROTECT} after the cleanup forms run. The
cleanup forms are evaluated in the same dynamic environment as the
@code{UNWIND-PROTECT}, so the same dynamic variable bindings, restarts,
and condition handlers will be visible to code in cleanup forms as were
visible just before the @code{UNWIND-PROTECT}.

You'll occasionally use @code{UNWIND-PROTECT} directly. More often
you'll use it as the basis for @code{WITH-} style macros, similar to
@code{WITH-OPEN-FILE}, that evaluate any number of body forms in a
context where they have access to some resource that needs to be
cleaned up after they're done, regardless of whether they return
normally or bail via a restart or other nonlocal exit. For example, if
you were writing a database library that defined functions
@code{open-connection} and @code{close-connection}, you might write a
macro like this:@footnote{And indeed, CLSQL, the multi-Lisp,
multidatabase SQL interface library, provides a similar macro called
@code{with-database}.  CLSQL's home page is at
@code{http://clsql.b9.com}.}

@verbatim
(defmacro with-database-connection ((var &rest open-args) &body body)
  `(let ((,var (open-connection ,@open-args)))
    (unwind-protect (progn ,@body)
      (close-connection ,var))))
@end verbatim

which lets you write code like this:

@verbatim
(with-database-connection (conn :host "foo" :user "scott" :password "tiger")
  (do-stuff conn)
  (do-more-stuff conn))
@end verbatim

and not have to worry about closing the database connection, since the
@code{UNWIND-PROTECT} will make sure it gets closed no matter what
happens in the body of the @code{with-database-connection} form.

@node Multiple Values
@section Multiple Values
@anchor{#multiple-values}
Another feature of Common Lisp that I've mentioned in passing--in
Chapter 11, when I discussed @code{GETHASH}--is the ability for a single
form to return multiple values. I'll discuss it in greater detail now.
It is, however, slightly misplaced in a chapter on special operators
since the ability to return multiple values isn't provided by just one
or two special operators but is deeply integrated into the language. The
operators you'll most often use when dealing with multiple values are
macros and functions, not special operators. But it is the case that the
basic ability to get at multiple return values is provided by a special
operator, @code{MULTIPLE-VALUE-CALL}, upon which the more commonly used
@code{MULTIPLE-VALUE-BIND} macro is built.

The key thing to understand about multiple values is that returning
multiple values is quite different from returning a list--if a form
returns multiple values, unless you do something specific to capture the
multiple values, all but the @emph{primary value} will be silently
discarded. To see the distinction, consider the function @code{GETHASH},
which returns two values: the value found in the hash table and a
boolean that's @code{NIL} when no value was found. If it returned those
two values in a list, every time you called @code{GETHASH} you'd have to
take apart the list to get at the actual value, regardless of whether
you cared about the second return value. Suppose you have a hash table,
@code{*h*}, that contains numeric values. If @code{GETHASH} returned a
list, you couldn't write something like this:

@verbatim
(+ (gethash 'a *h*) (gethash 'b *h*))
@end verbatim

because @code{+} expects its arguments to be numbers, not lists. But
because the multiple value mechanism silently discards the secondary
return value when it's not wanted, this form works fine.

There are two aspects to using multiple values--returning multiple
values and getting at the nonprimary values returned by forms that
return multiple values. The starting points for returning multiple
values are the functions @code{VALUES} and @code{VALUES-LIST}. These are
regular functions, not special operators, so their arguments are passed
in the normal way. @code{VALUES} takes a variable number of arguments
and returns them as multiple values; @code{VALUES-LIST} takes a single
list and returns its elements as multiple values. In other words:

@verbatim
(values-list x) === (apply #'values x)
@end verbatim

The mechanism by which multiple values are returned is implementation
dependent just like the mechanism for passing arguments into functions
is. Almost all language constructs that return the value of some
subform will "pass through" multiple values, returning all the values
returned by the subform. Thus, a function that returns the result of
calling @code{VALUES} or @code{VALUES-LIST} will itself return
multiple values--and so will another function whose result comes from
calling the first function. And so on.@footnote{A small handful of
macros don't pass through extra return values of the forms they
evaluate. In particular, the @code{PROG1} macro, which evaluates a
number of forms like a @code{PROGN} before returning the value of the
first form, returns that form's primary value only. Likewise,
@code{PROG2}, which returns the value of the second of its subforms,
returns only the primary value. The special operator
@code{MULTIPLE-VALUE-PROG1} is a variant of @code{PROG1} that returns
all the values returned by the first form.  It's a minor wart that
@code{PROG1} doesn't already behave like @code{MULTIPLE-VALUE-PROG1},
but neither is used often enough that it matters much. The @code{OR}
and @code{COND} macros are also not always transparent to multiple
values, returning only the primary value of certain subforms.}

But when a form is evaluated in a value position, only the primary value
will be used, which is why the previous addition form works the way
you'd expect. The special operator @code{MULTIPLE-VALUE-CALL} provides
the mechanism for getting your hands on the multiple values returned by
a form. @code{MULTIPLE-VALUE-CALL} is similar to @code{FUNCALL} except
that while @code{FUNCALL} is a regular function and, therefore, can see
and pass on only the primary values passed to it,
@code{MULTIPLE-VALUE-CALL} passes, to the function returned by its first
subform, @emph{all} the values returned by the remaining subforms.

@verbatim
(funcall #'+ (values 1 2) (values 3 4))             ==> 4
(multiple-value-call #'+ (values 1 2) (values 3 4)) ==> 10
@end verbatim

However, it's fairly rare that you'll simply want to pass all the values
returned by a function onto another function. More likely, you'll want
to stash the multiple values in different variables and then do
something with them. The @code{MULTIPLE-VALUE-BIND} macro, which you saw
in Chapter 11, is the most frequently used operator for accepting
multiple return values. Its skeleton looks like this:

@verbatim
(multiple-value-bind (variable*) values-form
  body-form*)
@end verbatim

The @emph{values-form} is evaluated, and the multiple values it returns
are bound to the @emph{variables}. Then the @emph{body-forms} are
evaluated with those bindings in effect. Thus:

@verbatim
(multiple-value-bind (x y) (values 1 2)
  (+ x y)) ==> 3
@end verbatim

Another macro, @code{MULTIPLE-VALUE-LIST}, is even simpler--it takes a
single form, evaluates it, and collects the resulting multiple values
into a list. In other words, it's the inverse of @code{VALUES-LIST}.

@verbatim
CL-USER> (multiple-value-list (values 1 2))
(1 2)
CL-USER> (values-list (multiple-value-list (values 1 2)))
1
2
@end verbatim

However, if you find yourself using @code{MULTIPLE-VALUE-LIST} a lot, it
may be a sign that some function should be returning a list to start
with rather than multiple values.

Finally, if you want to assign multiple values returned by a form to
existing variables, you can use @code{VALUES} as a @code{SETF}able
place. For example:

@verbatim
CL-USER> (defparameter *x* nil)
*X*
CL-USER> (defparameter *y* nil)
*Y*
CL-USER> (setf (values *x* *y*) (floor (/ 57 34)))
1
23/34
CL-USER> *x*
1
CL-USER> *y*
23/34
@end verbatim

@node EVAL-WHEN
@section EVAL-WHEN
@anchor{#eval-when}
A special operator you'll need to understand in order to write certain
kinds of macros is @code{EVAL-WHEN}. For some reason, Lisp books often
treat @code{EVAL-WHEN} as a wizards-only topic. But the only
prerequisite to understanding @code{EVAL-WHEN} is an understanding of
how the two functions @code{LOAD} and @code{COMPILE-FILE} interact. And
understanding @code{EVAL-WHEN} will be important as you start writing
certain kinds of more sophisticated macros, such as the ones you'll
write in Chapters 24 and 31.

I've touched briefly on the relation between @code{LOAD} and
@code{COMPILE-FILE} in previous chapters, but it's worth reviewing again
here. The job of @code{LOAD} is to load a file and evaluate all the
top-level forms it contains. The job of @code{COMPILE-FILE} is to
compile a source file into a FASL file, which can then be loaded with
@code{LOAD} such that @code{(load "foo.lisp")} and
@code{(load "foo.fasl")} are essentially equivalent.

Because @code{LOAD} evaluates each form before reading the next, the
side effects of evaluating forms earlier in the file can affect how
forms later in the form are read and evaluated. For instance,
evaluating an @code{IN-PACKAGE} form changes the value of
@code{*PACKAGE*}, which will affect the way subsequent forms are
read.@footnote{The reason loading a file with an @code{IN-PACKAGE}
form in it has no effect on the value of @code{*PACKAGE*} after
@code{LOAD} returns is because @code{LOAD} binds @code{*PACKAGE*} to
its current value before doing anything else. In other words,
something equivalent to the following @code{LET} is wrapped around the
rest of the code in @code{LOAD}:

@verbatim
(let ((*package* *package*)) ...)
@end verbatim

Any assignment to @code{*PACKAGE*} will be to the new binding, and the
old binding will be restored when @code{LOAD} returns. It also binds
the variable @code{*READTABLE*}, which I haven't discussed, in the
same way.}  Similarly, a @code{DEFMACRO} form early in a file can
define a macro that can then be used by code later in the
file.@footnote{In some implementations, you may be able to get away
with evaluating @code{DEFUN}s that use undefined macros in the
function body as long as the macros are defined before the function is
actually called. But that works, if at all, only when @code{LOAD}ing
the definitions from source, not when compiling with
@code{COMPILE-FILE}, so in general macro definitions must be evaluated
before they're used.}

@code{COMPILE-FILE}, on the other hand, normally doesn't evaluate the
forms it's compiling; it's when the FASL is loaded that the forms--or
their compiled equivalents--will be evaluated. However,
@code{COMPILE-FILE} must evaluate some forms, such as @code{IN-PACKAGE}
and @code{DEFMACRO} forms, in order to keep the behavior of
@code{(load "foo.lisp")} and @code{(load "foo.fasl")} consistent.

So how do macros such as @code{IN-PACKAGE} and @code{DEFMACRO} work when
processed by @code{COMPILE-FILE}? In some pre-Common Lisp versions of
Lisp, the file compiler simply knew it should evaluate certain macros in
addition to compiling them. Common Lisp avoided the need for such
kludges by borrowing the @code{EVAL-WHEN} special operator from Maclisp.
This operator, as its name suggests, allows you to control when specific
bits of code are evaluated. The skeleton of an @code{EVAL-WHEN} form
looks like this:

@verbatim
(eval-when (situation*)
  body-form*)
@end verbatim

There are three possible @emph{situations}--@code{:compile-toplevel},
@code{:load-toplevel}, and @code{:execute}--and which ones you specify
controls when the @emph{body-forms} will be evaluated. An
@code{EVAL-WHEN} with multiple situations is equivalent to several
@code{EVAL-WHEN} forms, one per situation, each with the same body code.
To explain the meaning of the three situations, I'll need to explain a
bit about how @code{COMPILE-FILE}, which is also referred to as the
@emph{file compiler}, goes about compiling a file.

To explain how @code{COMPILE-FILE} compiles @code{EVAL-WHEN} forms, I
need to introduce a distinction between compiling @emph{top-level}
forms and compiling non-top-level forms. A top-level form is, roughly
speaking, one that will be compiled into code that will be run when
the FASL is loaded. Thus, all forms that appear directly at the top
level of a source file are compiled as top-level forms. Similarly, any
forms appearing directly in a top-level @code{PROGN} are compiled as
top-level forms since the @code{PROGN} itself doesn't @emph{do}
anything--it just groups together its subforms, which will be run when
the FASL is loaded.@footnote{By contrast, the subforms in a top-level
@code{LET} aren't compiled as top-level forms because they're not run
directly when the FASL is loaded. They will run, but it's in the
runtime context of the bindings established by the
@code{LET}. Theoretically, a @code{LET} that binds no variables could
be treated like a @code{PROGN}, but it's not--the forms appearing in a
@code{LET} are never treated as top-level forms.} Similarly, forms
appearing directly in a @code{MACROLET} or @code{SYMBOL-MACROLET} are
compiled as top-level forms because after the compiler has expanded
the local macros or symbol macros, there will be no remnant of the
@code{MACROLET} or @code{SYMBOL-MACROLET} in the compiled
code. Finally, the expansion of a top-level macro form will be
compiled as a top-level form.

Thus, a @code{DEFUN} appearing at the top level of a source file is a
top-level form--the code that defines the function and associates it
with its name will run when the FASL is loaded--but the forms within the
body of the function, which won't run until the function is called,
aren't top-level forms. Most forms are compiled the same when compiled
as top-level and non-top-level forms, but the semantics of an
@code{EVAL-WHEN} depend on whether it's being compiled as a top- level
form, compiled as a non-top-level form, or simply evaluated, combined
with what situations are listed in its situation list.

The situations @code{:compile-toplevel} and @code{:load-toplevel}
control the meaning of an @code{EVAL-WHEN} compiled as a top-level form.
When @code{:compile-toplevel} is present, the file compiler will
evaluate the subforms at compile time. When @code{:load-toplevel} is
present, it will compile the subforms as top-level forms. If neither of
these situations is present in a top-level @code{EVAL-WHEN}, the
compiler ignores it.

When an @code{EVAL-WHEN} is compiled as a non-top-level form, it's
either compiled like a @code{PROGN}, if the @code{:execute} situation is
specified, or ignored. Similarly, an evaluated @code{EVAL-WHEN}--which
includes top-level @code{EVAL-WHEN}s in a source file processed by
@code{LOAD} and @code{EVAL-WHEN}s evaluated at compile time because they
appear as subforms of a top-level @code{EVAL-WHEN} with the
@code{:compile-toplevel} situation--is treated like a @code{PROGN} if
@code{:execute} is present and ignored otherwise.

Thus, a macro such as @code{IN-PACKAGE} can have the necessary effect at
both compile time and when loading from source by expanding into an
@code{EVAL-WHEN} like the following:

@verbatim
(eval-when (:compile-toplevel :load-toplevel :execute)
  (setf *package* (find-package "PACKAGE-NAME")))
@end verbatim

@code{*PACKAGE*} will be set at compile time because of the
@code{:compile-toplevel} situation, set when the FASL is loaded because
of @code{:load-toplevel}, and set when the source is loaded because of
the @code{:execute}.

There are two ways you're most likely to use @code{EVAL-WHEN}. One is if
you want to write macros that need to save some information at compile
time to be used when generating the expansion of other macro forms in
the same file. This typically arises with definitional macros where a
definition early in a file can affect the code generated for a
definition later in the same file. You'll write this kind of macro in
Chapter 24.

The other time you might need @code{EVAL-WHEN} is if you want to put the
definition of a macro and helper functions it uses in the same file as
code that uses the macro. @code{DEFMACRO} already includes an
@code{EVAL-WHEN} in its expansion so the macro definition is immediately
available to be used later in the file. But @code{DEFUN} normally
doesn't make function definitions available at compile time. But if you
use a macro in the same file as it's defined in, you need the macro
@emph{and} any functions it uses to be defined. If you wrap the
@code{DEFUN}s of any helper functions used by the macro in an
@code{EVAL-WHEN} with @code{:compile-toplevel}, the definitions will be
available when the macro's expansion function runs. You'll probably want
to include @code{:load-toplevel} and @code{:execute} as well since the
macros will also need the function definitions after the file is
compiled and loaded or if you load the source instead of compiling.

@node Other Special Operators
@section Other Special Operators
@anchor{#other-special-operators} The four remaining special
operators, @code{LOCALLY}, @code{THE}, @code{LOAD-TIME-VALUE}, and
@code{PROGV}, all allow you to get at parts of the underlying language
that can't be accessed any other way.  @code{LOCALLY} and @code{THE}
are part of Common Lisp's declaration system, which is used to
communicate things to the compiler that don't affect the meaning of
your code but that may help the compiler generate better code--faster,
clearer error messages, and so on.@footnote{The one declaration that
has an effect on the semantics of a program is the @code{SPECIAL}
declaration mentioned in Chapter 6.} I'll discuss declarations briefly
in Chapter 32.

The other two, @code{LOAD-TIME-VALUE} and @code{PROGV}, are infrequently
used, and explaining the reason why you might ever @emph{want} to use
them would take longer than explaining what they do. So I'll just tell
you what they do so you know they're there. Someday you'll hit on one of
those rare times when they're just the thing, and then you'll be ready.

@code{LOAD-TIME-VALUE} is used, as its name suggests, to create a value
that's determined at load time. When the file compiler compiles code
that contains a @code{LOAD-TIME-VALUE} form, it arranges to evaluate the
first subform once, when the FASL is loaded, and for the code containing
the @code{LOAD-TIME-VALUE} form to refer to that value. In other words,
instead of writing this:

@verbatim
(defvar *loaded-at* (get-universal-time))

(defun when-loaded () *loaded-at*)
@end verbatim

you can write the following:

@verbatim
(defun when-loaded () (load-time-value (get-universal-time)))
@end verbatim

In code not processed by @code{COMPILE-FILE}, @code{LOAD-TIME-VALUE} is
evaluated once when the code is compiled, which may be when you
explicitly compile a function with @code{COMPILE} or earlier because of
implicit compilation performed by the implementation in the course of
evaluating the code. In uncompiled code, @code{LOAD-TIME-VALUE}
evaluates its form each time it's evaluated.

Finally, @code{PROGV} creates new dynamic bindings for variables whose
names are determined at runtime. This is mostly useful for implementing
embedded interpreters for languages with dynamically scoped variables.
The basic skeleton is as follows:

@verbatim
(progv symbols-list values-list
  body-form*)
@end verbatim

where @emph{symbols-list} is a form that evaluates to a list of symbols
and @emph{values-list} is a form that evaluates to a list of values.
Each symbol is dynamically bound to the corresponding value, and then
the @emph{body-forms} are evaluated. The difference between @code{PROGV}
and @code{LET} is that because @emph{symbols-list} is evaluated at
runtime, the names of the variables to bind can be determined
dynamically. As I say, this isn't something you need to do often.

And that's it for special operators. In the next chapter, I'll get back
to hard-nosed practical topics and show you how to use Common Lisp's
package system to take control of your namespaces so you can write
libraries and applications that can coexist without stomping on each
other's names.

@node Programming in the Large Packages and Symbols
@chapter Programming in the Large: Packages and Symbols
@anchor{#programming-in-the-large-packages-and-symbols} In Chapter 4 I
discussed how the Lisp reader translates textual names into objects to
be passed to the evaluator, representing them with a kind of object
called a @emph{symbol}. It turns out that having a built-in data type
specifically for representing names is quite handy for a lot of kinds
of programming.@footnote{The kind of programming that relies on a
symbol data type is called, appropriately enough, @emph{symbolic}
computation. It's typically contrasted to @emph{numeric}
programming. An example of a primarily symbolic program that all
programmers should be familiar with is a compiler--it treats the text
of a program as symbolic data and translates it into a new form.}
That, however, isn't the topic of this chapter. In this chapter I'll
discuss one of the more immediate and practical aspects of dealing
with names: how to avoid name conflicts between independently
developed pieces of code.

Suppose, for instance, you're writing a program and decide to use a
third-party library. You don't want to have to know the name of every
function, variable, class, or macro used in the internals of that
library in order to avoid conflicts between those names and the names
you use in your program. You'd like for most of the names in the library
and the names in your program to be considered distinct even if they
happen to have the same textual representation. At the same time, you'd
like certain names defined in the library to be readily accessible--the
names that make up its public API, which you'll want to use in your
program.

In Common Lisp, this namespace problem boils down to a question of
controlling how the reader translates textual names into symbols: if you
want two occurrences of the same name to be considered the same by the
evaluator, you need to make sure the reader uses the same symbol to
represent each name. Conversely, if you want two names to be considered
distinct, even if they happen to have the same textual name, you need
the reader to create different symbols to represent each name.
@menu
* How the Reader Uses Packages::
* A Bit of Package and Symbol Vocabulary::
* Three Standard Packages::
* Defining Your Own Packages::
* Packaging Reusable Libraries::
* Importing Individual Names::
* Packaging Mechanics::
* Package Gotchas::
@end menu

@node How the Reader Uses Packages
@section How the Reader Uses Packages
@anchor{#how-the-reader-uses-packages}
In Chapter 4 I discussed briefly how the Lisp reader translates names
into symbols, but I glossed over most of the details--now it's time to
take a closer look at what actually happens.

I'll start by describing the syntax of names understood by the reader
and how that syntax relates to packages. For the moment you can think of
a package as a table that maps strings to symbols. As you'll see in the
next section, the actual mapping is slightly more flexible than a simple
lookup table but not in ways that matter much to the reader. Each
package also has a name, which can be used to find the package using the
function @code{FIND-PACKAGE}.

The two key functions that the reader uses to access the name-to-symbol
mappings in a package are @code{FIND-SYMBOL} and @code{INTERN}. Both
these functions take a string and, optionally, a package. If not
supplied, the package argument defaults to the value of the global
variable @code{*PACKAGE*}, also called the @emph{current package}.

@code{FIND-SYMBOL} looks in the package for a symbol with the given
string for a name and returns it, or @code{NIL} if no symbol is found.
@code{INTERN} also will return an existing symbol; otherwise it creates
a new symbol with the string as its name and adds it to the package.

Most names you use are @emph{unqualified}, names that contain no colons.
When the reader reads such a name, it translates it to a symbol by
converting any unescaped letters to uppercase and passing the resulting
string to @code{INTERN}. Thus, each time the reader reads the same name
in the same package, it'll get the same symbol object. This is important
because the evaluator uses the object identity of symbols to determine
which function, variable, or other program element a given symbol refers
to. Thus, the reason an expression such as @code{(hello-world)} results
in calling a particular @code{hello-world} function is because the
reader returns the same symbol when it reads the function call as it did
when it read the @code{DEFUN} form that defined the function.

A name containing either a single colon or a double colon is a
package-qualified name. When the reader reads a package-qualified name,
it splits the name on the colon(s) and uses the first part as the name
of a package and the second part as the name of the symbol. The reader
looks up the appropriate package and uses it to translate the symbol
name to a symbol object.

A name containing only a single colon must refer to an @emph{external}
symbol--one the package @emph{exports} for public use. If the named
package doesn't contain a symbol with a given name, or if it does but it
hasn't been exported, the reader signals an error. A double-colon name
can refer to any symbol from the named package, though it's usually a
bad idea--the set of exported symbols defines a package's public
interface, and if you don't respect the package author's decision about
what names to make public and which ones to keep private, you're asking
for trouble down the road. On the other hand, sometimes a package author
will neglect to export a symbol that really ought to be public. In that
case, a double-colon name lets you get work done without having to wait
for the next version of the package to be released.

Two other bits of symbol syntax the reader understands are those for
keyword symbols and uninterned symbols. Keyword symbols are written with
names starting with a colon. Such symbols are interned in the package
named @code{KEYWORD} and automatically exported. Additionally, when the
reader interns a symbol in the @code{KEYWORD}, it also defines a
constant variable with the symbol as both its name and value. This is
why you can use keywords in argument lists without quoting them--when
they appear in a value position, they evaluate to themselves. Thus:

@verbatim
(eql ':foo :foo) ==> T
@end verbatim

The names of keyword symbols, like all symbols, are converted to all
uppercase by the reader before they're interned. The name doesn't
include the leading colon.

@verbatim
(symbol-name :foo) ==> "FOO"
@end verbatim

Uninterned symbols are written with a leading @code{#:}. These names
(minus the @code{#:}) are converted to uppercase as normal and then
translated into symbols, but the symbols aren't interned in any package;
each time the reader reads a @code{#:} name, it creates a new symbol.
Thus:

@verbatim
(eql '#:foo '#:foo) ==> NIL
@end verbatim

You'll rarely, if ever, write this syntax yourself, but will sometimes
see it when you print an s-expression containing symbols returned by the
function @code{GENSYM}.

@verbatim
(gensym) ==> #:G3128
@end verbatim

@node A Bit of Package and Symbol Vocabulary
@section A Bit of Package and Symbol Vocabulary
@anchor{#a-bit-of-package-and-symbol-vocabulary}
As I mentioned previously, the mapping from names to symbols implemented
by a package is slightly more flexible than a simple lookup table. At
its core, every package contains a name-to-symbol lookup table, but a
symbol can be made accessible via an unqualified name in a given package
in other ways. To talk sensibly about these other mechanisms, you'll
need a little bit of vocabulary.

To start with, all the symbols that can be found in a given package
using @code{FIND-SYMBOL} are said to be @emph{accessible} in that
package. In other words, the accessible symbols in a package are those
that can be referred to with unqualified names when the package is
current.

A symbol can be accessible in two ways. The first is for the package's
name-to-symbol table to contain an entry for the symbol, in which case
the symbol is said to be @emph{present} in the package. When the reader
interns a new symbol in a package, it's added to the package's
name-to-symbol table. The package in which a symbol is first interned is
called the symbol's @emph{home package}.

The other way a symbol can be accessible in a package is if the package
@emph{inherits} it. A package inherits symbols from other packages by
@emph{using} the other packages. Only @emph{external} symbols in the
used packages are inherited. A symbol is made external in a package by
@emph{exporting} it. In addition to causing it to be inherited by using
packages, exporting a symbol also--as you saw in the previous
section--makes it possible to refer to the symbol using a single-colon
qualified name.

To keep the mappings from names to symbols deterministic, the package
system allows only one symbol to be accessible in a given package for
each name. That is, a package can't have a present symbol and an
inherited symbol with the same name or inherit two different symbols,
from different packages, with the same name. However, you can resolve
conflicts by making one of the accessible symbols a @emph{shadowing}
symbol, which makes the other symbols of the same name inaccessible. In
addition to its name-to-symbol table, each package maintains a list of
shadowing symbols.

An existing symbol can be @emph{imported} into another package by adding
it to the package's name-to-symbol table. Thus, the same symbol can be
present in multiple packages. Sometimes you'll import symbols simply
because you want them to be accessible in the importing package without
using their home package. Other times you'll import a symbol because
only present symbols can be exported or be shadowing symbols. For
instance, if a package needs to use two packages that have external
symbols of the same name, one of the symbols must be imported into the
using package in order to be added to its shadowing list and make the
other symbol inaccessible.

Finally, a present symbol can be @emph{uninterned} from a package, which
causes it to be removed from the name-to-symbol table and, if it's a
shadowing symbol, from the shadowing list. You might unintern a symbol
from a package to resolve a conflict between the symbol and an external
symbol from a package you want to use. A symbol that isn't present in
any package is called an @emph{uninterned} symbol, can no longer be read
by the reader, and will be printed using the @code{#:foo} syntax.

@node Three Standard Packages
@section Three Standard Packages
@anchor{#three-standard-packages} In the next section I'll show you
how to define your own packages, including how to make one package use
another and how to export, shadow, and import symbols. But first let's
look at a few packages you've been using already. When you first start
Lisp, the value of @code{*PACKAGE*} is typically the
@code{COMMON-LISP-USER} package, also known as
@code{CL-USER}.@footnote{Every package has one official name and zero
or more @emph{nicknames} that can be used anywhere you need to use the
package name, such as in package-qualified names or to refer to the
package in a @code{DEFPACKAGE} or @code{IN-PACKAGE} form.}
@code{CL-USER} uses the package @code{COMMON-LISP}, which exports all
the names defined by the language standard. Thus, when you type an
expression at the REPL, all the names of standard functions, macros,
variables, and so on, will be translated to the symbols exported from
@code{COMMON-LISP}, and all other names will be interned in the
@code{COMMON-LISP-USER} package. For example, the name
@code{*PACKAGE*} is exported from @code{COMMON-LISP}--if you want to
see the value of @code{*PACKAGE*}, you can type this:

@verbatim
CL-USER> *package*
#<The COMMON-LISP-USER package>
@end verbatim

because @code{COMMON-LISP-USER} uses @code{COMMON-LISP}. Or you can use
a package-qualified name.

@verbatim
CL-USER> common-lisp:*package*
#<The COMMON-LISP-USER package>
@end verbatim

You can even use @code{COMMON-LISP}'s nickname, @code{CL}.

@verbatim
CL-USER> cl:*package*
#<The COMMON-LISP-USER package>
@end verbatim

But @code{*X*} isn't a symbol in @code{COMMON-LISP}, so you if type
this:

@verbatim
CL-USER> (defvar *x* 10)
*X*
@end verbatim

the reader reads @code{DEFVAR} as the symbol from the @code{COMMON-LISP}
package and @code{*X*} as a symbol in @code{COMMON-LISP-USER}.

The REPL can't start in the @code{COMMON-LISP} package because you're
not allowed to intern new symbols in it; @code{COMMON-LISP-USER}
serves as a "scratch" package where you can create your own names
while still having easy access to all the symbols in
@code{COMMON-LISP}.@footnote{@code{COMMON-LISP-USER} is also allowed
to provide access to symbols exported by other implementation-defined
packages.  While this is intended as a convenience for the user--it
makes implementation-specific functionality readily accessible--it can
also cause confusion for new Lispers: Lisp will complain about an
attempt to redefine some name that isn't listed in the language
standard. To see what packages @code{COMMON-LISP-USER} inherits
symbols from in a particular implementation, evaluate this expression
at the REPL:

@verbatim
(mapcar #'package-name (package-use-list :cl-user))
@end verbatim

And to find out what package a symbol came from originally, evaluate
this:

@verbatim
(package-name (symbol-package 'some-symbol))
@end verbatim

with @code{some-symbol} replaced by the symbol in question. For
instance:

@verbatim
(package-name (symbol-package 'car)) ==> "COMMON-LISP"
(package-name (symbol-package 'foo)) ==> "COMMON-LISP-USER"
@end verbatim

Symbols inherited from implementation-defined packages will return
some other value.} Typically, all packages you'll define will also use
@code{COMMON-LISP}, so you don't have to write things like this:

@verbatim
(cl:defun (x) (cl:+ x 2))
@end verbatim

The third standard package is the @code{KEYWORD} package, the package
the Lisp reader uses to intern names starting with colon. Thus, you can
also refer to any keyword symbol with an explicit package qualification
of @code{keyword} like this:

@verbatim
CL-USER> :a
:A
CL-USER> keyword:a
:A
CL-USER> (eql :a keyword:a)
T
@end verbatim

@node Defining Your Own Packages
@section Defining Your Own Packages
@anchor{#defining-your-own-packages}
Working in @code{COMMON-LISP-USER} is fine for experiments at the REPL,
but once you start writing actual programs you'll want to define new
packages so different programs loaded into the same Lisp environment
don't stomp on each other's names. And when you write libraries that you
intend to use in different contexts, you'll want to define separate
packages and then export the symbols that make up the libraries' public
APIs.

However, before you start defining packages, it's important to
understand one thing about what packages do @emph{not} do. Packages
don't provide direct control over who can call what function or access
what variable. They provide you with basic control over namespaces by
controlling how the reader translates textual names into symbol
objects, but it isn't until later, in the evaluator, that the symbol
is interpreted as the name of a function or variable or whatever else.
Thus, it doesn't make sense to talk about exporting a function or a
variable from a package. You can export symbols to make certain names
easier to refer to, but the package system doesn't allow you to
restrict how those names are used.@footnote{This is different from the
Java package system, which provides a namespace for classes but is
also involved in Java's access control mechanism. The non-Lisp
language with a package system most like Common Lisp's packages is
Perl.}

With that in mind, you can start looking at how to define packages and
tie them together. You define new packages with the macro
@code{DEFPACKAGE}, which allows you to not only create the package but
to specify what packages it uses, what symbols it exports, and what
symbols it imports from other packages and to resolve conflicts by
creating shadowing symbols.@footnote{All the manipulations performed
by @code{DEFPACKAGE} can also be performed with functions that man-
ipulate package objects.  However, since a package generally needs to
be fully defined before it can be used, those functions are rarely
used. Also, @code{DEFPACKAGE} takes care of performing all the package
manipulations in the right order--for instance, @code{DEFPACKAGE} adds
symbols to the shadowing list before it tries to use the used
packages.}

I'll describe the various options in terms of how you might use packages
while writing a program that organizes e-mail messages into a searchable
database. The program is purely hypothetical, as are the libraries I'll
refer to--the point is to look at how the packages used in such a
program might be structured.

The first package you'd need is one to provide a namespace for the
application--you want to be able to name your functions, variables, and
so on, without having to worry about name collisions with unrelated
code. So you'd define a new package with @code{DEFPACKAGE}.

If the application is simple enough to be written with no libraries
beyond the facilities provided by the language itself, you could define
a simple package like this:

@verbatim
(defpackage :com.gigamonkeys.email-db
  (:use :common-lisp))
@end verbatim

This defines a package, named @code{COM.GIGAMONKEYS.EMAIL-DB}, that
inherits all the symbols exported by the @code{COMMON-LISP}
package.@footnote{In many Lisp implementations the @code{:use} clause
is optional if you want only to @code{:use} @code{COMMON-LISP}--if
it's omitted, the package will automatically inherit names from an
implementation-defined list of packages that will usually include
@code{COMMON-LISP}. However, your code will be more portable if you
always explicitly specify the packages you want to @code{:use}. Those
who are averse to typing can use the package's nickname and write
@code{(:use :cl)}.}

You actually have several choices of how to represent the names of
packages and, as you'll see, the names of symbols in a
@code{DEFPACKAGE}. Packages and symbols are named with
strings. However, in a @code{DEFPACKAGE} form, you can specify the
names of packages and symbols with @emph{string designators}. A string
designator is either a string, which designates itself; a symbol,
which designates its name; or a character, which designates a
one-character string containing just the character. Using keyword
symbols, as in the previous @code{DEFPACKAGE}, is a common style that
allows you to write the names in lowercase--the reader will convert
the names to uppercase for you. You could also write the
@code{DEFPACKAGE} with strings, but then you have to write them in all
uppercase, because the true names of most symbols and packages are in
fact uppercase because of the case conversion performed by the
reader.@footnote{Using keywords instead of strings has another
advantage--Allegro provides a "modern mode" Lisp in which the reader
does no case conversion of names and in which, instead of a
@code{COMMON-LISP} package with uppercase names, provides a
@code{common-lisp} package with lowercase names. Strictly speaking,
this Lisp isn't a conforming Common Lisp since all the names in the
standard are defined to be uppercase. But if you write your
@code{DEFPACKAGE} forms using keyword symbols, they will work both in
Common Lisp and in this near relative.}

@verbatim
(defpackage "COM.GIGAMONKEYS.EMAIL-DB"
  (:use "COMMON-LISP"))
@end verbatim

You could also use nonkeyword symbols--the names in @code{DEFPACKAGE}
aren't evaluated--but then the very act of reading the
@code{DEFPACKAGE} form would cause those symbols to be interned in the
current package, which at the very least will pollute that namespace
and may also cause problems later if you try to use the
package.@footnote{Some folks, instead of keywords, use uninterned
symbols, using the @code{#:} syntax.

@verbatim
(defpackage #:com.gigamonkeys.email-db
  (:use #:common-lisp))
@end verbatim

This saves a tiny bit of memory by not interning any symbols in the
keyword package--the symbol can become garbage after @code{DEFPACKAGE}
(or the code it expands into) is done with it. However, the difference
is so slight that it really boils down to a matter of aesthetics.}

To read code in this package, you need to make it the current package
with the @code{IN-PACKAGE} macro:

@verbatim
(in-package :com.gigamonkeys.email-db)
@end verbatim

If you type this expression at the REPL, it will change the value of
@code{*PACKAGE*}, affecting how the REPL reads subsequent expressions,
until you change it with another call to @code{IN-PACKAGE}. Similarly,
if you include an @code{IN-PACKAGE} in a file that's loaded with
@code{LOAD} or compiled with @code{COMPILE-FILE}, it will change the
package, affecting the way subsequent expressions in the file are
read.@footnote{The reason to use @code{IN-PACKAGE} instead of just
@code{SETF}ing @code{*PACKAGE*} is that @code{IN-PACKAGE} expands into
code that will run when the file is compiled by @code{COMPILE-FILE} as
well as when the file is loaded, changing the way the reader reads the
rest of the file during compilation.}

With the current package set to the @code{COM.GIGAMONKEYS.EMAIL-DB}
package, other than names inherited from the @code{COMMON-LISP} package,
you can use any name you want for whatever purpose you want. Thus, you
could define a new @code{hello-world} function that could coexist with
the @code{hello-world} function previously defined in
@code{COMMON-LISP-USER}. Here's the behavior of the existing function:

@verbatim
CL-USER> (hello-world)
hello, world
NIL
@end verbatim

Now you can switch to the new package using
@code{IN-PACKAGE}.@footnote{In the REPL buffer in SLIME you can also
change packages with a REPL shortcut. Type a comma, and then enter
@code{change-package} at the @code{Command:} prompt.} Notice how the
prompt changes--the exact form is determined by the development
environment, but in SLIME the default prompt consists of an
abbreviated version of the package name.

@verbatim
CL-USER> (in-package :com.gigamonkeys.email-db)
#<The COM.GIGAMONKEYS.EMAIL-DB package>
EMAIL-DB> 
@end verbatim

You can define a new @code{hello-world} in this package:

@verbatim
EMAIL-DB> (defun hello-world () (format t "hello from EMAIL-DB package~%"))
HELLO-WORLD
@end verbatim

And test it, like this:

@verbatim
EMAIL-DB> (hello-world)
hello from EMAIL-DB package
NIL
@end verbatim

Now switch back to @code{CL-USER}.

@verbatim
EMAIL-DB> (in-package :cl-user)
#<The COMMON-LISP-USER package>
CL-USER> 
@end verbatim

And the old function is undisturbed.

@verbatim
CL-USER> (hello-world)
hello, world
NIL
@end verbatim

@node Packaging Reusable Libraries
@section Packaging Reusable Libraries
@anchor{#packaging-reusable-libraries}
While working on the e-mail database, you might write several functions
related to storing and retrieving text that don't have anything in
particular to do with e-mail. You might realize that those functions
could be useful in other programs and decide to repackage them as a
library. You should define a new package, but this time you'll export
certain names to make them available to other packages.

@verbatim
(defpackage :com.gigamonkeys.text-db
  (:use :common-lisp)
  (:export :open-db   
           :save
           :store))
@end verbatim

Again, you use the @code{COMMON-LISP} package, because you'll need
access to standard functions within @code{COM.GIGAMONKEYS.TEXT-DB}. The
@code{:export} clause specifies names that will be external in
@code{COM.GIGAMONKEYS.TEXT-DB} and thus accessible in packages that
@code{:use} it. Therefore, after you've defined this package, you can
change the definition of the main application package to the following:

@verbatim
(defpackage :com.gigamonkeys.email-db
  (:use :common-lisp :com.gigamonkeys.text-db))
@end verbatim

Now code written in @code{COM.GIGAMONKEYS.EMAIL-DB} can use unqualified
names to refer to the exported symbols from both @code{COMMON-LISP} and
@code{COM.GIGAMONKEYS.TEXT-DB}. All other names will continue to be
interned directly in the @code{COM.GIGAMONKEYS.EMAIL-DB} package.

@node Importing Individual Names
@section Importing Individual Names
@anchor{#importing-individual-names} Now suppose you find a
third-party library of functions for manipulating e-mail messages. The
names used in the library's API are exported from the package
@code{COM.ACME.EMAIL}, so you could @code{:use} that package to get
easy access to those names. But suppose you need to use only one
function from this library, and other exported symbols conflict with
names you already use (or plan to use) in our own
code.@footnote{During development, if you try to @code{:use} a package
that exports a symbol with the same name as a symbol already interned
in the using package, Lisp will signal an error and typically offer
you a restart that will unintern the offending symbol from the using
package. For more on this, see the section "Package Gotchas."} In this
case, you can import the one symbol you need with an
@code{:import-from} clause in the @code{DEFPACKAGE}.  For instance, if
the name of the function you want to use is
@code{parse-email-address}, you can change the @code{DEFPACKAGE} to
this:

@verbatim
(defpackage :com.gigamonkeys.email-db
  (:use :common-lisp :com.gigamonkeys.text-db)
  (:import-from :com.acme.email :parse-email-address))
@end verbatim

Now anywhere the name @code{parse-email-address} appears in code read in
the @code{COM.GIGAMONKEYS.EMAIL-DB} package, it will be read as the
symbol from @code{COM.ACME.EMAIL}. If you need to import more than one
symbol from a single package, you can include multiple names after the
package name in a single @code{:import-from} clause. A @code{DEFPACKAGE}
can also include multiple @code{:import-from} clauses in order to import
symbols from different packages.

Occasionally you'll run into the opposite situation--a package may
export a bunch of names you want to use and a few you don't. Rather than
listing all the symbols you @emph{do} want to use in an
@code{:import-from} clause, you can instead @code{:use} the package and
then list the names you @emph{don't} want to inherit in a @code{:shadow}
clause. For instance, suppose the @code{COM.ACME.TEXT} package exports a
bunch of names of functions and classes used in text processing. Further
suppose that most of these functions and classes are ones you'll want to
use in your code, but one of the names, @code{build-index}, conflicts
with a name you've already used. You can make the @code{build-index}
from @code{COM.ACME.TEXT} inaccessible by shadowing it.

@verbatim
(defpackage :com.gigamonkeys.email-db
  (:use
   :common-lisp
   :com.gigamonkeys.text-db
   :com.acme.text)
  (:import-from :com.acme.email :parse-email-address)
  (:shadow :build-index))
@end verbatim

The @code{:shadow} clause causes a new symbol named @code{BUILD-INDEX}
to be created and added directly to @code{COM.GIGAMONKEYS.EMAIL-DB}'s
name-to-symbol map. Now if the reader reads the name @code{BUILD-INDEX},
it will translate it to the symbol in @code{COM.GIGAMONKEYS.EMAIL-DB}'s
map, rather than the one that would otherwise be inherited from
@code{COM.ACME.TEXT}. The new symbol is also added to a @emph{shadowing
symbols list} that's part of the @code{COM.GIGAMONKEYS.EMAIL-DB}
package, so if you later use another package that also exports a
@code{BUILD-INDEX} symbol, the package system will know there's no
conflict--that you want the symbol from @code{COM.GIGAMONKEYS.EMAIL-DB}
to be used rather than any other symbols with the same name inherited
from other packages.

A similar situation can arise if you want to use two packages that
export the same name. In this case the reader won't know which inherited
name to use when it reads the textual name. In such situations you must
resolve the ambiguity by shadowing the conflicting names. If you don't
need to use the name from either package, you could shadow the name with
a @code{:shadow} clause, creating a new symbol with the same name in
your package. But if you actually want to use one of the inherited
symbols, then you need to resolve the ambiguity with a
@code{:shadowing-import-from} clause. Like an @code{:import-from}
clause, a @code{:shadowing-import-from} clause consists of a package
name followed by the names to import from that package. For instance, if
@code{COM.ACME.TEXT} exports a name @code{SAVE} that conflicts with the
name exported from @code{COM.GIGAMONKEYS.TEXT-DB}, you could resolve the
ambiguity with the following @code{DEFPACKAGE}:

@verbatim
(defpackage :com.gigamonkeys.email-db
  (:use
   :common-lisp
   :com.gigamonkeys.text-db
   :com.acme.text)
  (:import-from :com.acme.email :parse-email-address)
  (:shadow :build-index)
  (:shadowing-import-from :com.gigamonkeys.text-db :save))
@end verbatim

@node Packaging Mechanics
@section Packaging Mechanics
@anchor{#packaging-mechanics}
That covers the basics of how to use packages to manage namespaces in
several common situations. However, another level of how to use packages
is worth discussing--the raw mechanics of how to organize code that uses
different packages. In this section I'll discuss a few rules of thumb
about how to organize code--where to put your @code{DEFPACKAGE} forms
relative to the code that uses your packages via @code{IN-PACKAGE}.

Because packages are used by the reader, a package must be defined
before you can @code{LOAD} or @code{COMPILE-FILE} a file that contains
an @code{IN-PACKAGE} expression switching to that package. Packages also
must be defined before other @code{DEFPACKAGE} forms can refer to them.
For instance, if you're going to @code{:use}
@code{COM.GIGAMONKEYS.TEXT-DB} in @code{COM.GIGAMONKEYS.EMAIL-DB}, then
@code{COM.GIGAMONKEYS.TEXT-DB}'s @code{DEFPACKAGE} must be evaluated
before the @code{DEFPACKAGE} of @code{COM.GIGAMONKEYS.EMAIL-DB}.

The best first step toward making sure packages exist when they need to
is to put all your @code{DEFPACKAGE}s in files separate from the code
that needs to be read in those packages. Some folks like to create a
@code{foo-package.lisp} file for each individual package, and others
create a single @code{packages.lisp} that contains all the
@code{DEFPACKAGE} forms for a group of related packages. Either approach
is reasonable, though the one-file-per-package approach also requires
that you arrange to load the individual files in the right order
according to the interpackage dependencies.

Either way, once all the @code{DEFPACKAGE} forms have been separated
from the code that will be read in the packages they define, you can
arrange to @code{LOAD} the files containing the @code{DEFPACKAGE}s
before you compile or load any of the other files. For simple programs
you can do this by hand: simply @code{LOAD} the file or files containing
the @code{DEFPACKAGE} forms, possibly compiling them with
@code{COMPILE-FILE} first. Then @code{LOAD} the files that use those
packages, again optionally compiling them first with
@code{COMPILE-FILE}. Note, however, that the packages don't exist until
you @code{LOAD} the package definitions, either the source or the files
produced by @code{COMPILE-FILE}. Thus, if you're compiling everything,
you must still @code{LOAD} all the package definitions before you can
@code{COMPILE-FILE} any files to be read in the packages.

Doing these steps by hand will get tedious after a while. For simple
programs you can automate the steps by writing a file,
@code{load.lisp}, that contains the appropriate @code{LOAD} and
@code{COMPILE-FILE} calls in the right order. Then you can just
@code{LOAD} that file. For more complex programs you'll want to use a
@emph{system definition} facility to manage loading and compiling
files in the right order.@footnote{The code for the "Practical"
chapters, available from this book's Web site, uses the ASDF system
definition library. ASDF stands for Another System Definition
Facility.}

The other key rule of thumb is that each file should contain exactly one
@code{IN-PACKAGE} form, and it should be the first form in the file
other than comments. Files containing @code{DEFPACKAGE} forms should
start with @code{(in-package "COMMON-LISP-USER")}, and all other files
should contain an @code{IN-PACKAGE} of one of your packages.

If you violate this rule and switch packages in the middle of a file,
you'll confuse human readers who don't notice the second
@code{IN-PACKAGE}. Also, many Lisp development environments,
particularly Emacs-based ones such as SLIME, look for an
@code{IN-PACKAGE} to determine the package they should use when
communicating with Common Lisp. Multiple @code{IN-PACKAGE} forms per
file may confuse these tools as well.

On the other hand, it's fine to have multiple files read in the same
package, each with an identical @code{IN-PACKAGE} form. It's just a
matter of how you like to organize your code.

The other bit of packaging mechanics has to do with how to name
packages. Package names live in a flat namespace--package names are just
strings, and different packages must have textually distinct names.
Thus, you have to consider the possibility of conflicts between package
names. If you're using only packages you developed yourself, then you
can probably get away with using short names for your packages. But if
you're planning to use third-party libraries or to publish your code for
use by other programmers, then you need to follow a naming convention
that will minimize the possibility of name collisions between different
packages. Many Lispers these days are adopting Java-style names, like
the ones used in this chapter, consisting of a reversed Internet domain
name followed by a dot and a descriptive string.

@node Package Gotchas
@section Package Gotchas
@anchor{#package-gotchas}
Once you're familiar with packages, you won't spend a bunch of time
thinking about them. There's just not that much to them. However, a
couple of gotchas that bite most new Lisp programmers make the package
system seem more complicated and unfriendly than it really is.

The number-one gotcha arises most commonly when playing around at the
REPL. You'll be looking at some library that defines certain interesting
functions. You'll try to call one of the functions like this:

@verbatim
CL-USER> (foo)
@end verbatim

and get dropped into the debugger with this error:

@verbatim
attempt to call `FOO' which is an undefined function.
   [Condition of type UNDEFINED-FUNCTION]

Restarts:
  0: [TRY-AGAIN] Try calling FOO again.
  1: [RETURN-VALUE] Return a value instead of calling FOO.
  2: [USE-VALUE] Try calling a function other than FOO.
  3: [STORE-VALUE] Setf the symbol-function of FOO and call it again.
  4: [ABORT] Abort handling SLIME request.
  5: [ABORT] Abort entirely from this (lisp) process.
@end verbatim

Ah, of course--you forgot to use the library's package. So you quit the
debugger and try to @code{USE-PACKAGE} the library's package in order to
get access to the name @code{FOO} so you can call the function.

@verbatim
CL-USER> (use-package :foolib)
@end verbatim

But that drops you back into the debugger with this error message:

@verbatim
Using package `FOOLIB' results in name conflicts for these symbols: FOO
   [Condition of type PACKAGE-ERROR]

Restarts:
  0: [CONTINUE] Unintern the conflicting symbols from the `COMMON-LISP-USER' package.
  1: [ABORT] Abort handling SLIME request.
  2: [ABORT] Abort entirely from this (lisp) process.
@end verbatim

Huh? The problem is the first time you called @code{foo}, the reader
read the name @code{foo} and interned it in @code{CL-USER} before the
evaluator got hold of it and discovered that this newly interned symbol
isn't the name of a function. This new symbol then conflicts with the
symbol of the same name exported from the @code{FOOLIB} package. If you
had remembered to @code{USE-PACKAGE} @code{FOOLIB} before you tried to
call @code{foo}, the reader would have read @code{foo} as the inherited
symbol and not interned a @code{foo} symbol in @code{CL-USER}.

However, all isn't lost, because the first restart offered by the
debugger will patch things up in just the right way: it will unintern
the @code{foo} symbol from @code{COMMON-LISP-USER}, putting the
@code{CL-USER} package back to the state it was in before you called
@code{foo}, allowing the @code{USE-PACKAGE} to proceed and allowing for
the inherited @code{foo} to be available in @code{CL-USER}.

This kind of problem can also occur when loading and compiling files.
For instance, if you defined a package, @code{MY-APP}, for code that was
going to use functions with names from the @code{FOOLIB} package, but
forgot to @code{:use} @code{FOOLIB}, when you compile the files with an
@code{(in-package :my-app)} in them, the reader will intern new symbols
in @code{MY-APP} for the names that were supposed to be read as symbols
from @code{FOOLIB}. When you try to run the compiled code, you'll get
undefined function errors. If you then try to redefine the @code{MY-APP}
package to @code{:use} @code{FOOLIB}, you'll get the conflicting symbols
error. The solution is the same: select the restart to unintern the
conflicting symbols from @code{MY-APP}. You'll then need to recompile
the code in the @code{MY-APP} package so it will refer to the inherited
names.

The next gotcha is essentially the reverse of the first gotcha. In this
case, you'd have defined a package--again, let's say it's
@code{MY-APP}--that uses another package, say, @code{FOOLIB}. Now you
start writing code in the @code{MY-APP} package. Although you used
@code{FOOLIB} in order to be able to refer to the @code{foo} function,
@code{FOOLIB} may export other symbols as well. If you use one of those
exported symbols--say, @code{bar}--as the name of a function in your own
code, Lisp won't complain. Instead, the name of your function will be
the symbol exported by @code{FOOLIB}, which will clobber the definition
of @code{bar} from @code{FOOLIB}.

This gotcha is more insidious because it doesn't cause an error--from
the evaluator's point of view it's just being asked to associate a new
function with an old name, something that's perfectly legal. It's
suspect only because the code doing the redefining was read with a
different value for @code{*PACKAGE*} than the name's package. But the
evaluator doesn't necessarily know that. However, in most Lisps you'll
get an warning about "@code{redefining BAR, originally defined in}?".
You should heed those warnings. If you clobber a definition from a
library, you can restore it by reloading the library code with
@code{LOAD}.@footnote{Some Common Lisp implementations, such as
Allegro and SBCL, provide a facility for "locking" the symbols in a
particular package so they can be used in defining forms such as
@code{DEFUN}, @code{DEFVAR}, and @code{DEFCLASS} only when their home
package is the current package.}

The last package-related gotcha is, by comparison, quite trivial, but it
bites most Lisp programmers at least a few times: you define a package
that uses @code{COMMON-LISP} and maybe a few libraries. Then at the REPL
you change to that package to play around. Then you decide to quit Lisp
altogether and try to call @code{(quit)}. However, @code{quit} isn't a
name from the @code{COMMON-LISP} package--it's defined by the
implementation in some implementation-specific package that happens to
be used by @code{COMMON-LISP-USER}. The solution is simple--change
packages back to @code{CL-USER} to quit. Or use the SLIME REPL shortcut
@code{quit}, which will also save you from having to remember that in
certain Common Lisp implementations the function to quit is @code{exit},
not @code{quit}.

You're almost done with your tour of Common Lisp. In the next chapter
I'll discuss the details of the extended @code{LOOP} macro. After that,
the rest of the book is devoted to "practicals": a spam filter, a
library for parsing binary files, and various parts of a streaming MP3
server with a Web interface.

@node LOOP for Black Belts
@chapter LOOP for Black Belts
@anchor{#loop-for-black-belts}
In Chapter 7 I briefly discussed the extended @code{LOOP} macro. As I
mentioned then, @code{LOOP} provides what is essentially a
special-purpose language just for writing iteration constructs.

This might seem like a lot of bother--inventing a whole language just
for writing loops. But if you think about the ways loops are used in
programs, it actually makes a fair bit of sense. Any program of any size
at all will contain quite a number of loops. And while they won't all be
the same, they won't all be unique either; patterns will emerge,
particularly if you include the code immediately preceding and following
the loops--patterns of how things are set up for the loop, patterns in
what gets done in the loop proper, and patterns in what gets done after
the loop. The @code{LOOP} language captures these patterns so you can
express them directly.

The @code{LOOP} macro has a lot of parts--one of the main complaints of
@code{LOOP}'s detractors is that it's too complex. In this chapter, I'll
tackle @code{LOOP} head on, giving you a systematic tour of the various
parts and how they fit together.
@menu
* The Parts of a LOOP::
* Iteration Control::
* Counting Loops::
* Looping Over Collections and Packages::
* Equals-Then Iteration::
* Local Variables::
* Destructuring Variables::
* Value Accumulation::
* Unconditional Execution::
* Conditional Execution::
* Setting Up and Tearing Down::
* Termination Tests::
* Putting It All Together::
@end menu

@node The Parts of a LOOP
@section The Parts of a LOOP
@anchor{#the-parts-of-a-loop}
You can do the following in a @code{LOOP}:

@itemize
@item
Step variables numerically and over various data structures
@item
Collect, count, sum, minimize, and maximize values seen while looping
@item
Execute arbitrary Lisp expressions
@item
Decide when to terminate the loop
@item
Conditionally do any of these
@end itemize

Additionally, @code{LOOP} provides syntax for the following:

@itemize
@item
Creating local variables for use within the loop
@item
Specifying arbitrary Lisp expressions to run before and after the loop
proper
@end itemize

The basic structure of a @code{LOOP} is a set of clauses, each of
which begins with a @emph{loop keyword}.@footnote{The term @emph{loop
keyword} is a bit unfortunate, as loop keywords aren't keywords in the
normal sense of being symbols in the @code{KEYWORD} package. In fact,
any symbol, from any package, with the appropriate name will do; the
@code{LOOP} macro cares only about their names. Typically, though,
they're written with no package qualifier and are thus read (and
interned as necessary) in the current package.} How each clause is
parsed by the @code{LOOP} macro depends on the keyword. Some of the
main keywords, which you saw in Chapter 7, are @code{for},
@code{collecting}, @code{summing}, @code{counting}, @code{do}, and
@code{finally}.

@node Iteration Control
@section Iteration Control
@anchor{#iteration-control} Most of the so-called iteration control
clauses start with the loop keyword @code{for}, or its synonym
@code{as},@footnote{Because one of the goals of @code{LOOP} is to
allow loop expressions to be written with a quasi-English syntax, many
of the keywords have synonyms that are treated the same by @code{LOOP}
but allow some freedom to express things in slightly more idiomatic
English for different contexts.}  followed by the name of a
variable. What follows after the variable name depends on the type of
@code{for} clause.

The subclauses of a @code{for} clause can iterate over the following:

@itemize
@item
Ranges of numbers, up or down, by specified intervals
@item
The individual items of a list
@item
The cons cells that make up a list
@item
The elements of a vector, including subtypes such as strings and bit
vectors
@item
The pairs of a hash table
@item
The symbols in a package
@item
The results of repeatedly evaluating a given form
@end itemize

A single loop can have multiple @code{for} clauses with each clause
naming its own variable. When a loop has multiple @code{for} clauses,
the loop terminates as soon as any @code{for} clause reaches its end
condition. For instance, the following loop:

@verbatim
(loop
  for item in list
  for i from 1 to 10
  do (something))
@end verbatim

will iterate at most ten times but may stop sooner if @code{list}
contains fewer than ten items.

@node Counting Loops
@section Counting Loops
@anchor{#counting-loops}
Arithmetic iteration clauses control the number of times the loop body
will be executed by stepping a variable over a range of numbers,
executing the body once per step. These clauses consist of from one to
three of the following @emph{prepositional phrases} after the @code{for}
(or @code{as}): the @emph{from where} phrase, the @emph{to where}
phrase, and the @emph{by how much} phrase.

The @emph{from where} phrase specifies the initial value of the clause's
variable. It consists of one of the prepositions @code{from},
@code{downfrom}, or @code{upfrom} followed by a form, which supplies the
initial value (a number).

The @emph{to where} phrase specifies a stopping point for the loop and
consists of one of the prepositions @code{to}, @code{upto},
@code{below}, @code{downto}, or @code{above} followed by a form, which
supplies the stopping point. With @code{upto} and @code{downto}, the
loop body will be terminated (without executing the body again) when the
variable passes the stopping point; with @code{below} and @code{above},
it stops one iteration earlier.The @emph{by how much} phrase consists of
the prepositions @code{by} and a form, which must evaluate to a positive
number. The variable will be stepped (up or down, as determined by the
other phrases) by this amount on each iteration or by one if it's
omitted.

You must specify at least one of these prepositional phrases. The
defaults are to start at zero, increment the variable by one at each
iteration, and go forever or, more likely, until some other clause
terminates the loop. You can modify any or all of these defaults by
adding the appropriate prepositional phrases. The only wrinkle is that
if you want decremental stepping, there's no default @emph{from where}
value, so you must specify one with either @code{from} or
@code{downfrom}. So, the following:

@verbatim
(loop for i upto 10 collect i)
@end verbatim

collects the first eleven integers (zero to ten), but the behavior of
this:

@verbatim
(loop for i downto -10 collect i)         ; wrong
@end verbatim

is undefined. Instead, you need to write this:

@verbatim
(loop for i from 0 downto -10 collect i)
@end verbatim

Also note that because @code{LOOP} is a macro, which runs at compile
time, it has to be able to determine the direction to step the variable
based solely on the prepositions--not the values of the forms, which may
not be known until runtime. So, the following:

@verbatim
(loop for i from 10 to 20 ...) 
@end verbatim

works fine since the default is incremental stepping. But this:

@verbatim
(loop for i from 20 to 10 ...) 
@end verbatim

won't know to count down from twenty to ten. Worse yet, it won't give
you an error--it will just not execute the loop since @code{i} is
already greater than ten. Instead, you must write this:

@verbatim
(loop for i from 20 downto 10 ...)
@end verbatim

or this:

@verbatim
(loop for i downfrom 20 to 10 ...)
@end verbatim

Finally, if you just want a loop that repeats a certain number of times,
you can replace a clause of the following form:

@verbatim
for i from 1 to number-form
@end verbatim

with a @code{repeat} clause like this:

@verbatim
repeat number-form
@end verbatim

These clauses are identical in effect except the @code{repeat} clause
doesn't create an explicit loop variable.

@node Looping Over Collections and Packages
@section Looping Over Collections and Packages
@anchor{#looping-over-collections-and-packages}
The @code{for} clauses for iterating over lists are much simpler than
the arithmetic clauses. They support only two prepositional phrases,
@code{in} and @code{on}.

A phrase of this form:

@verbatim
for var in list-form
@end verbatim

steps @emph{var} over all the elements of the list produced by
evaluating @emph{list-form}.

@verbatim
(loop for i in (list 10 20 30 40) collect i) ==> (10 20 30 40)
@end verbatim

Occasionally this clause is supplemented with a @code{by} phrase, which
specifies a function to use to move down the list. The default is
@code{CDR} but can be any function that takes a list and returns a
sublist. For instance, you could collect every other element of a list
with a loop like this:

@verbatim
(loop for i in (list 10 20 30 40) by #'cddr collect i) ==> (10 30)
@end verbatim

An @code{on} prepositional phrase is used to step @emph{var} over the
cons cells that make up a list.

@verbatim
(loop for x on (list 10 20 30) collect x) ==> ((10 20 30) (20 30) (30))
@end verbatim

This phrase too can take a @code{by} preposition:

@verbatim
(loop for x on (list 10 20 30 40) by #'cddr collect x) ==> ((10 20 30 40) (30 40))
@end verbatim

Looping over the elements of a vector (which includes strings and bit
vectors) is similar to looping over the elements of a list except the
preposition @code{across} is used instead of @code{in}.@footnote{You
may wonder why @code{LOOP} can't figure out whether it's looping over
a list or a vector without needing different prepositions. This is
another consequence of @code{LOOP} being a macro: the value of the
list or vector won't be known until runtime, but @code{LOOP}, as a
macro, has to generate code at compile time. And @code{LOOP}'s
designers wanted it to generate extremely efficient code.  To be able
to generate efficient code for looping across, say, a vector, it needs
to know at compile time that the value will be a vector at
runtime--thus, the different prepositions are needed.} For instance:

@verbatim
(loop for x across "abcd" collect x) ==> (#\a #\b #\c #\d)
@end verbatim

Iterating over a hash table or package is slightly more complicated
because hash tables and packages have different sets of values you might
want to iterate over--the keys or values in a hash table and the
different kinds of symbols in a package. Both kinds of iteration follow
the same pattern. The basic pattern looks like this:

@verbatim
(loop for var being the things in hash-or-package ...)
@end verbatim

For hash tables, the possible values for @emph{things} are
@code{hash-keys} and @code{hash-values}, which cause @code{var} to be
bound to successive values of either the keys or the values of the hash
table. The @emph{hash-or-package} form is evaluated once to produce a
value, which must be a hash table.

To iterate over a package, @emph{things} can be @code{symbols},
@code{present-symbols}, and @code{external-symbols}, which cause
@emph{var} to be bound to each of the symbols accessible in a package,
each of the symbols present in a package (in other words, interned or
imported into that package), or each of the symbols that have been
exported from the package. The @emph{hash-or-package} form is evaluated
to produce the name of a package, which is looked up as if by
@code{FIND-PACKAGE} or a package object. Synonyms are also available for
parts of the @code{for} clause. In place of @code{the}, you can use
@code{each}; you can use @code{of} instead of @code{in}; and you can
write the @emph{things} in the singular (for example, @code{hash-key} or
@code{symbol}).

Finally, since you'll often want both the keys and the values when
iterating over a hash table, the hash table clauses support a
@code{using} subclause at the end of the hash table clause.

@verbatim
(loop for k being the hash-keys in h using (hash-value v) ...)
(loop for v being the hash-values in h using (hash-key k) ...)
@end verbatim

Both of these loops will bind @code{k} to each key in the hash table
and @code{v} to the corresponding value. Note that the first element
of the @code{using} subclause must be in the singular
form.@footnote{Don't ask me why @code{LOOP}'s authors chickened out on
the no-parentheses style for the @code{using} subclause.}

@node Equals-Then Iteration
@section Equals-Then Iteration
@anchor{#equals-then-iteration}
If none of the other @code{for} clauses supports exactly the form of
variable stepping you need, you can take complete control over stepping
with an @emph{equals-then} clause. This clause is similar to the binding
clauses in a @code{DO} loop but cast in a more Algolish syntax. The
template is as follows:

@verbatim
(loop for var = initial-value-form [ then step-form ] ...)
@end verbatim

As usual, @emph{var} is the name of the variable to be stepped. Its
initial value is obtained by evaluating @emph{initial-value-form} once
before the first iteration. In each subsequent iteration,
@emph{step-form} is evaluated, and its value becomes the new value of
@emph{var}. With no @code{then} part to the clause, the
@emph{initial-value-form} is reevaluated on each iteration to provide
the new value. Note that this is different from a @code{DO} binding
clause with no step form.

The @emph{step-form} can refer to other loop variables, including
variables created by other @code{for} clauses later in the loop. For
instance:

@verbatim
(loop repeat 5 
      for x = 0 then y
      for y = 1 then (+ x y)
      collect y) ==> (1 2 4 8 16)
@end verbatim

However, note that each @code{for} clause is evaluated separately in the
order it appears. So in the previous loop, on the second iteration
@code{x} is set to the value of @code{y} before @code{y} changes (in
other words, @code{1}). But @code{y} is then set to the sum of its old
value (still @code{1}) and the new value of @code{x}. If the order of
the @code{for} clauses is reversed, the results change.

@verbatim
(loop repeat 5
      for y = 1 then (+ x y)
      for x = 0 then y
      collect y) ==> (1 1 2 4 8)
@end verbatim

Often, however, you'll want the step forms for multiple variables to be
evaluated before any of the variables is given its new value (similar to
how @code{DO} steps its variables). In that case, you can join multiple
@code{for} clauses by replacing all but the first @code{for} with
@code{and}. You saw this formulation already in the @code{LOOP} version
of the Fibonacci computation in Chapter 7. Here's another variant, based
on the two previous examples:

@verbatim
(loop repeat 5 
      for x = 0 then y
      and y = 1 then (+ x y)
      collect y) ==> (1 1 2 3 5)
@end verbatim

@node Local Variables
@section Local Variables
@anchor{#local-variables}
While the main variables needed within a loop are usually declared
implicitly in @code{for} clauses, sometimes you'll need auxiliary
variables, which you can declare with @code{with} clauses.

@verbatim
with var [ = value-form ]
@end verbatim

The name @emph{var} becomes the name of a local variable that will cease
to exist when the loop finishes. If the @code{with} clause contains an
@code{=} @code{value-form} part, the variable will be initialized,
before the first iteration of the loop, to the value of
@emph{value-form}.

Multiple @code{with} clauses can appear in a loop; each clause is
evaluated independently in the order it appears and the value is
assigned before proceeding to the next clause, allowing later variables
to depend on the value of already declared variables. Mutually
independent variables can be declared in one @code{with} clause with an
@code{and} between each declaration.

@node Destructuring Variables
@section Destructuring Variables
@anchor{#destructuring-variables}
One handy feature of @code{LOOP} I haven't mentioned yet is the ability
to destructure list values assigned to loop variables. This lets you
take apart the value of lists that would otherwise be assigned to a loop
variable, similar to the way @code{DESTRUCTURING-BIND} works but a bit
less elaborate. Basically, you can replace any loop variable in a
@code{for} or @code{with} clause with a tree of symbols, and the list
value that would have been assigned to the simple variable will instead
be destructured into variables named by the symbols in the tree. A
simple example looks like this:

@verbatim
CL-USER> (loop for (a b) in '((1 2) (3 4) (5 6))
            do (format t "a: ~a; b: ~a~%" a b))
a: 1; b: 2
a: 3; b: 4
a: 5; b: 6
NIL
@end verbatim

The tree can also include dotted lists, in which case the name after the
dot acts like a @code{&rest} parameter, being bound to a list containing
any remaining elements of the list. This is particularly handy with
@code{for}/@code{on} loops since the value is always a list. For
instance, this @code{LOOP} (which I used in Chapter 18 to emit a
comma-delimited list):

@verbatim
(loop for cons on list
    do (format t "~a" (car cons))
    when (cdr cons) do (format t ", "))
@end verbatim

could also be written like this:

@verbatim
(loop for (item . rest) on list
    do (format t "~a" item)
    when rest do (format t ", "))
@end verbatim

If you want to ignore a value in the destructured list, you can use
@code{NIL} in place of a variable name.

@verbatim
(loop for (a nil) in '((1 2) (3 4) (5 6)) collect a) ==> (1 3 5)
@end verbatim

If the destructuring list contains more variables than there are values
in the list, the extra variables are set to @code{NIL}, making all the
variables essentially like @code{&optional} parameters. There isn't,
however, any equivalent to @code{&key} parameters.

@node Value Accumulation
@section Value Accumulation
@anchor{#value-accumulation}
The value accumulation clauses are perhaps the most powerful part of
@code{LOOP}. While the iteration control clauses provide a concise
syntax for expressing the basic mechanics of looping, they aren't
dramatically different from the equivalent mechanisms provided by
@code{DO}, @code{DOLIST}, and @code{DOTIMES}.

The value accumulation clauses, on the other hand, provide a concise
notation for a handful of common loop idioms having to do with
accumulating values while looping. Each accumulation clause starts with
a verb and follows this pattern:

@verbatim
verb form [ into var ]
@end verbatim

Each time through the loop, an accumulation clause evaluates @emph{form}
and saves the value in a manner determined by the @emph{verb}. With an
@code{into} subclause, the value is saved into the variable named by
@emph{var}. The variable is local to the loop, as if it'd been declared
in a @code{with} clause. With no @code{into} subclause, the accumulation
clause instead accumulates a default value for the whole loop
expression.

The possible verbs are @code{collect}, @code{append}, @code{nconc},
@code{count}, @code{sum}, @code{maximize}, and @code{minimize}. Also
available as synonyms are the present participle forms:
@code{collecting}, @code{appending}, @code{nconcing}, @code{counting},
@code{summing}, @code{maximizing}, and @code{minimizing}.

A @code{collect} clause builds up a list containing all the values of
@emph{form} in the order they're seen. This is a particularly useful
construct because the code you'd have to write to collect a list in
order as efficiently as @code{LOOP} does is more painful than you'd
normally write by hand.@footnote{The trick is to keep ahold of the
tail of the list and add new cons cells by @code{SETF}ing the
@code{CDR} of the tail. A handwritten equivalent of the code generated
by @code{(loop for i upto 10 collect i)} would look like this:

@verbatim
(do ((list nil) (tail nil) (i 0 (1+ i)))
    ((> i 10) list)
  (let ((new (cons i nil)))
    (if (null list)
        (setf list new)
        (setf (cdr tail) new))
    (setf tail new)))
@end verbatim

Of course you'll rarely, if ever, write code like that. You'll use
either @code{LOOP} or (if, for some reason, you don't want to use
@code{LOOP}) the standard @code{PUSH}/@code{NREVERSE} idiom for
collecting values.} Related to @code{collect} are the verbs
@code{append} and @code{nconc}. These verbs also accumulate values
into a list, but they join the values, which must be lists, into a
single list as if by the functions @code{APPEND} or @code{NCONC}.
@footnote{Recall that @code{NCONC} is the destructive version of
@code{APPEND}--it's safe to use an @code{nconc} clause only if the
values you're collecting are fresh lists that don't share any
structure with other lists. For instance, this is safe:

@verbatim
(loop for i upto 3 nconc (list i i)) ==> (0 0 1 1 2 2 3 3)
@end verbatim

But this will get you into trouble:

@verbatim
(loop for i on (list 1 2 3) nconc i) ==> undefined
@end verbatim

The later will most likely get into an infinite loop as the various
parts of the list produced by (list 1 2 3) are destructively modified
to point to each other. But even that's not guaranteed--the behavior
is simply undefined.}

The remaining accumulation clauses are used to accumulate numeric
values. The verb @code{count} counts the number of times @emph{form} is
true, @code{sum} collects a running total of the values of @emph{form},
@code{maximize} collects the largest value seen for @emph{form}, and
@code{minimize} collects the smallest. For instance, suppose you define
a variable @code{*random*} that contains a list of random numbers.

@verbatim
(defparameter *random* (loop repeat 100 collect (random 10000)))
@end verbatim

Then the following loop will return a list containing various summary
information about the numbers:

@verbatim
(loop for i in *random*
   counting (evenp i) into evens
   counting (oddp i) into odds
   summing i into total
   maximizing i into max
   minimizing i into min
   finally (return (list min max total evens odds)))
@end verbatim

@node Unconditional Execution
@section Unconditional Execution
@anchor{#unconditional-execution}
As useful as the value accumulation constructs are, @code{LOOP} wouldn't
be a very good general-purpose iteration facility if there wasn't a way
to execute arbitrary Lisp code in the loop body.

The simplest way to execute arbitrary code within a loop body is with
a @code{do} clause. Compared to the clauses I've described so far,
with their prepositions and subclauses, @code{do} is a model of
Yodaesque simplicity.@footnote{"No! Try not. Do . . . or do not. There
is no try."  -- Yoda, @emph{The Empire Strikes Back}} A @code{do}
clause consists of the word @code{do} (or @code{doing}) followed by
one or more Lisp forms that are all evaluated when the @code{do}
clause is. The @code{do} clause ends at the closing parenthesis of the
loop or the next loop keyword.

For instance, to print the numbers from one to ten, you could write
this:

@verbatim
(loop for i from 1 to 10 do (print i))
@end verbatim

Another, more dramatic, form of immediate execution is a @code{return}
clause. This clause consists of the word @code{return} followed by a
single Lisp form, which is evaluated, with the resulting value
immediately returned as the value of the loop.

You can also break out of a loop in a @code{do} clause using any of
Lisp's normal control flow operators, such as @code{RETURN} and
@code{RETURN-FROM}. Note that a @code{return} clause always returns from
the immediately enclosing @code{LOOP} expression, while a @code{RETURN}
or @code{RETURN-FROM} in a @code{do} clause can return from any
enclosing expression. For instance, compare the following:

@verbatim
(block outer
  (loop for i from 0 return 100) ; 100 returned from LOOP
  (print "This will print")
  200) ==> 200
@end verbatim

to this:

@verbatim
(block outer
  (loop for i from 0 do (return-from outer 100)) ; 100 returned from BLOCK
  (print "This won't print")
  200) ==> 100
@end verbatim

The @code{do} and @code{return} clauses are collectively called the
@emph{unconditional execution} clauses.

@node Conditional Execution
@section Conditional Execution
@anchor{#conditional-execution}
Because a @code{do} clause can contain arbitrary Lisp forms, you can use
any Lisp expressions you want, including control constructs such as
@code{IF} and @code{WHEN}. So, the following is one way to write a loop
that prints only the even numbers between one and ten:

@verbatim
(loop for i from 1 to 10 do (when (evenp i) (print i)))
@end verbatim

However, sometimes you'll want conditional control at the level of loop
clauses. For instance, suppose you wanted to sum only the even numbers
between one and ten using a @code{summing} clause. You couldn't write
such a loop with a @code{do} clause because there'd be no way to "call"
the @code{sum i} in the middle of a regular Lisp form. In cases like
this, you need to use one of @code{LOOP}'s own conditional expressions
like this:

@verbatim
(loop for i from 1 to 10 when (evenp i) sum i) ==> 30
@end verbatim

@code{LOOP} provides three conditional constructs, and they all follow
this basic pattern:

@verbatim
conditional test-form loop-clause
@end verbatim

The @emph{conditional} can be @code{if}, @code{when}, or @code{unless}.
The @emph{test-form} is any regular Lisp form, and @emph{loop-clause}
can be a value accumulation clause (@code{count}@emph{,}
@code{collect}@emph{, and so on), an unconditional execution} clause, or
another conditional execution clause. Multiple loop clauses can be
attached to a single conditional by joining them with @code{and}.

As an extra bit of syntactic sugar, within the first loop clause, after
the test form, you can use the variable @code{it} to refer to the value
returned by the test form. For instance, the following loop collects the
non-@code{NIL} values found in @code{some-hash} when looking up the keys
in @code{some-list}:

@verbatim
(loop for key in some-list when (gethash key some-hash) collect it)
@end verbatim

A conditional clause is executed each time through the loop. An
@code{if} or @code{when} clause executes its @emph{loop-clause} if
@emph{test-form} evaluates to true. An @code{unless} reverses the test,
executing @emph{loop-clause} only when @emph{test-form} is @code{NIL}.
Unlike their Common Lisp namesakes, @code{LOOP}'s @code{if} and
@code{when} are merely synonyms--there's no difference in their
behavior.

All three conditional clauses can also take an @code{else} branch, which
is followed by another loop clause or multiple clauses joined by
@code{and}. When conditional clauses are nested, the set of clauses
connected to an inner conditional clause can be closed with the word
@code{end}. The @code{end} is optional when not needed to disambiguate a
nested conditional--the end of a conditional clause will be inferred
from the end of the loop or the start of another clause not joined by
@code{and}.

The following rather silly loop demonstrates the various forms of
@code{LOOP} conditionals. The @code{update-analysis} function will be
called each time through the loop with the latest values of the various
variables accumulated by the clauses within the conditionals.

@verbatim
(loop for i from 1 to 100
      if (evenp i)
        minimize i into min-even and 
        maximize i into max-even and
        unless (zerop (mod i 4))
          sum i into even-not-fours-total
        end
        and sum i into even-total
      else
        minimize i into min-odd and
        maximize i into max-odd and
        when (zerop (mod i 5)) 
          sum i into fives-total
        end
        and sum i into odd-total
      do (update-analysis min-even
                          max-even
                          min-odd
                          max-odd
                          even-total
                          odd-total
                          fives-total
                          even-not-fours-total))
@end verbatim

@node Setting Up and Tearing Down
@section Setting Up and Tearing Down
@anchor{#setting-up-and-tearing-down} One of the key insights the
designers of the @code{LOOP} language had about actual loops "in the
wild" is that the loop proper is often preceded by a bit of code to
set things up and then followed by some more code that does something
with the values computed by the loop. A trivial example, in
Perl,@footnote{I'm not picking on Perl here--this example would look
pretty much the same in any language that bases its syntax on C's.}
might look like this:

@verbatim
my $evens_sum = 0;
my $odds_sum  = 0;
foreach my $i (@list_of_numbers) {
  if ($i % 2) {
    $odds_sum += $i;
  } else {
    $evens_sum += $i;
  }
}
if ($evens_sum > $odds_sum) {
  print "Sum of evens greater\n";
} else {
  print "Sum of odds greater\n";
}
@end verbatim

The loop proper in this code is the @code{foreach} statement. But the
@code{foreach} loop doesn't stand on its own: the code in the loop
body refers to variables declared in the two lines before the
loop.@footnote{Perl would let you get away with not declaring those
variables if your program didn't @code{use strict}. But you should
@emph{always} @code{use strict} in Perl. The equivalent code in
Python, Java, or C would always require the variables to be declared.}
And the work the loop does is all for naught without the @code{if}
statement after the loop that actually reports the results. In Common
Lisp, of course, the @code{LOOP} construct is an expression that
returns a value, so there's even more often a need to do something
after the loop proper, namely, generate the return value.

So, said the @code{LOOP} designers, let's give a way to include the code
that's really part of the loop in the loop itself. Thus, @code{LOOP}
provides two keywords, @code{initially} and @code{finally}, that
introduce code to be run outside the loop's main body.

After the @code{initially} or @code{finally}, these clauses consist of
all the Lisp forms up to the start of the next loop clause or the end of
the loop. All the @code{initially} forms are combined into a single
@emph{prologue}, which runs once, immediately after all the local loop
variables are initialized and before the body of the loop. The
@code{finally} forms are similarly combined into a @emph{epilogue} to be
run after the last iteration of the loop body. Both the prologue and
epilogue code can refer to local loop variables.

The prologue is always run, even if the loop body iterates zero times.
The loop can return without running the epilogue if any of the following
happens:

@itemize
@item
A @code{return} clause executes.
@item
@code{RETURN} , @code{RETURN-FROM}, or another transfer of control
construct is called from within a Lisp form within the
body.@footnote{You can cause a loop to finish normally, running the
epilogue, from Lisp code executed as part of the loop body with the
local macro @code{LOOP-FINISH}.}
@item
The loop is terminated by an @code{always}, @code{never}, or
@code{thereis} clause, as I'll discuss in the next section.
@end itemize

Within the epilogue code, @code{RETURN} or @code{RETURN-FROM} can be
used to explicitly provide a return value for the loop. Such an explicit
return value will take precedence over any value that might otherwise be
provided by an accumulation or termination test clause.

To allow @code{RETURN-FROM} to be used to return from a specific loop
(useful when nesting @code{LOOP} expressions), you can name a
@code{LOOP} with the loop keyword @code{named}. If a @code{named} clause
appears in a loop, it must be the first clause. For a simple example,
assume @code{lists} is a list of lists and you want to find an item that
matches some criteria in one of those nested lists. You could find it
with a pair of nested loops like this:

@verbatim
(loop named outer for list in lists do
     (loop for item in list do
          (if (what-i-am-looking-for-p item)
            (return-from outer item))))
@end verbatim

@node Termination Tests
@section Termination Tests
@anchor{#termination-tests}
While the @code{for} and @code{repeat} clauses provide the basic
infrastructure for controlling the number of iterations, sometimes
you'll need to break out of a loop early. You've already seen how a
@code{return} clause or a @code{RETURN} or @code{RETURN-FROM} within a
@code{do} clause can immediately terminate the loop; but just as there
are common patterns for accumulating values, there are also common
patterns for deciding when it's time to bail on a loop. These patterns
are supported in @code{LOOP} by the termination clauses, @code{while},
@code{until}, @code{always}, @code{never}, and @code{thereis}. They all
follow the same pattern.

@verbatim
loop-keyword test-form
@end verbatim

All five evaluate @emph{test-form} each time through the iteration and
decide, based on the resulting value, whether to terminate the loop.
They differ in what happens after they terminate the loop--if they
do--and how they decide.

The loop keywords @code{while} and @code{until} introduce the "mild"
termination clauses. When they decide to terminate the loop, control
passes to the epilogue, skipping the rest of the loop body. The epilogue
can then return a value or do whatever it wants to finish the loop. A
@code{while} clause terminates the loop the first time the test form is
false; @code{until}, conversely, stops it the first time the test form
is true.

Another form of mild termination is provided by the @code{LOOP-FINISH}
macro. This is a regular Lisp form, not a loop clause, so it can be used
anywhere within the Lisp forms of a @code{do} clause. It also causes an
immediate jump to the loop epilogue. It can be useful when the decision
to break out of the loop can't be easily condensed into a single form
that can be used with a @code{while} or @code{until} clause.

The other three clauses--@code{always}, @code{never}, and
@code{thereis}--terminate the loop with extreme prejudice; they
immediately return from the loop, skipping not only any subsequent loop
clauses but also the epilogue. They also provide a default value for the
loop even when they don't cause the loop to terminate. However, if the
loop is @emph{not} terminated by one of these termination tests, the
epilogue is run and can return a value other than the default provided
by the termination clauses.

Because these clauses provide their own return values, they can't be
combined with accumulation clauses unless the accumulation clause has an
@code{into} subclause. The compiler (or interpreter) should signal an
error at compile time if they are.The @code{always} and @code{never}
clauses return only boolean values, so they're most useful when you need
to use a loop expression as part of a predicate. You can use
@code{always} to check that the test form is true on every iteration of
the loop. Conversely, @code{never} tests that the test form evaluates to
@code{NIL} on every iteration. If the test form fails (returning
@code{NIL} in an @code{always} clause or non-@code{NIL} in a
@code{never} clause), the loop is immediately terminated, returning
@code{NIL}. If the loop runs to completion, the default value of
@code{T} is provided.

For instance, if you want to test that all the numbers in a list,
@code{numbers}, are even, you can write this:

@verbatim
(if (loop for n in numbers always (evenp n))
    (print "All numbers even."))
@end verbatim

Equivalently you could write the following:

@verbatim
(if (loop for n in numbers never (oddp n))
    (print "All numbers even."))
@end verbatim

A @code{thereis} clause is used to test whether the test form is
@emph{ever} true. As soon as the test form returns a non-@code{NIL}
value, the loop is terminated, returning that value. If the loop runs to
completion, the @code{thereis} clause provides a default return value of
@code{NIL}.

@verbatim
(loop for char across "abc123" thereis (digit-char-p char)) ==> 1

(loop for char across "abcdef" thereis (digit-char-p char)) ==> NIL
@end verbatim

@node Putting It All Together
@section Putting It All Together
@anchor{#putting-it-all-together}
Now you've seen all the main features of the @code{LOOP} facility. You
can combine any of the clauses I've discussed as long as you abide by
the following rules:

@itemize
@item
The @code{named} clause, if any, must be the first clause.
@item
After the @code{named} clause come all the @code{initially},
@code{with}, @code{for}, and @code{repeat} clauses.
@item
Then comes the body clauses: conditional and unconditional execution,
accumulation, and termination test.@footnote{Some Common Lisp
implementations will let you get away with mixing body clauses and
@code{for} clauses, but that's strictly undefined, and some
implementations will reject such loops.}
@item
End with any @code{finally} clauses.
@end itemize

The @code{LOOP} macro will expand into code that performs the following
actions:

@itemize
@item
Initializes all local loop variables as declared with @code{with} or
@code{for} clauses as well as those implicitly created by accumulation
clauses. The initial value forms are evaluated in the order the clauses
appear in the loop.
@item
Execute the forms provided by any @code{initially} clauses--the
prologue--in the order they appear in the loop.
@item
Iterate, executing the body of the loop as described in the next
paragraph.
@item
Execute the forms provided by any @code{finally} clauses--the
epilogue--in the order they appear in the loop.
@end itemize

While the loop is iterating, the body is executed by first stepping any
iteration control variables and then executing any conditional or
unconditional execution, accumulation, or termination test clauses in
the order they appear in the loop code. If any of the clauses in the
loop body terminate the loop, the rest of the body is skipped and the
loop returns, possibly after running the epilogue.

And that's pretty much all there is to it.@footnote{The one aspect of
@code{LOOP} I haven't touched on at all is the syntax for declaring
the types of loop variables. Of course, I haven't discussed type
declarations outside of @code{LOOP} either. I'll cover the general
topic a bit in Chapter 32. For information on how they work with
@code{LOOP}, consult your favorite Common Lisp reference.} You'll use
@code{LOOP} fairly often in the code later in this book, so it's worth
having some knowledge of it. Beyond that, it's up to you how much you
use it.

And with that, you're ready to dive into the practical chapters that
make up the rest of the book--up first, writing a spam filter.

@node Practical A Spam Filter
@chapter Practical: A Spam Filter
@anchor{#practical-a-spam-filter} In 2002 Paul Graham, having some
time on his hands after selling Viaweb to Yahoo, wrote the essay "A
Plan for Spam"@footnote{Available at
@code{http://www.paulgraham.com/spam.html} and also in @emph{Hackers &
Painters: Big Ideas from the Computer Age} (O'Reilly, 2004)} that
launched a minor revolution in spam-filtering technology. Prior to
Graham's article, most spam filters were written in terms of
handcrafted rules: if a message has @emph{XXX} in the subject, it's
probably a spam; if a message has a more than three or more words in a
row in ALL CAPITAL LETTERS, it's probably a spam. Graham spent several
months trying to write such a rule-based filter before realizing it
was fundamentally a soul-sucking task.

@quotation
To recognize individual spam features you have to try to get into the
mind of the spammer, and frankly I want to spend as little time inside
the minds of spammers as possible.
@end quotation
To avoid having to think like a spammer, Graham decided to try
distinguishing spam from nonspam, a.k.a. @emph{ham}, based on
statistics gathered about which words occur in which kinds of
e-mails. The filter would keep track of how often specific words
appear in both spam and ham messages and then use the frequencies
associated with the words in a new message to compute a probability
that it was either spam or ham. He called his approach @emph{Bayesian}
filtering after the statistical technique that he used to combine the
individual word frequencies into an overall
probability.@footnote{There has since been some disagreement over
whether the technique Graham described was actually "Bayesian."
However, the name has stuck and is well on its way to becoming a
synonym for "statistical" when talking about spam filters.}
@menu
* The Heart of a Spam Filter::
* Training the Filter I::
* Per-Word Statistics::
* Combining Probabilities::
* Inverse Chi Square::
* Training the Filter II::
* Testing the Filter::
* A Couple of Utility Functions::
* Analyzing the Results::
* What's Next::
@end menu

@node The Heart of a Spam Filter
@section The Heart of a Spam Filter
@anchor{#the-heart-of-a-spam-filter}
In this chapter, you'll implement the core of a spam-filtering engine.
You won't write a soup-to-nuts spam-filtering application; rather,
you'll focus on the functions for classifying new messages and training
the filter.

This application is going to be large enough that it's worth defining a
new package to avoid name conflicts. For instance, in the source code
you can download from this book's Web site, I use the package name
@code{COM.GIGAMONKEYS.SPAM}, defining a package that uses both the
standard @code{COMMON-LISP} package and the
@code{COM.GIGAMONKEYS.PATHNAMES} package from Chapter 15, like this:

@verbatim
(defpackage :com.gigamonkeys.spam
  (:use :common-lisp :com.gigamonkeys.pathnames))
@end verbatim

Any file containing code for this application should start with this
line:

@verbatim
(in-package :com.gigamonkeys.spam)
@end verbatim

You can use the same package name or replace @code{com.gigamonkeys}
with some domain you control.@footnote{It would, however, be poor form
to distribute a version of this application using a package starting
with @code{com.gigamonkeys} since you don't control that domain.}

You can also type this same form at the REPL to switch to this package
to test the functions you write. In SLIME this will change the prompt
from @code{CL-USER>} to @code{SPAM>} like this:

@verbatim
CL-USER> (in-package :com.gigamonkeys.spam)
#<The COM.GIGAMONKEYS.SPAM package>
SPAM> 
@end verbatim

Once you have a package defined, you can start on the actual code. The
main function you'll need to implement has a simple job--take the text
of a message as an argument and classify the message as spam, ham, or
unsure. You can easily implement this basic function by defining it in
terms of other functions that you'll write in a moment.

@verbatim
(defun classify (text)
  (classification (score (extract-features text))))
@end verbatim

Reading from the inside out, the first step in classifying a message is
to extract features to pass to the @code{score} function. In
@code{score} you'll compute a value that can then be translated into one
of three classifications--spam, ham, or unsure--by the function
@code{classification}. Of the three functions, @code{classification} is
the simplest. You can assume @code{score} will return a value near 1 if
the message is a spam, near 0 if it's a ham, and near .5 if it's
unclear.

Thus, you can implement @code{classification} like this:

@verbatim
(defparameter *max-ham-score* .4)
(defparameter *min-spam-score* .6)

(defun classification (score)
  (cond
    ((<= score *max-ham-score*) 'ham)
    ((>= score *min-spam-score*) 'spam)
    (t 'unsure)))
@end verbatim

The @code{extract-features} function is almost as straightforward,
though it requires a bit more code. For the moment, the features you'll
extract will be the words appearing in the text. For each word, you need
to keep track of the number of times it has been seen in a spam and the
number of times it has been seen in a ham. A convenient way to keep
those pieces of data together with the word itself is to define a class,
@code{word-feature}, with three slots.

@verbatim
(defclass word-feature ()
  ((word       
    :initarg :word
    :accessor word
    :initform (error "Must supply :word")
    :documentation "The word this feature represents.")
   (spam-count
    :initarg :spam-count
    :accessor spam-count
    :initform 0
    :documentation "Number of spams we have seen this feature in.")
   (ham-count
    :initarg :ham-count
    :accessor ham-count
    :initform 0
    :documentation "Number of hams we have seen this feature in.")))
@end verbatim

You'll keep the database of features in a hash table so you can easily
find the object representing a given feature. You can define a special
variable, @code{*feature-database*}, to hold a reference to this hash
table.

@verbatim
(defvar *feature-database* (make-hash-table :test #'equal))
@end verbatim

You should use @code{DEFVAR} rather than @code{DEFPARAMETER} because you
don't want @code{*feature-database*} to be reset if you happen to reload
the file containing this definition during development--you might have
data stored in @code{*feature-database*} that you don't want to lose. Of
course, that means if you @emph{do} want to clear out the feature
database, you can't just reevaluate the @code{DEFVAR} form. So you
should define a function @code{clear-database}.

@verbatim
(defun clear-database ()
  (setf *feature-database* (make-hash-table :test #'equal)))
@end verbatim

To find the features present in a given message, the code will need to
extract the individual words and then look up the corresponding
@code{word-feature} object in @code{*feature-database*}. If
@code{*feature-database*} contains no such feature, it'll need to create
a new @code{word-feature} to represent the word. You can encapsulate
that bit of logic in a function, @code{intern-feature}, that takes a
word and returns the appropriate feature, creating it if necessary.

@verbatim
(defun intern-feature (word)
  (or (gethash word *feature-database*)
      (setf (gethash word *feature-database*)
            (make-instance 'word-feature :word word))))
@end verbatim

You can extract the individual words from the message text using a
regular expression. For example, using the Common Lisp Portable
Perl-Compatible Regular Expression (CL-PPCRE) library written by Edi
Weitz, you can write @code{extract-words} like this:@footnote{A
version of CL-PPCRE is included with the book's source code available
from the book's Web site. Or you can download it from Weitz's site at
@code{http://www.weitz.de/cl-ppcre/}.}

@verbatim
(defun extract-words (text)
  (delete-duplicates
   (cl-ppcre:all-matches-as-strings "[a-zA-Z]{3,}" text)
   :test #'string=))
@end verbatim

Now all that remains to implement @code{extract-features} is to put
@code{extract-features} and @code{intern-feature} together. Since
@code{extract-words} returns a list of strings and you want a list with
each string translated to the corresponding @code{word-feature}, this is
a perfect time to use @code{MAPCAR}.

@verbatim
(defun extract-features (text)
  (mapcar #'intern-feature (extract-words text)))
@end verbatim

You can test these functions at the REPL like this:

@verbatim
SPAM> (extract-words "foo bar baz")
("foo" "bar" "baz")
@end verbatim

And you can make sure the @code{DELETE-DUPLICATES} is working like this:

@verbatim
SPAM> (extract-words "foo bar baz foo bar")
("baz" "foo" "bar")
@end verbatim

You can also test @code{extract-features}.

@verbatim
SPAM> (extract-features "foo bar baz foo bar")
(#<WORD-FEATURE @ #x71ef28da> #<WORD-FEATURE @ #x71e3809a>
 #<WORD-FEATURE @ #x71ef28aa>)
@end verbatim

However, as you can see, the default method for printing arbitrary
objects isn't very informative. As you work on this program, it'll be
useful to be able to print @code{word-feature} objects in a less
opaque way. Luckily, as I mentioned in Chapter 17, the printing of all
objects is implemented in terms of a generic function
@code{PRINT-OBJECT}, so to change the way @code{word-feature} objects
are printed, you just need to define a method on @code{PRINT-OBJECT}
that specializes on @code{word-feature}. To make implementing such
methods easier, Common Lisp provides the macro
@code{PRINT-UNREADABLE-OBJECT}.@footnote{The main reason to use
@code{PRINT-UNREADABLE-OBJECT} is that it takes care of signaling the
appropriate error if someone tries to print your object readably, such
as with the @code{~S} @code{FORMAT} directive.}

The basic form of @code{PRINT-UNREADABLE-OBJECT} is as follows:

@verbatim
(print-unreadable-object (object stream-variable &key type identity)
  body-form*)
@end verbatim

The @emph{object} argument is an expression that evaluates to the
object to be printed. Within the body of
@code{PRINT-UNREADABLE-OBJECT}, @emph{stream-variable} is bound to a
stream to which you can print anything you want. Whatever you print to
that stream will be output by @code{PRINT-UNREADABLE-OBJECT} and
enclosed in the standard syntax for unreadable objects,
@code{#<>}.@footnote{@code{PRINT-UNREADABLE-OBJECT} also signals an
error if it's used when the printer control variable
@code{*PRINT-READABLY*} is true. Thus, a @code{PRINT-OBJECT} method
consisting solely of a @code{PRINT-UNREADABLE-OBJECT} form will
correctly implement the @code{PRINT-OBJECT} contract with regard to
@code{*PRINT-READABLY*}.}

@code{PRINT-UNREADABLE-OBJECT} also lets you include the type of the
object and an indication of the object's identity via the keyword
parameters @emph{type} and @emph{identity}. If they're non-@code{NIL},
the output will start with the name of the object's class and end with
an indication of the object's identity similar to what's printed by the
default @code{PRINT-OBJECT} method for @code{STANDARD-OBJECT}s. For
@code{word-feature}, you probably want to define a @code{PRINT-OBJECT}
method that includes the type but not the identity along with the values
of the @code{word}, @code{ham-count}, and @code{spam-count} slots. Such
a method would look like this:

@verbatim
(defmethod print-object ((object word-feature) stream)
  (print-unreadable-object (object stream :type t)
    (with-slots (word ham-count spam-count) object
      (format stream "~s :hams ~d :spams ~d" word ham-count spam-count))))
@end verbatim

Now when you test @code{extract-features} at the REPL, you can see more
clearly what features are being extracted.

@verbatim
SPAM> (extract-features "foo bar baz foo bar")
(#<WORD-FEATURE "baz" :hams 0 :spams 0>
 #<WORD-FEATURE "foo" :hams 0 :spams 0>
 #<WORD-FEATURE "bar" :hams 0 :spams 0>)
@end verbatim

@node Training the Filter I
@section Training the Filter
@anchor{#training-the-filter}
Now that you have a way to keep track of individual features, you're
almost ready to implement @code{score}. But first you need to write the
code you'll use to train the spam filter so @code{score} will have some
data to use. You'll define a function, @code{train}, that takes some
text and a symbol indicating what kind of message it is--@code{ham} or
@code{spam}--and that increments either the ham count or the spam count
of all the features present in the text as well as a global count of
hams or spams processed. Again, you can take a top-down approach and
implement it in terms of other functions that don't yet exist.

@verbatim
(defun train (text type)
  (dolist (feature (extract-features text))
    (increment-count feature type))
  (increment-total-count type))
@end verbatim

You've already written @code{extract-features}, so next up is
@code{increment-count}, which takes a @code{word-feature} and a
message type and increments the appropriate slot of the feature. Since
there's no reason to think that the logic of incrementing these counts
is going to change for different kinds of objects, you can write this
as a regular function.@footnote{If you decide later that you do need
to have different versions of @code{increment-feature} for different
classes, you can redefine @code{increment-count} as a generic function
and this function as a method specialized on @code{word-feature}.}
Because you defined both @code{ham-count} and @code{spam-count} with
an @code{:accessor} option, you can use @code{INCF} and the accessor
functions created by @code{DEFCLASS} to increment the appropriate
slot.

@verbatim
(defun increment-count (feature type)
  (ecase type
    (ham (incf (ham-count feature)))
    (spam (incf (spam-count feature)))))
@end verbatim

The @code{ECASE} construct is a variant of @code{CASE}, both of which
are similar to @code{case} statements in Algol-derived languages
(renamed @code{switch} in C and its progeny). They both evaluate their
first argument--the @emph{key form}--and then find the clause whose
first element--the @emph{key}--is the same value according to
@code{EQL}. In this case, that means the variable @code{type} is
evaluated, yielding whatever value was passed as the second argument to
@code{increment-count}.

The keys aren't evaluated. In other words, the value of @code{type} will
be compared to the literal objects read by the Lisp reader as part of
the @code{ECASE} form. In this function, that means the keys are the
symbols @code{ham} and @code{spam}, not the values of any variables
named @code{ham} and @code{spam}. So, if @code{increment-count} is
called like this:

@verbatim
(increment-count some-feature 'ham)
@end verbatim

the value of @code{type} will be the symbol @code{ham}, and the first
branch of the @code{ECASE} will be evaluated and the feature's ham count
incremented. On the other hand, if it's called like this:

@verbatim
(increment-count some-feature 'spam)
@end verbatim

then the second branch will run, incrementing the spam count. Note
that the symbols @code{ham} and @code{spam} are quoted when calling
@code{increment-count} since otherwise they'd be evaluated as the
names of variables. But they're not quoted when they appear in
@code{ECASE} since @code{ECASE} doesn't evaluate the
keys.@footnote{Technically, the key in each clause of a @code{CASE} or
@code{ECASE} is interpreted as a @emph{list designator}, an object
that designates a list of objects. A single nonlist object, treated as
a list designator, designates a list containing just that one object,
while a list designates itself. Thus, each clause can have multiple
keys; @code{CASE} and @code{ECASE} will select the clause whose list
of keys contains the value of the key form. For example, if you wanted
to make @code{good} a synonym for @code{ham} and @code{bad} a synonym
for @code{spam}, you could write @code{increment-count} like this:

@verbatim
(defun increment-count (feature type)
  (ecase type
    ((ham good) (incf (ham-count feature)))
    ((spam bad) (incf (spam-count feature)))))
@end verbatim
}

The @emph{E} in @code{ECASE} stands for "exhaustive" or "error,"
meaning @code{ECASE} should signal an error if the key value is
anything other than one of the keys listed. The regular @code{CASE} is
looser, returning @code{NIL} if no matching clause is found.

To implement @code{increment-total-count}, you need to decide where to
store the counts; for the moment, two more special variables,
@code{*total-spams*} and @code{*total-hams*}, will do fine.

@verbatim
(defvar *total-spams* 0)
(defvar *total-hams* 0)

(defun increment-total-count (type)
  (ecase type
    (ham (incf *total-hams*))
    (spam (incf *total-spams*))))
@end verbatim

You should use @code{DEFVAR} to define these two variables for the same
reason you used it with @code{*feature-database*}--they'll hold data
built up while you run the program that you don't necessarily want to
throw away just because you happen to reload your code during
development. But you'll want to reset those variables if you ever reset
@code{*feature-database*}, so you should add a few lines to
@code{clear-database} as shown here:

@verbatim
(defun clear-database ()
  (setf
   *feature-database* (make-hash-table :test #'equal)
   *total-spams* 0
   *total-hams* 0))
@end verbatim

@node Per-Word Statistics
@section Per-Word Statistics
@anchor{#per-word-statistics} The heart of a statistical spam filter
is, of course, the functions that compute statistics-based
probabilities. The mathematical nuances@footnote{Speaking of
mathematical nuances, hard-core statisticians may be offended by the
sometimes loose use of the word @emph{probability} in this
chapter. However, since even the pros, who are divided between the
Bayesians and the frequentists, can't agree on what a probability is,
I'm not going to worry about it. This is a book about programming, not
statistics.} of why exactly these computations work are beyond the
scope of this book--interested readers may want to refer to several
papers by Gary Robinson.@footnote{Robinson's articles that directly
informed this chapter are "A Statistical Approach to the Spam Problem"
(published in the @emph{Linux Journal} and available at
@code{http://www.linuxjournal.com/ article.php?sid=6467} and in a
shorter form on Robinson's blog at @code{http://radio.weblogs.com/
0101454/stories/2002/09/16/spamDetection.html}) and "Why Chi?
Motivations for the Use of Fisher's Inverse Chi-Square Procedure in
Spam Classification" (available at @code{http://garyrob.blogs.com/
whychi93.pdf}). Another article that may be useful is "Handling
Redundancy in Email Token Probabilities" (available at
@code{http://garyrob.blogs.com//handlingtokenredundancy94.pdf}). The
archived mailing lists of the SpamBayes project
(@code{http://spambayes.sourceforge.net/}) also contain a lot of
useful information about different algorithms and approaches to
testing spam filters.} I'll focus rather on how they're implemented.

The starting point for the statistical computations is the set of
measured values--the frequencies stored in @code{*feature-database*},
@code{*total-spams*}, and @code{*total-hams*}. Assuming that the set of
messages trained on is statistically representative, you can treat the
observed frequencies as probabilities of the same features showing up in
hams and spams in future messages.

The basic plan is to classify a message by extracting the features it
contains, computing the individual probability that a given message
containing the feature is a spam, and then combining all the individual
probabilities into a total score for the message. Messages with many
"spammy" features and few "hammy" features will receive a score near 1,
and messages with many hammy features and few spammy features will score
near 0.

The first statistical function you need is one that computes the basic
probability that a message containing a given feature is a spam. By one
point of view, the probability that a given message containing the
feature is a spam is the ratio of spam messages containing the feature
to all messages containing the feature. Thus, you could compute it this
way:

@verbatim
(defun spam-probability (feature)
  (with-slots (spam-count ham-count) feature
    (/ spam-count (+ spam-count ham-count))))
@end verbatim

The problem with the value computed by this function is that it's
strongly affected by the overall probability that @emph{any} message
will be a spam or a ham. For instance, suppose you get nine times as
much ham as spam in general. A completely neutral feature will then
appear in one spam for every nine hams, giving you a spam probability of
1/10 according to this function.

But you're more interested in the probability that a given feature will
appear in a spam message, independent of the overall probability of
getting a spam or ham. Thus, you need to divide the spam count by the
total number of spams trained on and the ham count by the total number
of hams. To avoid division-by-zero errors, if either of
@code{*total-spams*} or @code{*total-hams*} is zero, you should treat
the corresponding frequency as zero. (Obviously, if the total number of
either spams or hams is zero, then the corresponding per-feature count
will also be zero, so you can treat the resulting frequency as zero
without ill effect.)

@verbatim
(defun spam-probability (feature)
  (with-slots (spam-count ham-count) feature
    (let ((spam-frequency (/ spam-count (max 1 *total-spams*)))
          (ham-frequency (/ ham-count (max 1 *total-hams*))))
      (/ spam-frequency (+ spam-frequency ham-frequency)))))
@end verbatim

This version suffers from another problem--it doesn't take into account
the number of messages analyzed to arrive at the per-word probabilities.
Suppose you've trained on 2,000 messages, half spam and half ham. Now
consider two features that have appeared only in spams. One has appeared
in all 1,000 spams, while the other appeared only once. According to the
current definition of @code{spam-probability}, the appearance of either
feature predicts that a message is spam with equal probability, namely,
1.

However, it's still quite possible that the feature that has appeared
only once is actually a neutral feature--it's obviously rare in either
spams or hams, appearing only once in 2,000 messages. If you trained on
another 2,000 messages, it might very well appear one more time, this
time in a ham, making it suddenly a neutral feature with a spam
probability of .5.

So it seems you might like to compute a probability that somehow factors
in the number of data points that go into each feature's probability. In
his papers, Robinson suggested a function based on the Bayesian notion
of incorporating observed data into prior knowledge or assumptions.
Basically, you calculate a new probability by starting with an assumed
prior probability and a weight to give that assumed probability before
adding new information. Robinson's function is this:

@verbatim
(defun bayesian-spam-probability (feature &optional
                                  (assumed-probability 1/2)
                                  (weight 1))
  (let ((basic-probability (spam-probability feature))
        (data-points (+ (spam-count feature) (ham-count feature))))
    (/ (+ (* weight assumed-probability)
          (* data-points basic-probability))
       (+ weight data-points))))
@end verbatim

Robinson suggests values of 1/2 for @code{assumed-probability} and 1 for
@code{weight}. Using those values, a feature that has appeared in one
spam and no hams has a @code{bayesian-spam-probability} of 0.75, a
feature that has appeared in 10 spams and no hams has a
@code{bayesian-spam-probability} of approximately 0.955, and one that
has matched in 1,000 spams and no hams has a spam probability of
approximately 0.9995.

@node Combining Probabilities
@section Combining Probabilities
@anchor{#combining-probabilities}
Now that you can compute the @code{bayesian-spam-probability} of each
individual feature you find in a message, the last step in implementing
the @code{score} function is to find a way to combine a bunch of
individual probabilities into a single value between 0 and 1.

If the individual feature probabilities were independent, then it'd be
mathematically sound to multiply them together to get a combined
probability. But it's unlikely they actually are independent--certain
features are likely to appear together, while others never
do.@footnote{Techniques that combine nonindependent probabilities as
though they were, in fact, independent, are called @emph{naive
Bayesian}. Graham's original proposal was essentially a naive Bayesian
classifier with some "empirically derived" constant factors thrown
in.}

Robinson proposed using a method for combining probabilities invented by
the statistician R. A. Fisher. Without going into the details of exactly
why his technique works, it's this: First you combine the probabilities
by multiplying them together. This gives you a number nearer to 0 the
more low probabilities there were in the original set. Then take the log
of that number and multiply by -2. Fisher showed in 1950 that if the
individual probabilities were independent and drawn from a uniform
distribution between 0 and 1, then the resulting value would be on a
chi-square distribution. This value and twice the number of
probabilities can be fed into an inverse chi-square function, and it'll
return the probability that reflects the likelihood of obtaining a value
that large or larger by combining the same number of randomly selected
probabilities. When the inverse chi-square function returns a low
probability, it means there was a disproportionate number of low
probabilities (either a lot of relatively low probabilities or a few
very low probabilities) in the individual probabilities.

To use this probability in determining whether a given message is a
spam, you start with a @emph{null hypothesis}, a straw man you hope to
knock down. The null hypothesis is that the message being classified is
in fact just a random collection of features. If it were, then the
individual probabilities--the likelihood that each feature would appear
in a spam--would also be random. That is, a random selection of features
would usually contain some features with a high probability of appearing
in spam and other features with a low probability of appearing in spam.
If you were to combine these randomly selected probabilities according
to Fisher's method, you should get a middling combined value, which the
inverse chi-square function will tell you is quite likely to arise just
by chance, as, in fact, it would have. But if the inverse chi-square
function returns a very low probability, it means it's unlikely the
probabilities that went into the combined value were selected at random;
there were too many low probabilities for that to be likely. So you can
reject the null hypothesis and instead adopt the alternative hypothesis
that the features involved were drawn from a biased sample--one with few
high spam probability features and many low spam probability features.
In other words, it must be a ham message.

However, the Fisher method isn't symmetrical since the inverse
chi-square function returns the probability that a given number of
randomly selected probabilities would combine to a value as large or
larger than the one you got by combining the actual probabilities. This
asymmetry works to your advantage because when you reject the null
hypothesis, you know what the more likely hypothesis is. When you
combine the individual spam probabilities via the Fisher method, and it
tells you there's a high probability that the null hypothesis is
wrong--that the message isn't a random collection of words--then it
means it's likely the message is a ham. The number returned is, if not
literally the probability that the message is a ham, at least a good
measure of its "hamminess." Conversely, the Fisher combination of the
individual ham probabilities gives you a measure of the message's
"spamminess."

To get a final score, you need to combine those two measures into a
single number that gives you a combined hamminess-spamminess score
ranging from 0 to 1. The method recommended by Robinson is to add half
the difference between the hamminess and spamminess scores to 1/2, in
other words, to average the spamminess and 1 minus the hamminess. This
has the nice effect that when the two scores agree (high spamminess and
low hamminess, or vice versa) you'll end up with a strong indicator near
either 0 or 1. But when the spamminess and hamminess scores are both
high or both low, then you'll end up with a final value near 1/2, which
you can treat as an "uncertain" classification.

The @code{score} function that implements this scheme looks like this:

@verbatim
(defun score (features)
  (let ((spam-probs ()) (ham-probs ()) (number-of-probs 0))
    (dolist (feature features)
      (unless (untrained-p feature)
        (let ((spam-prob (float (bayesian-spam-probability feature) 0.0d0)))
          (push spam-prob spam-probs)
          (push (- 1.0d0 spam-prob) ham-probs)
          (incf number-of-probs))))
    (let ((h (- 1 (fisher spam-probs number-of-probs)))
          (s (- 1 (fisher ham-probs number-of-probs))))
      (/ (+ (- 1 h) s) 2.0d0))))
@end verbatim

You take a list of features and loop over them, building up two lists of
probabilities, one listing the probabilities that a message containing
each feature is a spam and the other that a message containing each
feature is a ham. As an optimization, you can also count the number of
probabilities while looping over them and pass the count to
@code{fisher} to avoid having to count them again in @code{fisher}
itself. The value returned by @code{fisher} will be low if the
individual probabilities contained too many low probabilities to have
come from random text. Thus, a low @code{fisher} score for the spam
probabilities means there were many hammy features; subtracting that
score from 1 gives you a probability that the message is a ham.
Conversely, subtracting the @code{fisher} score for the ham
probabilities gives you the probability that the message was a spam.
Combining those two probabilities gives you an overall spamminess score
between 0 and 1.

Within the loop, you can use the function @code{untrained-p} to skip
features extracted from the message that were never seen during
training. These features will have spam counts and ham counts of zero.
The @code{untrained-p} function is trivial.

@verbatim
(defun untrained-p (feature)
  (with-slots (spam-count ham-count) feature
    (and (zerop spam-count) (zerop ham-count))))
@end verbatim

The only other new function is @code{fisher} itself. Assuming you
already had an @code{inverse-chi-square} function, @code{fisher} is
conceptually simple.

@verbatim
(defun fisher (probs number-of-probs)
  "The Fisher computation described by Robinson."
  (inverse-chi-square 
   (* -2 (log (reduce #'* probs)))
   (* 2 number-of-probs)))
@end verbatim

Unfortunately, there's a small problem with this straightforward
implementation. While using @code{REDUCE} is a concise and idiomatic way
of multiplying a list of numbers, in this particular application there's
a danger the product will be too small a number to be represented as a
floating-point number. In that case, the result will @emph{underflow} to
zero. And if the product of the probabilities underflows, all bets are
off because taking the @code{LOG} of zero will either signal an error
or, in some implementation, result in a special negative-infinity value,
which will render all subsequent calculations essentially meaningless.
This is particularly unfortunate in this function because the Fisher
method is most sensitive when the input probabilities are low--near
zero--and therefore in the most danger of causing the multiplication to
underflow.

Luckily, you can use a bit of high-school math to avoid this problem.
Recall that the log of a product is the same as the sum of the logs of
the factors. So instead of multiplying all the probabilities and then
taking the log, you can sum the logs of each probability. And since
@code{REDUCE} takes a @code{:key} keyword parameter, you can use it to
perform the whole calculation. Instead of this:

@verbatim
(log (reduce #'* probs))
@end verbatim

write this:

@verbatim
(reduce #'+ probs :key #'log)
@end verbatim

@node Inverse Chi Square
@section Inverse Chi Square
@anchor{#inverse-chi-square}
The implementation of @code{inverse-chi-square} in this section is a
fairly straightforward translation of a version written in Python by
Robinson. The exact mathematical meaning of this function is beyond the
scope of this book, but you can get an intuitive sense of what it does
by thinking about how the values you pass to @code{fisher} will affect
the result: the more low probabilities you pass to @code{fisher}, the
smaller the product of the probabilities will be. The log of a small
product will be a negative number with a large absolute value, which is
then multiplied by -2, making it an even larger positive number. Thus,
the more low probabilities were passed to @code{fisher}, the larger the
value it'll pass to @code{inverse-chi-square}. Of course, the number of
probabilities involved also affects the value passed to
@code{inverse-chi-square}. Since probabilities are, by definition, less
than or equal to 1, the more probabilities that go into a product, the
smaller it'll be and the larger the value passed to
@code{inverse-chi-square}. Thus, @code{inverse-chi-square} should return
a low probability when the Fisher combined value is abnormally large for
the number of probabilities that went into it. The following function
does exactly that:

@verbatim
(defun inverse-chi-square (value degrees-of-freedom)
  (assert (evenp degrees-of-freedom))
  (min 
   (loop with m = (/ value 2)
      for i below (/ degrees-of-freedom 2)
      for prob = (exp (- m)) then (* prob (/ m i))
      summing prob)
   1.0))
@end verbatim

Recall from Chapter 10 that @code{EXP} raises @emph{e} to the argument
given. Thus, the larger @code{value} is, the smaller the initial value
of @code{prob} will be. But that initial value will then be adjusted
upward slightly for each degree of freedom as long as @code{m} is
greater than the number of degrees of freedom. Since the value returned
by @code{inverse-chi-square} is supposed to be another probability, it's
important to clamp the value returned with @code{MIN} since rounding
errors in the multiplication and exponentiation may cause the
@code{LOOP} to return a sum just a shade over 1.

@node Training the Filter II
@section Training the Filter
@anchor{#training-the-filter-1}
Since you wrote @code{classify} and @code{train} to take a string
argument, you can test them easily at the REPL. If you haven't yet, you
should switch to the package in which you've been writing this code by
evaluating an @code{IN-PACKAGE} form at the REPL or using the SLIME
shortcut @code{change-package}. To use the SLIME shortcut, type a comma
at the REPL and then type the name at the prompt. Pressing Tab while
typing the package name will autocomplete based on the packages your
Lisp knows about. Now you can invoke any of the functions that are part
of the spam application. You should first make sure the database is
empty.

@verbatim
SPAM> (clear-database)
@end verbatim

Now you can train the filter with some text.

@verbatim
SPAM> (train "Make money fast" 'spam)
@end verbatim

And then see what the classifier thinks.

@verbatim
SPAM> (classify "Make money fast")
SPAM
SPAM> (classify "Want to go to the movies?")
UNSURE
@end verbatim

While ultimately all you care about is the classification, it'd be nice
to be able to see the raw score too. The easiest way to get both values
without disturbing any other code is to change @code{classification} to
return multiple values.

@verbatim
(defun classification (score)
  (values
   (cond
     ((<= score *max-ham-score*) 'ham)
     ((>= score *min-spam-score*) 'spam)
     (t 'unsure))
   score))
@end verbatim

You can make this change and then recompile just this one function.
Because @code{classify} returns whatever @code{classification} returns,
it'll also now return two values. But since the primary return value is
the same, callers of either function who expect only one value won't be
affected. Now when you test @code{classify}, you can see exactly what
score went into the classification.

@verbatim
SPAM> (classify "Make money fast")
SPAM
0.863677101854273D0
SPAM> (classify "Want to go to the movies?")
UNSURE
0.5D0
@end verbatim

And now you can see what happens if you train the filter with some more
ham text.

@verbatim
SPAM> (train "Do you have any money for the movies?" 'ham)
1
SPAM> (classify "Make money fast")
SPAM
0.7685351219857626D0
@end verbatim

It's still spam but a bit less certain since @emph{money} was seen in
ham text.

@verbatim
SPAM> (classify "Want to go to the movies?")
HAM
0.17482223132078922D0
@end verbatim

And now this is clearly recognizable ham thanks to the presence of the
word @emph{movies}, now a hammy feature.

However, you don't really want to train the filter by hand. What you'd
really like is an easy way to point it at a bunch of files and train it
on them. And if you want to test how well the filter actually works,
you'd like to then use it to classify another set of files of known
types and see how it does. So the last bit of code you'll write in this
chapter will be a test harness that tests the filter on a corpus of
messages of known types, using a certain fraction for training and then
measuring how accurate the filter is when classifying the remainder.

@node Testing the Filter
@section Testing the Filter
@anchor{#testing-the-filter} To test the filter, you need a corpus of
messages of known types. You can use messages lying around in your
inbox, or you can grab one of the corpora available on the Web. For
instance, the SpamAssassin corpus@footnote{Several spam corpora
including the SpamAssassin corpus are linked to from
@code{http://nexp.cs.pdx.edu/~psam/cgi-bin/view/PSAM/CorpusSets}.}
contains several thousand messages hand classified as spam, easy ham,
and hard ham. To make it easy to use whatever files you have, you can
define a test rig that's driven off an array of file/type pairs. You
can define a function that takes a filename and a type and adds it to
the corpus like this:

@verbatim
(defun add-file-to-corpus (filename type corpus)
  (vector-push-extend (list filename type) corpus))
@end verbatim

The value of @code{corpus} should be an adjustable vector with a fill
pointer. For instance, you can make a new corpus like this:

@verbatim
(defparameter *corpus* (make-array 1000 :adjustable t :fill-pointer 0))
@end verbatim

If you have the hams and spams already segregated into separate
directories, you might want to add all the files in a directory as the
same type. This function, which uses the @code{list-directory} function
from Chapter 15, will do the trick:

@verbatim
(defun add-directory-to-corpus (dir type corpus)
  (dolist (filename (list-directory dir))
    (add-file-to-corpus filename type corpus)))
@end verbatim

For instance, suppose you have a directory @code{mail} containing two
subdirectories, @code{spam} and @code{ham}, each containing messages of
the indicated type; you can add all the files in those two directories
to @code{*corpus*} like this:

@verbatim
SPAM> (add-directory-to-corpus "mail/spam/" 'spam *corpus*)
NIL
SPAM> (add-directory-to-corpus "mail/ham/" 'ham *corpus*)
NIL
@end verbatim

Now you need a function to test the classifier. The basic strategy will
be to select a random chunk of the corpus to train on and then test the
corpus by classifying the remainder of the corpus, comparing the
classification returned by the @code{classify} function to the known
classification. The main thing you want to know is how accurate the
classifier is--what percentage of the messages are classified correctly?
But you'll probably also be interested in what messages were
misclassified and in what direction--were there more false positives or
more false negatives? To make it easy to perform different analyses of
the classifier's behavior, you should define the testing functions to
build a list of raw results, which you can then analyze however you
like.

The main testing function might look like this:

@verbatim
(defun test-classifier (corpus testing-fraction)
  (clear-database)
  (let* ((shuffled (shuffle-vector corpus))
         (size (length corpus))
         (train-on (floor (* size (- 1 testing-fraction)))))
    (train-from-corpus shuffled :start 0 :end train-on)
    (test-from-corpus shuffled :start train-on)))
@end verbatim

This function starts by clearing out the feature database.@footnote{If
you wanted to conduct a test without disturbing the existing database,
you could bind @code{*feature-database*}, @code{*total-spams*}, and
@code{*total-hams*} with a @code{LET}, but then you'd have no way of
looking at the database after the fact--unless you returned the values
you used within the function.} Then it shuffles the corpus, using a
function you'll implement in a moment, and figures out, based on the
@code{testing-fraction} parameter, how many messages it'll train on
and how many it'll reserve for testing. The two helper functions
@code{train-from-corpus} and @code{test-from-corpus} will both take
@code{:start} and @code{:end} keyword parameters, allowing them to
operate on a subsequence of the given corpus.

The @code{train-from-corpus} function is quite simple--simply loop over
the appropriate part of the corpus, use @code{DESTRUCTURING-BIND} to
extract the filename and type from the list found in each element, and
then pass the text of the named file and the type to @code{train}. Since
some mail messages, such as those with attachments, are quite large, you
should limit the number of characters it'll take from the message. It'll
obtain the text with a function @code{start-of-file}, which you'll
implement in a moment, that takes a filename and a maximum number of
characters to return. @code{train-from-corpus} looks like this:

@verbatim
(defparameter *max-chars* (* 10 1024))

(defun train-from-corpus (corpus &key (start 0) end)
  (loop for idx from start below (or end (length corpus)) do
        (destructuring-bind (file type) (aref corpus idx)
          (train (start-of-file file *max-chars*) type))))
@end verbatim

The @code{test-from-corpus} function is similar except you want to
return a list containing the results of each classification so you can
analyze them after the fact. Thus, you should capture both the
classification and score returned by @code{classify} and then collect a
list of the filename, the actual type, the type returned by
@code{classify}, and the score. To make the results more human readable,
you can include keywords in the list to indicate which values are which.

@verbatim
(defun test-from-corpus (corpus &key (start 0) end)
  (loop for idx from start below (or end (length corpus)) collect
        (destructuring-bind (file type) (aref corpus idx)
          (multiple-value-bind (classification score)
              (classify (start-of-file file *max-chars*))
            (list 
             :file file
             :type type
             :classification classification
             :score score)))))
@end verbatim

@node A Couple of Utility Functions
@section A Couple of Utility Functions
@anchor{#a-couple-of-utility-functions}
To finish the implementation of @code{test-classifier}, you need to
write the two utility functions that don't really have anything
particularly to do with spam filtering, @code{shuffle-vector} and
@code{start-of-file}.

An easy and efficient way to implement @code{shuffle-vector} is using
the Fisher-Yates algorithm.@footnote{This algorithm is named for the
same Fisher who invented the method used for combining probabilities
and for Frank Yates, his coauthor of the book @emph{Statistical Tables
for Biological, Agricultural and Medical Research} (Oliver & Boyd,
1938) in which, according to Knuth, they provided the first published
description of the algorithm.} You can start by implementing a
function, @code{nshuffle-vector}, that shuffles a vector in
place. This name follows the same naming convention of other
destructive functions such as @code{NCONC} and @code{NREVERSE}. It
looks like this:

@verbatim
(defun nshuffle-vector (vector)
  (loop for idx downfrom (1- (length vector)) to 1
        for other = (random (1+ idx))
        do (unless (= idx other)
             (rotatef (aref vector idx) (aref vector other))))
  vector)
@end verbatim

The nondestructive version simply makes a copy of the original vector
and passes it to the destructive version.

@verbatim
(defun shuffle-vector (vector)
  (nshuffle-vector (copy-seq vector)))
@end verbatim

The other utility function, @code{start-of-file}, is almost as
straightforward with just one wrinkle. The most efficient way to read
the contents of a file into memory is to create an array of the
appropriate size and use @code{READ-SEQUENCE} to fill it in. So it might
seem you could make a character array that's either the size of the file
or the maximum number of characters you want to read, whichever is
smaller. Unfortunately, as I mentioned in Chapter 14, the function
@code{FILE-LENGTH} isn't entirely well defined when dealing with
character streams since the number of characters encoded in a file can
depend on both the character encoding used and the particular text in
the file. In the worst case, the only way to get an accurate measure of
the number of characters in a file is to actually read the whole file.
Thus, it's ambiguous what @code{FILE-LENGTH} should do when passed a
character stream; in most implementations, @code{FILE-LENGTH} always
returns the number of octets in the file, which may be greater than the
number of characters that can be read from the file.

However, @code{READ-SEQUENCE} returns the number of characters actually
read. So, you can attempt to read the number of characters reported by
@code{FILE-LENGTH} and return a substring if the actual number of
characters read was smaller.

@verbatim
(defun start-of-file (file max-chars)
  (with-open-file (in file)
    (let* ((length (min (file-length in) max-chars))
           (text (make-string length))
           (read (read-sequence text in)))
      (if (< read length)
        (subseq text 0 read)
        text))))
@end verbatim

@node Analyzing the Results
@section Analyzing the Results
@anchor{#analyzing-the-results}
Now you're ready to write some code to analyze the results generated by
@code{test-classifier}. Recall that @code{test-classifier} returns the
list returned by @code{test-from-corpus} in which each element is a
plist representing the result of classifying one file. This plist
contains the name of the file, the actual type of the file, the
classification, and the score returned by @code{classify}. The first bit
of analytical code you should write is a function that returns a symbol
indicating whether a given result was correct, a false positive, a false
negative, a missed ham, or a missed spam. You can use
@code{DESTRUCTURING-BIND} to pull out the @code{:type} and
@code{:classification} elements of an individual result list (using
@code{&allow-other-keys} to tell @code{DESTRUCTURING-BIND} to ignore any
other key/value pairs it sees) and then use nested @code{ECASE} to
translate the different pairings into a single symbol.

@verbatim
(defun result-type (result)
  (destructuring-bind (&key type classification &allow-other-keys) result
    (ecase type
      (ham
       (ecase classification
         (ham 'correct)
         (spam 'false-positive)
         (unsure 'missed-ham)))
      (spam
       (ecase classification
         (ham 'false-negative)
         (spam 'correct)
         (unsure 'missed-spam))))))
@end verbatim

You can test out this function at the REPL.

@verbatim
SPAM> (result-type '(:FILE #p"foo" :type ham :classification ham :score 0))
CORRECT
SPAM> (result-type '(:FILE #p"foo" :type spam :classification spam :score 0))
CORRECT
SPAM> (result-type '(:FILE #p"foo" :type ham :classification spam :score 0))
FALSE-POSITIVE
SPAM> (result-type '(:FILE #p"foo" :type spam :classification ham :score 0))
FALSE-NEGATIVE
SPAM> (result-type '(:FILE #p"foo" :type ham :classification unsure :score 0))
MISSED-HAM
SPAM> (result-type '(:FILE #p"foo" :type spam :classification unsure :score 0))
MISSED-SPAM
@end verbatim

Having this function makes it easy to slice and dice the results of
@code{test-classifier} in a variety of ways. For instance, you can start
by defining predicate functions for each type of result.

@verbatim
(defun false-positive-p (result)
  (eql (result-type result) 'false-positive))

(defun false-negative-p (result)
  (eql (result-type result) 'false-negative))

(defun missed-ham-p (result)
  (eql (result-type result) 'missed-ham))

(defun missed-spam-p (result)
  (eql (result-type result) 'missed-spam))

(defun correct-p (result)
  (eql (result-type result) 'correct))
@end verbatim

With those functions, you can easily use the list and sequence
manipulation functions I discussed in Chapter 11 to extract and count
particular kinds of results.

@verbatim
SPAM> (count-if #'false-positive-p *results*)
6
SPAM> (remove-if-not #'false-positive-p *results*)
((:FILE #p"ham/5349" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.9999983107355541d0)
 (:FILE #p"ham/2746" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.6286468956619795d0)
 (:FILE #p"ham/3427" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.9833753501352983d0)
 (:FILE #p"ham/7785" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.9542788587998488d0)
 (:FILE #p"ham/1728" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.684339162891261d0)
 (:FILE #p"ham/10581" :TYPE HAM :CLASSIFICATION SPAM :SCORE 0.9999924537959615d0))
@end verbatim

You can also use the symbols returned by @code{result-type} as keys into
a hash table or an alist. For instance, you can write a function to
print a summary of the counts and percentages of each type of result
using an alist that maps each type plus the extra symbol @code{total} to
a count.

@verbatim
(defun analyze-results (results)
  (let* ((keys '(total correct false-positive 
                 false-negative missed-ham missed-spam))
         (counts (loop for x in keys collect (cons x 0))))
    (dolist (item results)
      (incf (cdr (assoc 'total counts)))
      (incf (cdr (assoc (result-type item) counts))))
    (loop with total = (cdr (assoc 'total counts))
          for (label . count) in counts
          do (format t "~&~@(~a~):~20t~5d~,5t: ~6,2f%~%"
                     label count (* 100 (/ count total))))))
@end verbatim

This function will give output like this when passed a list of results
generated by @code{test-classifier}:

@verbatim
SPAM> (analyze-results *results*)
Total:               3761 : 100.00%
Correct:             3689 :  98.09%
False-positive:         4 :   0.11%
False-negative:         9 :   0.24%
Missed-ham:            19 :   0.51%
Missed-spam:           40 :   1.06%
NIL
@end verbatim

And as a last bit of analysis you might want to look at why an
individual message was classified the way it was. The following
functions will show you:

@verbatim
(defun explain-classification (file)
  (let* ((text (start-of-file file *max-chars*))
         (features (extract-features text))
         (score (score features))
         (classification (classification score)))
    (show-summary file text classification score)
    (dolist (feature (sorted-interesting features))
      (show-feature feature))))

(defun show-summary (file text classification score)
  (format t "~&~a" file)
  (format t "~2%~a~2%" text)
  (format t "Classified as ~a with score of ~,5f~%" classification score))

(defun show-feature (feature)
  (with-slots (word ham-count spam-count) feature
    (format
     t "~&~2t~a~30thams: ~5d; spams: ~5d;~,10tprob: ~,f~%"
     word ham-count spam-count (bayesian-spam-probability feature))))

(defun sorted-interesting (features)
  (sort (remove-if #'untrained-p features) #'< :key #'bayesian-spam-probability))
@end verbatim

@node What's Next
@section What's Next
@anchor{#whats-next}
Obviously, you could do a lot more with this code. To turn it into a
real spam-filtering application, you'd need to find a way to integrate
it into your normal e-mail infrastructure. One approach that would make
it easy to integrate with almost any e-mail client is to write a bit of
code to act as a POP3 proxy--that's the protocol most e-mail clients use
to fetch mail from mail servers. Such a proxy would fetch mail from your
real POP3 server and serve it to your mail client after either tagging
spam with a header that your e-mail client's filters can easily
recognize or simply putting it aside. Of course, you'd also need a way
to communicate with the filter about misclassifications--as long as
you're setting it up as a server, you could also provide a Web
interface. I'll talk about how to write Web interfaces in Chapter 26,
and you'll build one, for a different application, in Chapter 29.

Or you might want to work on improving the basic classification--a
likely place to start is to make @code{extract-features} more
sophisticated. In particular, you could make the tokenizer smarter about
the internal structure of e-mail--you could extract different kinds of
features for words appearing in the body versus the message headers. And
you could decode various kinds of message encoding such as base 64 and
quoted printable since spammers often try to obfuscate their message
with those encodings.

But I'll leave those improvements to you. Now you're ready to head down
the path of building a streaming MP3 server, starting by writing a
general-purpose library for parsing binary files.

@node Practical Parsing Binary Files
@chapter Practical: Parsing Binary Files
@anchor{#practical-parsing-binary-files}
In this chapter I'll show you how to build a library that you can use to
write code for reading and writing binary files. You'll use this library
in Chapter 25 to write a parser for ID3 tags, the mechanism used to
store metadata such as artist and album names in MP3 files. This library
is also an example of how to use macros to extend the language with new
constructs, turning it into a special-purpose language for solving a
particular problem, in this case reading and writing binary data.
Because you'll develop the library a bit at a time, including several
partial versions, it may seem you're writing a lot of code. But when all
is said and done, the whole library is fewer than 150 lines of code, and
the longest macro is only 20 lines long.
@menu
* Binary Files::
* Binary Format Basics::
* Strings in Binary Files::
* Composite Structures::
* Designing the Macros::
* Making the Dream a Reality::
* Reading Binary Objects::
* Writing Binary Objects::
* Adding Inheritance and Tagged Structures::
* Keeping Track of Inherited Slots::
* Tagged Structures::
* Primitive Binary Types::
* The Current Object Stack::
@end menu

@node Binary Files
@section Binary Files
@anchor{#binary-files} At a sufficiently low level of abstraction, all
files are "binary" in the sense that they just contain a bunch of
numbers encoded in binary form. However, it's customary to distinguish
between @emph{text files}, where all the numbers can be interpreted as
characters representing human-readable text, and @emph{binary files},
which contain data that, if interpreted as characters, yields
nonprintable characters.@footnote{In ASCII, the first 32 characters
are nonprinting @emph{control characters} originally used to control
the behavior of a Teletype machine, causing it to do such things as
sound the bell, back up one character, move to a new line, and move
the carriage to the beginning of the line. Of these 32 control
characters, only three, the newline, carriage return, and horizontal
tab, are typically found in text files.}

Binary file formats are usually designed to be both compact and
efficient to parse--that's their main advantage over text-based
formats.  To meet both those criteria, they're usually composed of
on-disk structures that are easily mapped to data structures that a
program might use to represent the same data in memory.@footnote{Some
binary file formats @emph{are} in-memory data structures--on many
operating systems it's possible to map a file into memory, and
low-level languages such as C can then treat the region of memory
containing the contents of the file just like any other memory; data
written to that area of memory is saved to the underlying file when
it's unmapped. However, these formats are platform-dependent since the
in-memory representation of even such simple data types as integers
depends on the hardware on which the program is running. Thus, any
file format that's intended to be portable must define a canonical
representation for all the data types it uses that can be mapped to
the actual in-memory data representation on a particular kind of
machine or in a particular language.}

The library will give you an easy way to define the mapping between the
on-disk structures defined by a binary file format and in-memory Lisp
objects. Using the library, it should be easy to write a program that
can read a binary file, translating it into Lisp objects that you can
manipulate, and then write back out to another properly formatted binary
file.

@node Binary Format Basics
@section Binary Format Basics
@anchor{#binary-format-basics}
The starting point for reading and writing binary files is to open the
file for reading or writing individual bytes. As I discussed in Chapter
14, both @code{OPEN} and @code{WITH-OPEN-FILE} accept a keyword
argument, @code{:element-type}, that controls the basic unit of transfer
for the stream. When you're dealing with binary files, you'll specify
@code{(unsigned-byte 8)}. An input stream opened with such an
@code{:element-type} will return an integer between 0 and 255 each time
it's passed to @code{READ-BYTE}. Conversely, you can write bytes to an
@code{(unsigned-byte 8)} output stream by passing numbers between 0 and
255 to @code{WRITE-BYTE}.

Above the level of individual bytes, most binary formats use a smallish
number of primitive data types--numbers encoded in various ways, textual
strings, bit fields, and so on--which are then composed into more
complex structures. So your first task is to define a framework for
writing code to read and write the primitive data types used by a given
binary format.

To take a simple example, suppose you're dealing with a binary format
that uses an unsigned 16-bit integer as a primitive data type. To read
such an integer, you need to read the two bytes and then combine them
into a single number by multiplying one byte by 256, a.k.a. 2^8, and
adding it to the other byte. For instance, assuming the binary format
specifies that such 16-bit quantities are stored in
@emph{big-endian}@footnote{The term @emph{big-endian} and its
opposite, @emph{little-endian}, borrowed from Jonathan Swift's
@emph{Gulliver's Travels}, refer to the way a multibyte number is
represented in an ordered sequence of bytes such as in memory or in a
file. For instance, the number 43981, or @code{abcd} in hex,
represented as a 16-bit quantity, consists of two bytes, @code{ab} and
@code{cd}. It doesn't matter to a computer in what order these two
bytes are stored as long as everybody agrees. Of course, whenever
there's an arbitrary choice to be made between two equally good
options, the one thing you can be sure of is that everybody is not
going to agree. For more than you ever wanted to know about it, and to
see where the terms @emph{big-endian} and @emph{little-endian} were
first applied in this fashion, read "On Holy Wars and a Plea for
Peace" by Danny Cohen, available at
@code{http://khavrinen.lcs.mit.edu/wollman/ien-137.txt}.} form, with
the most significant byte first, you can read such a number with this
function:

@verbatim
(defun read-u2 (in)
  (+ (* (read-byte in) 256) (read-byte in)))
@end verbatim

However, Common Lisp provides a more convenient way to perform this
kind of bit twiddling. The function @code{LDB}, whose name stands for
load byte, can be used to extract and set (with @code{SETF}) any
number of contiguous bits from an integer.@footnote{@code{LDB} and
@code{DPB}, a related function, were named after the DEC PDP-10
assembly functions that did essentially the same thing. Both functions
operate on integers as if they were represented using twos-complement
format, regardless of the internal representation used by a particular
Common Lisp implementation.} The number of bits and their position
within the integer is specified with a @emph{byte specifier} created
with the @code{BYTE} function. @code{BYTE} takes two arguments, the
number of bits to extract (or set) and the position of the rightmost
bit where the least significant bit is at position zero.  @code{LDB}
takes a byte specifier and the integer from which to extract the bits
and returns the positive integer represented by the extracted
bits. Thus, you can extract the least significant octet of an integer
like this:

@verbatim
(ldb (byte 8 0) #xabcd) ==> 205 ; 205 is #xcd
@end verbatim

To get the next octet, you'd use a byte specifier of @code{(byte 8 8)}
like this:

@verbatim
(ldb (byte 8 8) #xabcd) ==> 171 ; 171 is #xab
@end verbatim

You can use @code{LDB} with @code{SETF} to set the specified bits of an
integer stored in a @code{SETF}able place.

@verbatim
CL-USER> (defvar *num* 0)
*NUM*
CL-USER> (setf (ldb (byte 8 0) *num*) 128)
128
CL-USER> *num*
128
CL-USER> (setf (ldb (byte 8 8) *num*) 255)
255
CL-USER> *num*
65408
@end verbatim

Thus, you can also write @code{read-u2} like this:@footnote{Common
Lisp also provides functions for shifting and masking the bits of
integers in a way that may be more familiar to C and Java
programmers. For instance, you could write @code{read-u2} yet a third
way, using those functions, like this:

@verbatim
(defun read-u2 (in)
  (logior (ash (read-byte in) 8) (read-byte in)))
@end verbatim

which would be roughly equivalent to this Java method:

@verbatim
public int readU2 (InputStream in) throws IOException {
  return (in.read() << 8) | (in.read());
}
@end verbatim

The names @code{LOGIOR} and @code{ASH} are short for @emph{LOGical
Inclusive OR} and @emph{Arithmetic SHift}. @code{ASH} shifts an
integer a given number of bits to the left when its second argument is
positive or to the right if the second argument is
negative. @code{LOGIOR} combines integers by logically @emph{or}ing
each bit. Another function, @code{LOGAND}, performs a bitwise
@emph{and}, which can be used to mask off certain bits. However, for
the kinds of bit twiddling you'll need to do in this chapter and the
next, @code{LDB} and @code{BYTE} will be both more convenient and more
idiomatic Common Lisp style.}

@verbatim
(defun read-u2 (in)
  (let ((u2 0))
    (setf (ldb (byte 8 8) u2) (read-byte in))
    (setf (ldb (byte 8 0) u2) (read-byte in))
    u2))
@end verbatim

To write a number out as a 16-bit integer, you need to extract the
individual 8-bit bytes and write them one at a time. To extract the
individual bytes, you just need to use @code{LDB} with the same byte
specifiers.

@verbatim
(defun write-u2 (out value)
  (write-byte (ldb (byte 8 8) value) out)
  (write-byte (ldb (byte 8 0) value) out))
@end verbatim

Of course, you can also encode integers in many other ways--with
different numbers of bytes, with different endianness, and in signed and
unsigned format.

@node Strings in Binary Files
@section Strings in Binary Files
@anchor{#strings-in-binary-files}
Textual strings are another kind of primitive data type you'll find in
many binary formats. When you read files one byte at a time, you can't
read and write strings directly--you need to decode and encode them one
byte at a time, just as you do with binary-encoded numbers. And just as
you can encode an integer in several ways, you can encode a string in
many ways. To start with, the binary format must specify how individual
characters are encoded.

To translate bytes to characters, you need to know both what character
@emph{code} and what character @emph{encoding} you're using. A character
code defines a mapping from positive integers to characters. Each number
in the mapping is called a @emph{code point}. For instance, ASCII is a
character code that maps the numbers from 0-127 to particular characters
used in the Latin alphabet. A character encoding, on the other hand,
defines how the code points are represented as a sequence of bytes in a
byte-oriented medium such as a file. For codes that use eight or fewer
bits, such as ASCII and ISO-8859-1, the encoding is trivial--each
numeric value is encoded as a single byte.

Nearly as straightforward are pure double-byte encodings, such as UCS-2,
which map between 16-bit values and characters. The only reason
double-byte encodings can be more complex than single-byte encodings is
that you may also need to know whether the 16-bit values are supposed to
be encoded in big-endian or little-endian format.

Variable-width encodings use different numbers of octets for different
numeric values, making them more complex but allowing them to be more
compact in many cases. For instance, UTF-8, an encoding designed for
use with the Unicode character code, uses a single octet to encode the
values 0-127 while using up to four octets to encode values up to
1,114,111.@footnote{Originally, UTF-8 was designed to represent a
31-bit character code and used up to six bytes per code
point. However, the maximum Unicode code point is @code{#x10ffff}, so
a UTF-8 encoding of Unicode requires at most four bytes per code
point.}

Since the code points from 0-127 map to the same characters in Unicode
as they do in ASCII, a UTF-8 encoding of text consisting only of
characters also in ASCII is the same as the ASCII encoding. On the other
hand, texts consisting mostly of characters requiring four bytes in
UTF-8 could be more compactly encoded in a straight double-byte
encoding.

Common Lisp provides two functions for translating between numeric
character codes and character objects: @code{CODE-CHAR}, which takes
an numeric code and returns as a character, and @code{CHAR-CODE},
which takes a character and returns its numeric code. The language
standard doesn't specify what character encoding an implementation
must use, so there's no guarantee you can represent every character
that can possibly be encoded in a given file format as a Lisp
character. However, almost all contemporary Common Lisp
implementations use ASCII, ISO-8859-1, or Unicode as their native
character code. Because Unicode is a superset ofISO-8859-1, which is
in turn a superset of ASCII, if you're using a Unicode Lisp,
@code{CODE-CHAR} and @code{CHAR-CODE} can be used directly for
translating any of those three character codes.@footnote{If you need
to parse a file format that uses other character codes, or if you need
to parse files containing arbitrary Unicode strings using a
non-Unicode-Common-Lisp implementation, you can always represent such
strings in memory as vectors of integer code points. They won't be
Lisp strings, so you won't be able to manipulate or compare them with
the string functions, but you'll still be able to do anything with
them that you can with arbitrary vectors.}

In addition to specifying a character encoding, a string encoding must
also specify how to encode the length of the string. Three techniques
are typically used in binary file formats.

The simplest is to not encode it but to let it be implicit in the
position of the string in some larger structure: a particular element of
a file may always be a string of a certain length, or a string may be
the last element of a variable-length data structure whose overall size
determines how many bytes are left to read as string data. Both these
techniques are used in ID3 tags, as you'll see in the next chapter.

The other two techniques can be used to encode variable-length strings
without relying on context. One is to encode the length of the string
followed by the character data--the parser reads an integer value (in
some specified integer format) and then reads that number of characters.
Another is to write the character data followed by a delimiter that
can't appear in the string such as a null character.

The different representations have different advantages and
disadvantages, but when you're dealing with already specified binary
formats, you won't have any control over which encoding is used.
However, none of the encodings is particularly more difficult to read
and write than any other. Here, as an example, is a function that reads
a null-terminated ASCII string, assuming your Lisp implementation uses
ASCII or one of its supersets such as ISO-8859-1 or full Unicode as its
native character encoding:

@verbatim
(defconstant +null+ (code-char 0))

(defun read-null-terminated-ascii (in)
  (with-output-to-string (s)
    (loop for char = (code-char (read-byte in))
          until (char= char +null+) do (write-char char s))))
@end verbatim

The @code{WITH-OUTPUT-TO-STRING} macro, which I mentioned in Chapter 14,
is an easy way to build up a string when you don't know how long it'll
be. It creates a @code{STRING-STREAM} and binds it to the variable name
specified, @code{s} in this case. All characters written to the stream
are collected into a string, which is then returned as the value of the
@code{WITH-OUTPUT-TO-STRING} form.

To write a string back out, you just need to translate the characters
back to numeric values that can be written with @code{WRITE-BYTE} and
then write the null terminator after the string contents.

@verbatim
(defun write-null-terminated-ascii (string out)
  (loop for char across string
        do (write-byte (char-code char) out))
  (write-byte (char-code +null+) out))
@end verbatim

As these examples show, the main intellectual challenge--such as it
is--of reading and writing primitive elements of binary files is
understanding how exactly to interpret the bytes that appear in a file
and to map them to Lisp data types. If a binary file format is well
specified, this should be a straightforward proposition. Actually
writing functions to read and write a particular encoding is, as they
say, a simple matter of programming.

Now you can turn to the issue of reading and writing more complex
on-disk structures and how to map them to Lisp objects.

@node Composite Structures
@section Composite Structures
@anchor{#composite-structures}
Since binary formats are usually used to represent data in a way that
makes it easy to map to in-memory data structures, it should come as no
surprise that composite on-disk structures are usually defined in ways
similar to the way programming languages define in-memory structures.
Usually a composite on-disk structure will consist of a number of named
parts, each of which is itself either a primitive type such as a number
or a string, another composite structure, or possibly a collection of
such values.

For instance, an ID3 tag defined in the 2.2 version of the specification
consists of a header made up of a three-character ISO-8859-1 string,
which is always "ID3"; two one-byte unsigned integers that specify the
major version and revision of the specification; eight bits worth of
boolean flags; and four bytes that encode the size of the tag in an
encoding particular to the ID3 specification. Following the header is a
list of @emph{frames}, each of which has its own internal structure.
After the frames are as many null bytes as are necessary to pad the tag
out to the size specified in the header.

If you look at the world through the lens of object orientation,
composite structures look a lot like classes. For instance, you could
write a class to represent an ID3 tag.

@verbatim
(defclass id3-tag ()
  ((identifier    :initarg :identifier    :accessor identifier)
   (major-version :initarg :major-version :accessor major-version)
   (revision      :initarg :revision      :accessor revision)
   (flags         :initarg :flags         :accessor flags)
   (size          :initarg :size          :accessor size)
   (frames        :initarg :frames        :accessor frames)))
@end verbatim

An instance of this class would make a perfect repository to hold the
data needed to represent an ID3 tag. You could then write functions to
read and write instances of this class. For example, assuming the
existence of certain other functions for reading the appropriate
primitive data types, a @code{read-id3-tag} function might look like
this:

@verbatim
(defun read-id3-tag (in)
  (let ((tag (make-instance 'id3-tag)))
    (with-slots (identifier major-version revision flags size frames) tag
      (setf identifier    (read-iso-8859-1-string in :length 3))
      (setf major-version (read-u1 in))
      (setf revision      (read-u1 in))
      (setf flags         (read-u1 in))
      (setf size          (read-id3-encoded-size in))
      (setf frames        (read-id3-frames in :tag-size size)))
    tag))
@end verbatim

The @code{write-id3-tag} function would be structured similarly--you'd
use the appropriate @code{write-*} functions to write out the values
stored in the slots of the @code{id3-tag} object.

It's not hard to see how you could write the appropriate classes to
represent all the composite data structures in a specification along
with @code{read-foo} and @code{write-foo} functions for each class and
for necessary primitive types. But it's also easy to tell that all the
reading and writing functions are going to be pretty similar, differing
only in the specifics of what types they read and the names of the slots
they store them in. It's particularly irksome when you consider that in
the ID3 specification it takes about four lines of text to specify the
structure of an ID3 tag, while you've already written eighteen lines of
code and haven't even written @code{write-id3-tag} yet.

What you'd really like is a way to describe the structure of something
like an ID3 tag in a form that's as compressed as the specification's
pseudocode yet that can also be expanded into code that defines the
@code{id3-tag} class @emph{and} the functions that translate between
bytes on disk and instances of the class. Sounds like a job for a macro.

@node Designing the Macros
@section Designing the Macros
@anchor{#designing-the-macros}
Since you already have a rough idea what code your macros will need to
generate, the next step, according to the process for writing a macro I
outlined in Chapter 8, is to switch perspectives and think about what a
call to the macro should look like. Since the goal is to be able to
write something as compressed as the pseudocode in the ID3
specification, you can start there. The header of an ID3 tag is
specified like this:

@verbatim
ID3/file identifier      "ID3"
ID3 version              $02 00
ID3 flags                %xx000000
ID3 size             4 * %0xxxxxxx
@end verbatim

In the notation of the specification, this means the "file identifier"
slot of an ID3 tag is the string "ID3" in ISO-8859-1 encoding. The
version consists of two bytes, the first of which--for this version of
the specification--has the value 2 and the second of which--again for
this version of the specification--is 0. The flags slot is eight bits,
of which all but the first two are 0, and the size consists of four
bytes, each of which has a 0 in the most significant bit.

Some information isn't captured by this pseudocode. For instance,
exactly how the four bytes that encode the size are to be interpreted is
described in a few lines of prose. Likewise, the spec describes in prose
how the frame and subsequent padding is stored after this header. But
most of what you need to know to be able to write code to read and write
an ID3 tag is specified by this pseudocode. Thus, you ought to be able
to write an s-expression version of this pseudocode and have it expanded
into the class and function definitions you'd otherwise have to write by
hand--something, perhaps, like this:

@verbatim
(define-binary-class id3-tag
  ((file-identifier (iso-8859-1-string :length 3))
   (major-version   u1)
   (revision        u1)
   (flags           u1)
   (size            id3-tag-size)
   (frames          (id3-frames :tag-size size))))
@end verbatim

The basic idea is that this form defines a class @code{id3-tag} similar
to the way you could with @code{DEFCLASS}, but instead of specifying
things such as @code{:initarg} and @code{:accessors}, each slot
specification consists of the name of the slot--@code{file-identifier},
@code{major-version}, and so on--and information about how that slot is
represented on disk. Since this is just a bit of fantasizing, you don't
have to worry about exactly how the macro @code{define-binary-class}
will know what to do with expressions such as
@code{(iso-8859-1-string :length 3)}, @code{u1}, @code{id3-tag-size},
and @code{(id3-frames :tag-size size)}; as long as each expression
contains the information necessary to know how to read and write a
particular data encoding, you should be okay.

@node Making the Dream a Reality
@section Making the Dream a Reality
@anchor{#making-the-dream-a-reality}
Okay, enough fantasizing about good-looking code; now you need to get to
work writing @code{define-binary-class}--writing the code that will turn
that concise expression of what an ID3 tag looks like into code that can
represent one in memory, read one off disk, and write it back out.

To start with, you should define a package for this library. Here's the
package file that comes with the version you can download from the
book's Web site:

@verbatim
(in-package :cl-user)

(defpackage :com.gigamonkeys.binary-data
  (:use :common-lisp :com.gigamonkeys.macro-utilities)
  (:export :define-binary-class
           :define-tagged-binary-class
           :define-binary-type
           :read-value
           :write-value
           :*in-progress-objects*
           :parent-of-type
           :current-binary-object
           :+null+))
@end verbatim

The @code{COM.GIGAMONKEYS.MACRO-UTILITIES} package contains the
@code{with-gensyms} and @code{once-only} macros from Chapter 8.

Since you already have a handwritten version of the code you want to
generate, it shouldn't be too hard to write such a macro. Just take it
in small pieces, starting with a version of @code{define-binary-class}
that generates just the @code{DEFCLASS} form.

If you look back at the @code{define-binary-class} form, you'll see that
it takes two arguments, the name @code{id3-tag} and a list of slot
specifiers, each of which is itself a two-item list. From those pieces
you need to build the appropriate @code{DEFCLASS} form. Clearly, the
biggest difference between the @code{define-binary-class} form and a
proper @code{DEFCLASS} form is in the slot specifiers. A single slot
specifier from @code{define-binary-class} looks something like this:

@verbatim
(major-version u1)
@end verbatim

But that's not a legal slot specifier for a @code{DEFCLASS}. Instead,
you need something like this:

@verbatim
(major-version :initarg :major-version :accessor major-version)
@end verbatim

Easy enough. First define a simple function to translate a symbol to the
corresponding keyword symbol.

@verbatim
(defun as-keyword (sym) (intern (string sym) :keyword))
@end verbatim

Now define a function that takes a @code{define-binary-class} slot
specifier and returns a @code{DEFCLASS} slot specifier.

@verbatim
(defun slot->defclass-slot (spec)
  (let ((name (first spec)))
    `(,name :initarg ,(as-keyword name) :accessor ,name)))
@end verbatim

You can test this function at the REPL after switching to your new
package with a call to @code{IN-PACKAGE}.

@verbatim
BINARY-DATA> (slot->defclass-slot '(major-version u1))
(MAJOR-VERSION :INITARG :MAJOR-VERSION :ACCESSOR MAJOR-VERSION)
@end verbatim

Looks good. Now the first version of @code{define-binary-class} is
trivial.

@verbatim
(defmacro define-binary-class (name slots)
  `(defclass ,name ()
     ,(mapcar #'slot->defclass-slot slots)))
@end verbatim

This is simple template-style macro--@code{define-binary-class}
generates a @code{DEFCLASS} form by interpolating the name of the class
and a list of slot specifiers constructed by applying
@code{slot->defclass-slot} to each element of the list of slots
specifiers from the @code{define-binary-class} form.

To see exactly what code this macro generates, you can evaluate this
expression at the REPL.

@verbatim
(macroexpand-1 '(define-binary-class id3-tag
  ((identifier      (iso-8859-1-string :length 3))
   (major-version   u1)
   (revision        u1)
   (flags           u1)
   (size            id3-tag-size)
   (frames          (id3-frames :tag-size size)))))
@end verbatim

The result, slightly reformatted here for better readability, should
look familiar since it's exactly the class definition you wrote by hand
earlier:

@verbatim
(defclass id3-tag ()
  ((identifier      :initarg :identifier    :accessor identifier)
   (major-version   :initarg :major-version :accessor major-version)
   (revision        :initarg :revision      :accessor revision)
   (flags           :initarg :flags         :accessor flags)
   (size            :initarg :size          :accessor size)
   (frames          :initarg :frames        :accessor frames)))
@end verbatim

@node Reading Binary Objects
@section Reading Binary Objects
@anchor{#reading-binary-objects}
Next you need to make @code{define-binary-class} also generate a
function that can read an instance of the new class. Looking back at the
@code{read-id3-tag} function you wrote before, this seems a bit
trickier, as the @code{read-id3-tag} wasn't quite so regular--to read
each slot's value, you had to call a different function. Not to mention,
the name of the function, @code{read-id3-tag}, while derived from the
name of the class you're defining, isn't one of the arguments to
@code{define-binary-class} and thus isn't available to be interpolated
into a template the way the class name was.

You could deal with both of those problems by devising and following a
naming convention so the macro can figure out the name of the function
to call based on the name of the type in the slot specifier. However,
this would require @code{define-binary-class} to generate the name
@code{read-id3-tag}, which is possible but a bad idea. Macros that
create global definitions should generally use only names passed to
them by their callers; macros that generate names under the covers can
cause hard-to-predict--and hard-to-debug--name conflicts when the
generated names happen to be the same as names used
elsewhere.@footnote{Unfortunately, the language itself doesn't always
provide a good model in this respect: the macro @code{DEFSTRUCT},
which I don't discuss since it has largely been superseded by
@code{DEFCLASS}, generates functions with names that it generates
based on the name of the structure it's given. @code{DEFSTRUCT}'s bad
example leads many new macro writers astray.}

You can avoid both these inconveniences by noticing that all the
functions that read a particular type of value have the same fundamental
purpose, to read a value of a specific type from a stream. Speaking
colloquially, you might say they're all instances of a single generic
operation. And the colloquial use of the word @emph{generic} should lead
you directly to the solution to your problem: instead of defining a
bunch of independent functions, all with different names, you can define
a single generic function, @code{read-value}, with methods specialized
to read different types of values.

That is, instead of defining functions @code{read-iso-8859-1-string} and
@code{read-u1}, you can define @code{read-value} as a generic function
taking two required arguments, a type and a stream, and possibly some
keyword arguments.

@verbatim
(defgeneric read-value (type stream &key)
  (:documentation "Read a value of the given type from the stream."))
@end verbatim

By specifying @code{&key} without any actual keyword parameters, you
allow different methods to define their own @code{&key} parameters
without requiring them to do so. This does mean every method specialized
on @code{read-value} will have to include either @code{&key} or an
@code{&rest} parameter in its parameter list to be compatible with the
generic function.

Then you'll define methods that use @code{EQL} specializers to
specialize the type argument on the name of the type you want to read.

@verbatim
(defmethod read-value ((type (eql 'iso-8859-1-string)) in &key length) ...)

(defmethod read-value ((type (eql 'u1)) in &key) ...)
@end verbatim

Then you can make @code{define-binary-class} generate a
@code{read-value} method specialized on the type name @code{id3-tag},
and that method can be implemented in terms of calls to
@code{read-value} with the appropriate slot types as the first argument.
The code you want to generate is going to look like this:

@verbatim
(defmethod read-value ((type (eql 'id3-tag)) in &key)
  (let ((object (make-instance 'id3-tag)))
    (with-slots (identifier major-version revision flags size frames) object
      (setf identifier    (read-value 'iso-8859-1-string in :length 3))
      (setf major-version (read-value 'u1 in))
      (setf revision      (read-value 'u1 in))
      (setf flags         (read-value 'u1 in))
      (setf size          (read-value 'id3-encoded-size in))
      (setf frames        (read-value 'id3-frames in :tag-size size)))
    object))
@end verbatim

So, just as you needed a function to translate a
@code{define-binary-class} slot specifier to a @code{DEFCLASS} slot
specifier in order to generate the @code{DEFCLASS} form, now you need a
function that takes a @code{define-binary-class} slot specifier and
generates the appropriate @code{SETF} form, that is, something that
takes this:

@verbatim
(identifier (iso-8859-1-string :length 3))
@end verbatim

and returns this:

@verbatim
(setf identifier (read-value 'iso-8859-1-string in :length 3))
@end verbatim

However, there's a difference between this code and the @code{DEFCLASS}
slot specifier: it includes a reference to a variable @code{in}--the
method parameter from the @code{read-value} method--that wasn't derived
from the slot specifier. It doesn't have to be called @code{in}, but
whatever name you use has to be the same as the one used in the method's
parameter list and in the other calls to @code{read-value}. For now you
can dodge the issue of where that name comes from by defining
@code{slot->read-value} to take a second argument of the name of the
stream variable.

@verbatim
(defun slot->read-value (spec stream)
  (destructuring-bind (name (type &rest args)) (normalize-slot-spec spec)
    `(setf ,name (read-value ',type ,stream ,@args))))
@end verbatim

The function @code{normalize-slot-spec} normalizes the second element of
the slot specifier, converting a symbol like @code{u1} to the list
@code{(u1)} so the @code{DESTRUCTURING-BIND} can parse it. It looks like
this:

@verbatim
(defun normalize-slot-spec (spec)
  (list (first spec) (mklist (second spec))))

(defun mklist (x) (if (listp x) x (list x)))
@end verbatim

You can test @code{slot->read-value} with each type of slot specifier.

@verbatim
BINARY-DATA> (slot->read-value '(major-version u1) 'stream)
(SETF MAJOR-VERSION (READ-VALUE 'U1 STREAM))
BINARY-DATA> (slot->read-value '(identifier (iso-8859-1-string :length 3)) 'stream)
(SETF IDENTIFIER (READ-VALUE 'ISO-8859-1-STRING STREAM :LENGTH 3))
@end verbatim

With these functions you're ready to add @code{read-value} to
@code{define-binary-class}. If you take the handwritten
@code{read-value} method and strip out anything that's tied to a
particular class, you're left with this skeleton:

@verbatim
(defmethod read-value ((type (eql ...)) stream &key)
  (let ((object (make-instance ...)))
    (with-slots (...) object
      ...
    object)))
@end verbatim

All you need to do is add this skeleton to the
@code{define-binary-class} template, replacing ellipses with code that
fills in the skeleton with the appropriate names and code. You'll also
want to replace the variables @code{type}, @code{stream}, and
@code{object} with gensymed names to avoid potential conflicts with
slot names,@footnote{Technically there's no possibility of @code{type}
or @code{object} conflicting with slot names--at worst they'd be
shadowed within the @code{WITH-SLOTS} form. But it doesn't hurt
anything to simply @code{GENSYM} all local variable names used within
a macro template.} which you can do with the @code{with-gensyms} macro
from Chapter 8.

Also, because a macro must expand into a single form, you need to wrap
some form around the @code{DEFCLASS} and @code{DEFMETHOD}. @code{PROGN}
is the customary form to use for macros that expand into multiple
definitions because of the special treatment it gets from the file
compiler when appearing at the top level of a file, as I discussed in
Chapter 20.

So, you can change @code{define-binary-class} as follows:

@verbatim
(defmacro define-binary-class (name slots)
  (with-gensyms (typevar objectvar streamvar)
    `(progn
       (defclass ,name ()
         ,(mapcar #'slot->defclass-slot slots))

       (defmethod read-value ((,typevar (eql ',name)) ,streamvar &key)
         (let ((,objectvar (make-instance ',name)))
           (with-slots ,(mapcar #'first slots) ,objectvar
             ,@(mapcar #'(lambda (x) (slot->read-value x streamvar)) slots))
           ,objectvar)))))
@end verbatim

@node Writing Binary Objects
@section Writing Binary Objects
@anchor{#writing-binary-objects}
Generating code to write out an instance of a binary class will proceed
similarly. First you can define a @code{write-value} generic function.

@verbatim
(defgeneric write-value (type stream value &key)
  (:documentation "Write a value as the given type to the stream."))
@end verbatim

Then you define a helper function that translates a
@code{define-binary-class} slot specifier into code that writes out the
slot using @code{write-value}. As with the @code{slot->read-value}
function, this helper function needs to take the name of the stream
variable as an argument.

@verbatim
(defun slot->write-value (spec stream)
  (destructuring-bind (name (type &rest args)) (normalize-slot-spec spec)
    `(write-value ',type ,stream ,name ,@args)))
@end verbatim

Now you can add a @code{write-value} template to the
@code{define-binary-class} macro.

@verbatim
(defmacro define-binary-class (name slots)
  (with-gensyms (typevar objectvar streamvar)
    `(progn
       (defclass ,name ()
         ,(mapcar #'slot->defclass-slot slots))

       (defmethod read-value ((,typevar (eql ',name)) ,streamvar &key)
         (let ((,objectvar (make-instance ',name)))
           (with-slots ,(mapcar #'first slots) ,objectvar
             ,@(mapcar #'(lambda (x) (slot->read-value x streamvar)) slots))
           ,objectvar))

       (defmethod write-value ((,typevar (eql ',name)) ,streamvar ,objectvar &key)
         (with-slots ,(mapcar #'first slots) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->write-value x streamvar)) slots))))))
@end verbatim

@node Adding Inheritance and Tagged Structures
@section Adding Inheritance and Tagged Structures
@anchor{#adding-inheritance-and-tagged-structures}
While this version of @code{define-binary-class} will handle stand-alone
structures, binary file formats often define on-disk structures that
would be natural to model with subclasses and superclasses. So you might
want to extend @code{define-binary-class} to support inheritance.

A related technique used in many binary formats is to have several
on-disk structures whose exact type can be determined only by reading
some data that indicates how to parse the following bytes. For instance,
the frames that make up the bulk of an ID3 tag all share a common header
structure consisting of a string identifier and a length. To read a
frame, you need to read the identifier and use its value to determine
what kind of frame you're looking at and thus how to parse the body of
the frame.

The current @code{define-binary-class} macro has no way to handle this
kind of reading--you could use @code{define-binary-class} to define a
class to represent each kind of frame, but you'd have no way to know
what type of frame to read without reading at least the identifier. And
if other code reads the identifier in order to determine what type to
pass to @code{read-value}, then that will break @code{read-value} since
it's expecting to read all the data that makes up the instance of the
class it instantiates.

You can solve this problem by adding inheritance to
@code{define-binary-class} and then writing another macro,
@code{define-tagged-binary-class}, for defining "abstract" classes that
aren't instantiated directly but that can be specialized on by
@code{read-value} methods that know how to read enough data to determine
what kind of class to create.

The first step to adding inheritance to @code{define-binary-class} is to
add a parameter to the macro to accept a list of superclasses.

@verbatim
(defmacro define-binary-class (name (&rest superclasses) slots) ...
@end verbatim

Then, in the @code{DEFCLASS} template, interpolate that value instead of
the empty list.

@verbatim
(defclass ,name ,superclasses
  ...)
@end verbatim

However, there's a bit more to it than that. You also need to change the
@code{read-value} and @code{write-value} methods so the methods
generated when defining a superclass can be used by the methods
generated as part of a subclass to read and write inherited slots.

The current way @code{read-value} works is particularly problematic
since it instantiates the object before filling it in--obviously, you
can't have the method responsible for reading the superclass's fields
instantiate one object while the subclass's method instantiates and
fills in a different object.

You can fix that problem by splitting @code{read-value} into two
parts--one responsible for instantiating the correct kind of object and
another responsible for filling slots in an existing object. On the
writing side it's a bit simpler, but you can use the same technique.

So you'll define two new generic functions, @code{read-object} and
@code{write-object}, that will both take an existing object and a
stream. Methods on these generic functions will be responsible for
reading or writing the slots specific to the class of the object on
which they're specialized.

@verbatim
(defgeneric read-object (object stream)
  (:method-combination progn :most-specific-last)
  (:documentation "Fill in the slots of object from stream."))

(defgeneric write-object (object stream)
  (:method-combination progn :most-specific-last)
  (:documentation "Write out the slots of object to the stream."))
@end verbatim

Defining these generic functions to use the @code{PROGN} method
combination with the option @code{:most-specific-last} allows you to
define methods that specialize @code{object} on each binary class and
have them deal only with the slots actually defined in that class; the
@code{PROGN} method combination will combine all the applicable methods
so the method specialized on the least specific class in the hierarchy
runs first, reading or writing the slots defined in that class, then the
method specialized on next least specific subclass, and so on. And since
all the heavy lifting for a specific class is now going to be done by
@code{read-object} and @code{write-object}, you don't even need to
define specialized @code{read-value} and @code{write-value} methods; you
can define default methods that assume the type argument is the name of
a binary class.

@verbatim
(defmethod read-value ((type symbol) stream &key)
  (let ((object (make-instance type)))
    (read-object object stream)
    object))

(defmethod write-value ((type symbol) stream value &key)
  (assert (typep value type))
  (write-object value stream))
@end verbatim

Note how you can use @code{MAKE-INSTANCE} as a generic object
factory--while you normally call @code{MAKE-INSTANCE} with a quoted
symbol as the first argument because you normally know exactly what
class you want to instantiate, you can use any expression that evaluates
to a class name such as, in this case, the @code{type} parameter in the
@code{read-value} method.

The actual changes to @code{define-binary-class} to define methods on
@code{read-object} and @code{write-object} rather than @code{read-value}
and @code{write-value} are fairly minor.

@verbatim
(defmacro define-binary-class (name superclasses slots)
  (with-gensyms (objectvar streamvar)
    `(progn
       (defclass ,name ,superclasses
         ,(mapcar #'slot->defclass-slot slots))

       (defmethod read-object progn ((,objectvar ,name) ,streamvar)
         (with-slots ,(mapcar #'first slots) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->read-value x streamvar)) slots)))

       (defmethod write-object progn ((,objectvar ,name) ,streamvar)
         (with-slots ,(mapcar #'first slots) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->write-value x streamvar)) slots))))))
@end verbatim

@node Keeping Track of Inherited Slots
@section Keeping Track of Inherited Slots
@anchor{#keeping-track-of-inherited-slots}
This definition will work for many purposes. However, it doesn't handle
one fairly common situation, namely, when you have a subclass that needs
to refer to inherited slots in its own slot specifications. For
instance, with the current definition of @code{define-binary-class}, you
can define a single class like this:

@verbatim
(define-binary-class generic-frame ()
  ((id (iso-8859-1-string :length 3))
   (size u3)
   (data (raw-bytes :bytes size))))
@end verbatim

The reference to @code{size} in the specification of @code{data} works
the way you'd expect because the expressions that read and write the
@code{data} slot are wrapped in a @code{WITH-SLOTS} that lists all the
object's slots. However, if you try to split that class into two classes
like this:

@verbatim
(define-binary-class frame ()
  ((id (iso-8859-1-string :length 3))
   (size u3)))

(define-binary-class generic-frame (frame)
  ((data (raw-bytes :bytes size))))
@end verbatim

you'll get a compile-time warning when you compile the
@code{generic-frame} definition and a runtime error when you try to use
it because there will be no lexically apparent variable @code{size} in
the @code{read-object} and @code{write-object} methods specialized on
@code{generic-frame}.

What you need to do is keep track of the slots defined by each binary
class and then include inherited slots in the @code{WITH-SLOTS} forms in
the @code{read-object} and @code{write-object} methods.

The easiest way to keep track of information like this is to hang it off
the symbol that names the class. As I discussed in Chapter 21, every
symbol object has an associated property list, which can be accessed via
the functions @code{SYMBOL-PLIST} and @code{GET}. You can associate
arbitrary key/value pairs with a symbol by adding them to its property
list with @code{SETF} of @code{GET}. For instance, if the binary class
@code{foo} defines three slots--@code{x}, @code{y}, and @code{z}--you
can keep track of that fact by adding a @code{slots} key to the symbol
@code{foo}'s property list with the value @code{(x y z)} with this
expression:

@verbatim
(setf (get 'foo 'slots) '(x y z))
@end verbatim

You want this bookkeeping to happen as part of evaluating the
@code{define-binary-class} of @code{foo}. However, it's not clear where
to put the expression. If you evaluate it when you compute the macro's
expansion, it'll get evaluated when you compile the
@code{define-binary-class} form but not if you later load a file that
contains the resulting compiled code. On the other hand, if you include
the expression in the expansion, then it @emph{won't} be evaluated
during compilation, which means if you compile a file with several
@code{define-binary-class} forms, none of the information about what
classes define what slots will be available until the whole file is
loaded, which is too late.

This is what the special operator @code{EVAL-WHEN} I discussed in
Chapter 20 is for. By wrapping a form in an @code{EVAL-WHEN}, you can
control whether it's evaluated at compile time, when the compiled code
is loaded, or both. For cases like this where you want to squirrel away
some information during the compilation of a macro form that you also
want to be available after the compiled form is loaded, you should wrap
it in an @code{EVAL-WHEN} like this:

@verbatim
(eval-when (:compile-toplevel :load-toplevel :execute)
  (setf (get 'foo 'slots) '(x y z)))
@end verbatim

and include the @code{EVAL-WHEN} in the expansion generated by the
macro. Thus, you can save both the slots and the direct superclasses of
a binary class by adding this form to the expansion generated by
@code{define-binary-class}:

@verbatim
(eval-when (:compile-toplevel :load-toplevel :execute)
  (setf (get ',name 'slots) ',(mapcar #'first slots))
  (setf (get ',name 'superclasses) ',superclasses))
@end verbatim

Now you can define three helper functions for accessing this
information. The first simply returns the slots directly defined by a
binary class. It's a good idea to return a copy of the list since you
don't want other code to modify the list of slots after the binary class
has been defined.

@verbatim
(defun direct-slots (name)
  (copy-list (get name 'slots)))
@end verbatim

The next function returns the slots inherited from other binary classes.

@verbatim
(defun inherited-slots (name)
  (loop for super in (get name 'superclasses)
        nconc (direct-slots super)
        nconc (inherited-slots super)))
@end verbatim

Finally, you can define a function that returns a list containing the
names of all directly defined and inherited slots.

@verbatim
(defun all-slots (name)
  (nconc (direct-slots name) (inherited-slots name)))
@end verbatim

When you're computing the expansion of a
@code{define-generic-binary-class} form, you want to generate a
@code{WITH-SLOTS} form that contains the names of all the slots defined
in the new class and all its superclasses. However, you can't use
@code{all-slots} while you're generating the expansion since the
information won't be available until after the expansion is compiled.
Instead, you should use the following function, which takes the list of
slot specifiers and superclasses passed to
@code{define-generic-binary-class} and uses them to compute the list of
all the new class's slots:

@verbatim
(defun new-class-all-slots (slots superclasses)
  (nconc (mapcan #'all-slots superclasses) (mapcar #'first slots)))
@end verbatim

With these functions defined, you can change @code{define-binary-class}
to store the information about the class currently being defined and to
use the already stored information about the superclasses' slots to
generate the @code{WITH-SLOTS} forms you want like this:

@verbatim
(defmacro define-binary-class (name (&rest superclasses) slots)
  (with-gensyms (objectvar streamvar)
    `(progn
       (eval-when (:compile-toplevel :load-toplevel :execute)
         (setf (get ',name 'slots) ',(mapcar #'first slots))
         (setf (get ',name 'superclasses) ',superclasses))

       (defclass ,name ,superclasses
         ,(mapcar #'slot->defclass-slot slots))

       (defmethod read-object progn ((,objectvar ,name) ,streamvar)
         (with-slots ,(new-class-all-slots slots superclasses) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->read-value x streamvar)) slots)))

       (defmethod write-object progn ((,objectvar ,name) ,streamvar)
         (with-slots ,(new-class-all-slots slots superclasses) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->write-value x streamvar)) slots))))))
@end verbatim

@node Tagged Structures
@section Tagged Structures
@anchor{#tagged-structures}
With the ability to define binary classes that extend other binary
classes, you're ready to define a new macro for defining classes to
represent "tagged" structures. The strategy for reading tagged
structures will be to define a specialized @code{read-value} method that
knows how to read the values that make up the start of the structure and
then use those values to determine what subclass to instantiate. It'll
then make an instance of that class with @code{MAKE-INSTANCE}, passing
the already read values as initargs, and pass the object to
@code{read-object}, allowing the actual class of the object to determine
how the rest of the structure is read.

The new macro, @code{define-tagged-binary-class}, will look like
@code{define-binary-class} with the addition of a @code{:dispatch}
option used to specify a form that should evaluate to the name of a
binary class. The @code{:dispatch} form will be evaluated in a context
where the names of the slots defined by the tagged class are bound to
variables that hold the values read from the file. The class whose name
it returns must accept initargs corresponding to the slot names defined
by the tagged class. This is easily ensured if the @code{:dispatch} form
always evaluates to the name of a class that subclasses the tagged
class.

For instance, supposing you have a function, @code{find-frame-class},
that will map a string identifier to a binary class representing a
particular kind of ID3 frame, you might define a tagged binary class,
@code{id3-frame}, like this:

@verbatim
(define-tagged-binary-class id3-frame ()
  ((id   (iso-8859-1-string :length 3))
   (size u3))
  (:dispatch (find-frame-class id)))
@end verbatim

The expansion of a @code{define-tagged-binary-class} will contain a
@code{DEFCLASS} and a @code{write-object} method just like the expansion
of @code{define-binary-class}, but instead of a @code{read-object}
method it'll contain a @code{read-value} method that looks like this:

@verbatim
(defmethod read-value ((type (eql 'id3-frame)) stream &key)
  (let ((id (read-value 'iso-8859-1-string stream :length 3))
        (size (read-value 'u3 stream)))
    (let ((object (make-instance (find-frame-class id) :id id :size size)))
      (read-object object stream)
      object)))
@end verbatim

Since the expansions of @code{define-tagged-binary-class} and
@code{define-binary-class} are going to be identical except for the read
method, you can factor out the common bits into a helper macro,
@code{define-generic-binary-class}, that accepts the read method as a
parameter and interpolates it.

@verbatim
(defmacro define-generic-binary-class (name (&rest superclasses) slots read-method)
  (with-gensyms (objectvar streamvar)
    `(progn
       (eval-when (:compile-toplevel :load-toplevel :execute)
         (setf (get ',name 'slots) ',(mapcar #'first slots))
         (setf (get ',name 'superclasses) ',superclasses))

       (defclass ,name ,superclasses
         ,(mapcar #'slot->defclass-slot slots))

       ,read-method

       (defmethod write-object progn ((,objectvar ,name) ,streamvar)
         (declare (ignorable ,streamvar))
         (with-slots ,(new-class-all-slots slots superclasses) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->write-value x streamvar)) slots))))))
@end verbatim

Now you can define both @code{define-binary-class} and
@code{define-tagged-binary-class} to expand into a call to
@code{define-generic-binary-class}. Here's a new version of
@code{define-binary-class} that generates the same code as the earlier
version when it's fully expanded:

@verbatim
(defmacro define-binary-class (name (&rest superclasses) slots)
  (with-gensyms (objectvar streamvar)
    `(define-generic-binary-class ,name ,superclasses ,slots
       (defmethod read-object progn ((,objectvar ,name) ,streamvar)
         (declare (ignorable ,streamvar))
         (with-slots ,(new-class-all-slots slots superclasses) ,objectvar
           ,@(mapcar #'(lambda (x) (slot->read-value x streamvar)) slots))))))
@end verbatim

And here's @code{define-tagged-binary-class} along with two new helper
functions it uses:

@verbatim
(defmacro define-tagged-binary-class (name (&rest superclasses) slots &rest options)
  (with-gensyms (typevar objectvar streamvar)
    `(define-generic-binary-class ,name ,superclasses ,slots
      (defmethod read-value ((,typevar (eql ',name)) ,streamvar &key)
        (let* ,(mapcar #'(lambda (x) (slot->binding x streamvar)) slots)
          (let ((,objectvar
                 (make-instance 
                  ,@(or (cdr (assoc :dispatch options))
                        (error "Must supply :dispatch form."))
                  ,@(mapcan #'slot->keyword-arg slots))))
            (read-object ,objectvar ,streamvar)
            ,objectvar))))))

(defun slot->binding (spec stream)
  (destructuring-bind (name (type &rest args)) (normalize-slot-spec spec)
    `(,name (read-value ',type ,stream ,@args))))

(defun slot->keyword-arg (spec)
  (let ((name (first spec)))
    `(,(as-keyword name) ,name)))
@end verbatim

@node Primitive Binary Types
@section Primitive Binary Types
@anchor{#primitive-binary-types}
While @code{define-binary-class} and @code{define-tagged-binary-class}
make it easy to define composite structures, you still have to write
@code{read-value} and @code{write-value} methods for primitive data
types by hand. You could decide to live with that, specifying that users
of the library need to write appropriate methods on @code{read-value}
and @code{write-value} to support the primitive types used by their
binary classes.

However, rather than having to document how to write a suitable
@code{read-value}/@code{write-value} pair, you can provide a macro to do
it automatically. This also has the advantage of making the abstraction
created by @code{define-binary-class} less leaky. Currently,
@code{define-binary-class} depends on having methods on
@code{read-value} and @code{write-value} defined in a particular way,
but that's really just an implementation detail. By defining a macro
that generates the @code{read-value} and @code{write-value} methods for
primitive types, you hide those details behind an abstraction you
control. If you decide later to change the implementation of
@code{define-binary-class}, you can change your primitive-type-defining
macro to meet the new requirements without requiring any changes to code
that uses the binary data library.

So you should define one last macro, @code{define-binary-type}, that
will generate @code{read-value} and @code{write-value} methods for
reading values represented by instances of existing classes, rather than
by classes defined with @code{define-binary-class}.

For a concrete example, consider a type used in the @code{id3-tag}
class, a fixed-length string encoded in ISO-8859-1 characters. I'll
assume, as I did earlier, that the native character encoding of your
Lisp is ISO-8859-1 or a superset, so you can use @code{CODE-CHAR} and
@code{CHAR-CODE} to translate bytes to characters and back.

As always, your goal is to write a macro that allows you to express only
the essential information needed to generate the required code. In this
case, there are four pieces of essential information: the name of the
type, @code{iso-8859-1-string}; the @code{&key} parameters that should
be accepted by the @code{read-value} and @code{write-value} methods,
@code{length} in this case; the code for reading from a stream; and the
code for writing to a stream. Here's an expression that contains those
four pieces of information:

@verbatim
(define-binary-type iso-8859-1-string (length)
  (:reader (in)
    (let ((string (make-string length)))
      (dotimes (i length)
        (setf (char string i) (code-char (read-byte in))))
      string))
  (:writer (out string)
    (dotimes (i length)
      (write-byte (char-code (char string i)) out))))
@end verbatim

Now you just need a macro that can take apart this form and put it back
together in the form of two @code{DEFMETHOD}s wrapped in a @code{PROGN}.
If you define the parameter list to @code{define-binary-type} like this:

@verbatim
 (defmacro define-binary-type (name (&rest args) &body spec) ...
@end verbatim

then within the macro the parameter @code{spec} will be a list
containing the reader and writer definitions. You can then use
@code{ASSOC} to extract the elements of @code{spec} using the tags
@code{:reader} and @code{:writer} and then use
@code{DESTRUCTURING-BIND} to take apart the @code{REST} of each
element.@footnote{Using @code{ASSOC} to extract the @code{:reader} and
@code{:writer} elements of @code{spec} allows users of
@code{define-binary-type} to include the elements in either order; if
you required the @code{:reader} element to be always be first, you
could then have used @code{(rest (first spec))} to extract the reader
and @code{(rest (second spec))} to extract the writer. However, as
long as you require the @code{:reader} and @code{:writer} keywords to
improve the readability of @code{define-binary-type} forms, you might
as well use them to extract the correct data.}

From there it's just a matter of interpolating the extracted values into
the backquoted templates of the @code{read-value} and @code{write-value}
methods.

@verbatim
(defmacro define-binary-type (name (&rest args) &body spec)
  (with-gensyms (type)
    `(progn
      ,(destructuring-bind ((in) &body body) (rest (assoc :reader spec))
        `(defmethod read-value ((,type (eql ',name)) ,in &key ,@args)
          ,@body))
      ,(destructuring-bind ((out value) &body body) (rest (assoc :writer spec))
        `(defmethod write-value ((,type (eql ',name)) ,out ,value &key ,@args)
          ,@body)))))
@end verbatim

Note how the backquoted templates are nested: the outermost template
starts with the backquoted @code{PROGN} form. That template consists of
the symbol @code{PROGN} and two comma-unquoted @code{DESTRUCTURING-BIND}
expressions. Thus, the outer template is filled in by evaluating the
@code{DESTRUCTURING-BIND} expressions and interpolating their values.
Each @code{DESTRUCTURING-BIND} expression in turn contains another
backquoted template, which is used to generate one of the method
definitions to be interpolated in the outer template.

With this macro defined, the @code{define-binary-type} form given
previously expands to this code:

@verbatim
(progn
  (defmethod read-value ((#:g1618 (eql 'iso-8859-1-string)) in &key length)
    (let ((string (make-string length)))
      (dotimes (i length)
        (setf (char string i) (code-char (read-byte in))))
      string))
  (defmethod write-value ((#:g1618 (eql 'iso-8859-1-string)) out string &key length)
    (dotimes (i length)
      (write-byte (char-code (char string i)) out))))
@end verbatim

Of course, now that you've got this nice macro for defining binary
types, it's tempting to make it do a bit more work. For now you should
just make one small enhancement that will turn out to be pretty handy
when you start using this library to deal with actual formats such as
ID3 tags.

ID3 tags, like many other binary formats, use lots of primitive types
that are minor variations on a theme, such as unsigned integers in one-,
two-, three-, and four-byte varieties. You could certainly define each
of those types with @code{define-binary-type} as it stands. Or you could
factor out the common algorithm for reading and writing @emph{n}-byte
unsigned integers into helper functions.

But suppose you had already defined a binary type,
@code{unsigned-integer}, that accepts a @code{:bytes} parameter to
specify how many bytes to read and write. Using that type, you could
specify a slot representing a one-byte unsigned integer with a type
specifier of @code{(unsigned-integer :bytes 1)}. But if a particular
binary format specifies lots of slots of that type, it'd be nice to be
able to easily define a new type--say, @code{u1}--that means the same
thing. As it turns out, it's easy to change @code{define-binary-type} to
support two forms, a long form consisting of a @code{:reader} and
@code{:writer} pair and a short form that defines a new binary type in
terms of an existing type. Using a short form @code{define-binary-type},
you can define @code{u1} like this:

@verbatim
(define-binary-type u1 () (unsigned-integer :bytes 1))
@end verbatim

which will expand to this:

@verbatim
(progn
  (defmethod read-value ((#:g161887 (eql 'u1)) #:g161888 &key)
    (read-value 'unsigned-integer #:g161888 :bytes 1))
  (defmethod write-value ((#:g161887 (eql 'u1)) #:g161888 #:g161889 &key)
    (write-value 'unsigned-integer #:g161888 #:g161889 :bytes 1)))
@end verbatim

To support both long- and short-form @code{define-binary-type} calls,
you need to differentiate based on the value of the @code{spec}
argument. If @code{spec} is two items long, it represents a long-form
call, and the two items should be the @code{:reader} and @code{:writer}
specifications, which you extract as before. On the other hand, if it's
only one item long, the one item should be a type specifier, which needs
to be parsed differently. You can use @code{ECASE} to switch on the
@code{LENGTH} of @code{spec} and then parse @code{spec} and generate an
appropriate expansion for either the long form or the short form.

@verbatim
(defmacro define-binary-type (name (&rest args) &body spec)
  (ecase (length spec)
    (1
     (with-gensyms (type stream value)
       (destructuring-bind (derived-from &rest derived-args) (mklist (first spec))
         `(progn
            (defmethod read-value ((,type (eql ',name)) ,stream &key ,@args)
              (read-value ',derived-from ,stream ,@derived-args))
            (defmethod write-value ((,type (eql ',name)) ,stream ,value &key ,@args)
              (write-value ',derived-from ,stream ,value ,@derived-args))))))
    (2
     (with-gensyms (type)
       `(progn
          ,(destructuring-bind ((in) &body body) (rest (assoc :reader spec))
             `(defmethod read-value ((,type (eql ',name)) ,in &key ,@args)
                ,@body))
          ,(destructuring-bind ((out value) &body body) (rest (assoc :writer spec))
             `(defmethod write-value ((,type (eql ',name)) ,out ,value &key ,@args)
                ,@body)))))))
@end verbatim

@node The Current Object Stack
@section The Current Object Stack
@anchor{#the-current-object-stack}
One last bit of functionality you'll need in the next chapter is a way
to get at the binary object being read or written while reading and
writing. More generally, when reading or writing nested composite
objects, it's useful to be able to get at any of the objects currently
being read or written. Thanks to dynamic variables and @code{:around}
methods, you can add this enhancement with about a dozen lines of code.
To start, you should define a dynamic variable that will hold a stack of
objects currently being read or written.

@verbatim
(defvar *in-progress-objects* nil)
@end verbatim

Then you can define @code{:around} methods on @code{read-object} and
@code{write-object} that push the object being read or written onto this
variable before invoking @code{CALL-NEXT-METHOD}.

@verbatim
(defmethod read-object :around (object stream)
  (declare (ignore stream))
  (let ((*in-progress-objects* (cons object *in-progress-objects*)))
    (call-next-method)))

(defmethod write-object :around (object stream)
  (declare (ignore stream))
  (let ((*in-progress-objects* (cons object *in-progress-objects*)))
    (call-next-method)))
@end verbatim

Note how you rebind @code{*in-progress-objects*} to a list with a new
item on the front rather than assigning it a new value. This way, at the
end of the @code{LET}, after @code{CALL-NEXT-METHOD} returns, the old
value of @code{*in-progress-objects*} will be restored, effectively
popping the object of the stack.

With those two methods defined, you can provide two convenience
functions for getting at specific objects in the in-progress stack. The
function @code{current-binary-object} will return the head of the stack,
the object whose @code{read-object} or @code{write-object} method was
invoked most recently. The other, @code{parent-of-type}, takes an
argument that should be the name of a binary object class and returns
the most recently pushed object of that type, using the @code{TYPEP}
function that tests whether a given object is an instance of a
particular type.

@verbatim
(defun current-binary-object () (first *in-progress-objects*))

(defun parent-of-type (type)
  (find-if #'(lambda (x) (typep x type)) *in-progress-objects*))
@end verbatim

These two functions can be used in any code that will be called within
the dynamic extent of a @code{read-object} or @code{write-object}
call.  You'll see one example of how @code{current-binary-object} can
be used in the next chapter.@footnote{The ID3 format doesn't require
the @code{parent-of-type} function since it's a relatively flat
structure.  This function comes into its own when you need to parse a
format made up of many deeply nested structures whose parsing depends
on information stored in higher-level structures. For example, in the
Java class file format, the top-level class file structure contains a
@emph{constant pool} that maps numeric values used in other
substructures within the class file to constant values that are needed
while parsing those substructures. If you were writing a class file
parser, you could use @code{parent-of-type} in the code that reads and
writes those substructures to get at the top-level class file object
and from there to the constant pool.}

Now you have all the tools you need to tackle an ID3 parsing library, so
you're ready to move onto the next chapter where you'll do just that.

@node Practical An ID3 Parser
@chapter Practical: An ID3 Parser
@anchor{#practical-an-id3-parser}
With a library for parsing binary data, you're ready to write some code
for reading and writing an actual binary format, that of ID3 tags. ID3
tags are used to embed metadata in MP3 audio files. Dealing with ID3
tags will be a good test of the binary data library because the ID3
format is a true real-world format--a mix of engineering trade-offs and
idiosyncratic design choices that does, whatever else might be said
about it, get the job done. In case you missed the file-sharing
revolution, here's a quick overview of what ID3 tags are and how they
relate to MP3 files.

MP3, also known as MPEG Audio Layer 3, is a format for storing
compressed audio data, designed by researchers at Fraunhofer IIS and
standardized by the Moving Picture Experts Group, a joint committee of
the International Organization for Standardization (ISO) and the
International Electrotechnical Commission (IEC). However, the MP3
format, by itself, defines only how to store audio data. That's fine as
long as all your MP3 files are managed by a single application that can
store metadata externally and keep track of which metadata goes with
which files. However, when people started passing around individual MP3
files on the Internet, via file-sharing systems such as Napster, they
soon discovered they needed a way to embed metadata in the MP3 files
themselves.

Because the MP3 standard was already codified and a fair bit of software
and hardware had already been written that knew how to decode the
existing MP3 format, any scheme for embedding information in an MP3 file
would have to be invisible to MP3 decoders. Enter ID3.

The original ID3 format, invented by programmer Eric Kemp, consisted of
128 bytes stuck on the end of an MP3 file where it'd be ignored by most
MP3 software. It consisted of four 30-character fields, one each for the
song title, the album title, the artist name, and a comment; a four-byte
year field; and a one-byte genre code. Kemp provided standard meanings
for the first 80 genre codes. Nullsoft, the makers of Winamp, a popular
MP3 player, later supplemented this list with another 60 or so genres.

This format was easy to parse but obviously quite limited. It had no way
to encode names longer than 30 characters; it was limited to 256 genres,
and the meaning of the genre codes had to be agreed upon by all users of
ID3-aware software. There wasn't even a way to encode the CD track
number of a particular MP3 file until another programmer, Michael
Mutschler, proposed embedding the track number in the comment field,
separated from the rest of the comment by a null byte, so existing ID3
software, which tended to read up to the first null in each of the text
fields, would ignore it. Kemp's version is now called ID3v1, and
Mutschler's is ID3v1.1.

Limited as they were, the version 1 proposals were at least a partial
solution to the metadata problem, so they were adopted by many MP3
ripping programs (which had to put the ID3 tag into the MP3 files) and
MP3 players (which would extract the information in the ID3 tag to
display to the user).@footnote{@emph{Ripping} is the process by which
a song on an audio CD is converted to an MP3 file on your hard
drive. These days most ripping software also automatically retrieves
information about the songs being ripped from online databases such as
Gracenote (nee the Compact Disc Database [CDDB]) or FreeDB, which it
then embeds in the MP3 files as ID3 tags.}

By 1998, however, the limitations were really becoming annoying, and a
new group, led by Martin Nilsson, started work on a completely new
tagging scheme, which came to be called ID3v2. The ID3v2 format is
extremely flexible, allowing for many kinds of information to be
included, with almost no length limitations. It also takes advantage of
certain details of the MP3 format to allow ID3v2 tags to be placed at
the beginning of an MP3 file.

ID3v2 tags are, however, more of a challenge to parse than version 1
tags. In this chapter, you'll use the binary data parsing library from
the previous chapter to develop code that can read and write ID3v2 tags.
Or at least you'll make a reasonable start--where ID3v1 was too simple,
ID3v2 is baroque to the point of being completely overengineered.
Implementing every nook and cranny of the specification, especially if
you want to support all three versions that have been specified, would
be a fair bit of work. However, you can ignore many of the features in
those specifications since they're rarely used "in the wild." For
starters, you can ignore, for now, a whole version, 2.4, since it has
not been widely adopted and mostly just adds more needless flexibility
compared to version 2.3. I'll focus on versions 2.2 and 2.3 because
they're both widely used and are different enough from each other to
keep things interesting.
@menu
* Structure of an ID3v2 Tag::
* Defining a Package::
* Integer Types::
* String Types::
* ID3 Tag Header::
* ID3 Frames::
* Detecting Tag Padding::
* Supporting Multiple Versions of ID3::
* Versioned Frame Base Classes::
* Versioned Concrete Frame Classes::
* What Frames Do You Actually Need?::
* Text Information Frames::
* Comment Frames::
* Extracting Information from an ID3 Tag::
@end menu

@node Structure of an ID3v2 Tag
@section Structure of an ID3v2 Tag
@anchor{#structure-of-an-id3v2-tag}
Before you can start cutting code, you'll need to be familiar with the
overall structure of an ID3v2 tag. A tag starts with a header containing
information about the tag as a whole. The first three bytes of the
header encode the string "ID3" in ISO-8859-1 characters. In other words,
they're the bytes 73, 68, and 51. Then comes two bytes that encode the
major version and revision of the ID3 specification to which the tag
purports to conform. They're followed by a single byte whose individual
bits are treated as flags. The meanings of the individual flags depend
on the version of the spec. Some of the flags can affect the way the
rest of the tag is parsed. The "major version" is actually used to
record the minor version of the spec, while the "revision" is the
subminor version of the spec. Thus, the "major version" field for a tag
conforming to the 2.3.0 spec is 3. The revision field is always zero
since each new ID3v2 spec has bumped the minor version, leaving the
subminor version at zero. The value stored in the major version field of
the tag has, as you'll see, a dramatic effect on how you'll parse the
rest of the tag.

The last field in the tag header is an integer, encoded in four bytes
but using only seven bits from each byte, that gives the total size of
the tag, not counting the header. In version 2.3 tags, the header may be
followed by several @emph{extended header} fields; otherwise, the
remainder of the tag data is divided into @emph{frames}. Different types
of frames store different kinds of information, from simple textual
information, such as the song name, to embedded images. Each frame
starts with a header containing a string identifier and a size. In
version 2.3, the frame header also contains two bytes worth of flags
and, depending on the value of one the flags, an optional one-byte code
indicating how the rest of the frame is encrypted.

Frames are a perfect example of a tagged data structure--to know how to
parse the body of a frame, you need to read the header and use the
identifier to determine what kind of frame you're reading.

The ID3 tag header contains no direct indication of how many frames
are in a tag--the tag header tells you how big the tag is, but since
many frames are variable length, the only way to find out how many
frames the tag contains is to read the frame data. Also, the size
given in the tag header may be larger than the actual number of bytes
of frame data; the frames may be followed with enough null bytes to
pad the tag out to the specified size. This makes it possible for tag
editors to modify a tag without having to rewrite the whole MP3
file.@footnote{Almost all file systems provide the ability to
overwrite existing bytes of a file, but few, if any, provide a way to
add or remove data at the beginning or middle of a file without having
to rewrite the rest of the file. Since ID3 tags are typically stored
at the beginning of a file, to rewrite an ID3 tag without disturbing
the rest of the file you must replace the old tag with a new tag of
exactly the same length. By writing ID3 tags with a certain amount of
padding, you have a better chance of being able to do so--if the new
tag has more data than the original tag, you use less padding, and if
it's shorter, you use more.}

So, the main issues you have to deal with are reading the ID3 header;
determining whether you're reading a version 2.2 or 2.3 tag; and reading
the frame data, stopping either when you've read the complete tag or
when you've hit the padding bytes.

@node Defining a Package
@section Defining a Package
@anchor{#defining-a-package}
Like the other libraries you've developed so far, the code you'll write
in this chapter is worth putting in its own package. You'll need to
refer to functions from both the binary data and pathname libraries
developed in Chapters 24 and 15 and will also want to export the names
of the functions that make up the public API to this package. The
following package definition does all that:

@verbatim
(defpackage :com.gigamonkeys.id3v2
  (:use :common-lisp
        :com.gigamonkeys.binary-data
        :com.gigamonkeys.pathnames)
  (:export
   :read-id3
   :mp3-p
   :id3-p
   :album
   :composer
   :genre
   :encoding-program
   :artist
   :part-of-set
   :track
   :song
   :year
   :size
   :translated-genre))
@end verbatim

As usual, you can, and probably should, change the
@code{com.gigamonkeys} part of the package name to your own domain.

@node Integer Types
@section Integer Types
@anchor{#integer-types}
You can start by defining binary types for reading and writing several
of the primitive types used by the ID3 format, various sizes of unsigned
integers, and four kinds of strings.

ID3 uses unsigned integers encoded in one, two, three, and four bytes.
If you first write a general @code{unsigned-integer} binary type that
takes the number of bytes to read as an argument, you can then use the
short form of @code{define-binary-type} to define the specific types.
The general @code{unsigned-integer} type looks like this:

@verbatim
(define-binary-type unsigned-integer (bytes)
  (:reader (in)
    (loop with value = 0
       for low-bit downfrom (* 8 (1- bytes)) to 0 by 8 do
         (setf (ldb (byte 8 low-bit) value) (read-byte in))
       finally (return value)))
  (:writer (out value)
    (loop for low-bit downfrom (* 8 (1- bytes)) to 0 by 8
       do (write-byte (ldb (byte 8 low-bit) value) out))))
@end verbatim

Now you can use the short form of @code{define-binary-type} to define
one type for each size of integer used in the ID3 format like this:

@verbatim
(define-binary-type u1 () (unsigned-integer :bytes 1))
(define-binary-type u2 () (unsigned-integer :bytes 2))
(define-binary-type u3 () (unsigned-integer :bytes 3))
(define-binary-type u4 () (unsigned-integer :bytes 4))
@end verbatim

Another type you'll need to be able to read and write is the 28-bit
value used in the header. This size is encoded using 28 bits rather
than a multiple of 8, such as 32 bits, because an ID3 tag can't
contain the byte @code{#xff} followed by a byte with the top 3 bits on
because that pattern has a special meaning to MP3 decoders. None of
the other fields in the ID3 header could possibly contain such a byte
sequence, but if you encoded the tag size as a regular
@code{unsigned-integer}, it might.  To avoid that possibility, the
size is encoded using only the bottom seven bits of each byte, with
the top bit always zero.@footnote{The frame data following the ID3
header could also potentially contain the illegal sequence. That's
prevented using a different scheme that's turned on via one of the
flags in the tag header. The code in this chapter doesn't account for
the possibility that this flag might be set; in practice it's rarely
used.}

Thus, it can be read and written a lot like an @code{unsigned-integer}
except the size of the byte specifier you pass to @code{LDB} should be
seven rather than eight. This similarity suggests that if you add a
parameter, @code{bits-per-byte}, to the existing @code{unsigned-integer}
binary type, you could then define a new type, @code{id3-tag-size},
using a short-form @code{define-binary-type}. The new version of
@code{unsigned-integer} is just like the old version except with
@code{bits-per-byte} used everywhere the old version hardwired the
number eight. It looks like this:

@verbatim
(define-binary-type unsigned-integer (bytes bits-per-byte)
  (:reader (in)
    (loop with value = 0
       for low-bit downfrom (* bits-per-byte (1- bytes)) to 0 by bits-per-byte do
         (setf (ldb (byte bits-per-byte low-bit) value) (read-byte in))
       finally (return value)))
  (:writer (out value)
    (loop for low-bit downfrom (* bits-per-byte (1- bytes)) to 0 by bits-per-byte
       do (write-byte (ldb (byte bits-per-byte low-bit) value) out))))
@end verbatim

The definition of @code{id3-tag-size} is then trivial.

@verbatim
(define-binary-type id3-tag-size () (unsigned-integer :bytes 4 :bits-per-byte 7))
@end verbatim

You'll also have to change the definitions of @code{u1} through
@code{u4} to specify eight bits per byte like this:

@verbatim
(define-binary-type u1 () (unsigned-integer :bytes 1 :bits-per-byte 8))
(define-binary-type u2 () (unsigned-integer :bytes 2 :bits-per-byte 8))
(define-binary-type u3 () (unsigned-integer :bytes 3 :bits-per-byte 8))
(define-binary-type u4 () (unsigned-integer :bytes 4 :bits-per-byte 8))
@end verbatim

@node String Types
@section String Types
@anchor{#string-types}
The other kinds of primitive types that are ubiquitous in the ID3 format
are strings. In the previous chapter I discussed some of the issues you
have to consider when dealing with strings in binary files, such as the
difference between character codes and character encodings.

ID3 uses two different character codes, ISO 8859-1 and Unicode. ISO
8859-1, also known as Latin-1, is an eight-bit character code that
extends ASCII with characters used by the languages of Western Europe.
In other words, the code points from 0-127 map to the same characters in
ASCII and ISO 8859-1, but ISO 8859-1 also provides mappings for code
points up to 255. Unicode is a character code designed to provide a code
point for virtually every character of all the world's languages.
Unicode is a superset of ISO 8859-1 in the same way that ISO 8859-1 is a
superset of ASCII--the code points from 0-255 map to the same characters
in both ISO 8859-1 and Unicode. (Thus, Unicode is also a superset of
ASCII.)

Since ISO 8859-1 is an eight-bit character code, it's encoded using
one byte per character. For Unicode strings, ID3 uses the UCS-2
encoding with a leading @emph{byte order mark}.@footnote{In ID3v2.4,
UCS-2 is replaced by the virtually identical UTF-16, and UTF-16BE and
UTF-8 are added as additional encodings.} I'll discuss what a byte
order mark is in a moment.

Reading and writing these two encodings isn't a problem--it's just a
question of reading and writing unsigned integers in various formats,
and you just finished writing the code to do that. The trick is how you
translate those numeric values to Lisp character objects.

The Lisp implementation you're using probably uses either Unicode or ISO
8859-1 as its internal character code. And since all the values from
0-255 map to the same characters in both ISO 8859-1 and Unicode, you can
use Lisp's @code{CODE-CHAR} and @code{CHAR-CODE} functions to translate
those values in both character codes. However, if your Lisp supports
only ISO 8859-1, then you'll be able to represent only the first 255
Unicode characters as Lisp characters. In other words, in such a Lisp
implementation, if you try to process an ID3 tag that uses Unicode
strings and if any of those strings contain characters with code points
higher than 255, you'll get an error when you try to translate the code
point to a Lisp character. For now I'll assume either you're using a
Unicode-based Lisp or you won't process any files containing characters
outside the ISO 8859-1 range.

The other issue with encoding strings is how to know how many bytes to
interpret as character data. ID3 uses two strategies I mentioned in the
previous chapter--some strings are terminated with a null character,
while other strings occur in positions where you can determine the
number of bytes to read, either because the string at that position is
always the same length or because the string is at the end of a
composite structure whose overall size you know. Note, however, that the
number of bytes isn't necessarily the same as the number of characters
in the string.

Putting all these variations together, the ID3 format uses four ways to
read and write strings--two characters crossed with two ways of
delimiting the string data.

Obviously, much of the logic of reading and writing strings will be
quite similar. So, you can start by defining two binary types, one for
reading strings of a specific length (in characters) and another for
reading terminated strings. Both types take advantage of that the type
argument to @code{read-value} and @code{write-value} is just another
piece of data; you can make the type of character to read a parameter of
these types. This is a technique you'll use quite a few times in this
chapter.

@verbatim
(define-binary-type generic-string (length character-type)
  (:reader (in)
    (let ((string (make-string length)))
      (dotimes (i length)
        (setf (char string i) (read-value character-type in)))
      string))
  (:writer (out string)
    (dotimes (i length)
      (write-value character-type out (char string i)))))

(define-binary-type generic-terminated-string (terminator character-type)
  (:reader (in)
    (with-output-to-string (s)
      (loop for char = (read-value character-type in)
            until (char= char terminator) do (write-char char s))))
  (:writer (out string)
    (loop for char across string
          do (write-value character-type out char)
          finally (write-value character-type out terminator))))
@end verbatim

With these types available, there's not much to reading ISO 8859-1
strings. Because the @code{character-type} argument you pass to
@code{read-value} and @code{write-value} of a @code{generic-string} must
be the name of a binary type, you need to define an
@code{iso-8859-1-char} binary type. This also gives you a good place to
put a bit of sanity checking on the code points of characters you read
and write.

@verbatim
(define-binary-type iso-8859-1-char ()
  (:reader (in)
    (let ((code (read-byte in)))
      (or (code-char code)
          (error "Character code ~d not supported" code))))
  (:writer (out char)
    (let ((code (char-code char)))
      (if (<= 0 code #xff)
          (write-byte code out)
          (error "Illegal character for iso-8859-1 encoding: character: ~c with code: ~d" char code)))))
@end verbatim

Now defining the ISO 8859-1 string types is trivial using the short form
of @code{define-binary-type} as follows:

@verbatim
(define-binary-type iso-8859-1-string (length)
  (generic-string :length length :character-type 'iso-8859-1-char))

(define-binary-type iso-8859-1-terminated-string (terminator)
  (generic-terminated-string :terminator terminator :character-type 'iso-8859-1-char))
@end verbatim

Reading UCS-2 strings is only slightly more complex. The complexity
arises because you can encode a UCS-2 code point in two ways: most
significant byte first (big-endian) or least significant byte first
(little-endian). UCS-2 strings therefore start with two extra bytes,
called the @emph{byte order mark}, made up of the numeric value
@code{#xfeff} encoded in either big-endian form or little-endian form.
When reading a UCS-2 string, you read the byte order mark and then,
depending on its value, read either big-endian or little-endian
characters. Thus, you'll need two different UCS-2 character types. But
you need only one version of the sanity-checking code, so you can define
a parameterized binary type like this:

@verbatim
(define-binary-type ucs-2-char (swap)
  (:reader (in)
    (let ((code (read-value 'u2 in)))
      (when swap (setf code (swap-bytes code)))
      (or (code-char code) (error "Character code ~d not supported" code))))
  (:writer (out char)
    (let ((code (char-code char)))
      (unless (<= 0 code #xffff)
        (error "Illegal character for ucs-2 encoding: ~c with char-code: ~d" char code))
      (when swap (setf code (swap-bytes code)))
      (write-value 'u2 out code))))
@end verbatim

where the @code{swap-bytes} function can be defined as follows, taking
advantage of @code{LDB} being @code{SETF}able and thus
@code{ROTATEF}able:

@verbatim
(defun swap-bytes (code)
  (assert (<= code #xffff))
  (rotatef (ldb (byte 8 0) code) (ldb (byte 8 8) code))
  code)
@end verbatim

Using @code{ucs-2-char}, you can define two character types that will be
used as the @code{character-type} arguments to the generic string
functions.

@verbatim
(define-binary-type ucs-2-char-big-endian () (ucs-2-char :swap nil))

(define-binary-type ucs-2-char-little-endian () (ucs-2-char :swap t))
@end verbatim

Then you need a function that returns the name of the character type to
use based on the value of the byte order mark.

@verbatim
(defun ucs-2-char-type (byte-order-mark)
  (ecase byte-order-mark
    (#xfeff 'ucs-2-char-big-endian)
    (#xfffe 'ucs-2-char-little-endian)))
@end verbatim

Now you can define length- and terminator-delimited string types for
UCS-2-encoded strings that read the byte order mark and use it to
determine which variant of UCS-2 character to pass as the
@code{character-type} argument to @code{read-value} and
@code{write-value}. The only other wrinkle is that you need to translate
the @code{length} argument, which is a number of bytes, to the number of
characters to read, accounting for the byte order mark.

@verbatim
(define-binary-type ucs-2-string (length)
  (:reader (in)
    (let ((byte-order-mark (read-value 'u2 in))
          (characters (1- (/ length 2))))
      (read-value
       'generic-string in
       :length characters
       :character-type (ucs-2-char-type byte-order-mark))))
  (:writer (out string)
    (write-value 'u2 out #xfeff)
    (write-value
     'generic-string out string
     :length (length string)
     :character-type (ucs-2-char-type #xfeff))))

(define-binary-type ucs-2-terminated-string (terminator)
  (:reader (in)
    (let ((byte-order-mark (read-value 'u2 in)))
      (read-value
       'generic-terminated-string in
       :terminator terminator
       :character-type (ucs-2-char-type byte-order-mark))))
  (:writer (out string)
    (write-value 'u2 out #xfeff)
    (write-value 
     'generic-terminated-string out string
     :terminator terminator
     :character-type (ucs-2-char-type #xfeff))))
@end verbatim

@node ID3 Tag Header
@section ID3 Tag Header
@anchor{#id3-tag-header}
With the basic primitive types done, you're ready to switch to a
high-level view and start defining binary classes to represent first the
ID3 tag as a whole and then the individual frames.

If you turn first to the ID3v2.2 specification, you'll see that the
basic structure of the tag is this header:

@verbatim
ID3/file identifier      "ID3"
ID3 version              $02 00
ID3 flags                %xx000000
ID3 size             4 * %0xxxxxxx
@end verbatim

followed by frame data and padding. Since you've already defined binary
types to read and write all the fields in the header, defining a class
that can read the header of an ID3 tag is just a matter of putting them
together.

@verbatim
(define-binary-class id3-tag ()
  ((identifier     (iso-8859-1-string :length 3))
   (major-version  u1)
   (revision       u1)
   (flags          u1)
   (size           id3-tag-size)))
@end verbatim

If you have some MP3 files lying around, you can test this much of the
code and also see what version of ID3 tags your MP3s contain. First
you can write a function that reads an @code{id3-tag}, as just
defined, from the beginning of a file. Be aware, however, that ID3
tags aren't required to appear at the beginning of a file, though
these days they almost always do. To find an ID3 tag elsewhere in a
file, you can scan the file looking for the sequence of bytes 73, 68,
51 (in other words, the string "ID3").@footnote{The 2.4 version of the
ID3 format also supports placing a footer at the end of a tag, which
makes it easier to find a tag appended to the end of a file.} For now
you can probably get away with assuming the tags are the first thing
in the file.

@verbatim
(defun read-id3 (file)
  (with-open-file (in file :element-type '(unsigned-byte 8))
    (read-value 'id3-tag in)))
@end verbatim

On top of this function you can build a function that takes a filename
and prints the information in the tag header along with the name of the
file.

@verbatim
(defun show-tag-header (file)
  (with-slots (identifier major-version revision flags size) (read-id3 file)
    (format t "~a ~d.~d ~8,'0b ~d bytes -- ~a~%"
            identifier major-version revision flags size (enough-namestring file))))
@end verbatim

It prints output that looks like this:

@verbatim
ID3V2> (show-tag-header "/usr2/mp3/Kitka/Wintersongs/02 Byla Cesta.mp3")
ID3 2.0 00000000 2165 bytes -- Kitka/Wintersongs/02 Byla Cesta.mp3
NIL
@end verbatim

Of course, to determine what versions of ID3 are most common in your MP3
library, it'd be handier to have a function that returns a summary of
all the MP3 files under a given directory. You can write one easily
enough using the @code{walk-directory} function defined in Chapter 15.
First define a helper function that tests whether a given filename has
an @code{mp3} extension.

@verbatim
(defun mp3-p (file)
  (and
   (not (directory-pathname-p file))
   (string-equal "mp3" (pathname-type file))))
@end verbatim

Then you can combine @code{show-tag-header} and @code{mp3-p} with
@code{walk-directory} to print a summary of the ID3 header in each file
under a given directory.

@verbatim
(defun show-tag-headers (dir) 
  (walk-directory dir #'show-tag-header :test #'mp3-p))
@end verbatim

However, if you have a lot of MP3s, you may just want a count of how
many ID3 tags of each version you have in your MP3 collection. To get
that information, you might write a function like this:

@verbatim
(defun count-versions (dir)
  (let ((versions (mapcar #'(lambda (x) (cons x 0)) '(2 3 4))))
    (flet ((count-version (file)
             (incf (cdr (assoc (major-version (read-id3 file)) versions)))))
      (walk-directory dir #'count-version :test #'mp3-p))
    versions))
@end verbatim

Another function you'll need in Chapter 29 is one that tests whether a
file actually starts with an ID3 tag, which you can define like this:

@verbatim
(defun id3-p (file)
  (with-open-file (in file :element-type '(unsigned-byte 8))
    (string= "ID3" (read-value 'iso-8859-1-string in :length 3))))
@end verbatim

@node ID3 Frames
@section ID3 Frames
@anchor{#id3-frames}
As I discussed earlier, the bulk of an ID3 tag is divided into frames.
Each frame has a structure similar to that of the tag as a whole. Each
frame starts with a header indicating what kind of frame it is and the
size of the frame in bytes. The structure of the frame header changed
slightly between version 2.2 and version 2.3 of the ID3 format, and
eventually you'll have to deal with both forms. To start, you can focus
on parsing version 2.2 frames.

The header of a 2.2 frame consists of three bytes that encode a
three-character ISO 8859-1 string followed by a three-byte unsigned
integer, which specifies the size of the frame in bytes, excluding the
six-byte header. The string identifies what type of frame it is, which
determines how you parse the data following the size. This is exactly
the kind of situation for which you defined the
@code{define-tagged-binary-class} macro. You can define a tagged class
that reads the frame header and then dispatches to the appropriate
concrete class using a function that maps IDs to a class names.

@verbatim
(define-tagged-binary-class id3-frame ()
  ((id (iso-8859-1-string :length 3))
   (size u3))
  (:dispatch (find-frame-class id)))
@end verbatim

Now you're ready to start implementing concrete frame classes. However,
the specification defines quite a few--63 in version 2.2 and even more
in later specs. Even considering frame types that share a common
structure to be equivalent, you'll still find 24 unique frame types in
version 2.2. But only a few of these are used "in the wild." So rather
than immediately setting to work defining classes for each of the frame
types, you can start by writing a generic frame class that lets you read
the frames in a tag without parsing the data within the frames
themselves. This will give you a way to find out what frames are
actually present in the MP3s you want to process. You'll need this class
eventually anyway because the specification allows for experimental
frames that you'll need to be able to read without parsing.

Since the size field of the frame header tells you exactly how many
bytes long the frame is, you can define a @code{generic-frame} class
that extends @code{id3-frame} and adds a single field, @code{data}, that
will hold an array of bytes.

@verbatim
(define-binary-class generic-frame (id3-frame)
  ((data (raw-bytes :size size))))
@end verbatim

The type of the data field, @code{raw-bytes}, just needs to hold an
array of bytes. You can define it like this:

@verbatim
(define-binary-type raw-bytes (size)
  (:reader (in)
    (let ((buf (make-array size :element-type '(unsigned-byte 8))))
      (read-sequence buf in)
      buf))
  (:writer (out buf)
    (write-sequence buf out)))
@end verbatim

For the time being, you'll want all frames to be read as
@code{generic-frame}s, so you can define the @code{find-frame-class}
function used in @code{id3-frame}'s @code{:dispatch} expression to
always return @code{generic-frame}, regardless of the frame's @code{id}.

@verbatim
(defun find-frame-class (id)
  (declare (ignore id))
  'generic-frame)
@end verbatim

Now you need to modify @code{id3-tag} so it'll read frames after the
header fields. There's only one tricky bit to reading the frame data:
although the tag header tells you how many bytes long the tag is, that
number includes the padding that can follow the frame data. Since the
tag header doesn't tell you how many frames the tag contains, the only
way to tell when you've hit the padding is to look for a null byte where
you'd expect a frame identifier.

To handle this, you can define a binary type, @code{id3-frames}, that
will be responsible for reading the remainder of a tag, creating frame
objects to represent all the frames it finds, and then skipping over any
padding. This type will take as a parameter the tag size, which it can
use to avoid reading past the end of the tag. But the reading code will
also need to detect the beginning of the padding that can follow the
tag's frame data. Rather than calling @code{read-value} directly in
@code{id3-frames} @code{:reader}, you should use a function
@code{read-frame}, which you'll define to return @code{NIL} when it
detects padding, otherwise returning an @code{id3-frame} object read
using @code{read-value}. Assuming you define @code{read-frame} so it
reads only one byte past the end of the last frame in order to detect
the start of the padding, you can define the @code{id3-frames} binary
type like this:

@verbatim
(define-binary-type id3-frames (tag-size)
  (:reader (in)
    (loop with to-read = tag-size
          while (plusp to-read)
          for frame = (read-frame in)
          while frame
          do (decf to-read (+ 6 (size frame)))
          collect frame
          finally (loop repeat (1- to-read) do (read-byte in))))
  (:writer (out frames)
    (loop with to-write = tag-size
          for frame in frames
          do (write-value 'id3-frame out frame)
          (decf to-write (+ 6 (size frame)))
          finally (loop repeat to-write do (write-byte 0 out)))))
@end verbatim

You can use this type to add a @code{frames} slot to @code{id3-tag}.

@verbatim
(define-binary-class id3-tag ()
  ((identifier     (iso-8859-1-string :length 3))
   (major-version  u1)
   (revision       u1)
   (flags          u1)
   (size           id3-tag-size)
   (frames         (id3-frames :tag-size size))))
@end verbatim

@node Detecting Tag Padding
@section Detecting Tag Padding
@anchor{#detecting-tag-padding}
Now all that remains is to implement @code{read-frame}. This is a bit
tricky since the code that actually reads bytes from the stream is
several layers down from @code{read-frame}.

What you'd really like to do in @code{read-frame} is read one byte and
return @code{NIL} if it's a null and otherwise read a frame with
@code{read-value}. Unfortunately, if you read the byte in
@code{read-frame}, then it won't be available to be read by
@code{read-value}.@footnote{Character streams support two functions,
@code{PEEK-CHAR} and @code{UNREAD-CHAR}, either of which would be a
perfect solution to this problem, but binary streams support no
equivalent functions.}

It turns out this is a perfect opportunity to use the condition
system--you can check for null bytes in the low-level code that reads
from the stream and signal a condition when you read a null;
@code{read-frame} can then handle the condition by unwinding the stack
before more bytes are read. In addition to turning out to be a tidy
solution to the problem of detecting the start of the tag's padding,
this is also an example of how you can use conditions for purposes other
than handling errors.

You can start by defining a condition type to be signaled by the
low-level code and handled by the high-level code. This condition
doesn't need any slots--you just need a distinct class of condition so
you know no other code will be signaling or handling it.

@verbatim
(define-condition in-padding () ())
@end verbatim

Next you need to define a binary type whose @code{:reader} reads a given
number of bytes, first reading a single byte and signaling an
@code{in-padding} condition if the byte is null and otherwise reading
the remaining bytes as an @code{iso-8859-1-string} and combining it with
the first byte read.

@verbatim
(define-binary-type frame-id (length)
  (:reader (in)
    (let ((first-byte (read-byte in)))
      (when (= first-byte 0) (signal 'in-padding))
      (let ((rest (read-value 'iso-8859-1-string in :length (1- length))))
        (concatenate
         'string (string (code-char first-byte)) rest))))
  (:writer (out id)
    (write-value 'iso-8859-1-string out id :length length)))
@end verbatim

If you redefine @code{id3-frame} to make the type of its @code{id} slot
@code{frame-id} instead of @code{iso-8859-1-string}, the condition will
be signaled whenever @code{id3-frame}'s @code{read-value} method reads a
null byte instead of the beginning of a frame.

@verbatim
(define-tagged-binary-class id3-frame ()
  ((id (frame-id :length 3))
   (size u3))
  (:dispatch (find-frame-class id)))
@end verbatim

Now all @code{read-frame} has to do is wrap a call to @code{read-value}
in a @code{HANDLER-CASE} that handles the @code{in-padding} condition by
returning @code{NIL}.

@verbatim
(defun read-frame (in)
  (handler-case (read-value 'id3-frame in)
    (in-padding () nil)))
@end verbatim

With @code{read-frame} defined, you can now read a complete version 2.2
ID3 tag, representing frames with instances of @code{generic-frame}. In
the "What Frames Do You Actually Need?" section, you'll do some
experiments at the REPL to determine what frame classes you need to
implement. But first let's add support for version 2.3 ID3 tags.

@node Supporting Multiple Versions of ID3
@section Supporting Multiple Versions of ID3
@anchor{#supporting-multiple-versions-of-id3}
Currently, @code{id3-tag} is defined using @code{define-binary-class},
but if you want to support multiple versions of ID3, it makes more sense
to use a @code{define-tagged-binary-class} that dispatches on the
@code{major-version} value. As it turns out, all versions of ID3v2 have
the same structure up to the size field. So, you can define a tagged
binary class like the following that defines this basic structure and
then dispatches to the appropriate version-specific subclass:

@verbatim
(define-tagged-binary-class id3-tag ()
  ((identifier     (iso-8859-1-string :length 3))
   (major-version  u1)
   (revision       u1)
   (flags          u1)
   (size           id3-tag-size))
  (:dispatch 
   (ecase major-version
     (2 'id3v2.2-tag)
     (3 'id3v2.3-tag))))
@end verbatim

Version 2.2 and version 2.3 tags differ in two ways. First, the header
of a version 2.3 tag may be extended with up to four optional extended
header fields, as determined by values in the flags field. Second, the
frame format changed between version 2.2 and version 2.3, which means
you'll have to use different classes to represent version 2.2 frames and
the corresponding version 2.3 frames.

Since the new @code{id3-tag} class is based on the one you originally
wrote to represent version 2.2 tags, it's not surprising that the new
@code{id3v2.2-tag} class is trivial, inheriting most of its slots from
the new @code{id3-tag} class and adding the one missing slot,
@code{frames}. Because version 2.2 and version 2.3 tags use different
frame formats, you'll have to change the @code{id3-frames} type to be
parameterized with the type of frame to read. For now, assume you'll do
that and add a @code{:frame-type} argument to the @code{id3-frames} type
descriptor like this:

@verbatim
(define-binary-class id3v2.2-tag (id3-tag)
  ((frames (id3-frames :tag-size size :frame-type 'id3v2.2-frame))))
@end verbatim

The @code{id3v2.3-tag} class is slightly more complex because of the
optional fields. The first three of the four optional fields are
included when the sixth bit in @code{flags} is set. They're a four-
byte integer specifying the size of the extended header, two bytes
worth of flags, and another four-byte integer specifying how many
bytes of padding are included in the tag.@footnote{If a tag had an
extended header, you could use this value to determine where the frame
data should end. However, if the extended header isn't used, you'd
have to use the old algorithm anyway, so it's not worth adding code to
do it another way.} The fourth optional field, included when the
fifteenth bit of the extended header flags is set, is a four-byte
cyclic redundancy check (CRC) of the rest of the tag.

The binary data library doesn't provide any special support for optional
fields in a binary class, but it turns out that regular parameterized
binary types are sufficient. You can define a type parameterized with
the name of a type and a value that indicates whether a value of that
type should actually be read or written.

@verbatim
(define-binary-type optional (type if)
  (:reader (in)
    (when if (read-value type in)))
  (:writer (out value)
    (when if (write-value type out value))))
@end verbatim

Using @code{if} as the parameter name looks a bit strange in that code,
but it makes the @code{optional} type descriptors quite readable. For
instance, here's the definition of @code{id3v2.3-tag} using
@code{optional} slots:

@verbatim
(define-binary-class id3v2.3-tag (id3-tag)
  ((extended-header-size (optional :type 'u4 :if (extended-p flags)))
   (extra-flags          (optional :type 'u2 :if (extended-p flags)))
   (padding-size         (optional :type 'u4 :if (extended-p flags)))
   (crc                  (optional :type 'u4 :if (crc-p flags extra-flags)))
   (frames               (id3-frames :tag-size size :frame-type 'id3v2.3-frame))))
@end verbatim

where @code{extended-p} and @code{crc-p} are helper functions that test
the appropriate bit of the flags value they're passed. To test whether
an individual bit of an integer is set, you can use @code{LOGBITP},
another bit-twiddling function. It takes an index and an integer and
returns true if the specified bit is set in the integer.

@verbatim
(defun extended-p (flags) (logbitp 6 flags))

(defun crc-p (flags extra-flags)
  (and (extended-p flags) (logbitp 15 extra-flags)))
@end verbatim

As in the version 2.2 tag class, the frames slot is defined to be of
type @code{id3-frames}, passing the name of the frame type as a
parameter. You do, however, need to make a few small changes to
@code{id3-frames} and @code{read-frame} to support the extra
@code{frame-type} parameter.

@verbatim
(define-binary-type id3-frames (tag-size frame-type)
  (:reader (in)
    (loop with to-read = tag-size
          while (plusp to-read)
          for frame = (read-frame frame-type in)
          while frame
          do (decf to-read (+ (frame-header-size frame) (size frame)))
          collect frame
          finally (loop repeat (1- to-read) do (read-byte in))))
  (:writer (out frames)
    (loop with to-write = tag-size
          for frame in frames
          do (write-value frame-type out frame)
          (decf to-write (+ (frame-header-size frame) (size frame)))
          finally (loop repeat to-write do (write-byte 0 out)))))

(defun read-frame (frame-type in)
  (handler-case (read-value frame-type in)
    (in-padding () nil)))
@end verbatim

The changes are in the calls to @code{read-frame} and
@code{write-value}, where you need to pass the @code{frame-type}
argument and, in computing the size of the frame, where you need to use
a function @code{frame-header-size} instead of the literal value
@code{6} since the frame header changed size between version 2.2 and
version 2.3. Since the difference in the result of this function is
based on the class of the frame, it makes sense to define it as a
generic function like this:

@verbatim
(defgeneric frame-header-size (frame))
@end verbatim

You'll define the necessary methods on that generic function in the next
section after you define the new frame classes.

@node Versioned Frame Base Classes
@section Versioned Frame Base Classes
@anchor{#versioned-frame-base-classes}
Where before you defined a single base class for all frames, you'll now
have two classes, @code{id3v2.2-frame} and @code{id3v2.3-frame}. The
@code{id3v2.2-frame} class will be essentially the same as the original
@code{id3-frame} class.

@verbatim
(define-tagged-binary-class id3v2.2-frame ()
  ((id (frame-id :length 3))
   (size u3))
  (:dispatch (find-frame-class id)))
@end verbatim

The @code{id3v2.3-frame}, on the other hand, requires more
changes. The frame identifier and size fields were extended in version
2.3 from three to four bytes each, and two bytes worth of flags were
added.  Additionally, the frame, like the version 2.3 tag, can contain
optional fields, controlled by the values of three of the frame's
flags.@footnote{These flags, in addition to controlling whether the
optional fields are included, can affect the parsing of the rest of
the tag. In particular, if the seventh bit of the flags is set, then
the actual frame data is compressed using the zlib algorithm, and if
the sixth bit is set, the data is encrypted. In practice these options
are rarely, if ever, used, so you can get away with ignoring them for
now.  But that would be an area you'd have to address to make this a
production-quality ID3 library. One simple half solution would be to
change @code{find-frame-class} to accept a second argument and pass it
the flags; if the frame is compressed or encrypted, you could
instantiate a generic frame to hold the data.} With those changes in
mind, you can define the version 2.3 frame base class, along with some
helper functions, like this:

@verbatim
(define-tagged-binary-class id3v2.3-frame ()
  ((id                (frame-id :length 4))
   (size              u4)
   (flags             u2)
   (decompressed-size (optional :type 'u4 :if (frame-compressed-p flags)))
   (encryption-scheme (optional :type 'u1 :if (frame-encrypted-p flags)))
   (grouping-identity (optional :type 'u1 :if (frame-grouped-p flags))))
  (:dispatch (find-frame-class id)))

(defun frame-compressed-p (flags) (logbitp 7 flags))

(defun frame-encrypted-p (flags) (logbitp 6 flags))

(defun frame-grouped-p (flags) (logbitp 5 flags))
@end verbatim

With these two classes defined, you can now implement the methods on the
generic function @code{frame-header-size}.

@verbatim
(defmethod frame-header-size ((frame id3v2.2-frame)) 6)

(defmethod frame-header-size ((frame id3v2.3-frame)) 10)
@end verbatim

The optional fields in a version 2.3 frame aren't counted as part of the
header for this computation since they're already included in the value
of the frame's @code{size}.

@node Versioned Concrete Frame Classes
@section Versioned Concrete Frame Classes
@anchor{#versioned-concrete-frame-classes}
In the original definition, @code{generic-frame} subclassed
@code{id3-frame}. But now @code{id3-frame} has been replaced with the
two version-specific base classes, @code{id3v2.2-frame} and
@code{id3v2.3-frame}. So, you need to define two new versions of
@code{generic-frame}, one for each base class. One way to define this
classes would be like this:

@verbatim
(define-binary-class generic-frame-v2.2 (id3v2.2-frame)
  ((data (raw-bytes :size size))))

(define-binary-class generic-frame-v2.3 (id3v2.3-frame)
  ((data (raw-bytes :size size))))
@end verbatim

However, it's a bit annoying that these two classes are the same except
for their superclass. It's not too bad in this case since there's only
one additional field. But if you take this approach for other concrete
frame classes, ones that have a more complex internal structure that's
identical between the two ID3 versions, the duplication will be more
irksome.

Another approach, and the one you should actually use, is to define a
class @code{generic-frame} as a @emph{mixin}: a class intended to be
used as a superclass along with one of the version-specific base classes
to produce a concrete, version-specific frame class. The only tricky bit
about this approach is that if @code{generic-frame} doesn't extend
either of the frame base classes, then you can't refer to the
@code{size} slot in its definition. Instead, you must use the
@code{current-binary-object} function I discussed at the end of the
previous chapter to access the object you're in the midst of reading or
writing and pass it to @code{size}. And you need to account for the
difference in the number of bytes of the total frame size that will be
left over, in the case of a version 2.3 frame, if any of the optional
fields are included in the frame. So, you should define a generic
function @code{data-bytes} with methods that do the right thing for both
version 2.2 and version 2.3 frames.

@verbatim
(define-binary-class generic-frame ()
  ((data (raw-bytes :size (data-bytes (current-binary-object))))))

(defgeneric data-bytes (frame))

(defmethod data-bytes ((frame id3v2.2-frame))
  (size frame))

(defmethod data-bytes ((frame id3v2.3-frame))
  (let ((flags (flags frame)))
    (- (size frame)
       (if (frame-compressed-p flags) 4 0)
       (if (frame-encrypted-p flags) 1 0)
       (if (frame-grouped-p flags) 1 0))))
@end verbatim

Then you can define concrete classes that extend one of the
version-specific base classes and @code{generic-frame} to define
version-specific generic frame classes.

@verbatim
(define-binary-class generic-frame-v2.2 (id3v2.2-frame generic-frame) ())

(define-binary-class generic-frame-v2.3 (id3v2.3-frame generic-frame) ())
@end verbatim

With these classes defined, you can redefine the @code{find-frame-class}
function to return the right versioned class based on the length of the
identifier.

@verbatim
(defun find-frame-class (id)
  (ecase (length id)
    (3 'generic-frame-v2.2)
    (4 'generic-frame-v2.3)))
@end verbatim

@node What Frames Do You Actually Need?
@section What Frames Do You Actually Need?
@anchor{#what-frames-do-you-actually-need}
With the ability to read both version 2.2 and version 2.3 tags using
generic frames, you're ready to start implementing classes to represent
the specific frames you care about. However, before you dive in, you
should take a breather and figure out what frames you actually care
about since, as I mentioned earlier, the ID3 spec specifies many frames
that are almost never used. Of course, what frames you care about
depends on what kinds of applications you're interested in writing. If
you're mostly interested in extracting information from existing ID3
tags, then you need implement only the classes representing the frames
containing the information you care about. On the other hand, if you
want to write an ID3 tag editor, you may need to support all the frames.

Rather than guessing which frames will be most useful, you can use the
code you've already written to poke around a bit at the REPL and see
what frames are actually used in your own MP3s. To start, you need an
instance of @code{id3-tag}, which you can get with the @code{read-id3}
function.

@verbatim
ID3V2> (read-id3 "/usr2/mp3/Kitka/Wintersongs/02 Byla Cesta.mp3")
#<ID3V2.2-TAG @ #x727b2912>
@end verbatim

Since you'll want to play with this object a bit, you should save it in
a variable.

@verbatim
ID3V2> (defparameter *id3* (read-id3 "/usr2/mp3/Kitka/Wintersongs/02 Byla Cesta.mp3"))
*ID3*
@end verbatim

Now you can see, for example, how many frames it has.

@verbatim
ID3V2> (length (frames *id3*))
11
@end verbatim

Not too many--let's take a look at what they are.

@verbatim
ID3V2> (frames *id3*)
(#<GENERIC-FRAME-V2.2 @ #x72dabdda> #<GENERIC-FRAME-V2.2 @ #x72dabec2>
 #<GENERIC-FRAME-V2.2 @ #x72dabfa2> #<GENERIC-FRAME-V2.2 @ #x72dac08a>
 #<GENERIC-FRAME-V2.2 @ #x72dac16a> #<GENERIC-FRAME-V2.2 @ #x72dac24a>
 #<GENERIC-FRAME-V2.2 @ #x72dac32a> #<GENERIC-FRAME-V2.2 @ #x72dac40a>
 #<GENERIC-FRAME-V2.2 @ #x72dac4f2> #<GENERIC-FRAME-V2.2 @ #x72dac632>
 #<GENERIC-FRAME-V2.2 @ #x72dac7b2>)
@end verbatim

Okay, that's not too informative. What you really want to know are what
kinds of frames are in there. In other words, you want to know the
@code{id}s of those frames, which you can get with a simple
@code{MAPCAR} like this:

@verbatim
ID3V2> (mapcar #'id (frames *id3*))
("TT2" "TP1" "TAL" "TRK" "TPA" "TYE" "TCO" "TEN" "COM" "COM" "COM")
@end verbatim

If you look up these identifiers in the ID3v2.2 spec, you'll discover
that all the frames with identifiers starting with @emph{T} are text
information frames and have a similar structure. And @emph{COM} is the
identifier for comment frames, which have a structure similar to that of
text information frames. The particular text information frames
identified here turn out to be the frames for representing the song
title, artist, album, track, part of set, year, genre, and encoding
program.

Of course, this is just one MP3 file. Maybe other frames are used in
other files. It's easy enough to discover. First define a function that
combines the previous @code{MAPCAR} expression with a call to
@code{read-id3} and wraps the whole thing in a @code{DELETE-DUPLICATES}
to keep things tidy. You'll have to use a @code{:test} argument of
@code{#'string=} to @code{DELETE-DUPLICATES} to specify that you want
two elements considered the same if they're the same string.

@verbatim
(defun frame-types (file)
  (delete-duplicates (mapcar #'id (frames (read-id3 file))) :test #'string=))
@end verbatim

This should give the same answer except with only one of each identifier
when passed the same filename.

@verbatim
ID3V2> (frame-types "/usr2/mp3/Kitka/Wintersongs/02 Byla Cesta.mp3")
("TT2" "TP1" "TAL" "TRK" "TPA" "TYE" "TCO" "TEN" "COM")
@end verbatim

Then you can use Chapter 15's @code{walk-directory} function along with
@code{mp3-p} to find every MP3 file under a directory and combine the
results of calling @code{frame-types} on each file. Recall that
@code{NUNION} is the recycling version of the @code{UNION} function;
since @code{frame-types} makes a new list for each file, this is safe.

@verbatim
(defun frame-types-in-dir (dir)
  (let ((ids ()))
    (flet ((collect (file)
             (setf ids (nunion ids (frame-types file) :test #'string=))))
      (walk-directory dir #'collect :test #'mp3-p))
    ids))
@end verbatim

Now pass it the name of a directory, and it'll tell you the set of
identifiers used in all the MP3 files under that directory. It may take
a few seconds depending how many MP3 files you have, but you'll probably
get something similar to this:

@verbatim
ID3V2> (frame-types-in-dir "/usr2/mp3/")
("TCON" "COMM" "TRCK" "TIT2" "TPE1" "TALB" "TCP" "TT2" "TP1" "TCM"
 "TAL" "TRK" "TPA" "TYE" "TCO" "TEN" "COM")
@end verbatim

The four-letter identifiers are the version 2.3 equivalents of the
version 2.2 identifiers I discussed previously. Since the information
stored in those frames is exactly the information you'll need in Chapter
27, it makes sense to implement classes only for the frames actually
used, namely, text information and comment frames, which you'll do in
the next two sections. If you decide later that you want to support
other frame types, it's mostly a matter of translating the ID3
specifications into the appropriate binary class definitions.

@node Text Information Frames
@section Text Information Frames
@anchor{#text-information-frames}
All text information frames consist of two fields: a single byte
indicating which string encoding is used in the frame and a string
encoded in the remaining bytes of the frame. If the encoding byte is
zero, the string is encoded in ISO 8859-1; if the encoding is one, the
string is a UCS-2 string.

You've already defined binary types representing the four different
kinds of strings--two different encodings each with two different
methods of delimiting the string. However, @code{define-binary-class}
provides no direct facility for determining the type of value to read
based on other values in the object. Instead, you can define a binary
type that you pass the value of the encoding byte and that then reads or
writes the appropriate kind of string.

As long as you're defining such a type, you can also define it to take
two parameters, @code{:length} and @code{:terminator}, and pick the
right type of string based on which argument is supplied. To implement
this new type, you must first define some helper functions. The first
two return the name of the appropriate string type based on the encoding
byte.

@verbatim
(defun non-terminated-type (encoding)
  (ecase encoding
    (0 'iso-8859-1-string)
    (1 'ucs-2-string)))

(defun terminated-type (encoding)
  (ecase encoding
    (0 'iso-8859-1-terminated-string)
    (1 'ucs-2-terminated-string)))
@end verbatim

Then @code{string-args} uses the encoding byte, the length, and the
terminator to determine several of the arguments to be passed to
@code{read-value} and @code{write-value} by the @code{:reader} and
@code{:writer} of @code{id3-encoded-string}. One of the length and
terminator arguments to @code{string-args} should always be @code{NIL}.

@verbatim
(defun string-args (encoding length terminator)
  (cond 
    (length
     (values (non-terminated-type encoding) :length length))
    (terminator
     (values (terminated-type encoding) :terminator terminator))))
@end verbatim

With those helpers, the definition of @code{id3-encoded-string} is
simple. One detail to note is that the keyword--either @code{:length} or
@code{:terminator}--used in the call to @code{read-value} and
@code{write-value} is just another piece of data returned by
@code{string-args}. Although keywords in arguments lists are almost
always literal keywords, they don't have to be.

@verbatim
(define-binary-type id3-encoded-string (encoding length terminator)
  (:reader (in) 
    (multiple-value-bind (type keyword arg)
        (string-args encoding length terminator)
      (read-value type in keyword arg)))
  (:writer (out string)
    (multiple-value-bind (type keyword arg)
        (string-args encoding length terminator)
      (write-value type out string keyword arg))))
@end verbatim

Now you can define a @code{text-info} mixin class, much the way you
defined @code{generic-frame} earlier.

@verbatim
(define-binary-class text-info-frame ()
  ((encoding u1)
   (information (id3-encoded-string :encoding encoding :length (bytes-left 1)))))
@end verbatim

As when you defined @code{generic-frame}, you need access to the size of
the frame, in this case to compute the @code{:length} argument to pass
to @code{id3-encoded-string}. Because you'll need to do a similar
computation in the next class you define, you can go ahead and define a
helper function, @code{bytes-left}, that uses
@code{current-binary-object} to get at the size of the frame.

@verbatim
(defun bytes-left (bytes-read)
  (- (size (current-binary-object)) bytes-read))
@end verbatim

Now, as you did with the @code{generic-frame} mixin, you can define two
version-specific concrete classes with a minimum of duplicated code.

@verbatim
(define-binary-class text-info-frame-v2.2 (id3v2.2-frame text-info-frame) ())

(define-binary-class text-info-frame-v2.3 (id3v2.3-frame text-info-frame) ())
@end verbatim

To wire these classes in, you need to modify @code{find-frame-class} to
return the appropriate class name when the ID indicates the frame is a
text information frame, namely, whenever the ID starts with @emph{T} and
isn't @emph{TXX} or @emph{TXXX}.

@verbatim
(defun find-frame-class (name)
  (cond
    ((and (char= (char name 0) #\T)
          (not (member name '("TXX" "TXXX") :test #'string=)))
     (ecase (length name)
       (3 'text-info-frame-v2.2)
       (4 'text-info-frame-v2.3)))
    (t
     (ecase (length name)
       (3 'generic-frame-v2.2)
       (4 'generic-frame-v2.3)))))
@end verbatim

@node Comment Frames
@section Comment Frames
@anchor{#comment-frames}
Another commonly used frame type is the comment frame, which is like a
text information frame with a few extra fields. Like a text information
frame, it starts with a single byte indicating the string encoding used
in the frame. That byte is followed by a three-character ISO 8859-1
string (regardless of the value of the string encoding byte), which
indicates what language the comment is in using an ISO-639-2 code, for
example, "eng" for English or "jpn" for Japanese. That field is followed
by two strings encoded as indicated by the first byte. The first is a
null-terminated string containing a description of the comment. The
second, which takes up the remainder of the frame, is the comment text
itself.

@verbatim
(define-binary-class comment-frame ()
  ((encoding u1)
   (language (iso-8859-1-string :length 3))
   (description (id3-encoded-string :encoding encoding :terminator +null+))
   (text (id3-encoded-string
          :encoding encoding
          :length (bytes-left
                   (+ 1 ; encoding
                      3 ; language
                      (encoded-string-length description encoding t)))))))
@end verbatim

As in the definition of the @code{text-info} mixin, you can use
@code{bytes-left} to compute the size of the final string. However,
since the @code{description} field is a variable-length string, the
number of bytes read prior to the start of @code{text} isn't a constant.
To make matters worse, the number of bytes used to encode
@code{description} is dependent on the encoding. So, you should define a
helper function that returns the number of bytes used to encode a string
given the string, the encoding code, and a boolean indicating whether
the string is terminated with an extra character.

@verbatim
(defun encoded-string-length (string encoding terminated)
  (let ((characters (+ (length string) (if terminated 1 0))))
    (* characters (ecase encoding (0 1) (1 2)))))
@end verbatim

And, as before, you can define the concrete version-specific comment
frame classes and wire them into @code{find-frame-class}.

@verbatim
(define-binary-class comment-frame-v2.2 (id3v2.2-frame comment-frame) ())

(define-binary-class comment-frame-v2.3 (id3v2.3-frame comment-frame) ())

(defun find-frame-class (name)
  (cond
    ((and (char= (char name 0) #\T)
          (not (member name '("TXX" "TXXX") :test #'string=)))
     (ecase (length name)
       (3 'text-info-frame-v2.2)
       (4 'text-info-frame-v2.3)))
    ((string= name "COM")  'comment-frame-v2.2)
    ((string= name "COMM") 'comment-frame-v2.3)
    (t
     (ecase (length name)
       (3 'generic-frame-v2.2)
       (4 'generic-frame-v2.3)))))
@end verbatim

@node Extracting Information from an ID3 Tag
@section Extracting Information from an ID3 Tag
@anchor{#extracting-information-from-an-id3-tag}
Now that you have the basic ability to read and write ID3 tags, you
have a lot of directions you could take this code. If you want to
develop a complete ID3 tag editor, you'll need to implement specific
classes for all the frame types. You'd also need to define methods for
manipulating the tag and frame objects in a consistent way (for
instance, if you change the value of a string in a
@code{text-info-frame}, you'll likely need to adjust the size); as the
code stands, there's nothing to make sure that
happens.@footnote{Ensuring that kind of interfield consistency would
be a fine application for @code{:after} methods on the accessor
generic functions. For instance, you could define this @code{:after}
method to keep @code{size} in sync with the @code{information} string:

@verbatim
(defmethod (setf information) :after (value (frame text-info-frame))
  (declare (ignore value))
  (with-slots (encoding size information) frame
    (setf size (encoded-string-length information encoding nil))))
@end verbatim
}

Or, if you just need to extract certain pieces of information about an
MP3 file from its ID3 tag--as you will when you develop a streaming
MP3 server in Chapters 27, 28, and 29--you'll need to write functions
that find the appropriate frames and extract the information you want.

Finally, to make this production-quality code, you'd have to pore over
the ID3 specs and deal with the details I skipped over in the interest
of space. In particular, some of the flags in both the tag and the frame
can affect the way the contents of the tag or frame is read; unless you
write some code that does the right thing when those flags are set,
there may be ID3 tags that this code won't be able to parse correctly.
But the code from this chapter should be capable of parsing nearly all
the MP3s you actually encounter.

For now you can finish with a few functions to extract individual pieces
of information from an @code{id3-tag}. You'll need these functions in
Chapter 27 and probably in other code that uses this library. They
belong in this library because they depend on details of the ID3 format
that the users of this library shouldn't have to worry about.

To get, say, the name of the song of the MP3 from which an
@code{id3-tag} was extracted, you need to find the ID3 frame with a
specific identifier and then extract the information field. And some
pieces of information, such as the genre, can require further decoding.
Luckily, all the frames that contain the information you'll care about
are text information frames, so extracting a particular piece of
information mostly boils down to using the right identifier to look up
the appropriate frame. Of course, the ID3 authors decided to change all
the identifiers between ID3v2.2 and ID3v2.3, so you'll have to account
for that.

Nothing too complex--you just need to figure out the right path to get
to the various pieces of information. This is a perfect bit of code to
develop interactively, much the way you figured out what frame classes
you needed to implement. To start, you need an @code{id3-tag} object to
play with. Assuming you have an MP3 laying around, you can use
@code{read-id3} like this:

@verbatim
ID3V2> (defparameter *id3* (read-id3 "Kitka/Wintersongs/02 Byla Cesta.mp3"))
*ID3*
ID3V2> *id3*
#<ID3V2.2-TAG @ #x73d04c1a>
@end verbatim

replacing @code{Kitka/Wintersongs/02 Byla Cesta.mp3} with the filename
of your MP3. Once you have your @code{id3-tag} object, you can start
poking around. For instance, you can check out the list of frame objects
with the @code{frames} function.

@verbatim
ID3V2> (frames *id3*)
(#<TEXT-INFO-FRAME-V2.2 @ #x73d04cca>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d04dba>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d04ea2>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d04f9a>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d05082>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d0516a>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d05252>
 #<TEXT-INFO-FRAME-V2.2 @ #x73d0533a>
 #<COMMENT-FRAME-V2.2 @ #x73d0543a>
 #<COMMENT-FRAME-V2.2 @ #x73d05612>
 #<COMMENT-FRAME-V2.2 @ #x73d0586a>)
@end verbatim

Now suppose you want to extract the song title. It's probably in one of
those frames, but to find it, you need to find the frame with the "TT2"
identifier. Well, you can check easily enough to see if the tag contains
such a frame by extracting all the identifiers like this:

@verbatim
ID3V2> (mapcar #'id (frames *id3*))
("TT2" "TP1" "TAL" "TRK" "TPA" "TYE" "TCO" "TEN" "COM" "COM" "COM")
@end verbatim

There it is, the first frame. However, there's no guarantee it'll always
be the first frame, so you should probably look it up by identifier
rather than position. That's also straightforward using the @code{FIND}
function.

@verbatim
ID3V2> (find "TT2" (frames *id3*) :test #'string= :key #'id)
#<TEXT-INFO-FRAME-V2.2 @ #x73d04cca>
@end verbatim

Now, to get at the actual information in the frame, do this:

@verbatim
ID3V2> (information (find "TT2" (frames *id3*) :test #'string= :key #'id))
"Byla Cesta^@"
@end verbatim

Whoops. That @code{^@@} is how Emacs prints a null character. In a
maneuver reminiscent of the kludge that turned ID3v1 into ID3v1.1, the
@code{information} slot of a text information frame, though not
officially a null-terminated string, can contain a null, and ID3 readers
are supposed to ignore any characters after the null. So, you need a
function that takes a string and returns the contents up to the first
null character, if any. That's easy enough using the @code{+null+}
constant from the binary data library.

@verbatim
(defun upto-null (string)
  (subseq string 0 (position +null+ string)))
@end verbatim

Now you can get just the title.

@verbatim
ID3V2> (upto-null (information (find "TT2" (frames *id3*) :test #'string= :key #'id)))
"Byla Cesta"
@end verbatim

You could just wrap that code in a function named @code{song} that takes
an @code{id3-tag} as an argument, and you'd be done. However, the only
difference between this code and the code you'll use to extract the
other pieces of information you'll need (such as the album name, the
artist, and the genre) is the identifier. So, it's better to split up
the code a bit. For starters, you can write a function that just finds a
frame given an @code{id3-tag} and an identifier like this:

@verbatim
(defun find-frame (id3 id)
  (find id (frames id3) :test #'string= :key #'id))

ID3V2> (find-frame *id3* "TT2")
#<TEXT-INFO-FRAME-V2.2 @ #x73d04cca>
@end verbatim

Then the other bit of code, the part that extracts the information from
a @code{text-info-frame}, can go in another function.

@verbatim
(defun get-text-info (id3 id)
  (let ((frame (find-frame id3 id)))
    (when frame (upto-null (information frame)))))

ID3V2> (get-text-info *id3* "TT2")
"Byla Cesta"
@end verbatim

Now the definition of @code{song} is just a matter of passing the right
identifier.

@verbatim
(defun song (id3) (get-text-info id3 "TT2"))

ID3V2> (song *id3*)
"Byla Cesta"
@end verbatim

However, this definition of @code{song} works only with version 2.2 tags
since the identifier changed from "TT2" to "TIT2" between version 2.2
and version 2.3. And all the other tags changed too. Since the user of
this library shouldn't have to know about different versions of the ID3
format to do something as simple as get the song title, you should
probably handle those details for them. A simple way is to change
@code{find-frame} to take not just a single identifier but a list of
identifiers like this:

@verbatim
(defun find-frame (id3 ids)
  (find-if #'(lambda (x) (find (id x) ids :test #'string=)) (frames id3)))
@end verbatim

Then change @code{get-text-info} slightly so it can take one or more
identifiers using a @code{&rest} parameter.

@verbatim
(defun get-text-info (id3 &rest ids)
  (let ((frame (find-frame id3 ids)))
    (when frame (upto-null (information frame)))))
@end verbatim

Then the change needed to allow @code{song} to support both version 2.2
and version 2.3 tags is just a matter of adding the version 2.3
identifier.

@verbatim
(defun song (id3) (get-text-info id3 "TT2" "TIT2"))
@end verbatim

Then you just need to look up the appropriate version 2.2 and version
2.3 frame identifiers for any fields for which you want to provide an
accessor function. Here are the ones you'll need in Chapter 27:

@verbatim
(defun album (id3) (get-text-info id3 "TAL" "TALB"))

(defun artist (id3) (get-text-info id3 "TP1" "TPE1"))

(defun track (id3) (get-text-info id3 "TRK" "TRCK"))

(defun year (id3) (get-text-info id3 "TYE" "TYER" "TDRC"))

(defun genre (id3) (get-text-info id3 "TCO" "TCON"))
@end verbatim

The last wrinkle is that the way the @code{genre} is stored in the TCO
or TCON frames isn't always human readable. Recall that in ID3v1, genres
were stored as a single byte that encoded a particular genre from a
fixed list. Unfortunately, those codes live on in ID3v2--if the text of
the genre frame is a number in parentheses, the number is supposed to be
interpreted as an ID3v1 genre code. But, again, users of this library
probably won't care about that ancient history. So, you should provide a
function that automatically translates the genre. The following function
uses the @code{genre} function just defined to extract the actual genre
text and then checks whether it starts with a left parenthesis, decoding
the version 1 genre code with a function you'll define in a moment if it
does:

@verbatim
(defun translated-genre (id3)
  (let ((genre (genre id3)))
    (if (and genre (char= #\( (char genre 0)))
      (translate-v1-genre genre)
      genre)))
@end verbatim

Since a version 1 genre code is effectively just an index into an array
of standard names, the easiest way to implement
@code{translate-v1-genre} is to extract the number from the genre string
and use it as an index into an actual array.

@verbatim
(defun translate-v1-genre (genre)
  (aref *id3-v1-genres* (parse-integer genre :start 1 :junk-allowed t)))
@end verbatim

Then all you need to do is to define the array of names. The following
array of names includes the 80 official version 1 genres plus the genres
created by the authors of Winamp:

@verbatim
(defparameter *id3-v1-genres*
  #(
    ;; These are the official ID3v1 genres.
    "Blues" "Classic Rock" "Country" "Dance" "Disco" "Funk" "Grunge"
    "Hip-Hop" "Jazz" "Metal" "New Age" "Oldies" "Other" "Pop" "R&B" "Rap"
    "Reggae" "Rock" "Techno" "Industrial" "Alternative" "Ska"
    "Death Metal" "Pranks" "Soundtrack" "Euro-Techno" "Ambient"
    "Trip-Hop" "Vocal" "Jazz+Funk" "Fusion" "Trance" "Classical"
    "Instrumental" "Acid" "House" "Game" "Sound Clip" "Gospel" "Noise"
    "AlternRock" "Bass" "Soul" "Punk" "Space" "Meditative"
    "Instrumental Pop" "Instrumental Rock" "Ethnic" "Gothic" "Darkwave"
    "Techno-Industrial" "Electronic" "Pop-Folk" "Eurodance" "Dream"
    "Southern Rock" "Comedy" "Cult" "Gangsta" "Top 40" "Christian Rap"
    "Pop/Funk" "Jungle" "Native American" "Cabaret" "New Wave"
    "Psychadelic" "Rave" "Showtunes" "Trailer" "Lo-Fi" "Tribal"
    "Acid Punk" "Acid Jazz" "Polka" "Retro" "Musical" "Rock & Roll"
    "Hard Rock"

    ;; These were made up by the authors of Winamp but backported into
    ;; the ID3 spec.
    "Folk" "Folk-Rock" "National Folk" "Swing" "Fast Fusion"
    "Bebob" "Latin" "Revival" "Celtic" "Bluegrass" "Avantgarde"
    "Gothic Rock" "Progressive Rock" "Psychedelic Rock" "Symphonic Rock"
    "Slow Rock" "Big Band" "Chorus" "Easy Listening" "Acoustic" "Humour"
    "Speech" "Chanson" "Opera" "Chamber Music" "Sonata" "Symphony"
    "Booty Bass" "Primus" "Porn Groove" "Satire" "Slow Jam" "Club"
    "Tango" "Samba" "Folklore" "Ballad" "Power Ballad" "Rhythmic Soul"
    "Freestyle" "Duet" "Punk Rock" "Drum Solo" "A capella" "Euro-House"
    "Dance Hall"

    ;; These were also invented by the Winamp folks but ignored by the
    ;; ID3 authors.
    "Goa" "Drum & Bass" "Club-House" "Hardcore" "Terror" "Indie"
    "BritPop" "Negerpunk" "Polsk Punk" "Beat" "Christian Gangsta Rap"
    "Heavy Metal" "Black Metal" "Crossover" "Contemporary Christian"
    "Christian Rock" "Merengue" "Salsa" "Thrash Metal" "Anime" "Jpop"
    "Synthpop"))
@end verbatim

Once again, it probably feels like you wrote a ton of code in this
chapter. But if you put it all in a file, or if you download the version
from this book's Web site, you'll see it's just not that many
lines--most of the pain of writing this library stems from having to
understand the intricacies of the ID3 format itself. Anyway, now you
have a major piece of what you'll turn into a streaming MP3 server in
Chapters 27, 28, and 29. The other major bit of infrastructure you'll
need is a way to write server-side Web software, the topic of the next
chapter.

@node Practical Web Programming with AllegroServe
@chapter Practical: Web Programming with AllegroServe
@anchor{#practical-web-programming-with-allegroserve}
In this chapter you'll look at one way to develop Web-based programs in
Common Lisp, using the open-source AllegroServe Web server. This isn't
meant as a full introduction to AllegroServe. And I'm certainly not
going to cover anything more than a tiny corner of the larger topic of
Web programming. My goal here is to cover enough of the basics of using
AllegroServe that you'll be able, in Chapter 29, to develop an
application for browsing a library of MP3 files and streaming them to an
MP3 client. Similarly, this chapter will serve as a brief introduction
to Web programming for folks new to the topic.
@menu
* A 30-Second Intro to Server-Side Web Programming::
* AllegroServe::
* Generating Dynamic Content with AllegroServe::
* Generating HTML::
* HTML Macros::
* Query Parameters::
* Cookies::
* A Small Application Framework::
* The Implementation::
@end menu

@node A 30-Second Intro to Server-Side Web Programming
@section A 30-Second Intro to Server-Side Web Programming
@anchor{#a-30-second-intro-to-server-side-web-programming} While Web
programming today typically involves quite a number of software
frameworks and different protocols, the core bits of Web programming
haven't changed much since they were invented in the early 1990s. For
simple applications, such as the one you'll write in Chapter 29, you
need to understand only a few key concepts, so I'll review them
quickly here. Experienced Web programmers can skim or skip the rest of
this section.@footnote{Readers new to Web programming will probably
need to supplement this introduction with a more in-depth tutorial or
two. You can find a good set of online tutorials at
@code{http://www.jmarshall.com/easy/}.}

To start, you need to understand the roles the Web browser and the Web
server play in Web programming. While a modern browser comes with a lot
of bells and whistles, the core functionality of a Web browser is to
request Web pages from a Web server and then render them. Typically
those pages will be written in the Hypertext Markup Language (HTML),
which tells the browser how to render the page, including where to
insert inline images and links to other Web pages. HTML consists of text
@emph{marked up} with @emph{tags} that give the text a structure that
the browser uses when rendering the page. For instance, a simple HTML
document looks like this:

@verbatim
<html>
  <head>
  <title>Hello</title>
  </head>
  <body>
  <p>Hello, world!</p>
  <p>This is a picture: <img src="some-image.gif"></p>
  <p>This is a <a href="another-page.html">link</a> to another page.</p>
  </body>
</html>
@end verbatim

Figure 26-1 shows how the browser renders this page.

@float
@image{screenshots/new-sample,,,,jpg}
@caption{Figure 26-1. Sample Web page}
@end float

The browser and server communicate using a protocol called the Hypertext
Transfer Protocol (HTTP). While you don't need to worry about the
details of the protocol, it's worth understanding that it consists
entirely of a sequence of requests initiated by the browser and
responses generated by the server. That is, the browser connects to the
Web server and sends a request that includes, at the least, the desired
URL and the version of HTTP that the browser speaks. The browser can
also include data in its request; that's how the browser submits HTML
forms to the server.

To reply to a request, the server sends a response made up of a set of
headers and a body. The headers contain information about the body, such
as what type of data it is (for instance, HTML, plain text, or an
image), and the body is the data itself, which is then rendered by the
browser. The server can also send an error response telling the browser
that its request couldn't be answered for some reason.

And that's pretty much it. Once the browser has received the complete
response from the server, there's no communication between the browser
and the server until the next time the browser decides to request a
page from the server.@footnote{Loading a single Web page may actually
involve multiple requests--to render the HTML of a page containing
inline images, the browser must request each image individually and
then insert each into the appropriate place in the rendered HTML.}
This is the main constraint of Web programming--there's no way for
code running on the server to affect what the user sees in their
browser unless the browser issues a new request to the
server.@footnote{Much of the complexity around Web programming is a
result of trying to work around this fundamental limitation in order
to provide a user experience that's more like the interactivity
provided by desktop applications.}

Some Web pages, called @emph{static} pages, are simply HTML files
stored on the Web server and served up when requested by the browser.
@emph{Dynamic} pages, on the other hand, consist of HTML generated
each time the page is requested by a browser. For instance, a dynamic
page might be generated by querying a database and then constructing
HTML to represent the results of the query.@footnote{Unfortunately,
@emph{dynamic} is somewhat overloaded in the Web world. The phrase
@emph{Dynamic HTML} refers to HTML containing embedded code, usually
in the language JavaScript, that can be executed in the browser
without further communication with the Web server. Used with some
discretion, Dynamic HTML can improve the usability of a Web-based
application since, even with high-speed Internet connections, making a
request to a Web server, receiving the response, and rendering the new
page can take a noticeable amount of time. To further confuse things,
dynamically generated pages (in other words, generated on the server)
could also contain Dynamic HTML (code to be run on the client.) For
the purposes of this book, you'll stick to dynamically generating
plain old nondynamic HTML.}

When generating its response to a request, server-side code has four
main pieces of information to act on. The first piece of information is
the requested URL. Typically, however, the URL is used by the Web server
itself to determine @emph{what} code is responsible for generating the
response. Next, if the URL contains a question mark, everything after
the question mark is considered to be a @emph{query string}, which is
typically ignored by the Web server except that it makes it available to
the code generating the response. Most of the time the query string
contains a set of key/value pairs. The request from the browser can also
contain @emph{post data}, which also usually consists of key/value
pairs. Post data is typically used to submit HTML forms. The key/value
pairs supplied in either the query string or the post data are
collectively called the @emph{query parameters}.

Finally, in order to string together a sequence of individual requests
from the same browser, code running in the server can @emph{set a
cookie}, sending a special header in its response to the browser that
contains a bit of opaque data called a @emph{cookie}. After a cookie is
set by a particular server, the browser will send the cookie with each
request it sends to that server. The browser doesn't care about the data
in the cookie--it just echoes it back to the server for the server-side
code to interpret however it wants.

These are the primitive elements on top of which 99 percent of
server-side Web programming is built. The browser sends a request, the
server finds some code to handle the request and runs it, and the code
uses query parameters and cookies to determine what to do.

@node AllegroServe
@section AllegroServe
@anchor{#allegroserve} You can serve Web content using Common Lisp in
a number of ways; there are at least three open-source Web servers
written in Common Lisp as well as plug-ins such as
mod_lisp@footnote{@code{http://www.fractalconcept.com/asp/html/mod_lisp.html}}
and Lisplets@footnote{@code{http://lisplets.sourceforge.net/}} that
allow the Apache Web server or any Java Servlet container to delegate
requests to a Lisp server running in a separate process.

For this chapter, you'll use a version of the open-source Web server
AllegroServe, originally written by John Foderaro at Franz Inc..
AllegroServe is included in the version of Allegro available from Franz
for use with this book. If you're not using Allegro, you can use
PortableAllegroServe, a friendly fork of the AllegroServe code base,
which includes an Allegro compatibility layer that allows
PortableAllegroServe to run on most Common Lisps. The code you'll write
in this chapter and in Chapter 29 should run in both vanilla
AllegroServe and PortableAllegroServe.

AllegroServe provides a programming model similar in spirit to Java
Servlets--each time a browser requests a page, AllegroServe parses the
request and looks up an object, called an @emph{entity}, which handles
the request. Some entity classes provided as part of AllegroServe know
how to serve static content--either individual files or the contents
of a directory tree. Others, the ones I'll spend most of this chapter
discussing, run arbitrary Lisp code to generate the
response.@footnote{AllegroServe also provides a framework called
@emph{Webactions} that's analogous to JSPs in the Java world--instead
of writing code that generates HTML, with Webactions you write pages
that are essentially HTML with a bit of magic foo that turns into code
to be run when the page is served. I won't cover Webactions in this
book.}

But before I get to that, you need to know how to start AllegroServe
and set it up to serve a few files. The first step is to load the
AllegroServe code into your Lisp image. In Allegro, you can simply
type @code{(require :aserve)}. In other Lisps (or in Allegro), you can
load PortableAllegroServe by loading the file @code{INSTALL.lisp} at
the top of the @code{portableaserve} directory tree. Loading
AllegroServe will create three new packages, @code{NET.ASERVE},
@code{NET.HTML.GENERATOR}, and
@code{NET.ASERVE.CLIENT}.@footnote{Loading PortableAllegroServe will
create some other packages for the compatibility libraries, but the
packages you'll care about are those three.}

After loading the server, you start it with the function @code{start} in
the @code{NET.ASERVE} package. To have easy access to the symbols
exported from @code{NET.ASERVE}, from @code{COM.GIGAMONKEYS.HTML} (a
package I'll discuss in a moment), and from the rest of Common Lisp, you
should create a new package to play in like this:

@verbatim
CL-USER> (defpackage :com.gigamonkeys.web
            (:use :cl :net.aserve :com.gigamonkeys.html))
#<The COM.GIGAMONKEYS.WEB package>
@end verbatim

Now switch to that package with this @code{IN-PACKAGE} expression:

@verbatim
CL-USER> (in-package :com.gigamonkeys.web)
#<The COM.GIGAMONKEYS.WEB package>
WEB> 
@end verbatim

Now you can use the exported names from @code{NET.ASERVE} without
qualification. The function @code{start} starts the server. It takes
quite a number of keyword parameters, but the only one you need to pass
is @code{:port}, which specifies the port to listen on. You should
probably use a high port such as 2001 instead of the default port for
HTTP servers, 80, because on Unix-derived operating systems only the
root user can listen on ports below 1024. To run AllegroServe listening
on port 80 on Unix, you'd need to start Lisp as root and then use the
@code{:setuid} and @code{:setgid} parameters to tell @code{start} to
switch its identity after opening the port. You can start a server
listening on port 2001 like this:

@verbatim
WEB> (start :port 2001)
#<WSERVER port 2001 @ #x72511c72>
@end verbatim

The server is now running in your Lisp. It's possible you'll get an
error that says something about "port already in use" when you try to
start the server. This means port 2001 is already in use by some other
server on your machine. In that case, the simplest fix is to use a
different port, supplying a different argument to @code{start} and then
using that value instead of 2001 in the URLs used throughout this
chapter.

You can continue to interact with Lisp via the REPL because AllegroServe
starts its own threads to handle requests from browsers. This means,
among other things, that you can use the REPL to get a view into the
guts of your server while it's running, which makes debugging and
testing a lot easier than if the server is a complete black box.

Assuming you're running Lisp on the same machine as your browser, you
can check that the server is up and running by pointing your browser at
@code{http://localhost:2001/}. At this point you should get a
page-not-found error message in the browser since you haven't published
anything yet. But the error message will be from AllegroServe; it'll say
so at the bottom of the page. On the other hand, if the browser displays
an error dialog that says something like "The connection was refused
when attempting to contact localhost:2001," it means either that the
server isn't running or that you started it with a different port than
2001.

Now you can publish some files. Suppose you have a file
@code{hello.html} in the directory @code{/tmp/html} with the following
contents:

@verbatim
<html>
  <head>
  <title>Hello</title>
  </head>
  <body>
  <p>Hello, world!</p>
  </body>
</html>
@end verbatim

You can publish it individually with the @code{publish-file} function.

@verbatim
WEB> (publish-file :path "/hello.html" :file "/tmp/html/hello.html")
#<NET.ASERVE::FILE-ENTITY @ #x725eddea>
@end verbatim

The @code{:path} argument is the path that will appear in the URL
requested by the browser, while the @code{:file} argument is the name of
the file in the file system. After evaluating the @code{publish-file}
expression, you can point your browser to
@code{http://localhost:2001/hello.html}, and it should display a page
something like Figure 26-2.

@float
@image{screenshots/hello-world,,,,jpg}
@caption{Figure 26-2. @code{http://localhost:2001/hello.html}}
@end float

You could also publish a whole directory tree of files using the
@code{publish-directory} function. First let's clear out the already
published entity with the following call to @code{publish-file}:

@verbatim
WEB> (publish-file :path "/hello.html" :remove t)
NIL
@end verbatim

Now you can publish the whole @code{/tmp/html/} directory (and all its
subdirectories) with the @code{publish-directory} function.

@verbatim
WEB> (publish-directory :prefix "/" :destination "/tmp/html/")
#<NET.ASERVE::DIRECTORY-ENTITY @ #x72625aa2>
@end verbatim

In this case, the @code{:prefix} argument specifies the beginning of the
path part of URLs that should be handled by this entity. Thus, if the
server receives a request for @code{http://localhost:2001/foo/bar.html},
the path is @code{/foo/bar.html}, which starts with @code{/}. This path
is then translated to a filename by replacing the prefix, @code{/}, with
the destination, @code{/tmp/html/}. Thus, the URL
@code{http://localhost:2001/hello.html} will still be translated into a
request for the file @code{/tmp/html/hello.html}.

@node Generating Dynamic Content with AllegroServe
@section Generating Dynamic Content with AllegroServe
@anchor{#generating-dynamic-content-with-allegroserve}
Publishing entities that generate dynamic content is nearly as simple as
publishing static content. The functions @code{publish} and
@code{publish-prefix} are the dynamic analogs of @code{publish-file} and
@code{publish-directory}. The basic idea of these two functions is that
you publish a function that will be called to generate the response to a
request for either a specific URL or any URL with a given prefix. The
function will be called with two arguments: an object representing the
request and the published entity. Most of time you don't need to do
anything with the entity object except to pass it along to a couple
macros I'll discuss in a moment. On the other hand, you'll use the
request object to obtain information submitted by the browser--query
parameters included in the URL or data posted using an HTML form.

For a trivial example of using a function to generate dynamic content,
let's write a function that generates a page with a different random
number each time it's requested.

@verbatim
(defun random-number (request entity)
  (with-http-response (request entity :content-type "text/html")
    (with-http-body (request entity)
      (format 
       (request-reply-stream request)
       "<html>~@
        <head><title>Random</title></head>~@
        <body>~@
        <p>Random number: ~d</p>~@
        </body>~@
        </html>~@
       "
       (random 1000)))))
@end verbatim

The macros @code{with-http-response} and @code{with-http-body} are part
of AllegroServe. The former starts the process of generating an HTTP
response and can be used, as here, to specify things such as the type of
content that will be returned. It also handles various parts of HTTP
such as dealing with If-Modified-Since requests. The
@code{with-http-body} actually sends the HTTP response headers and then
executes its body, which should contain code that generates the content
of the reply. Within @code{with-http-response} but before the
@code{with-http-body}, you can add or change HTTP headers to be sent in
the reply. The function @code{request-reply-stream} is also part of
AllegroServe and returns the stream to which you should write output
intended to be sent to the browser.

As this function shows, you can just use @code{FORMAT} to print HTML
to the stream returned by @code{request-reply-stream}. In the next
section, I'll show you more convenient ways to programmatically
generate HTML.@footnote{The @code{~@@} followed by a newline tells
@code{FORMAT} to ignore whitespace after the newline, which allows you
to indent your code nicely without adding a bunch of whitespace to the
HTML. Since white-space is typically not significant in HTML, this
doesn't matter to the browser, but it makes the generated HTML source
look a bit nicer to humans.}

Now you're ready to publish this function.

@verbatim
WEB> (publish :path "/random-number" :function 'random-number)
#<COMPUTED-ENTITY @ #x7262bab2>
@end verbatim

As it does in the @code{publish-file} function, the @code{:path}
argument specifies the path part of the URL that will result in this
function being invoked. The @code{:function} argument specifies either
the name or an actual function object. Using the name of a function, as
shown here, allows you to redefine the function later without
republishing and have AllegroServe use the new function definition.
After evaluating the call to @code{publish}, you can point your browser
at @code{http:// localhost:2001/random-number} to get a page with a
random number on it, as shown in Figure 26-3.

@float
@image{screenshots/random-number,,,,jpg}
@caption{Figure 26-3. @code{http://localhost:2001/random-number}}
@end float

@node Generating HTML
@section Generating HTML
@anchor{#generating-html} Although using @code{FORMAT} to emit HTML
works fine for the simple pages I've discussed so far, as you start
building more elaborate pages it'd be nice to have a more concise way
to generate HTML. Several libraries are available for generating HTML
from an s-expression representation including one, htmlgen, that's
included with AllegroServe. In this chapter you'll use a library
called FOO,@footnote{FOO is a recursive tautological acronym for
@emph{FOO Outputs Output}.} which is loosely modeled on Franz's
htmlgen and whose implementation you'll look at in more detail in
Chapters 30 and 31. For now, however, you just need to know how to use
FOO.

Generating HTML from within Lisp is quite natural since s-expressions
and HTML are essentially isomorphic. You can represent HTML elements
with s-expressions by treating each element in HTML as a list "tagged"
with an appropriate first element, such as a keyword symbol of the same
name as the HTML tag. Thus, the HTML @code{<p>foo</p>} is represented by
the s-expression @code{(:p "foo")}. Because HTML elements nest the same
way lists in s-expressions do, this scheme extends to more complex HTML.
For instance, this HTML:

@verbatim
<html>
  <head>
  <title>Hello</title>
  </head>
  <body>
  <p>Hello, world!</p>
  </body>
</html>
@end verbatim

could be represented with the following s-expression:

@verbatim
(:html
  (:head (:title "Hello"))
  (:body (:p "Hello, world!")))
@end verbatim

HTML elements with attributes complicate things a bit but not in an
insurmountable way. FOO supports two ways of including attributes in a
tag. One is to simply follow the first item of the list with
keyword/value pairs. The first element that follows a keyword/value pair
that's not itself a keyword symbol marks the beginning of the element's
contents. Thus, you'd represent this HTML:

@verbatim
<a href="foo.html">This is a link</a>
@end verbatim

with the following s-expression:

@verbatim
(:a :href "foo.html" "This is a link")
@end verbatim

The other syntax FOO supports is to group the tag name and attributes
into their own list like this:

@verbatim
((:a :href "foo.html") "This is link.")
@end verbatim

FOO can use the s-expression representation of HTML in two ways. The
function @code{emit-html} takes an HTML s-expression and outputs the
corresponding HTML.

@verbatim
WEB> (emit-html '(:html (:head (:title "Hello")) (:body (:p "Hello, world!"))))
<html>
  <head>
    <title>Hello</title>
  </head>
  <body>
    <p>Hello, world!</p>
  </body>
</html>
T
@end verbatim

However, @code{emit-html} isn't always the most efficient way to
generate HTML because its argument must be a complete s-expression
representation of the HTML to be generated. While it's easy to build
such a representation, it's not always particularly efficient. For
instance, suppose you wanted to make an HTML page containing a list of
10,000 random numbers. You could build the s-expression using a
backquote template and then pass it to @code{emit-html} like this:

@verbatim
(emit-html
  `(:html
     (:head
       (:title "Random numbers"))
     (:body 
       (:h1 "Random numbers")
       (:p ,@(loop repeat 10000 collect (random 1000) collect " ")))))
@end verbatim

However, this has to build a tree containing a 10,000-element list
before it can even start emitting HTML, and the whole s-expression will
become garbage as soon as the HTML is emitted. To avoid this
inefficiency, FOO also provides a macro @code{html}, which allows you to
embed bits of Lisp code in the middle of an HTML s-expression.

Literal values such as strings and numbers in the input to @code{html}
are interpolated into the output HTML. Likewise, symbols are treated as
variable references, and code is generated to emit their value at
runtime. Thus, both of these:

@verbatim
(html (:p "foo"))

(let ((x "foo")) (html (:p x)))
@end verbatim

will emit the following:

@verbatim
<p>foo</p>
@end verbatim

List forms that don't start with a keyword symbol are assumed to be code
and are embedded in the generated code. Any values the embedded code
returns will be ignored, but the code can emit more HTML by calling
@code{html} itself. For instance, to emit the contents of a list in
HTML, you might write this:

@verbatim
(html (:ul (dolist (item (list 1 2 3)) (html (:li item)))))
@end verbatim

which will emit the following HTML:

@verbatim
<ul>
  <li>1</li>
  <li>2</li>
  <li>3</li>
</ul>
@end verbatim

If you want to emit the value of a list form, you must wrap it in the
pseudotag @code{:print}. Thus, this expression:

@verbatim
(html (:p (+ 1 2)))
@end verbatim

generates this HTML after computing and discarding the value @code{3}:

@verbatim
<p></p>
@end verbatim

To emit the @code{3}, you must write this:

@verbatim
(html (:p (:print (+ 1 2))))
@end verbatim

Or you could compute the value and store it in a variable outside the
call to @code{html} like this:

@verbatim
(let ((x (+ 1 2))) (html (:p x)))
@end verbatim

Thus, you can use the @code{html} macro to generate the list of random
numbers like this:

@verbatim
(html
  (:html
    (:head
      (:title "Random numbers"))
    (:body 
      (:h1 "Random numbers")
      (:p (loop repeat 10 do (html (:print (random 1000)) " "))))))
@end verbatim

The macro version will be quite a bit more efficient than the
@code{emit-html} version. Not only do you never have to generate an
s-expression representing the whole page, also much of the work that
@code{emit-html} does at runtime to interpret the s-expression will be
done once, when the macro is expanded, rather than every time the code
is run.

You can control where the output generated by both @code{html} and
@code{emit-html} is sent with the macro @code{with-html-output}, which
is part of the FOO library. Thus, you can use the
@code{with-html-output} and @code{html} macros from FOO to rewrite
@code{random-number} like this:

@verbatim
(defun random-number (request entity)
  (with-http-response (request entity :content-type "text/html")
    (with-http-body (request entity)
      (with-html-output ((request-reply-stream request))
        (html
          (:html
            (:head (:title "Random"))
            (:body
              (:p "Random number: " (:print (random 1000))))))))))
@end verbatim

@node HTML Macros
@section HTML Macros
@anchor{#html-macros}
Another feature of FOO is that it allows you to define HTML "macros"
that can translate arbitrary forms into HTML s-expressions that the
@code{html} macro understands. For instance, suppose you frequently find
yourself writing pages of this form:

@verbatim
(:html
  (:head (:title "Some title"))
  (:body
    (:h1 "Some title")
    ... stuff ...))
@end verbatim

You could define an HTML macro to capture that pattern like this:

@verbatim
(define-html-macro :standard-page ((&key title) &body body)
  `(:html
     (:head (:title ,title))
     (:body
      (:h1 ,title)
      ,@body)))
@end verbatim

Now you can use the "tag" @code{:standard-page} in your s-expression
HTML, and it'll be expanded before being interpreted or compiled. For
instance, the following:

@verbatim
(html (:standard-page (:title "Hello") (:p "Hello, world.")))
@end verbatim

generates the following HTML:

@verbatim
<html>
  <head>
    <title>Hello</title>
  </head>
  <body>
    <h1>Hello</h1>
    <p>Hello, world.</p>
  </body>
</html>
@end verbatim

@node Query Parameters
@section Query Parameters
@anchor{#query-parameters}
Of course, generating HTML output is only half of Web programming. The
other thing you need to do is get input from the user. As I discussed in
the "A 30-Second Intro to Server-Side Web Programming" section, when a
browser requests a page from a Web server, it can send query parameters
in the URL and post data, both of which act as input to the server-side
code.

AllegroServe, like most Web programming frameworks, takes care of
parsing both these sources of input for you. By the time your published
functions are called, all the key/value pairs from the query string
and/or post data have been decoded and placed into an alist that you can
retrieve from the request object with the function @code{request-query}.
The following function returns a page showing all the query parameters
it receives:

@verbatim
(defun show-query-params (request entity)
  (with-http-response (request entity :content-type "text/html")
    (with-http-body (request entity)
      (with-html-output ((request-reply-stream request))
        (html
          (:standard-page
           (:title "Query Parameters")
           (if (request-query request)
             (html 
               (:table :border 1
                       (loop for (k . v) in (request-query request)
                          do (html (:tr (:td k) (:td v))))))
             (html (:p "No query parameters.")))))))))

(publish :path "/show-query-params" :function 'show-query-params)
@end verbatim

If you give your browser a URL with a query string in it like the
following:

@verbatim
http://localhost:2001/show-query-params?foo=bar&baz=10
@end verbatim

you should get back a page similar to the one shown in Figure 26-4.

@float
@image{screenshots/show-query-params-1a,,,,jpg}
@caption{Figure 26-4.}
@end float

@code{http://localhost:2001/show-query-params?foo=bar&baz=10}
To generate some post data, you need an HTML form. The following
function generates a simple form, which submits its data to
@code{show-query-params}:

@verbatim
(defun simple-form (request entity)
  (with-http-response (request entity :content-type "text/html")
    (with-http-body (request entity)
      (let ((*html-output* (request-reply-stream request)))
        (html
          (:html
            (:head (:title "Simple Form"))
            (:body
             (:form :method "POST" :action "/show-query-params"
               (:table
                (:tr (:td "Foo")
                     (:td (:input :name "foo" :size 20)))
                (:tr (:td "Password")
                     (:td (:input :name "password" :type "password" :size 20))))
               (:p (:input :name "submit" :type "submit" :value "Okay")
                   (:input ::type "reset" :value "Reset"))))))))))

(publish :path "/simple-form" :function 'simple-form)
@end verbatim

Point your browser to @code{http://localhost:2001/simple-form}, and you
should see a page like the one in Figure 26-5.

If you fill in the form with the "abc" and "def" values, clicking the
Okay button should take you to a page like the one in Figure 26-6.

@float
@image{screenshots/simple-form,,,,jpg}
@caption{Figure 26-5. @code{http://localhost:2001/simple-form}}
@end float

@float
@image{screenshots/show-query-params-2,,,,jpg}
@caption{Figure 26-6. Result of submitting the simple form}
@end float

However, most of the time you won't need to iterate over all the query
parameters; you'll want to pick out individual parameters. For instance,
you might want to modify @code{random-number} so the limit value you
pass to @code{RANDOM} can be supplied via a query parameter. In that
case, you use the function @code{request-query-value}, which takes the
request object and the name of the parameter whose value you want and
returns the value as a string or @code{NIL} if no such parameter has
been supplied. A parameterizable version of @code{random-number} might
look like this:

@verbatim
(defun random-number (request entity)
  (with-http-response (request entity :content-type "text/html")
    (with-http-body (request entity)
      (let* ((*html-output* (request-reply-stream request))
             (limit-string (or (request-query-value "limit" request) ""))
             (limit (or (parse-integer limit-string :junk-allowed t) 1000)))
        (html
          (:html
            (:head (:title "Random"))
            (:body
              (:p "Random number: " (:print (random limit))))))))))
@end verbatim

Because @code{request-query-value} can return either @code{NIL} or an
empty string, you have to deal with both those cases when parsing the
parameter into a number to pass to @code{RANDOM}. You can deal with a
@code{NIL} value when you bind @code{limit-string}, binding it to
@code{""} if there's no "limit" query parameter. Then you can use the
@code{:junk-allowed} argument to @code{PARSE-INTEGER} to ensure that it
returns either @code{NIL} (if it can't parse an integer from the string
given) or an integer. In the section "A Small Application Framework,"
you'll develop some macros to make it easier to deal with grabbing query
parameters and converting them to various types.

@node Cookies
@section Cookies
@anchor{#cookies}
In AllegroServe you can send a Set-Cookie header that tells the browser
to save a cookie and send it along with subsequent requests by calling
the function @code{set-cookie-header} within the body of
@code{with-http-response} but before the call to @code{with-http-body}.
The first argument to the function is the request object, and the
remaining arguments are keyword arguments used to set the various
properties of the cookie. The only two you must pass are the
@code{:name} and @code{:value} arguments, both of which should be
strings. The other possible arguments that affect the cookie sent to the
browser are @code{:expires}, @code{:path}, @code{:domain}, and
@code{:secure}.

Of these, you need to worry only about @code{:expires}. It controls
how long the browser should save the cookie. If @code{:expires} is
@code{NIL} (the default), the browser will save the cookie only until
it exits. Other possible values are @code{:never}, which means the
cookie should be kept forever, or a universal time as returned by
@code{GET-UNIVERSAL-TIME} or @code{ENCODE-UNIVERSAL-TIME}. An
@code{:expires} of zero tells the client to immediately discard an
existing cookie.@footnote{For information about the meaning of the
other parameters, see the AllegroServe documentation and RFC 2109,
which describes the cookie mechanism.}

After you've set a cookie, you can use the function
@code{get-cookie-values} to get an alist containing one name/value pair
for each cookie sent by the browser. From that alist, you can pick out
individual cookie values using @code{ASSOC} and @code{CDR}.

The following function shows the names and values of all the cookies
sent by the browser:

@verbatim
(defun show-cookies (request entity)
  (with-http-response (request entity :content-type "text/html")
    (with-http-body (request entity)
      (with-html-output ((request-reply-stream request))
        (html
          (:standard-page
           (:title "Cookies")
           (if (null (get-cookie-values request))
             (html (:p "No cookies."))
             (html 
               (:table
                 (loop for (key . value) in (get-cookie-values request)
                    do (html (:tr (:td key) (:td value)))))))))))))

(publish :path "/show-cookies" :function 'show-cookies)
@end verbatim

The first time you load the page
@code{http://localhost:2001/show-cookies} it should say "No cookies" as
shown in Figure 26-7 since you haven't set any yet.

@float
@image{screenshots/show-cookies-no-cookies,,,,jpg}
@caption{Figure 26-7. @code{http://localhost:2001/show-cookies} with no cookies}
@end float

To set a cookie, you need another function, such as the following:

@verbatim
(defun set-cookie (request entity)
  (with-http-response (request entity :content-type "text/html")
    (set-cookie-header request :name "MyCookie" :value "A cookie value")
    (with-http-body (request entity)
      (with-html-output ((request-reply-stream request))
        (html 
          (:standard-page
           (:title "Set Cookie")
           (:p "Cookie set.")
           (:p (:a :href "/show-cookies" "Look at cookie jar."))))))))

(publish :path "/set-cookie" :function 'set-cookie)
@end verbatim

If you enter the URL @code{http://localhost:2001/set-cookie}, your
browser should display a page like the one in Figure 26-8. Additionally,
the server will send a Set-Cookie header with a cookie named "MyCookie"
with "A cookie value" as its value. If you click the link @emph{Look at
cookie jar}, you'll be taken to the @code{/show-cookies} page where
you'll see the new cookie, as shown in Figure 26-9. Because you didn't
specify an @code{:expires} argument, the browser will continue to send
the cookie with each request until you quit the browser.

@float
@image{screenshots/set-cookie,,,,jpg}
@caption{Figure 26-8. @code{http://localhost:2001/set-cookie}}
@end float

@float
@image{screenshots/show-cookies-one-cookie,,,,jpg}
@caption{Figure 26-9. @code{http://localhost:2001/show-cookies} after
setting a cookie}
@end float

@node A Small Application Framework
@section A Small Application Framework
@anchor{#a-small-application-framework}
Although AllegroServe provides fairly straightforward access to all the
basic facilities you need to write server-side Web code (access to query
parameters from both the URL's query string and the post data; the
ability to set cookies and retrieve their values; and, of course, the
ability to generate the response sent back to the browser), there's a
fair bit of annoyingly repetitive code.

For instance, every HTML-generating function you write is going to take
the arguments @code{request} and @code{entity} and then will contain
calls to @code{with-http-response}, @code{with-http-response}, and--if
you're going to use FOO to generate HTML--@code{with-html-output}. Then,
in functions that need to get at query parameters, there will be a bunch
of calls to @code{request-query-value} and then more code to convert the
string returned to whatever type you actually want. Finally, you need to
remember to @code{publish} the function.

To reduce the amount of boilerplate you have to write, you can write a
small framework on top of AllegroServe to make it easier to define
functions that handle requests for a particular URL.

The basic approach will be to define a macro,
@code{define-url-function}, that you'll use to define functions that
will automatically be published via @code{publish}. This macro will
expand into a @code{DEFUN} that contains the appropriate boilerplate as
well as code to publish the function under a URL of the same name. It'll
also take care of generating code to extract values from query
parameters and cookies and to bind them to variables declared in the
function's parameter list. Thus, the basic form of a
@code{define-url-function} definition is this:

@verbatim
(define-url-function name (request query-parameter*)
  body)
@end verbatim

where the @emph{body} is the code to emit the HTML of the page. It'll be
wrapped in a call to FOO's @code{html} macro, so for simple pages it
might contain nothing but s-expression HTML.

Within the body, the query parameter variables will be bound to values
of query parameters with the same name or from a cookie. In the simplest
case, a query parameter's value will be the string taken from the query
parameter or post data field of the same name. If the query parameter is
specified with a list, you can also specify an automatic type
conversion, a default value, and whether to look for and save the value
of the parameter in a cookie. The complete syntax for a
@emph{query-parameter} is as follows:

@verbatim
name | (name type [default-value] [stickiness])
@end verbatim

The @emph{type} must be a name recognized by @code{define-url-function}.
I'll discuss in a moment how to define new types. The
@emph{default-value} must be a value of the given type. Finally,
@emph{stickiness}, if supplied, indicates that the parameter's value
should be taken from an appropriately named cookie if no query parameter
is supplied and that a Set-Cookie header should be sent in the response
that saves the value in the cookie of the same name. Thus, a sticky
parameter, after being explicitly supplied a value via a query
parameter, will keep that value on subsequent requests of the page even
when no query parameter is supplied.

The name of the cookie used depends on the value of @emph{stickiness}:
with a value of @code{:global}, the cookie will be named the same as the
parameter. Thus, different functions that use globally sticky parameters
with the same name will share the value. If @emph{stickiness} is
@code{:package}, then the cookie name is constructed from the name of
the parameter and the package of the function's name; this allows
functions in the same package to share values but not have to worry
about stomping on parameters of functions in other packages. Finally, a
parameter with a @emph{stickiness} value of @code{:local} will use a
cookie made from the name of the parameter, the package of the function
name, and the function name, making it unique to that function.

For instance, you can use @code{define-url-function} to replace the
previous eleven-line definition of @code{random-page} with this
five-line version:

@verbatim
(define-url-function random-number (request (limit integer 1000))
  (:html
    (:head (:title "Random"))
    (:body
      (:p "Random number: " (:print (random limit))))))
@end verbatim

If you wanted the limit argument to be sticky, you could change the
limit declaration to @code{(limit integer 1000 :local)}.

@node The Implementation
@section The Implementation
@anchor{#the-implementation}
I'll explain the implementation of @code{define-url-function} from the
top down. The macro itself looks like this:

@verbatim
(defmacro define-url-function (name (request &rest params) &body body)
  (with-gensyms (entity)
    (let ((params (mapcar #'normalize-param params)))
      `(progn
         (defun ,name (,request ,entity)
           (with-http-response (,request ,entity :content-type "text/html")
             (let* (,@(param-bindings name request params))
               ,@(set-cookies-code name request params)
               (with-http-body (,request ,entity)
                 (with-html-output ((request-reply-stream ,request))
                   (html ,@body))))))
         (publish :path ,(format nil "/~(~a~)" name) :function ',name)))))
@end verbatim

Let's take it bit by bit, starting with the first few lines.

@verbatim
(defmacro define-url-function (name (request &rest params) &body body)
  (with-gensyms (entity)
    (let ((params (mapcar #'normalize-param params)))
@end verbatim

Up to here you're just getting ready to generate code. You @code{GENSYM}
a symbol to use later as the name of the entity parameter in the
@code{DEFUN}. Then you normalize the parameters, converting plain
symbols to list form using this function:

@verbatim
(defun normalize-param (param)
  (etypecase param
    (list param)
    (symbol `(,param string nil nil))))
@end verbatim

In other words, declaring a parameter with just a symbol is the same as
declaring a nonsticky, string parameter with no default value.

Then comes the @code{PROGN}. You must expand into a @code{PROGN} because
you need to generate code to do two things: define a function with
@code{DEFUN} and call @code{publish}. You should define the function
first so if there's an error in the definition, the function won't be
published. The first two lines of the @code{DEFUN} are just boilerplate.

@verbatim
(defun ,name (,request ,entity)
  (with-http-response (,request ,entity :content-type "text/html")  
@end verbatim

Now you do the real work. The following two lines generate the
bindings for the parameters specified in @code{define-url-function}
other than @code{request} and the code that calls
@code{set-cookie-header} for the sticky parameters. Of course, the
real work is done by helper functions that you'll look at in a
moment.@footnote{You need to use @code{LET*} rather than a @code{LET}
to allow the default value forms for parameters to refer to parameters
that appear earlier in the parameter list. For example, you could
write this:

@verbatim
(define-url-function (request (x integer 10) (y integer (* 2 x))) ...)
@end verbatim

and the value of @code{y}, if not explicitly supplied, would be twice
the value of @code{x}.}

@verbatim
    (let* (,@(param-bindings name request params))
      ,@(set-cookies-code name request params)
@end verbatim

The rest is just more boilerplate, putting the body from the
@code{define-url-function} definition in the appropriate context of
@code{with-http-body}, @code{with-html-output}, and @code{html} macros.
Then comes the call to @code{publish}.

@verbatim
   (publish :path ,(format nil "/~(~a~)" name) :function ',name)
@end verbatim

The expression @code{(format nil "/~(~a~)" name)} is evaluated at macro
expansion time, generating a string consisting of /, followed by an
all-lowercase version of the name of the function you're about to
define. That string becomes the @code{:path} argument to publish, while
the function name is interpolated as the @code{:function} argument.

Now let's look at the helper functions used to generate the @code{DEFUN}
form. To generate parameter bindings, you need to loop over the
@code{params} and collect a snippet of code for each one, generated by
@code{param-binding}. That snippet will be a list containing the name of
the variable to bind and the code that will compute the value of that
variable. The exact form of code used to compute the value will depend
on the type of the parameter, whether it's sticky, and the default
value, if any. Because you already normalized the params, you can use
@code{DESTRUCTURING-BIND} to take them apart in @code{param-binding}.

@verbatim
(defun param-bindings (function-name request params)
  (loop for param in params
     collect (param-binding function-name request param)))

(defun param-binding (function-name request param)
  (destructuring-bind (name type &optional default sticky) param
    (let ((query-name (symbol->query-name name))
          (cookie-name (symbol->cookie-name function-name name sticky)))
      `(,name (or 
               (string->type ',type (request-query-value ,query-name ,request))
               ,@(if cookie-name
                     (list `(string->type ',type (get-cookie-value ,request ,cookie-name))))
               ,default)))))
@end verbatim

The function @code{string->type}, which you use to convert strings
obtained from the query parameters and cookies to the desired type, is a
generic function with the following signature:

@verbatim
(defgeneric string->type (type value))
@end verbatim

To make a particular name usable as a type name for a query parameter,
you just need to define a method on @code{string->type}. You'll need to
define at least a method specialized on the symbol @code{string} since
that's the default type. Of course, that's pretty easy. Since browsers
sometimes submit forms with empty strings to indicate no value was
supplied for a particular value, you'll want to convert an empty string
to @code{NIL} as this method does:

@verbatim
(defmethod string->type ((type (eql 'string)) value)
  (and (plusp (length value)) value))
@end verbatim

You can add conversions for other types needed by your application. For
instance, to make @code{integer} usable as a query parameter type so you
can handle the @code{limit} parameter of @code{random-page}, you might
define this method:

@verbatim
(defmethod string->type ((type (eql 'integer)) value)
  (parse-integer (or value "") :junk-allowed t))
@end verbatim

Another helper function used in the code generated by
@code{param-binding} is @code{get-cookie-value}, which is just a bit of
sugar around the @code{get-cookie-values} function provided by
AllegroServe. It looks like this:

@verbatim
(defun get-cookie-value (request name)
  (cdr (assoc name (get-cookie-values request) :test #'string=)))
@end verbatim

The functions that compute the query parameter and cookies names are
similarly straightforward.

@verbatim
(defun symbol->query-name (sym)
  (string-downcase sym))

(defun symbol->cookie-name (function-name sym sticky)
  (let ((package-name (package-name (symbol-package function-name))))
    (when sticky
      (ecase sticky
        (:global
         (string-downcase sym))
        (:package
         (format nil "~(~a:~a~)" package-name sym))
        (:local 
         (format nil "~(~a:~a:~a~)" package-name function-name sym))))))
@end verbatim

To generate the code that sets cookies for sticky parameters, you again
loop over the list of parameters, this time collecting a snippet of code
for each sticky param. You can use the @code{when}and @code{collect it}
@code{LOOP }forms to collect only the non-@code{NIL} values returned by
@code{set-cookie-code}.

@verbatim
(defun set-cookies-code (function-name request params)
  (loop for param in params
       when (set-cookie-code function-name request param) collect it))

(defun set-cookie-code (function-name request param)
  (destructuring-bind (name type &optional default sticky) param
    (declare (ignore type default))
    (if sticky
      `(when ,name 
         (set-cookie-header 
          ,request
          :name ,(symbol->cookie-name function-name name sticky)
          :value (princ-to-string ,name))))))
@end verbatim

One of the advantages of defining macros in terms of helper functions
like this is that it's easy to make sure the individual bits of code
you're generating look right. For instance, you can check that the
following @code{set-cookie-code}:

@verbatim
(set-cookie-code 'foo 'request '(x integer 20 :local))
@end verbatim

generates something like this:

@verbatim
(WHEN X
  (SET-COOKIE-HEADER REQUEST
    :NAME "com.gigamonkeys.web:foo:x"
    :VALUE (PRINC-TO-STRING X)))
@end verbatim

Assuming this code will occur in a context where @code{x} is the name of
a variable, this looks good.

Once again, macros have allowed you to distill the code you need to
write down to its essence--in this case, the data you want to extract
from the request and the HTML you want to generate. That said, this
framework isn't meant to be the be-all and end-all of Web application
frameworks--it's just a little sugar to make it a bit easier to write
simple apps like the one you'll write in Chapter 29.

But before you can get to that, you need to write the guts of the
application for which the Chapter 29 application will be the user
interface. You'll start in the next chapter with a souped-up version of
the database you wrote in Chapter 3, this time to keep track of ID3 data
extracted from MP3 files.

@node Practical An MP3 Database
@chapter Practical: An MP3 Database
@anchor{#practical-an-mp3-database}
In this chapter you'll revisit the idea first explored in Chapter 3 of
building an in-memory database out of basic Lisp data structures. This
time your goal is to hold information that you'll extract from a
collection of MP3 files using the ID3v2 library from Chapter 25. You'll
then use this database in Chapters 28 and 29 as part of a Web-based
streaming MP3 server. Of course, this time around you can use some of
the language features you've learned since Chapter 3 to build a more
sophisticated version.
@menu
* The Database::
* Defining a Schema::
* Inserting Values::
* Querying the MP3 Database::
* Matching Functions::
* Getting at the Results::
* Other Database Operations::
@end menu

@node The Database
@section The Database
@anchor{#the-database}
The main problem with the database in Chapter 3 is that there's only one
table, the list stored in the variable @code{*db*}. Another is that the
code doesn't know anything about what type of values are stored in
different columns. In Chapter 3 you got away with that by using the
fairly general-purpose @code{EQUAL} method to compare column values when
selecting rows from the database, but you would've been in trouble if
you had wanted to store values that couldn't be compared with
@code{EQUAL} or if you had wanted to sort the rows in the database since
there's no ordering function that's as general as @code{EQUAL}.

This time you'll solve both problems by defining a class, @code{table},
to represent individual database tables. Each @code{table} instance will
consist of two slots--one to hold the table's data and another to hold
information about the columns in the table that database operations will
be able to use. The class looks like this:

@verbatim
(defclass table ()
  ((rows   :accessor rows   :initarg :rows :initform (make-rows))
   (schema :accessor schema :initarg :schema)))
@end verbatim

As in Chapter 3, you can represent the individual rows with plists, but
this time around you'll create an abstraction that will make that an
implementation detail you can change later without too much trouble. And
this time you'll store the rows in a vector rather than a list since
certain operations that you'll want to support, such as random access to
rows by a numeric index and the ability to sort a table, can be more
efficiently implemented with vectors.

The function @code{make-rows} used to initialize the @code{rows} slot
can be a simple wrapper around @code{MAKE-ARRAY} that builds an empty,
adjustable,vector with a fill pointer.

The Package
The package for the code you'll develop in this chapter looks like this:

@verbatim
(defpackage :com.gigamonkeys.mp3-database
  (:use :common-lisp 
        :com.gigamonkeys.pathnames
        :com.gigamonkeys.macro-utilities
        :com.gigamonkeys.id3v2)
  (:export  :*default-table-size*
            :*mp3-schema*
            :*mp3s*
            :column
            :column-value
            :delete-all-rows
            :delete-rows
            :do-rows
            :extract-schema
            :in
            :insert-row
            :load-database
            :make-column
            :make-schema
            :map-rows
            :matching
            :not-nullable
            :nth-row
            :random-selection
            :schema
            :select
            :shuffle-table
            :sort-rows
            :table
            :table-size
            :with-column-values))
@end verbatim

The @code{:use} section gives you access to the functions and macros
whose names are exported from the packages defined in Chapter 15, 8, and
25 and the @code{:export} section exports the API this library will
provide, which you'll use in Chapter 29.

@verbatim
(defparameter *default-table-size* 100)

(defun make-rows (&optional (size *default-table-size*))
  (make-array size :adjustable t :fill-pointer 0))
@end verbatim

To represent a table's schema, you need to define another class,
@code{column}, each instance of which will contain information about one
column in the table: its name, how to compare values in the column for
equality and ordering, a default value, and a function that will be used
to normalize the column's values when inserting data into the table and
when querying the table. The @code{schema} slot will hold a list of
@code{column} objects. The class definition looks like this:

@verbatim
(defclass column ()
  ((name               
    :reader name
    :initarg :name)

   (equality-predicate
    :reader equality-predicate
    :initarg :equality-predicate)

   (comparator
    :reader comparator
    :initarg :comparator)

   (default-value
    :reader default-value
    :initarg :default-value
    :initform nil)

   (value-normalizer
    :reader value-normalizer
    :initarg :value-normalizer
    :initform #'(lambda (v column) (declare (ignore column)) v))))
@end verbatim

The @code{equality-predicate} and @code{comparator} slots of a
@code{column} object hold functions used to compare values from the
given column for equivalence and ordering. Thus, a column containing
string values might have @code{STRING=} as its @code{equality-predicate}
and @code{STRING<} as its @code{comparator}, while a column containing
numbers might have @code{=} and @code{<}.

The @code{default-value} and @code{value-normalizer} slots are used when
inserting rows into the database and, in the case of
@code{value-normalizer}, when querying the database. When you insert a
row into the database, if no value is provided for a particular column,
you can use the value stored in the @code{column}'s @code{default-value}
slot. Then the value--defaulted or otherwise--is normalized by passing
it and the column object to the function stored in the
@code{value-normalizer} slot. You pass the column in case the
@code{value-normalizer} function needs to use some data associated with
the column object. (You'll see an example of this in the next section.)
You should also normalize values passed in queries before comparing them
with values in the database.

Thus, the @code{value-normalizer}'s responsibility is primarily to
return a value that can be safely and correctly passed to the
@code{equality-predicate} and @code{comparator} functions. If the
@code{value-normalizer} can't figure out an appropriate value to return,
it can signal an error.

The other reason to normalize values before you store them in the
database is to save both memory and CPU cycles. For instance, if you
have a column that's going to contain string values but the number of
distinct strings that will be stored in the column is small--for
instance, the genre column in the MP3 database--you can save space and
speed by using the @code{value-normalizer} to @emph{intern} the
strings (translate all @code{STRING=} values to a single string
object). Thus, you'll need only as many strings as there are distinct
values, regardless of how many rows are in the table, and you can use
@code{EQL} to compare column values rather than the slower
@code{STRING=}.@footnote{The general theory behind interning objects
is that if you're going to compare a particular value many times, it's
worth it to pay the cost of interning it. The @code{value-normalizer}
runs once when you insert a value into the table and, as you'll see,
once at the beginning of each query. Since a query can involve
invoking the @code{equality-predicate} once per row in the table, the
amortized cost of interning the values will quickly approach zero.}

@node Defining a Schema
@section Defining a Schema
@anchor{#defining-a-schema}
Thus, to make an instance of @code{table}, you need to build a list of
@code{column} objects. You could build the list by hand, using
@code{LIST} and @code{MAKE-INSTANCE}. But you'll soon notice that you're
frequently making a lot column objects with the same comparator and
equality-predicate combinations. This is because the combination of a
comparator and equality predicate essentially defines a column type.
It'd be nice if there was a way to give those types names that would
allow you to say simply that a given column is a string column, rather
than having to specify @code{STRING<} as its comparator and
@code{STRING=} as its equality predicate. One way is to define a generic
function, @code{make-column}, like this:

@verbatim
(defgeneric make-column (name type &optional default-value))
@end verbatim

Now you can implement methods on this generic function that specialize
on @code{type} with @code{EQL} specializers and return @code{column}
objects with the slots filled in with appropriate values. Here's the
generic function and methods that define column types for the type names
@code{string} and @code{number}:

@verbatim
(defmethod make-column (name (type (eql 'string)) &optional default-value)
  (make-instance
   'column 
   :name name
   :comparator #'string< 
   :equality-predicate #'string=
   :default-value default-value
   :value-normalizer #'not-nullable))

(defmethod make-column (name (type (eql 'number)) &optional default-value)
  (make-instance 
   'column
   :name name
   :comparator #'< 
   :equality-predicate #'=
   :default-value default-value))
@end verbatim

The following function, @code{not-nullable}, used as the
@code{value-normalizer} for @code{string} columns, simply returns the
value it's given unless the value is @code{NIL}, in which case it
signals an error:

@verbatim
(defun not-nullable (value column)
  (or value (error "Column ~a can't be null" (name column))))
@end verbatim

This is important because @code{STRING<} and @code{STRING=} will
signal an error if called on @code{NIL}; it's better to catch bad
values before they go into the table rather than when you try to use
them.@footnote{As always, the first causality of concise exposition in
programming books is proper error handling; in production code you'd
probably want to define your own error type, such as the following,
and signal it instead:

@verbatim
(error 'illegal-column-value :value value :column column)
@end verbatim

Then you'd want to think about where you can add restarts that might
be able to recover from this condition. And, finally, in any given
application you could establish condition handlers that would choose
from among those restarts.}

Another column type you'll need for the MP3 database is an
@code{interned-string} whose values are interned as discussed
previously. Since you need a hash table in which to intern values, you
should define a subclass of @code{column},
@code{interned-values-column}, that adds a slot whose value is the hash
table you use to intern.

To implement the actual interning, you'll also need to provide an
@code{:initform} for @code{value-normalizer} of a function that interns
the value in the column's @code{interned-values} hash table. And because
one of the main reasons to intern values is to allow you to use
@code{EQL} as the equality predicate, you should also add an
@code{:initform} for the @code{equality-predicate} of @code{#'eql}.

@verbatim
(defclass interned-values-column (column)
  ((interned-values
    :reader interned-values
    :initform (make-hash-table :test #'equal))
   (equality-predicate :initform #'eql)
   (value-normalizer   :initform #'intern-for-column)))

(defun intern-for-column (value column)
  (let ((hash (interned-values column)))
    (or (gethash (not-nullable value column) hash)
        (setf (gethash value hash) value))))
@end verbatim

You can then define a @code{make-column} method specialized on the name
@code{interned-string} that returns an instance of
@code{interned-values-column}.

@verbatim
(defmethod make-column (name (type (eql 'interned-string)) &optional default-value)
  (make-instance 
   'interned-values-column
   :name name
   :comparator #'string< 
   :default-value default-value))
@end verbatim

With these methods defined on @code{make-column}, you can now define a
function, @code{make-schema}, that builds a list of @code{column}
objects from a list of column specifications consisting of a column
name, a column type name, and, optionally, a default value.

@verbatim
(defun make-schema (spec)
  (mapcar #'(lambda (column-spec) (apply #'make-column column-spec)) spec))
@end verbatim

For instance, you can define the schema for the table you'll use to
store data extracted from MP3s like this:

@verbatim
(defparameter *mp3-schema* 
  (make-schema 
   '((:file     string)
     (:genre    interned-string "Unknown")
     (:artist   interned-string "Unknown")
     (:album    interned-string "Unknown")
     (:song     string)
     (:track    number 0)
     (:year     number 0)
     (:id3-size number))))
@end verbatim

To make an actual table for holding information about MP3s, you pass
@code{*mp3-schema*} as the @code{:schema} initarg to
@code{MAKE-INSTANCE}.

@verbatim
(defparameter *mp3s* (make-instance 'table :schema *mp3-schema*))
@end verbatim

@node Inserting Values
@section Inserting Values
@anchor{#inserting-values}
Now you're ready to define your first table operation,
@code{insert-row}, which takes a plist of names and values and a table
and adds a row to the table containing the given values. The bulk of the
work is done in a helper function, @code{normalize-row}, that builds a
plist with a defaulted, normalized value for each column, using the
values from @code{names-and-values} if available and the
@code{default-value} for the column if not.

@verbatim
(defun insert-row (names-and-values table)
  (vector-push-extend (normalize-row names-and-values (schema table)) (rows table)))

(defun normalize-row (names-and-values schema)
  (loop
     for column in schema
     for name  = (name column)
     for value = (or (getf names-and-values name) (default-value column))
     collect name
     collect (normalize-for-column value column)))
@end verbatim

It's worth defining a separate helper function,
@code{normalize-for-column}, that takes a value and a @code{column}
object and returns the normalized value because you'll need to perform
the same normalization on query arguments.

@verbatim
(defun normalize-for-column (value column)
  (funcall (value-normalizer column) value column))
@end verbatim

Now you're ready to combine this database code with code from previous
chapters to build a database of data extracted from MP3 files. You can
define a function, @code{file->row}, that uses @code{read-id3} from the
ID3v2 library to extract an ID3 tag from a file and turns it into a
plist that you can pass to @code{insert-row}.

@verbatim
(defun file->row (file)
  (let ((id3 (read-id3 file)))
    (list
     :file   (namestring (truename file))
     :genre  (translated-genre id3)
     :artist (artist id3)
     :album  (album id3)
     :song   (song id3)
     :track  (parse-track (track id3))
     :year   (parse-year (year id3))
     :id3-size (size id3))))
@end verbatim

You don't have to worry about normalizing the values since
@code{insert-row} takes care of that for you. You do, however, have to
convert the string values returned by the @code{track} and @code{year}
into numbers. The track number in an ID3 tag is sometimes stored as
the ASCII representation of the track number and sometimes as a number
followed by a slash followed by the total number of tracks on the
album.  Since you care only about the actual track number, you should
use the @code{:end} argument to @code{PARSE-INTEGER} to specify that
it should parse only up to the slash, if any.@footnote{If any MP3
files have malformed data in the track and year frames,
@code{PARSE-INTEGER} could signal an error. One way to deal with that
is to pass @code{PARSE-INTEGER} the @code{:junk-allowed} argument of
@code{T}, which will cause it to ignore any non-numeric junk following
the number and to return @code{NIL} if no number can be found in the
string. Or, if you want practice at using the condition system, you
could define an error and signal it from these functions when the data
is malformed and also establish a few restarts to allow these
functions to recover.}

@verbatim
(defun parse-track (track)
  (when track (parse-integer track :end (position #\/ track))))

(defun parse-year (year)
  (when year (parse-integer year)))
@end verbatim

Finally, you can put all these functions together, along with
@code{walk-directory} from the portable pathnames library and
@code{mp3-p} from the ID3v2 library, to define a function that loads an
MP3 database with data extracted from all the MP3 files it can find
under a given directory.

@verbatim
(defun load-database (dir db)
  (let ((count 0))
    (walk-directory 
     dir 
     #'(lambda (file)
         (princ #\.)
         (incf count)
         (insert-row (file->row file) db))
     :test #'mp3-p)
    (format t "~&Loaded ~d files into database." count)))
@end verbatim

@node Querying the MP3 Database
@section Querying the Database
@anchor{#querying-the-database-1}
Once you've loaded your database with data, you'll need a way to query
it. For the MP3 application you'll need a slightly more sophisticated
query function than you wrote in Chapter 3. This time around you want
not only to be able to select rows matching particular criteria but also
to limit the results to particular columns, to limit the results to
unique rows, and perhaps to sort the rows by particular columns. In
keeping with the spirit of relational database theory, the result of a
query will be a new @code{table} object containing the desired rows and
columns.

The query function you'll write, @code{select}, is loosely modeled on
the @code{SELECT} statement from Structured Query Language (SQL). It'll
take five keyword parameters: @code{:from}, @code{:columns},
@code{:where}, @code{:distinct}, and @code{:order-by}. The @code{:from}
argument is the @code{table} object you want to query. The
@code{:columns} argument specifies which columns should be included in
the result. The value should be a list of column names, a single column
name, or a @code{T}, the default, meaning return all columns. The
@code{:where} argument, if provided, should be a function that accepts a
row and returns true if it should be included in the results. In a
moment, you'll write two functions, @code{matching} and @code{in}, that
return functions appropriate for use as @code{:where} arguments. The
@code{:order-by} argument, if supplied, should be a list of column
names; the results will be sorted by the named columns. As with the
@code{:columns} argument, you can specify a single column using just the
name, which is equivalent to a one-item list containing the same name.
Finally, the @code{:distinct} argument is a boolean that says whether to
eliminate duplicate rows from the results. The default value for
@code{:distinct} is @code{NIL}.

Here are some examples of using @code{select}:

@verbatim
;; Select all rows where the :artist column is "Green Day"
(select :from *mp3s* :where (matching *mp3s* :artist "Green Day"))

;; Select a sorted list of artists with songs in the genre "Rock"
(select
  :columns :artist
  :from *mp3s*
  :where (matching *mp3s* :genre "Rock")
  :distinct t
  :order-by :artist)
@end verbatim

The implementation of @code{select} with its immediate helper functions
looks like this:

@verbatim
(defun select (&key (columns t) from where distinct order-by)
  (let ((rows (rows from))
        (schema (schema from)))

    (when where
      (setf rows (restrict-rows rows where)))

    (unless (eql columns 't)
      (setf schema (extract-schema (mklist columns) schema))
      (setf rows (project-columns rows schema)))

    (when distinct
      (setf rows (distinct-rows rows schema)))

    (when order-by
      (setf rows (sorted-rows rows schema (mklist order-by))))

    (make-instance 'table :rows rows :schema schema)))

(defun mklist (thing)
  (if (listp thing) thing (list thing)))

(defun extract-schema (column-names schema)
  (loop for c in column-names collect (find-column c schema)))

(defun find-column (column-name schema)
  (or (find column-name schema :key #'name)
      (error "No column: ~a in schema: ~a" column-name schema)))

(defun restrict-rows (rows where)
  (remove-if-not where rows))

(defun project-columns (rows schema)
  (map 'vector (extractor schema) rows))

(defun distinct-rows (rows schema)
  (remove-duplicates rows :test (row-equality-tester schema)))

(defun sorted-rows (rows schema order-by)
  (sort (copy-seq rows) (row-comparator order-by schema)))
@end verbatim

Of course, the really interesting part of @code{select} is how you
implement the functions @code{extractor}, @code{row-equality-tester},
and @code{row-comparator}.

As you can tell by how they're used, each of these functions must return
a function. For instance, @code{project-columns} uses the value returned
by @code{extractor} as the function argument to @code{MAP}. Since the
purpose of @code{project-columns} is to return a set of rows with only
certain column values, you can infer that @code{extractor} returns a
function that takes a row as an argument and returns a new row
containing only the columns specified in the schema it's passed. Here's
how you can implement it:

@verbatim
(defun extractor (schema)
  (let ((names (mapcar #'name schema)))
    #'(lambda (row)
        (loop for c in names collect c collect (getf row c)))))
@end verbatim

Note how you can do the work of extracting the names from the schema
outside the body of the closure: since the closure will be called many
times, you want it to do as little work as possible each time it's
called.

The functions @code{row-equality-tester} and @code{row-comparator} are
implemented in a similar way. To decide whether two rows are equivalent,
you need to apply the appropriate equality predicate for each column to
the appropriate column values. Recall from Chapter 22 that the
@code{LOOP} clause @code{always} will return @code{NIL} as soon as a
pair of values fails their test or will cause the @code{LOOP} to return
@code{T}.

@verbatim
(defun row-equality-tester (schema)
  (let ((names (mapcar #'name schema))
        (tests (mapcar #'equality-predicate schema)))
    #'(lambda (a b)
        (loop for name in names and test in tests
           always (funcall test (getf a name) (getf b name))))))
@end verbatim

Ordering two rows is a bit more complex. In Lisp, comparator functions
return true if their first argument should be sorted ahead of the second
and @code{NIL} otherwise. Thus, a @code{NIL} can mean that the second
argument should be sorted ahead of the first @emph{or} that they're
equivalent. You want your row comparators to behave the same way: return
@code{T} if the first row should be sorted ahead of the second and
@code{NIL} otherwise.

Thus, to compare two rows, you should compare the values from the
columns you're sorting by, in order, using the appropriate comparator
for each column. First call the comparator with the value from the first
row as the first argument. If the comparator returns true, that means
the first row should definitely be sorted ahead of the second row, so
you can immediately return @code{T}.

But if the column comparator returns @code{NIL}, then you need to
determine whether that's because the second value should sort ahead of
the first value or because they're equivalent. So you should call the
comparator again with the arguments reversed. If the comparator returns
true this time, it means the second column value sorts ahead of the
first and thus the second row ahead of the first row, so you can return
@code{NIL} immediately. Otherwise, the column values are equivalent, and
you need to move onto the next column. If you get through all the
columns without one row's value ever winning the comparison, then the
rows are equivalent, and you return @code{NIL}. A function that
implements this algorithm looks like this:

@verbatim
(defun row-comparator (column-names schema)
  (let ((comparators (mapcar #'comparator (extract-schema column-names schema))))
    #'(lambda (a b)
        (loop
           for name in column-names
           for comparator in comparators
           for a-value = (getf a name)
           for b-value = (getf b name)
           when (funcall comparator a-value b-value) return t
           when (funcall comparator b-value a-value) return nil
           finally (return nil)))))
@end verbatim

@node Matching Functions
@section Matching Functions
@anchor{#matching-functions}
The @code{:where} argument to @code{select} can be any function that
takes a row object and returns true if it should be included in the
results. In practice, however, you'll rarely need the full power of
arbitrary code to express query criteria. So you should provide two
functions, @code{matching} and @code{in}, that will build query
functions that allow you to express the common kinds of queries and that
take care of using the proper equality predicates and value normalizers
for each column.

The workhouse query-function constructor will be @code{matching}, which
returns a function that will match rows with specific column values. You
saw how it was used in the earlier examples of @code{select}. For
instance, this call to @code{matching}:

@verbatim
(matching *mp3s* :artist "Green Day")
@end verbatim

returns a function that matches rows whose @code{:artist} value is
"Green Day". You can also pass multiple names and values; the returned
function matches when all the columns match. For example, the following
returns a closure that matches rows where the artist is "Green Day" and
the album is "American Idiot":

@verbatim
(matching *mp3s* :artist "Green Day" :album "American Idiot")
@end verbatim

You have to pass @code{matching} the table object because it needs
access to the table's schema in order to get at the equality predicates
and value normalizer functions for the columns it matches against.

You build up the function returned by @code{matching} out of smaller
functions, each responsible for matching one column's value. To build
these functions, you should define a function, @code{column-matcher},
that takes a @code{column} object and an unnormalized value you want to
match and returns a function that accepts a single row and returns true
when the value of the given column in the row matches the normalized
version of the given value.

@verbatim
(defun column-matcher (column value)
  (let ((name (name column))
        (predicate (equality-predicate column))
        (normalized (normalize-for-column value column)))
    #'(lambda (row) (funcall predicate (getf row name) normalized))))
@end verbatim

You then build a list of column-matching functions for the names and
values you care about with the following function,
@code{column-matchers}:

@verbatim
(defun column-matchers (schema names-and-values)
  (loop for (name value) on names-and-values by #'cddr
     when value collect
       (column-matcher (find-column name schema) value)))
@end verbatim

Now you can implement @code{matching}. Again, note that you do as much
work as possible outside the closure in order to do it only once rather
than once per row in the table.

@verbatim
(defun matching (table &rest names-and-values)
  "Build a where function that matches rows with the given column values."
  (let ((matchers (column-matchers (schema table) names-and-values)))
    #'(lambda (row)
        (every #'(lambda (matcher) (funcall matcher row)) matchers))))
@end verbatim

This function is a bit of a twisty maze of closures, but it's worth
contemplating for a moment to get a flavor of the possibilities of
programming with functions as first-class objects.

The job of @code{matching} is to return a function that will be invoked
on each row in a table to determine whether it should be included in the
new table. So, @code{matching} returns a closure with one parameter,
@code{row}.

Now recall that the function @code{EVERY} takes a predicate function as
its first argument and returns true if, and only if, that function
returns true each time it's applied to an element of the list passed as
@code{EVERY}'s second argument. However, in this case, the list you pass
to @code{EVERY} is itself a list of functions, the column matchers. What
you want to know is that every column matcher, when invoked on the row
you're currently testing, returns true. So, as the predicate argument to
@code{EVERY}, you pass yet another closure that @code{FUNCALL}s the
column matcher, passing it the row.

Another matching function that you'll occasionally find useful is
@code{in}, which returns a function that matches rows where a
particular column is in a given set of values. You'll define @code{in}
to take two arguments: a column name and a table that contains the
values you want to match. For instance, suppose you wanted to find all
the songs in the MP3 database that have names the same as a song
performed by the Dixie Chicks. You can write that where clause using
@code{in} and a sub@code{select} like this:@footnote{This query will
also return all the songs performed by the Dixie Chicks. If you want
to limit it to songs by artists other than the Dixie Chicks, you need
a more complex @code{:where} function.  Since the @code{:where}
argument can be any function, it's certainly possible; you could
remove the Dixie Chicks' own songs with this query:

@verbatim
(let* ((dixie-chicks (matching *mp3s* :artist "Dixie Chicks"))
       (same-song (in :song (select :columns :song :from *mp3s* :where dixie-chicks)))
       (query #'(lambda (row) (and (not (funcall dixie-chicks row)) (funcall same-song row)))))
  (select :columns '(:artist :song) :from *mp3s* :where query))
@end verbatim

This obviously isn't quite as convenient. If you were going to write
an application that needed to do lots of complex queries, you might
want to consider coming up with a more expressive query language.}

@verbatim
(select
  :columns '(:artist :song)
  :from *mp3s*
  :where (in :song 
             (select
               :columns :song
               :from *mp3s*
               :where (matching *mp3s* :artist "Dixie Chicks"))))
@end verbatim

Although the queries are more complex, the definition of @code{in} is
much simpler than that of @code{matching}.

@verbatim
(defun in (column-name table)
  (let ((test (equality-predicate (find-column column-name (schema table))))
        (values (map 'list #'(lambda (r) (getf r column-name)) (rows table))))
    #'(lambda (row)
        (member (getf row column-name) values :test test))))
@end verbatim

@node Getting at the Results
@section Getting at the Results
@anchor{#getting-at-the-results}
Since @code{select} returns another @code{table}, you need to think a
bit about how you want to get at the individual row and column values in
a table. If you're sure you'll never want to change the way you
represent the data in a table, you can just make the structure of a
table part of the API--that @code{table} has a slot @code{rows} that's a
vector of plists--and use all the normal Common Lisp functions for
manipulating vectors and plists to get at the values in the table. But
that representation is really an internal detail that you might want to
change. Also, you don't necessarily want other code manipulating the
data structures directly--for instance, you don't want anyone to use
@code{SETF} to put an unnormalized column value into a row. So it might
be a good idea to define a few abstractions that provide the operations
you want to support. Then if you decide to change the internal
representation later, you'll need to change only the implementation of
these functions and macros. And while Common Lisp doesn't enable you to
absolutely prevent folks from getting at "internal" data, by providing
an official API you at least make it clear where the boundary is.

Probably the most common thing you'll need to do with the results of a
query is to iterate over the individual rows and extract specific column
values. So you need to provide a way to do both those things without
touching the @code{rows} vector directly or using @code{GETF} to get at
the column values within a row.

For now these operations are trivial to implement; they're merely
wrappers around the code you'd write if you didn't have these
abstractions. You can provide two ways to iterate over the rows of a
table: a macro @code{do-rows}, which provides a basic looping
construct, and a function @code{map-rows}, which builds a list
containing the results of applying a function to each row in the
table.@footnote{The version of @code{LOOP} implemented at M.I.T.
before Common Lisp was standardized included a mechanism for extending
the @code{LOOP} grammar to support iteration over new data structures.
Some Common Lisp implementations that inherited their @code{LOOP}
implementation from that code base may still support that facility,
which would make @code{do-rows} and @code{map-rows} less necessary.}

@verbatim
(defmacro do-rows ((row table) &body body)
  `(loop for ,row across (rows ,table) do ,@body))

(defun map-rows (fn table)
  (loop for row across (rows table) collect (funcall fn row)))
@end verbatim

To get at individual column values within a row, you should provide a
function, @code{column-value}, that takes a row and a column name and
returns the appropriate value. Again, it's a trivial wrapper around the
code you'd write otherwise. But if you change the internal
representation of a table later, users of @code{column-value} needn't be
any the wiser.

@verbatim
(defun column-value (row column-name)
  (getf row column-name))
@end verbatim

While @code{column-value} is a sufficient abstraction for getting at
column values, you'll often want to get at the values of multiple
columns at once. So you can provide a bit of syntactic sugar, a macro,
@code{with-column-values}, that binds a set of variables to the values
extracted from a row using the corresponding keyword names. Thus,
instead of writing this:

@verbatim
 (do-rows (row table)
   (let ((song (column-value row :song))
         (artist (column-value row :artist))
         (album (column-value row :album)))
     (format t "~a by ~a from ~a~%" song artist album)))
@end verbatim

you can simply write the following:

@verbatim
(do-rows (row table)
  (with-column-values (song artist album) row
    (format t "~a by ~a from ~a~%" song artist album)))
@end verbatim

Again, the actual implementation isn't complicated if you use the
@code{once-only} macro from Chapter 8.

@verbatim
(defmacro with-column-values ((&rest vars) row &body body)
  (once-only (row)
    `(let ,(column-bindings vars row) ,@body)))

(defun column-bindings (vars row)
  (loop for v in vars collect `(,v (column-value ,row ,(as-keyword v)))))

(defun as-keyword (symbol)
  (intern (symbol-name symbol) :keyword))
@end verbatim

Finally, you should provide abstractions for getting at the number of
rows in a table and for accessing a specific row by numeric index.

@verbatim
(defun table-size (table)
  (length (rows table)))

(defun nth-row (n table)
  (aref (rows table) n))
@end verbatim

@node Other Database Operations
@section Other Database Operations
@anchor{#other-database-operations}
Finally, you'll implement a few other database operations that you'll
need in Chapter 29. The first two are analogs of the SQL @code{DELETE}
statement. The function @code{delete-rows} is used to delete rows from a
table that match particular criteria. Like @code{select}, it takes
@code{:from} and @code{:where} keyword arguments. Unlike @code{select},
it doesn't return a new table--it actually modifies the table passed as
the @code{:from} argument.

@verbatim
(defun delete-rows (&key from where)
  (loop
     with rows = (rows from)
     with store-idx = 0
     for read-idx from 0
     for row across rows
     do (setf (aref rows read-idx) nil)
     unless (funcall where row) do
       (setf (aref rows store-idx) row)
       (incf store-idx)
     finally (setf (fill-pointer rows) store-idx)))
@end verbatim

In the interest of efficiency, you might want to provide a separate
function for deleting all the rows from a table.

@verbatim
(defun delete-all-rows (table)
  (setf (rows table) (make-rows *default-table-size*)))
@end verbatim

The remaining table operations don't really map to normal relational
database operations but will be useful in the MP3 browser application.
The first is a function to sort the rows of a table in place.

@verbatim
(defun sort-rows (table &rest column-names)
  (setf (rows table) (sort (rows table) (row-comparator column-names (schema table))))
  table)
@end verbatim

On the flip side, in the MP3 browser application, you'll need a function
that shuffles a table's rows in place using the function
@code{nshuffle-vector} from Chapter 23.

@verbatim
(defun shuffle-table (table)
  (nshuffle-vector (rows table))
  table)
@end verbatim

And finally, again for the purposes of the MP3 browser, you should
provide a function that selects @emph{n} random rows, returning the
results as a new table. It also uses @code{nshuffle-vector} along with a
version of @code{random-sample} based on Algorithm S from Donald Knuth's
@emph{The Art of Computer Programming, Volume 2: Seminumerical
Algorithms}, Third Edition (Addison-Wesley, 1998) that I discussed in
Chapter 20.

@verbatim
(defun random-selection (table n)
  (make-instance
   'table
   :schema (schema table)
   :rows (nshuffle-vector (random-sample (rows table) n))))

(defun random-sample (vector n)
  "Based on Algorithm S from Knuth. TAOCP, vol. 2. p. 142"
  (loop with selected = (make-array n :fill-pointer 0)
     for idx from 0
     do
       (loop
          with to-select = (- n (length selected))
          for remaining = (- (length vector) idx)
          while (>= (* remaining (random 1.0)) to-select)
          do (incf idx))
       (vector-push (aref vector idx) selected)
     when (= (length selected) n) return selected))
@end verbatim

With this code you'll be ready, in Chapter 29, to build a Web interface
for browsing a collection of MP3 files. But before you get to that, you
need to implement the part of the server that streams MP3s using the
Shoutcast protocol, which is the topic of the next chapter.

@node Practical A Shoutcast Server
@chapter Practical: A Shoutcast Server
@anchor{#practical-a-shoutcast-server} In this chapter you'll develop
another important part of what will eventually be a Web-based
application for streaming MP3s, namely, the server that implements the
Shoutcast protocol for actually streaming MP3s to clients such as
iTunes, XMMS,@footnote{The version of XMMS shipped with Red Hat 8.0
and 9.0 and Fedora no longer knows how to play MP3s because the folks
at Red Hat were worried about the licensing issues related to the MP3
codec. To get an XMMS with MP3 support on these versions of Linux, you
can grab the source from @code{http://www.xmms.org} and build it
yourself. Or, see @code{http://www.fedorafaq.org/#xmms-mp3} for
information about other possibilities.} or Winamp.
@menu
* The Shoutcast Protocol::
* Song Sources::
* Implementing Shoutcast::
@end menu

@node The Shoutcast Protocol
@section The Shoutcast Protocol
@anchor{#the-shoutcast-protocol}
The Shoutcast protocol was invented by the folks at Nullsoft, the makers
of the Winamp MP3 software. It was designed to support Internet audio
broadcasting--Shoutcast DJs send audio data from their personal
computers to a central Shoutcast server that then turns around and
streams it out to any connected listeners.

The server you'll build is actually only half a true Shoutcast
server--you'll use the protocol that Shoutcast servers use to stream
MP3s to listeners, but your server will be able to serve only songs
already stored on the file system of the computer where the server is
running.

You need to worry about only two parts of the Shoutcast protocol: the
request that a client makes in order to start receiving a stream and the
format of the response, including the mechanism by which metadata about
what song is currently playing is embedded in the stream.

The initial request from the MP3 client to the Shoutcast server is
formatted as a normal HTTP request. In response, the Shoutcast server
sends an ICY response that looks like an HTTP response except with the
string "ICY"@footnote{To further confuse matters, there's a different
streaming protocol called @emph{Icecast}. There seems to be no
connection between the ICY header used by Shoutcast and the Icecast
protocol.} in place of the normal HTTP version string and with
different headers. After sending the headers and a blank line, the
server streams a potentially endless amount of MP3 data.

The only tricky thing about the Shoutcast protocol is the way metadata
about the songs being streamed is embedded in the data sent to the
client. The problem facing the Shoutcast designers was to provide a way
for the Shoutcast server to communicate new title information to the
client each time it started playing a new song so the client could
display it in its UI. (Recall from Chapter 25 that the MP3 format
doesn't make any provision for encoding metadata.) While one of the
design goals of ID3v2 had been to make it better suited for use when
streaming MP3s, the Nullsoft folks decided to go their own route and
invent a new scheme that's fairly easy to implement on both the client
side and the server side. That, of course, was ideal for them since they
were also the authors of their own MP3 client.

Their scheme was to simply ignore the structure of MP3 data and embed a
chunk of self-delimiting metadata every @emph{n} bytes. The client would
then be responsible for stripping out this metadata so it wasn't treated
as MP3 data. Since metadata sent to a client that isn't ready for it
will cause glitches in the sound, the server is supposed to send
metadata only if the client's original request contains a special
Icy-Metadata header. And in order for the client to know how often to
expect metadata, the server must send back a header Icy-Metaint whose
value is the number of bytes of MP3 data that will be sent between each
chunk of metadata.

The basic content of the metadata is a string of the form
"StreamTitle='@emph{title}';" where @emph{title} is the title of the
current song and can't contain single quote marks. This payload is
encoded as a length-delimited array of bytes: a single byte is sent
indicating how many 16-byte blocks follow, and then that many blocks are
sent. They contain the string payload as an ASCII string, with the final
block padded out with null bytes as necessary.

Thus, the smallest legal metadata chunk is a single byte, zero,
indicating zero subsequent blocks. If the server doesn't need to update
the metadata, it can send such an empty chunk, but it must send at least
the one byte so the client doesn't throw away actual MP3 data.

@node Song Sources
@section Song Sources
@anchor{#song-sources}
Because a Shoutcast server has to keep streaming songs to the client for
as long as it's connected, you need to provide your server with a source
of songs to draw on. In the Web-based application, each connected client
will have a playlist that can be manipulated via the Web interface. But
in the interest of avoiding excessive coupling, you should define an
interface that the Shoutcast server can use to obtain songs to play. You
can write a simple implementation of this interface now and then a more
complex one as part of the Web application you'll build in Chapter 29.

The Package
The package for the code you'll develop in this chapter looks like this:

@verbatim
(defpackage :com.gigamonkeys.shoutcast
  (:use :common-lisp 
        :net.aserve 
        :com.gigamonkeys.id3v2)
  (:export :song
           :file
           :title
           :id3-size
           :find-song-source
           :current-song
           :still-current-p
           :maybe-move-to-next-song
           :*song-source-type*))
@end verbatim

The idea behind the interface is that the Shoutcast server will find a
source of songs based on an ID extracted from the AllegroServe request
object. It can then do three things with the song source it's given.

@itemize
@item
Get the current song from the source
@item
Tell the song source that it's done with the current song
@item
Ask the source whether the song it was given earlier is still the
current song
@end itemize

The last operation is necessary because there may be ways--and will be
in Chapter 29--to manipulate the songs source outside the Shoutcast
server. You can express the operations the Shoutcast server needs with
the following generic functions:

@verbatim
(defgeneric current-song (source)
  (:documentation "Return the currently playing song or NIL."))

(defgeneric maybe-move-to-next-song (song source)
  (:documentation
   "If the given song is still the current one update the value
returned by current-song."))

(defgeneric still-current-p (song source)
  (:documentation
   "Return true if the song given is the same as the current-song."))
@end verbatim

The function @code{maybe-move-to-next-song} is defined the way it is
so a single operation checks whether the song is current and, if it
is, moves the song source to the next song. This will be important in
the next chapter when you need to implement a song source that can be
safely manipulated from two different threads.@footnote{Technically,
the implementation in this chapter will also be manipulated from two
threads--the AllegroServe thread running the Shoutcast server and the
REPL thread. But you can live with the race condition for now. I'll
discuss how to use locking to make code thread safe in the next
chapter.}

To represent the information about a song that the Shoutcast server
needs, you can define a class, @code{song}, with slots to hold the name
of the MP3 file, the title to send in the Shoutcast metadata, and the
size of the ID3 tag so you can skip it when serving up the file.

@verbatim
(defclass song ()
  ((file     :reader file     :initarg :file)
   (title    :reader title    :initarg :title)
   (id3-size :reader id3-size :initarg :id3-size)))
@end verbatim

The value returned by @code{current-song} (and thus the first argument
to @code{still-current-p} and @code{maybe-move-to-next-song}) will be an
instance of @code{song}.

In addition, you need to define a generic function that the server can
use to find a song source based on the type of source desired and the
request object. Methods will specialize the @code{type} parameter in
order to return different kinds of song source and will pull whatever
information they need from the request object to determine which source
to return.

@verbatim
(defgeneric find-song-source (type request)
  (:documentation "Find the song-source of the given type for the given request."))
@end verbatim

However, for the purposes of this chapter, you can use a trivial
implementation of this interface that always uses the same object, a
simple queue of song objects that you can manipulate from the REPL. You
can start by defining a class, @code{simple-song-queue}, and a global
variable, @code{*songs*}, that holds an instance of this class.

@verbatim
(defclass simple-song-queue ()
  ((songs :accessor songs :initform (make-array 10 :adjustable t :fill-pointer 0))
   (index :accessor index :initform 0)))

(defparameter *songs* (make-instance 'simple-song-queue))
@end verbatim

Then you can define a method on @code{find-song-source} that specializes
@code{type} with an @code{EQL} specializer on the symbol
@code{singleton} and returns the instance stored in @code{*songs*}.

@verbatim
(defmethod find-song-source ((type (eql 'singleton)) request)
  (declare (ignore request))
  *songs*)
@end verbatim

Now you just need to implement methods on the three generic functions
that the Shoutcast server will use.

@verbatim
(defmethod current-song ((source simple-song-queue))
  (when (array-in-bounds-p (songs source) (index source))
    (aref (songs source) (index source))))

(defmethod still-current-p (song (source simple-song-queue))
  (eql song (current-song source)))

(defmethod maybe-move-to-next-song (song (source simple-song-queue))
  (when (still-current-p song source)
    (incf (index source))))
@end verbatim

And for testing purposes you should provide a way to add songs to this
queue.

@verbatim
(defun add-file-to-songs (file)
  (vector-push-extend (file->song file) (songs *songs*)))

(defun file->song (file)
  (let ((id3 (read-id3 file)))
    (make-instance 
     'song
     :file (namestring (truename file))
     :title (format nil "~a by ~a from ~a" (song id3) (artist id3) (album id3))
     :id3-size (size id3))))
@end verbatim

@node Implementing Shoutcast
@section Implementing Shoutcast
@anchor{#implementing-shoutcast}
Now you're ready to implement the Shoutcast server. Since the Shoutcast
protocol is loosely based on HTTP, you can implement the server as a
function within AllegroServe. However, since you need to interact with
some of the low-level features of AllegroServe, you can't use the
@code{define-url-function} macro from Chapter 26. Instead, you need to
write a regular function that looks like this:

@verbatim
(defun shoutcast (request entity)
  (with-http-response
      (request entity :content-type "audio/MP3" :timeout *timeout-seconds*)
    (prepare-icy-response request *metadata-interval*)
    (let ((wants-metadata-p (header-slot-value request :icy-metadata)))
      (with-http-body (request entity)
        (play-songs 
         (request-socket request)
         (find-song-source *song-source-type* request)
         (if wants-metadata-p *metadata-interval*))))))
@end verbatim

Then publish that function under the path @code{/stream.mp3} like
this:@footnote{Another thing you may want to do while working on this
code is to evaluate the form @code{(net.aserve::debug-on :notrap)}.
This tells AllegroServe to not trap errors signaled by your code,
which will allow you to debug them in the normal Lisp debugger. In
SLIME this will pop up a SLIME debugger buffer just like any other
error.}

@verbatim
(publish :path "/stream.mp3" :function 'shoutcast)
@end verbatim

In the call to @code{with-http-response}, in addition to the usual
@code{request} and @code{entity} arguments, you need to pass
@code{:content-type} and @code{:timeout} arguments. The
@code{:content-type} argument tells AllegroServe how to set the
Content-Type header it sends. And the @code{:timeout} argument specifies
the number of seconds AllegroServe gives the function to generate its
response. By default AllegroServe times out each request after five
minutes. Because you're going to stream an essentially endless sequence
of MP3s, you need much more time. There's no way to tell AllegroServe to
@emph{never} time out the request, so you should set it to the value of
@code{*timeout-seconds*}, which you can define to some suitably large
value such as the number of seconds in ten years.

@verbatim
(defparameter *timeout-seconds* (* 60 60 24 7 52 10))
@end verbatim

Then, within the body of the @code{with-http-response} and before the
call to @code{with-http-body} that will cause the response headers to
be sent, you need to manipulate the reply that AllegroServe will
send. The function @code{prepare-icy-response} encapsulates the
necessary manipulations: changing the protocol string from the default
of "HTTP" to "ICY" and adding the Shoutcast-specific
headers.@footnote{Shoutcast headers are usually sent in lowercase, so
you need to escape the names of the keyword symbols used to identify
them to AllegroServe to keep the Lisp reader from converting them to
all uppercase. Thus, you'd write @code{:|icy-metaint|} rather than
@code{:icy-metaint}. You could also write
@code{:\i\c\y-\m\e\t\a\i\n\t}, but that'd be silly.}  You also need,
in order to work around a bug in iTunes, to tell AllegroServe not to
use @emph{chunked transfer-encoding}.@footnote{The function
@code{turn-off-chunked-transfer-encoding} is a bit of a
kludge. There's no way to turn off chunked transfer encoding via
AllegroServe's official APIs without specifying a content length
because any client that advertises itself as an HTTP/1.1 client, which
iTunes does, is supposed to understand it. But this does the trick.}
The functions @code{request-reply-protocol-string},
@code{request-uri}, and @code{reply-header-slot-value} are all part of
AllegroServe.

@verbatim
(defun prepare-icy-response (request metadata-interval)
  (setf (request-reply-protocol-string request) "ICY")
  (loop for (k v) in (reverse
       `((:|icy-metaint| ,(princ-to-string metadata-interval))
         (:|icy-notice1| "<BR>This stream blah blah blah<BR>")
         (:|icy-notice2| "More blah")
         (:|icy-name|    "MyLispShoutcastServer")
         (:|icy-genre|   "Unknown")
         (:|icy-url|     ,(request-uri request))
         (:|icy-pub|     "1")))
     do (setf (reply-header-slot-value request k) v))
  ;; iTunes, despite claiming to speak HTTP/1.1, doesn't understand
  ;; chunked Transfer-encoding. Grrr. So we just turn it off.
  (turn-off-chunked-transfer-encoding request))

(defun turn-off-chunked-transfer-encoding (request)
  (setf (request-reply-strategy request)
        (remove :chunked (request-reply-strategy request))))
@end verbatim

Within the @code{with-http-body} of @code{shoutcast}, you actually
stream the MP3 data. The function @code{play-songs} takes the stream to
which it should write the data, the song source, and the metadata
interval it should use or @code{NIL} if the client doesn't want
metadata. The stream is the socket obtained from the request object, the
song source is obtained by calling @code{find-song-source}, and the
metadata interval comes from the global variable
@code{*metadata-interval*}. The type of song source is controlled by the
variable @code{*song-source-type*}, which for now you can set to
@code{singleton} in order to use the @code{simple-song-queue} you
implemented previously.

@verbatim
(defparameter *metadata-interval* (expt 2 12))

(defparameter *song-source-type* 'singleton)
@end verbatim

The function @code{play-songs} itself doesn't do much--it loops calling
the function @code{play-current}, which does all the heavy lifting of
sending the contents of a single MP3 file, skipping the ID3 tag and
embedding ICY metadata. The only wrinkle is that you need to keep track
of when to send the metadata.

Since you must send metadata chunks at a fixed intervals, regardless of
when you happen to switch from one MP3 file to the next, each time you
call @code{play-current} you need to tell it when the next metadata is
due, and when it returns, it must tell you the same thing so you can
pass the information to the next call to @code{play-current}. If
@code{play-current} gets @code{NIL} from the song source, it returns
@code{NIL}, which allows the @code{play-songs} @code{LOOP} to end.

In addition to handling the looping, @code{play-songs} also provides a
@code{HANDLER-CASE} to trap the error that will be signaled when the MP3
client disconnects from the server and one of the writes to the socket,
down in @code{play-current}, fails. Since the @code{HANDLER-CASE} is
outside the @code{LOOP}, handling the error will break out of the loop,
allowing @code{play-songs} to return.

@verbatim
(defun play-songs (stream song-source metadata-interval)
  (handler-case 
      (loop
         for next-metadata = metadata-interval
         then (play-current 
               stream 
               song-source
               next-metadata
               metadata-interval)
         while next-metadata)
    (error (e) (format *trace-output* "Caught error in play-songs: ~a" e))))
@end verbatim

Finally, you're ready to implement @code{play-current}, which actually
sends the Shoutcast data. The basic idea is that you get the current
song from the song source, open the song's file, and then loop reading
data from the file and writing it to the socket until either you reach
the end of the file or the current song is no longer the current song.

There are only two complications: One is that you need to make sure you
send the metadata at the correct interval. The other is that if the file
starts with an ID3 tag, you want to skip it. If you don't worry too much
about I/O efficiency, you can implement @code{play-current} like this:

@verbatim
(defun play-current (out song-source next-metadata metadata-interval)
  (let ((song (current-song song-source)))
    (when song
      (let ((metadata (make-icy-metadata (title song))))
        (with-open-file (mp3 (file song))
          (unless (file-position mp3 (id3-size song))
            (error "Can't skip to position ~d in ~a" (id3-size song) (file song)))
          (loop for byte = (read-byte mp3 nil nil)
             while (and byte (still-current-p song song-source)) do
               (write-byte byte out)
               (decf next-metadata)
             when (and (zerop next-metadata) metadata-interval) do
               (write-sequence metadata out)
               (setf next-metadata metadata-interval))

          (maybe-move-to-next-song song song-source)))
      next-metadata)))
@end verbatim

This function gets the current song from the song source and gets a
buffer containing the metadata it'll need to send by passing the title
to @code{make-icy-metadata}. Then it opens the file and skips past the
ID3 tag using the two-argument form of @code{FILE-POSITION}. Then it
commences reading bytes from the file and writing them to the request
stream.@footnote{Most MP3-playing software will display the metadata
somewhere in the user interface. However, the XMMS program on Linux by
default doesn't. To get XMMS to display Shoutcast metadata, press
Ctrl+P to see the Preferences pane. Then in the Audio I/O Plugins tab
(the leftmost tab in version 1.2.10), select the MPEG Layer 1/2/3
Player (@code{libmpg123.so}) and hit the Configure button. Then select
the Streaming tab on the configuration window, and at the bottom of
the tab in the SHOUTCAST/Icecast section, check the "Enable
SHOUTCAST/Icecast title streaming" box.}

It'll break out of the loop either when it reaches the end of the file
or when the song source's current song changes out from under it. In
the meantime, whenever @code{next-metadata} gets to zero (if you're
supposed to send metadata at all), it writes @code{metadata} to the
stream and resets @code{next-metadata}. Once it finishes the loop, it
checks to see if the song is still the song source's current song; if
it is, that means it broke out of the loop because it read the whole
file, in which case it tells the song source to move to the next
song. Otherwise, it broke out of the loop because someone changed the
current song out from under it, and it just returns. In either case,
it returns the number of bytes left before the next metadata is due so
it can be passed in the next call to
@code{play-current}.@footnote{Folks coming to Common Lisp from Scheme
might wonder why @code{play-current} can't just call itself
recursively. In Scheme that would work fine since Scheme
implementations are required by the Scheme specification to support
"an unbounded number of active tail calls." Common Lisp
implementations are allowed to have this property, but it isn't
required by the language standard. Thus, in Common Lisp the idiomatic
way to write loops is with a looping construct, not with recursion.}

The function @code{make-icy-metadata}, which takes the title of the
current song and generates an array of bytes containing a properly
formatted chunk of ICY metadata, is also
straightforward.@footnote{This function assumes, as has other code
you've written, that your Lisp implementation's internal character
encoding is ASCII or a superset of ASCII, so you can use
@code{CHAR-CODE} to translate Lisp @code{CHARACTER} objects to bytes
of ASCII data.}

@verbatim
(defun make-icy-metadata (title)
  (let* ((text (format nil "StreamTitle='~a';" (substitute #\Space #\' title)))
         (blocks (ceiling (length text) 16))
         (buffer (make-array (1+ (* blocks 16))
                             :element-type '(unsigned-byte 8)
                             :initial-element 0)))
    (setf (aref buffer 0) blocks)
    (loop 
       for char across text
       for i from 1 
       do (setf (aref buffer i) (char-code char)))
    buffer))
@end verbatim

Depending on how your particular Lisp implementation handles its
streams, and also how many MP3 clients you want to serve at once, the
simple version of @code{play-current} may or may not be efficient
enough.

The potential problem with the simple implementation is that you have to
call @code{READ-BYTE} and @code{WRITE-BYTE} for every byte you transfer.
It's possible that each call may result in a relatively expensive system
call to read or write one byte. And even if Lisp implements its own
streams with internal buffering so not every call to @code{READ-BYTE} or
@code{WRITE-BYTE} results in a system call, function calls still aren't
free. In particular, in implementations that provide user-extensible
streams using so-called Gray Streams, @code{READ-BYTE} and
@code{WRITE-BYTE} may result in a generic function call under the covers
to dispatch on the class of the stream argument. While generic function
dispatch is normally speedy enough that you don't have to worry about
it, it's a bit more expensive than a nongeneric function call and thus
not something you necessarily want to do several million times in a few
minutes if you can avoid it.

A more efficient, if slightly more complex, way to implement
@code{play-current} is to read and write multiple bytes at a time using
the functions @code{READ-SEQUENCE} and @code{WRITE-SEQUENCE}. This also
gives you a chance to match your file reads with the natural block size
of the file system, which will likely give you the best disk throughput.
Of course, no matter what buffer size you use, keeping track of when to
send the metadata becomes a bit more complicated. A more efficient
version of @code{play-current} that uses @code{READ-SEQUENCE} and
@code{WRITE-SEQUENCE} might look like this:

@verbatim
(defun play-current (out song-source next-metadata metadata-interval)
  (let ((song (current-song song-source)))
    (when song
      (let ((metadata (make-icy-metadata (title song)))
            (buffer (make-array size :element-type '(unsigned-byte 8))))
        (with-open-file (mp3 (file song))
          (labels ((write-buffer (start end)
                     (if metadata-interval
                       (write-buffer-with-metadata start end)
                       (write-sequence buffer out :start start :end end)))

                   (write-buffer-with-metadata (start end)
                     (cond
                       ((> next-metadata (- end start))
                        (write-sequence buffer out :start start :end end)
                        (decf next-metadata (- end start)))
                       (t 
                        (let ((middle (+ start next-metadata)))
                          (write-sequence buffer out :start start :end middle)
                          (write-sequence metadata out)
                          (setf next-metadata metadata-interval)
                          (write-buffer-with-metadata middle end))))))

            (multiple-value-bind (skip-blocks skip-bytes)
                (floor (id3-size song) (length buffer))

              (unless (file-position mp3 (* skip-blocks (length buffer)))
                (error "Couldn't skip over ~d ~d byte blocks."
                       skip-blocks (length buffer)))

              (loop for end = (read-sequence buffer mp3) 
                 for start = skip-bytes then 0
                 do (write-buffer start end)
                 while (and (= end (length buffer))
                            (still-current-p song song-source)))

              (maybe-move-to-next-song song song-source)))))
      next-metadata)))
@end verbatim

Now you're ready to put all the pieces together. In the next chapter
you'll write a Web interface to the Shoutcast server developed in this
chapter, using the MP3 database from Chapter 27 as the source of songs.

@node Practical An MP3 Browser
@chapter Practical: An MP3 Browser
@anchor{#practical-an-mp3-browser}
The final step in building the MP3 streaming application is to provide a
Web interface that allows a user to find the songs they want to listen
to and add them to a playlist that the Shoutcast server will draw upon
when the user's MP3 client requests the stream URL. For this component
of the application, you'll pull together several bits of code from the
previous few chapters: the MP3 database, the @code{define-url-function}
macro from Chapter 26, and, of course, the Shoutcast server itself.
@menu
* Playlists::
* Playlists As Song Sources::
* Manipulating the Playlist::
* Query Parameter Types::
* Boilerplate HTML::
* The Browse Page::
* The Playlist::
* Finding a Playlist::
* Running the App::
@end menu

@node Playlists
@section Playlists
@anchor{#playlists}
The basic idea behind the interface will be that each MP3 client that
connects to the Shoutcast server gets its own @emph{playlist}, which
serves as the source of songs for the Shoutcast server. A playlist will
also provide facilities beyond those needed by the Shoutcast server:
through the Web interface the user will be able to add songs to the
playlist, delete songs already in the playlist, and reorder the playlist
by sorting and shuffling.

You can define a class to represent playlists like this:

@verbatim
(defclass playlist ()
  ((id           :accessor id           :initarg :id)
   (songs-table  :accessor songs-table  :initform (make-playlist-table))
   (current-song :accessor current-song :initform *empty-playlist-song*)
   (current-idx  :accessor current-idx  :initform 0)
   (ordering     :accessor ordering     :initform :album)
   (shuffle      :accessor shuffle      :initform :none)
   (repeat       :accessor repeat       :initform :none)
   (user-agent   :accessor user-agent   :initform "Unknown")
   (lock         :reader   lock         :initform (make-process-lock))))
@end verbatim

The @code{id} of a playlist is the key you extract from the request
object passed to @code{find-song-source} when looking up a playlist. You
don't actually need to store it in the @code{playlist} object, but it
makes debugging a bit easier if you can find out from an arbitrary
playlist object what its @code{id} is.

The heart of the playlist is the @code{songs-table} slot, which will
hold a @code{table} object. The schema for this table will be the same
as for the main MP3 database. The function @code{make-playlist-table},
which you use to initialize @code{songs-table}, is simply this:

@verbatim
(defun make-playlist-table ()
  (make-instance 'table :schema *mp3-schema*))
@end verbatim

The Package
You can define the package for the code in this chapter with the
following @code{DEFPACKAGE}:

@verbatim
(defpackage :com.gigamonkeys.mp3-browser
  (:use :common-lisp
        :net.aserve
        :com.gigamonkeys.html
        :com.gigamonkeys.shoutcast
        :com.gigamonkeys.url-function
        :com.gigamonkeys.mp3-database
        :com.gigamonkeys.id3v2)
  (:import-from :acl-socket
                :ipaddr-to-dotted
                :remote-host)
  (:import-from :multiprocessing
                :make-process-lock
                :with-process-lock)
  (:export :start-mp3-browser))
@end verbatim

Because this is a high-level application, it uses a lot of lower-level
packages. It also imports three symbols from the @code{ACL-SOCKET}
package and two more from @code{MULTIPROCESSING} since it just needs
those five and not the other 139 symbols those two packages export.
By storing the list of songs as a table, you can use the database
functions from Chapter 27 to manipulate the playlist: you can add to the
playlist with @code{insert-row}, delete songs with @code{delete-rows},
and reorder the playlist with @code{sort-rows} and @code{shuffle-table}.

The @code{current-song} and @code{current-idx} slots keep track of which
song is playing: @code{current-song} is an actual @code{song} object,
while @code{current-idx} is the index into the @code{songs-table} of the
row representing the current song. You'll see in the section
"Manipulating the Playlist" how to make sure @code{current-song} is
updated whenever @code{current-idx} changes.

The @code{ordering} and @code{shuffle} slots hold information about how
the songs in @code{songs-table} are to be ordered. The @code{ordering}
slot holds a keyword that tells how the @code{songs-table} should be
sorted when it's not shuffled. The legal values are @code{:genre},
@code{:artist}, @code{:album}, and @code{:song}. The @code{shuffle} slot
holds one of the keywords @code{:none}, @code{:song}, or @code{:album},
which specifies how @code{songs-table} should be shuffled, if at all.

The @code{repeat} slot also holds a keyword, one of @code{:none},
@code{:song}, or @code{:all}, which specifies the repeat mode for the
playlist. If @code{repeat} is @code{:none}, after the last song in the
@code{songs-table} has been played, the @code{current-song} goes back to
a default MP3. When @code{:repeat} is @code{:song}, the playlist keeps
returning the same @code{current-song} forever. And if it's @code{:all},
after the last song, @code{current-song} goes back to the first song.

The @code{user-agent} slot holds the value of the User-Agent header sent
by the MP3 client in its request for the stream. You need to hold onto
this value purely for use in the Web interface--the User-Agent header
identifies the program that made the request, so you can display the
value on the page that lists all the playlists to make it easier to tell
which playlist goes with which connection when multiple clients connect.

Finally, the @code{lock} slot holds a @emph{process lock} created with
the function @code{make-process-lock}, which is part of Allegro's
@code{MULTIPROCESSING} package. You'll need to use that lock in certain
functions that manipulate @code{playlist} objects to ensure that only
one thread at a time manipulates a given playlist object. You can define
the following macro, built upon the @code{with-process-lock} macro from
@code{MULTIPROCESSING}, to give an easy way to wrap a body of code that
should be performed while holding a playlist's lock:

@verbatim
(defmacro with-playlist-locked ((playlist) &body body)
  `(with-process-lock ((lock ,playlist))
     ,@body))
@end verbatim

The @code{with-process-lock} macro acquires exclusive access to the
process lock given and then executes the body forms, releasing the lock
afterward. By default, @code{with-process-lock} allows recursive locks,
meaning the same thread can safely acquire the same lock multiple times.

@node Playlists As Song Sources
@section Playlists As Song Sources
@anchor{#playlists-as-song-sources}
To use @code{playlist}s as a source of songs for the Shoutcast server,
you'll need to implement a method on the generic function
@code{find-song-source} from Chapter 28. Since you're going to have
multiple playlists, you need a way to find the right one for each client
that connects to the server. The mapping part is easy--you can define a
variable that holds an @code{EQUAL} hash table that you can use to map
from some identifier to the @code{playlist} object.

@verbatim
(defvar *playlists* (make-hash-table :test #'equal))
@end verbatim

You'll also need to define a process lock to protect access to this hash
table like this:

@verbatim
(defparameter *playlists-lock* (make-process-lock :name "playlists-lock"))
@end verbatim

Then define a function that looks up a playlist given an ID, creating
a new @code{playlist} object if necessary and using
@code{with-process-lock} to ensure that only one thread at a time
manipulates the hash table.@footnote{The intricacies of concurrent
programming are beyond the scope of this book. The basic idea is that
if you have multiple threads of control--as you will in this
application with some threads running the @code{shoutcast} function
and other threads responding to requests from the browser--then you
need to make sure only one thread at a time manipulates an object in
order to prevent one thread from seeing the object in an inconsistent
state while another thread is working on it. In this function, for
instance, if two new MP3 clients are connecting at the same time,
they'd both try to add an entry to @code{*playlists*} and might
interfere with each other. The @code{with-process-lock} ensures that
each thread gets exclusive access to the hash table for long enough to
do the work it needs to do.}

@verbatim
(defun lookup-playlist (id)
  (with-process-lock (*playlists-lock*)
    (or (gethash id *playlists*)
        (setf (gethash id *playlists*) (make-instance 'playlist :id id)))))
@end verbatim

Then you can implement @code{find-song-source} on top of that function
and another, @code{playlist-id}, that takes an AllegroServe request
object and returns the appropriate playlist identifier. The
@code{find-song-source} function is also where you grab the User-Agent
string out of the request object and stash it in the playlist object.

@verbatim
(defmethod find-song-source ((type (eql 'playlist)) request)
  (let ((playlist (lookup-playlist (playlist-id request))))
    (with-playlist-locked (playlist)
      (let ((user-agent (header-slot-value request :user-agent)))
        (when user-agent (setf (user-agent playlist) user-agent))))
    playlist))
@end verbatim

The trick, then, is how you implement @code{playlist-id}, the function
that extracts the identifier from the request object. You have a couple
options, each with different implications for the user interface. You
can pull whatever information you want out of the request object, but
however you decide to identify the client, you need some way for the
user of the Web interface to get hooked up to the right playlist.

For now you can take an approach that "just works" as long as there's
only one MP3 client per machine connecting to the server and as long
as the user is browsing the Web interface from the machine running the
MP3 client: you'll use the IP address of the client machine as the
identifier. This way you can find the right playlist for a request
regardless of whether the request is from the MP3 client or a Web
browser. You will, however, provide a way in the Web interface to
select a different playlist from the browser, so the only real
constraint this choice puts on the application is that there can be
only one connected MP3 client per client IP address.@footnote{This
approach also assumes that every client machine has a unique IP
address. This assumption should hold as long as all the users are on
the same LAN but may not hold if clients are connecting from behind a
firewall that does network address translation. Deploying this
application outside a LAN will require some modifications, but if you
want to deploy this application to the wider Internet, you'd better
know enough about networking to figure out an appropriate scheme
yourself.} The implementation of @code{playlist-id} looks like this:

@verbatim
(defun playlist-id (request)
  (ipaddr-to-dotted (remote-host (request-socket request))))
@end verbatim

The function @code{request-socket} is part of AllegroServe, while
@code{remote-host} and @code{ipaddr-to-dotted} are part of Allegro's
socket library.

To make a playlist usable as a song source by the Shoutcast server, you
need to define methods on @code{current-song}, @code{still-current-p},
and @code{maybe-move-to-next-song} that specialize their @code{source}
parameter on @code{playlist}. The @code{current-song} method is already
taken care of: by defining the accessor @code{current-song} on the
eponymous slot, you automatically got a @code{current-song} method
specialized on @code{playlist} that returns the value of that slot.
However, to make accesses to the @code{playlist} thread safe, you need
to lock the @code{playlist} before accessing the @code{current-song}
slot. In this case, the easiest way is to define an @code{:around}
method like the following:

@verbatim
(defmethod current-song :around ((playlist playlist))
  (with-playlist-locked (playlist) (call-next-method)))
@end verbatim

Implementing @code{still-current-p} is also quite simple, assuming you
can be sure that @code{current-song} gets updated with a new @code{song}
object only when the current song actually changes. Again, you need to
acquire the process lock to ensure you get a consistent view of the
@code{playlist}'s state.

@verbatim
(defmethod still-current-p (song (playlist playlist))
  (with-playlist-locked (playlist)
    (eql song (current-song playlist))))
@end verbatim

The trick, then, is to make sure the @code{current-song} slot gets
updated at the right times. However, the current song can change in a
number of ways. The obvious one is when the Shoutcast server calls
@code{maybe-move-to-next-song}. But it can also change when songs are
added to the playlist, when the Shoutcast server has run out of songs,
or even if the playlist's repeat mode is changed.

Rather than trying to write code specific to every situation to
determine whether to update @code{current-song}, you can define a
function, @code{update-current-if-necessary}, that updates
@code{current-song} if the @code{song} object in @code{current-song} no
longer matches the file that the @code{current-idx} slot says should be
playing. Then, if you call this function after any manipulation of the
playlist that could possibly put those two slots out of sync, you're
sure to keep @code{current-song} set properly. Here are
@code{update-current-if-necessary} and its helper functions:

@verbatim
(defun update-current-if-necessary (playlist)
  (unless (equal (file (current-song playlist))
                 (file-for-current-idx playlist))
    (reset-current-song playlist)))

(defun file-for-current-idx (playlist)
  (if (at-end-p playlist)
    nil
    (column-value (nth-row (current-idx playlist) (songs-table playlist)) :file)))

(defun at-end-p (playlist)
  (>= (current-idx playlist) (table-size (songs-table playlist))))
@end verbatim

You don't need to add locking to these functions since they'll be called
only from functions that will take care of locking the playlist first.

The function @code{reset-current-song} introduces one more wrinkle:
because you want the playlist to provide an endless stream of MP3s to
the client, you don't want to ever set @code{current-song} to
@code{NIL}. Instead, when a playlist runs out of songs to play--when
@code{songs-table} is empty or after the last song has been played and
@code{repeat} is set to @code{:none}--then you need to set
@code{current-song} to a special song whose file is an MP3 of
silence@footnote{Unfortunately, because of licensing issues around the
MP3 format, it's not clear that it's legal for me to provide you with
such an MP3 without paying licensing fees to Fraunhofer IIS. I got
mine as part of the software that came with my Slimp3 from Slim
Devices. You can grab it from their Subversion repository via the Web
at @code{http://svn.slimdevices.com/*checkout*/trunk/server/
HT}@code{ML/EN/html/silentpacket.mp3?rev=2}.  Or buy a Squeezebox, the
new, wireless version of Slimp3, and you'll get
@code{silentpacket.mp3} as part of the software that comes with it. Or
find an MP3 of John Cage's piece @emph{4'33"}.} and whose title
explains why no music is playing. Here's some code to define two
parameters, @code{*empty-playlist-song*} and
@code{*end-of-playlist-song*}, each set to a song with the file named
by @code{*silence-mp3*} as their file and an appropriate title:

@verbatim
(defparameter *silence-mp3* ...)

(defun make-silent-song (title &optional (file *silence-mp3*))
  (make-instance
   'song 
   :file file
   :title title
   :id3-size (if (id3-p file) (size (read-id3 file)) 0)))

(defparameter *empty-playlist-song* (make-silent-song "Playlist empty."))

(defparameter *end-of-playlist-song* (make-silent-song "At end of playlist."))
@end verbatim

@code{reset-current-song} uses these parameters when the
@code{current-idx} doesn't point to a row in @code{songs-table}.
Otherwise, it sets @code{current-song} to a @code{song} object
representing the current row.

@verbatim
(defun reset-current-song (playlist)
  (setf
   (current-song playlist) 
   (cond
     ((empty-p playlist) *empty-playlist-song*)
     ((at-end-p playlist) *end-of-playlist-song*)
     (t (row->song (nth-row (current-idx playlist) (songs-table playlist)))))))

(defun row->song (song-db-entry)
  (with-column-values (file song artist album id3-size) song-db-entry
    (make-instance
     'song
     :file file
     :title (format nil "~a by ~a from ~a" song artist album)
     :id3-size id3-size)))

(defun empty-p (playlist)
  (zerop (table-size (songs-table playlist))))
@end verbatim

Now, at last, you can implement the method on
@code{maybe-move-to-next-song} that moves @code{current-idx} to its next
value, based on the playlist's repeat mode, and then calls
@code{update-current-if-necessary}. You don't change @code{current-idx}
when it's already at the end of the playlist because you want it to keep
its current value, so it'll point at the next song you add to the
playlist. This function must lock the playlist before manipulating it
since it's called by the Shoutcast server code, which doesn't do any
locking.

@verbatim
(defmethod maybe-move-to-next-song (song (playlist playlist))
  (with-playlist-locked (playlist)
    (when (still-current-p song playlist)
      (unless (at-end-p playlist)
        (ecase (repeat playlist)
          (:song) ; nothing changes
          (:none (incf (current-idx playlist)))
          (:all  (setf (current-idx playlist)
                       (mod (1+ (current-idx playlist))
                            (table-size (songs-table playlist)))))))
      (update-current-if-necessary playlist))))
@end verbatim

@node Manipulating the Playlist
@section Manipulating the Playlist
@anchor{#manipulating-the-playlist}
The rest of the playlist code is functions used by the Web interface to
manipulate @code{playlist} objects, including adding and deleting songs,
sorting and shuffling, and setting the repeat mode. As in the helper
functions in the previous section, you don't need to worry about locking
in these functions because, as you'll see, the lock will be acquired in
the Web interface function that calls these.

Adding and deleting is mostly a question of manipulating the
@code{songs-table}. The only extra work you have to do is to keep the
@code{current-song} and @code{current-idx} in sync. For instance,
whenever the playlist is empty, its @code{current-idx} will be zero, and
the @code{current-song} will be the @code{*empty-playlist-song*}. If you
add a song to an empty playlist, then the index of zero is now in
bounds, and you should change the @code{current-song} to the newly added
song. By the same token, when you've played all the songs in a playlist
and @code{current-song} is @code{*end-of-playlist-song*}, adding a song
should cause @code{current-song} to be reset. All this really means,
though, is that you need to call @code{update-current-if-necessary} at
the appropriate points.

Adding songs to a playlist is a bit involved because of the way the Web
interface communicates which songs to add. For reasons I'll discuss in
the next section, the Web interface code can't just give you a simple
set of criteria to use in selecting songs from the database. Instead, it
gives you the name of a column and a list of values, and you're supposed
to add all the songs from the main database where the given column has a
value in the list of values. Thus, to add the right songs, you need to
first build a table object containing the desired values, which you can
then use with an @code{in} query against the song database. So,
@code{add-songs} looks like this:

@verbatim
(defun add-songs (playlist column-name values)
  (let ((table (make-instance
                'table 
                :schema (extract-schema (list column-name) (schema *mp3s*)))))
    (dolist (v values) (insert-row (list column-name v) table))
    (do-rows (row (select :from *mp3s* :where (in column-name table)))
      (insert-row row (songs-table playlist))))
  (update-current-if-necessary playlist))
@end verbatim

Deleting songs is a bit simpler; you just need to be able to delete
songs from the @code{songs-table} that match particular criteria--either
a particular song or all songs in a particular genre, by a particular
artist, or from a particular album. So, you can provide a
@code{delete-songs} function that takes keyword/value pairs, which are
used to construct a @code{matching} @code{:where} clause you can pass to
the @code{delete-rows} database function.

Another complication that arises when deleting songs is that
@code{current-idx} may need to change. Assuming the current song isn't
one of the ones just deleted, you'd like it to remain the current song.
But if songs before it in @code{songs-table} are deleted, it'll be in a
different position in the table after the delete. So after a call to
@code{delete-rows}, you need to look for the row containing the current
song and reset @code{current-idx}. If the current song has itself been
deleted, then, for lack of anything better to do, you can reset
@code{current-idx} to zero. After updating @code{current-idx}, calling
@code{update-current-if-necessary} will take care of updating
@code{current-song}. And if @code{current-idx} changed but still points
at the same song, @code{current-song} will be left alone.

@verbatim
(defun delete-songs (playlist &rest names-and-values)
  (delete-rows
   :from (songs-table playlist)
   :where (apply #'matching (songs-table playlist) names-and-values))
  (setf (current-idx playlist) (or (position-of-current playlist) 0))
  (update-current-if-necessary playlist))

(defun position-of-current (playlist)
  (let* ((table (songs-table playlist))
         (matcher (matching table :file (file (current-song playlist))))
         (pos 0))
    (do-rows (row table)
      (when (funcall matcher row)
        (return-from position-of-current pos))
      (incf pos))))
@end verbatim

You can also provide a function to completely clear the playlist, which
uses @code{delete-all-rows} and doesn't have to worry about finding the
current song since it has obviously been deleted. The call to
@code{update-current-if-necessary} will take care of setting
@code{current-song} to @code{NIL}.

@verbatim
(defun clear-playlist (playlist)
  (delete-all-rows (songs-table playlist))
  (setf (current-idx playlist) 0)
  (update-current-if-necessary playlist))
@end verbatim

Sorting and shuffling the playlist are related in that the playlist is
always either sorted @emph{or} shuffled. The @code{shuffle} slot says
whether the playlist should be shuffled and if so how. If it's set to
@code{:none}, then the playlist is ordered according to the value in the
@code{ordering} slot. When @code{shuffle} is @code{:song}, the playlist
will be randomly permuted. And when it's set to @code{:album}, the list
of albums is randomly permuted, but the songs within each album are
listed in track order. Thus, the @code{sort-playlist} function, which
will be called by the Web interface code whenever the user selects a new
ordering, needs to set @code{ordering} to the desired ordering and set
@code{shuffle} to @code{:none} before calling @code{order-playlist},
which actually does the sort. As in @code{delete-songs}, you need to use
@code{position-of-current} to reset @code{current-idx} to the new
location of the current song. However, this time you don't need to call
@code{update-current-if-necessary} since you know the current song is
still in the table.

@verbatim
(defun sort-playlist (playlist ordering)
  (setf (ordering playlist) ordering)
  (setf (shuffle playlist) :none)
  (order-playlist playlist)
  (setf (current-idx playlist) (position-of-current playlist)))
@end verbatim

In @code{order-playlist}, you can use the database function
@code{sort-rows} to actually perform the sort, passing a list of columns
to sort by based on the value of @code{ordering}.

@verbatim
(defun order-playlist (playlist)
  (apply #'sort-rows (songs-table playlist)
    (case (ordering playlist)
      (:genre  '(:genre :album :track))
      (:artist '(:artist :album :track))
      (:album  '(:album :track))
      (:song   '(:song)))))
@end verbatim

The function @code{shuffle-playlist}, called by the Web interface code
when the user selects a new shuffle mode, works in a similar fashion
except it doesn't need to change the value of @code{ordering}. Thus,
when @code{shuffle-playlist} is called with a @code{shuffle} of
@code{:none}, the playlist goes back to being sorted according to the
most recent ordering. Shuffling by songs is simple--just call
@code{shuffle-table} on @code{songs-table}. Shuffling by albums is a bit
more involved but still not rocket science.

@verbatim
(defun shuffle-playlist (playlist shuffle)
  (setf (shuffle playlist) shuffle)
  (case shuffle
    (:none (order-playlist playlist))
    (:song (shuffle-by-song playlist))
    (:album (shuffle-by-album playlist)))
  (setf (current-idx playlist) (position-of-current playlist)))

(defun shuffle-by-song (playlist)
  (shuffle-table (songs-table playlist)))

(defun shuffle-by-album (playlist)
  (let ((new-table (make-playlist-table)))
    (do-rows (album-row (shuffled-album-names playlist))
      (do-rows (song (songs-for-album playlist (column-value album-row :album)))
        (insert-row song new-table)))
    (setf (songs-table playlist) new-table)))

(defun shuffled-album-names (playlist)
  (shuffle-table 
   (select
    :columns :album
    :from (songs-table playlist)
    :distinct t)))

(defun songs-for-album (playlist album)
  (select
   :from (songs-table playlist) 
   :where (matching (songs-table playlist) :album album)
   :order-by :track))
@end verbatim

The last manipulation you need to support is setting the playlist's
repeat mode. Most of the time you don't need to take any extra action
when setting @code{repeat}--its value comes into play only in
@code{maybe-move-to-next-song}. However, you need to update the
@code{current-song} as a result of changing @code{repeat} in one
situation, namely, if @code{current-idx} is at the end of a nonempty
playlist and @code{repeat} is being changed to @code{:song} or
@code{:all}. In that case, you want to continue playing, either
repeating the last song or starting at the beginning of the playlist.
So, you should define an @code{:after} method on the generic function
@code{(setf repeat)}.

@verbatim
(defmethod (setf repeat) :after (value (playlist playlist))
  (if (and (at-end-p playlist) (not (empty-p playlist)))
    (ecase value
      (:song (setf (current-idx playlist) (1- (table-size (songs-table playlist)))))
      (:none)
      (:all  (setf (current-idx playlist) 0)))
    (update-current-if-necessary playlist)))
@end verbatim

Now you have all the underlying bits you need. All that remains is the
code that will provide a Web-based user interface for browsing the MP3
database and manipulating playlists. The interface will consist of three
main functions defined with @code{define-url-function}: one for browsing
the song database, one for viewing and manipulating a single playlist,
and one for listing all the available playlists.

But before you get to writing these three functions, you need to start
with some helper functions and HTML macros that they'll use.

@node Query Parameter Types
@section Query Parameter Types
@anchor{#query-parameter-types}
Since you'll be using @code{define-url-function}, you need to define a
few methods on the @code{string->type} generic function from Chapter 28
that @code{define-url-function} uses to convert string query parameters
into Lisp objects. In this application, you'll need methods to convert
strings to integers, keyword symbols, and a list of values.

The first two are quite simple.

@verbatim
(defmethod string->type ((type (eql 'integer)) value)
  (parse-integer (or value "") :junk-allowed t))

(defmethod string->type ((type (eql 'keyword)) value)
  (and (plusp (length value)) (intern (string-upcase value) :keyword)))
@end verbatim

The last @code{string->type} method is slightly more complex. For
reasons I'll get to in a moment, you'll need to generate pages that
display a form that contains a hidden field whose value is a list of
strings. Since you're responsible for generating the value in the
hidden field @emph{and} for parsing it when it comes back, you can use
whatever encoding is convenient. You could use the functions
@code{WRITE-TO-STRING} and @code{READ-FROM-STRING}, which use the Lisp
printer and reader to write and read data to and from strings, except
the printed representation of strings can contain quotation marks and
other characters that may cause problems when embedded in the value
attribute of an @code{INPUT} element. So, you'll need to escape those
characters somehow. Rather than trying to come up with your own
escaping scheme, you can just use base 64, an encoding commonly used
to protect binary data sent through e-mail. AllegroServe comes with
two functions, @code{base64-encode} and @code{base64-decode}, that do
the encoding and decoding for you, so all you have to do is write a
pair of functions: one that encodes a Lisp object by converting it to
a readable string with @code{WRITE-TO-STRING} and then base 64
encoding it and, conversely, another to decode such a string by base
64 decoding it and passing the result to
@code{READ-FROM-STRING}. You'll want to wrap the calls to
@code{WRITE-TO-STRING} and @code{READ-FROM-STRING} in
@code{WITH-STANDARD-IO-SYNTAX} to make sure all the variables that
affect the printer and reader are set to their standard
values. However, because you're going to be reading data that's coming
in from the network, you'll definitely want to turn off one feature of
the reader--the ability to evaluate arbitrary Lisp code while
reading!@footnote{The reader supports a bit of syntax, @code{#.}, that
causes the following s-expression to be evaluated at read time. This
is occasionally useful in source code but obviously opens a big
security hole when you read untrusted data. However, you can turn off
this syntax by setting @code{*READ-EVAL*} to @code{NIL}, which will
cause the reader to signal an error if it encounters @code{#.}.} You
can define your own macro @code{with-safe-io-syntax}, which wraps its
body forms in @code{WITH-STANDARD-IO-SYNTAX} wrapped around a
@code{LET} that binds @code{*READ-EVAL*} to @code{NIL}.

@verbatim
(defmacro with-safe-io-syntax (&body body)
  `(with-standard-io-syntax
     (let ((*read-eval* nil))
       ,@body)))
@end verbatim

Then the encoding and decoding functions are trivial.

@verbatim
(defun obj->base64 (obj)
  (base64-encode (with-safe-io-syntax (write-to-string obj))))

(defun base64->obj (string)
  (ignore-errors
    (with-safe-io-syntax (read-from-string (base64-decode string)))))
@end verbatim

Finally, you can use these functions to define a method on
@code{string->type} that defines the conversion for the query parameter
type @code{base64-list}.

@verbatim
(defmethod string->type ((type (eql 'base-64-list)) value)
  (let ((obj (base64->obj value)))
    (if (listp obj) obj nil)))
@end verbatim

@node Boilerplate HTML
@section Boilerplate HTML
@anchor{#boilerplate-html}
Next you need to define some HTML macros and helper functions to make it
easy to give the different pages in the application a consistent look
and feel. You can start with an HTML macro that defines the basic
structure of a page in the application.

@verbatim
(define-html-macro :mp3-browser-page ((&key title (header title)) &body body)
  `(:html
     (:head
      (:title ,title)
      (:link :rel "stylesheet" :type "text/css" :href "mp3-browser.css"))
     (:body
      (standard-header)
      (when ,header (html (:h1 :class "title" ,header)))
      ,@body
      (standard-footer))))
@end verbatim

You should define @code{standard-header} and @code{standard-footer} as
separate functions for two reasons. First, during development you can
redefine those functions and see the effect immediately without having
to recompile functions that use the @code{:mp3-browser-page} macro.
Second, it turns out that one of the pages you'll write later won't be
defined with @code{:mp3-browser-page} but will still need the standard
header and footers. They look like this:

@verbatim
(defparameter *r* 25)

(defun standard-header ()
  (html
   ((:p :class "toolbar")
    "[" (:a :href (link "/browse" :what "genre") "All genres") "] "
    "[" (:a :href (link "/browse" :what "genre" :random *r*) "Random genres") "] "
    "[" (:a :href (link "/browse" :what "artist") "All artists") "] "
    "[" (:a :href (link "/browse" :what "artist" :random *r*) "Random artists") "] "
    "[" (:a :href (link "/browse" :what "album") "All albums") "] "
    "[" (:a :href (link "/browse" :what "album" :random *r*) "Random albums") "] "
    "[" (:a :href (link "/browse" :what "song" :random *r*) "Random songs") "] "
    "[" (:a :href (link "/playlist") "Playlist") "] "
    "[" (:a :href (link "/all-playlists") "All playlists") "]")))

(defun standard-footer ()
  (html (:hr) ((:p :class "footer") "MP3 Browser v" *major-version* "." *minor-version*)))
@end verbatim

A couple of smaller HTML macros and helper functions automate other
common patterns. The @code{:table-row} HTML macro makes it easier to
generate the HTML for a single row of a table. It uses a feature of FOO
that I'll discuss in Chapter 31, an @code{&attributes} parameter, which
causes uses of the macro to be parsed just like normal s-expression HTML
forms, with any attributes gathered into a list that will be bound to
the @code{&attributes} parameter. It looks like this:

@verbatim
(define-html-macro :table-row (&attributes attrs &rest values)
  `(:tr ,@attrs ,@(loop for v in values collect `(:td ,v))))
@end verbatim

And the @code{link} function generates a URL back into the application
to be used as the @code{HREF} attribute with an @code{A} element,
building a query string out of a set of keyword/value pairs and making
sure all special characters are properly escaped. For instance, instead
of writing this:

@verbatim
(:a :href "browse?what=artist&genre=Rhythm+%26+Blues" "Artists")
@end verbatim

you can write the following:

@verbatim
(:a :href (link "browse" :what "artist" :genre "Rhythm & Blues") "Artists")
@end verbatim

It looks like this:

@verbatim
(defun link (target &rest attributes)
  (html 
    (:attribute
     (:format "~a~@[?~{~(~a~)=~a~^&~}~]" target (mapcar #'urlencode attributes)))))
@end verbatim

To URL encode the keys and values, you use the helper function
@code{urlencode}, which is a wrapper around the function
@code{encode-form-urlencoded}, which is a nonpublic function from
AllegroServe. This is--on one hand--bad form; since the name
@code{encode-form-urlencoded} isn't exported from @code{NET.ASERVE},
it's possible that @code{encode-form-urlencoded} may go away or get
renamed out from under you. On the other hand, using this unexported
symbol for the time being lets you get work done for the moment; by
wrapping @code{encode-form-urlencoded} in your own function, you isolate
the crufty code to one function, which you could rewrite if you had to.

@verbatim
(defun urlencode (string)
  (net.aserve::encode-form-urlencoded string))
@end verbatim

Finally, you need the CSS style sheet @code{mp3-browser.css} used by
@code{:mp3-browser-page}. Since there's nothing dynamic about it, it's
probably easiest to just publish a static file with @code{publish-file}.

@verbatim
(publish-file :path "/mp3-browser.css"  :file filename :content-type "text/css")
@end verbatim

A sample style sheet is included with the source code for this chapter
on the book's Web site. You'll define a function, at the end of this
chapter, that starts the MP3 browser application. It'll take care of,
among other things, publishing this file.

@node The Browse Page
@section The Browse Page
@anchor{#the-browse-page}
The first URL function will generate a page for browsing the MP3
database. Its query parameters will tell it what kind of thing the user
is browsing and provide the criteria of what elements of the database
they're interested in. It'll give them a way to select database entries
that match a specific genre, artist, or album. In the interest of
serendipity, you can also provide a way to select a random subset of
matching items. When the user is browsing at the level of individual
songs, the title of the song will be a link that causes that song to be
added to the playlist. Otherwise, each item will be presented with links
that let the user browse the listed item by some other category. For
example, if the user is browsing genres, the entry "Blues" will contain
links to browse all albums, artists, and songs in the genre Blues.
Additionally, the browse page will feature an "Add all" button that adds
every song matching the page's criteria to the user's playlist. The
function looks like this:

@verbatim
(define-url-function browse
    (request (what keyword :genre) genre artist album (random integer))

  (let* ((values (values-for-page what genre artist album random))
         (title (browse-page-title what random genre artist album))
         (single-column (if (eql what :song) :file what))
         (values-string (values->base-64 single-column values)))
    (html
     (:mp3-browser-page
      (:title title)
      ((:form :method "POST" :action "playlist")
       (:input :name "values" :type "hidden" :value values-string)
       (:input :name "what" :type "hidden" :value single-column)
       (:input :name "action" :type "hidden" :value :add-songs)
       (:input :name "submit" :type "submit" :value "Add all"))
      (:ul (do-rows (row values) (list-item-for-page what row)))))))
@end verbatim

This function starts by using the function @code{values-for-page} to get
a table containing the values it needs to present. When the user is
browsing by song--when the @code{what} parameter is @code{:song}--you
want to select complete rows from the database. But when they're
browsing by genre, artist, or album, you want to select only the
distinct values for the given category. The database function
@code{select} does most of the heavy lifting, with
@code{values-for-page} mostly responsible for passing the right
arguments depending on the value of @code{what}. This is also where you
select a random subset of the matching rows if necessary.

@verbatim
(defun values-for-page (what genre artist album random)
  (let ((values
         (select 
          :from *mp3s*
          :columns (if (eql what :song) t what)
          :where (matching *mp3s* :genre genre :artist artist :album album)
          :distinct (not (eql what :song))
          :order-by (if (eql what :song) '(:album :track) what))))
    (if random (random-selection values random) values)))
@end verbatim

To generate the title for the browse page, you pass the browsing
criteria to the following function, @code{browse-page-title}:

@verbatim
(defun browse-page-title (what random genre artist album)
  (with-output-to-string (s)
    (when random (format s "~:(~r~) Random " random))
    (format s "~:(~a~p~)" what random)
    (when (or genre artist album)
      (when (not (eql what :song)) (princ " with songs" s))
      (when genre  (format s " in genre ~a" genre))
      (when artist (format s " by artist ~a " artist))
      (when album  (format s " on album ~a" album)))))
@end verbatim

Once you have the values you want to present, you need to do two things
with them. The main task, of course, is to present them, which happens
in the @code{do-rows} loop, leaving the rendering of each row to the
function @code{list-item-for-page}. That function renders @code{:song}
rows one way and all other kinds another way.

@verbatim
(defun list-item-for-page (what row)
  (if (eql what :song)
    (with-column-values (song file album artist genre) row
      (html
        (:li
         (:a :href (link "playlist" :file file :action "add-songs") (:b song)) " from "
         (:a :href (link "browse"  :what :song :album  album) album) " by "
         (:a :href (link "browse" :what :song :artist artist) artist) " in genre "
         (:a :href (link "browse"  :what :song :genre  genre) genre))))
    (let ((value (column-value row what)))
      (html
       (:li value " - "
            (browse-link :genre  what value)
            (browse-link :artist what value)
            (browse-link :album  what value)
            (browse-link :song   what value))))))

(defun browse-link (new-what what value)
  (unless (eql new-what what)
    (html
     "[" 
     (:a :href (link "browse" :what new-what what value) (:format "~(~as~)" new-what))
     "] ")))
@end verbatim

The other thing on the @code{browse} page is a form with several hidden
@code{INPUT} fields and an "Add all" submit button. You need to use an
HTML form instead of a regular link to keep the application
stateless--to make sure all the information needed to respond to a
request comes in the request itself. Because the browse page results can
be partially random, you need to submit a fair bit of data for the
server to be able to reconstitute the list of songs to add to the
playlist. If you didn't allow the browse page to return randomly
generated results, you wouldn't need much data--you could just submit a
request to add songs with whatever search criteria the browse page used.
But if you added songs that way, with criteria that included a
@code{random} argument, then you'd end up adding a different set of
random songs than the user was looking at on the page when they hit the
"Add all" button.

The solution you'll use is to send back a form that has enough
information stashed away in a hidden @code{INPUT} element to allow the
server to reconstitute the list of songs matching the browse page
criteria. That information is the list of values returned by
@code{values-for-page} and the value of the @code{what} parameter. This
is where you use the @code{base64-list} parameter type; the function
@code{values->base64} extracts the values of a specified column from the
table returned by @code{values-for-page} into a list and then makes a
base 64-encoded string out of that list to embed in the form.

@verbatim
(defun values->base-64 (column values-table)
  (flet ((value (r) (column-value r column)))
    (obj->base64 (map-rows #'value values-table))))
@end verbatim

When that parameter comes back as the value of the @code{values} query
parameter to a URL function that declares @code{values} to be of type
@code{base-64-list}, it'll be automatically converted back to a
list. As you'll see in a moment, that list can then be used to
construct a query that'll return the correct list of
songs.@footnote{This solution has its drawbacks--if a @code{browse}
page returns a lot of results, a fair bit of data is going back and
forth under the covers. Also, the database queries aren't necessarily
the most efficient. But it does keep the application stateless. An
alternative approach is to squirrel away, on the server side,
information about the results returned by @code{browse} and then, when
a request to add songs come in, find the appropriate bit of
information in order to re-create the correct set of songs. For
instance, you could just save the values list instead of sending it
back in the form. Or you could copy the @code{RANDOM-STATE} object
before you generate the browse results so you can later re-create the
same "random" results. But this approach causes its own problems. For
instance, you'd then need to worry about when you can get rid of the
squirreled-away information; you never know when the user might hit
the Back button on their browser to return to an old browse page and
then hit the "Add all" button. Welcome to the wonderful world of Web
programming.} When you're browsing by @code{:song}, you use the values
from the @code{:file} column since they uniquely identify the actual
songs while the song names may not.

@node The Playlist
@section The Playlist
@anchor{#the-playlist}
This brings me to the next URL function, @code{playlist}. This is the
most complex page of the three--it's responsible for displaying the
current contents of the user's playlist as well as for providing the
interface to manipulate the playlist. But with most of the tedious
bookkeeping handled by @code{define-url-function}, it's not too hard to
see how @code{playlist} works. Here's the beginning of the definition,
with just the parameter list:

@verbatim
(define-url-function playlist 
    (request
     (playlist-id string (playlist-id request) :package)
     (action keyword)      ; Playlist manipulation action
     (what keyword :file)  ; for :add-songs action
     (values base-64-list) ;             "
     file                  ; for :add-songs and :delete-songs actions
     genre                 ; for :delete-songs action
     artist                ;             "
     album                 ;             "
     (order-by keyword)    ; for :sort action
     (shuffle keyword)     ; for :shuffle action
     (repeat keyword))     ; for :set-repeat action
@end verbatim

In addition to the obligatory @code{request} parameter, @code{playlist}
takes a number of query parameters. The most important in some ways is
@code{playlist-id}, which identifies which @code{playlist} object the
page should display and manipulate. For this parameter, you can take
advantage of @code{define-url-function}'s "sticky parameter" feature.
Normally, the @code{playlist-id} won't be supplied explicitly,
defaulting to the value returned by the @code{playlist-id} function,
namely, the IP address of the client machine on which the browser is
running. However, users can also manipulate their playlists from
different machines than the ones running their MP3 clients by allowing
this value to be explicitly specified. And if it's specified once,
@code{define-url-function} will arrange for it to "stick" by setting a
cookie in the browser. Later you'll define a URL function that generates
a list of all existing playlists, which users can use to pick a playlist
other than the one for the machines they're browsing from.

The @code{action} parameter specifies some action to take on the user's
playlist object. The value of this parameter, which will be converted to
a keyword symbol for you, can be @code{:add-songs},
@code{:delete-songs}, @code{:clear}, @code{:sort}, @code{:shuffle}, or
@code{:set-repeat}. The @code{:add-songs} action is used by the "Add
all" button in the browse page and also by the links used to add
individual songs. The other actions are used by the links on the
playlist page itself.

The @code{file}, @code{what}, and @code{values} parameters are used with
the @code{:add-songs} action. By declaring @code{values} to be of type
@code{base-64-list}, the @code{define-url-function} infrastructure will
take care of decoding the value submitted by the "Add all" form. The
other parameters are used with other actions as noted in the comments.

Now let's look at the body of @code{playlist}. The first thing you need
to do is use the @code{playlist-id} to look up the queue object and then
acquire the playlist's lock with the following two lines:

@verbatim
(let ((playlist (lookup-playlist playlist-id)))
  (with-playlist-locked (playlist)
@end verbatim

Since @code{lookup-playlist} will create a new playlist if necessary,
this will always return a @code{playlist} object. Then you take care of
any necessary queue manipulation, dispatching on the value of the
@code{action} parameter in order to call one of the @code{playlist}
functions.

@verbatim
(case action
  (:add-songs      (add-songs playlist what (or values (list file))))
  (:delete-songs   (delete-songs 
                    playlist 
                    :file file :genre genre
                    :artist artist :album album))
  (:clear          (clear-playlist playlist))
  (:sort           (sort-playlist playlist order-by))
  (:shuffle        (shuffle-playlist playlist shuffle))
  (:set-repeat     (setf (repeat playlist) repeat)))
@end verbatim

All that's left of the @code{playlist} function is the actual HTML
generation. Again, you can use the @code{:mp3-browser-page} HTML macro
to make sure the basic form of the page matches the other pages in the
application, though this time you pass @code{NIL} to the @code{:header}
argument in order to leave out the @code{H1} header. Here's the rest of
the function:

@verbatim
(html
 (:mp3-browser-page
  (:title (:format "Playlist - ~a" (id playlist)) :header nil)
  (playlist-toolbar playlist)
  (if (empty-p playlist)
    (html (:p (:i "Empty.")))
    (html 
      ((:table :class "playlist")
       (:table-row "#" "Song" "Album" "Artist" "Genre")
       (let ((idx 0)
             (current-idx (current-idx playlist)))
         (do-rows (row (songs-table playlist))
           (with-column-values (track file song album artist genre) row
             (let ((row-style (if (= idx current-idx) "now-playing" "normal")))
               (html
                 ((:table-row :class row-style)
                  track
                  (:progn song   (delete-songs-link :file file))
                  (:progn album  (delete-songs-link :album album))
                  (:progn artist (delete-songs-link :artist artist))
                  (:progn genre  (delete-songs-link :genre genre)))))
             (incf idx))))))))))))
@end verbatim

The function @code{playlist-toolbar} generates a toolbar containing
links to @code{playlist} to perform the various @code{:action}
manipulations. And @code{delete-songs-link} generates a link to
@code{playlist} with the @code{:action} parameter set to
@code{:delete-songs} and the appropriate arguments to delete an
individual file, or all files on an album, by a particular artist or in
a specific genre.

@verbatim
(defun playlist-toolbar (playlist)
  (let ((current-repeat (repeat playlist))
        (current-sort (ordering playlist))
        (current-shuffle (shuffle playlist)))
    (html
     (:p :class "playlist-toolbar"
         (:i "Sort by:")
         " [ "
         (sort-playlist-button "genre" current-sort) " | " 
         (sort-playlist-button "artist" current-sort) " | " 
         (sort-playlist-button "album" current-sort) " | " 
         (sort-playlist-button "song" current-sort) " ] "
         (:i "Shuffle by:")
         " [ "
         (playlist-shuffle-button "none" current-shuffle) " | "
         (playlist-shuffle-button "song" current-shuffle) " | "
         (playlist-shuffle-button "album" current-shuffle) " ] "
         (:i "Repeat:")
         " [ "
         (playlist-repeat-button "none" current-repeat) " | "
         (playlist-repeat-button "song" current-repeat) " | "
         (playlist-repeat-button "all" current-repeat) " ] "
         "[ " (:a :href (link "playlist" :action "clear") "Clear") " ] "))))

(defun playlist-button (action argument new-value current-value)
  (let ((label (string-capitalize new-value)))
    (if (string-equal new-value current-value)
      (html (:b label))
      (html (:a :href (link "playlist" :action action argument new-value) label)))))

(defun sort-playlist-button (order-by current-sort)
  (playlist-button :sort :order-by order-by current-sort))

(defun playlist-shuffle-button (shuffle current-shuffle)
  (playlist-button :shuffle :shuffle shuffle current-shuffle))

(defun playlist-repeat-button (repeat current-repeat)
  (playlist-button :set-repeat :repeat repeat current-repeat))

(defun delete-songs-link (what value)
  (html " [" (:a :href (link "playlist" :action :delete-songs what value) "x") "]"))
@end verbatim

@node Finding a Playlist
@section Finding a Playlist
@anchor{#finding-a-playlist}
The last of the three URL functions is the simplest. It presents a table
listing all the playlists that have been created. Ordinarily users won't
need to use this page, but during development it gives you a useful view
into the state of the system. It also provides the mechanism to choose a
different playlist--each playlist ID is a link to the @code{playlist}
page with an explicit @code{playlist-id} query parameter, which will
then be made sticky by the @code{playlist} URL function. Note that you
need to acquire the @code{*playlists-lock*} to make sure the
@code{*playlists*} hash table doesn't change out from under you while
you're iterating over it.

@verbatim
(define-url-function all-playlists (request)
  (:mp3-browser-page
   (:title "All Playlists")
   ((:table :class "all-playlists")
    (:table-row "Playlist" "# Songs" "Most recent user agent")
    (with-process-lock (*playlists-lock*)
      (loop for playlist being the hash-values of *playlists* do
           (html
             (:table-row
              (:a :href (link "playlist" :playlist-id (id playlist)) (:print (id playlist)))
              (:print (table-size (songs-table playlist)))
              (:print (user-agent playlist)))))))))
@end verbatim

@node Running the App
@section Running the App
@anchor{#running-the-app}
And that's it. To use this app, you just need to load the MP3 database
with the @code{load-database} function from Chapter 27, publish the CSS
style sheet, set @code{*song-source-type*} to @code{playlist} so
@code{find-song-source} uses playlists instead of the singleton song
source defined in the previous chapter, and start AllegroServe. The
following function takes care of all these steps for you, after you fill
in appropriate values for the two parameters @code{*mp3-dir*}, which is
the root directory of your MP3 collection, and @code{*mp3-css*}, the
filename of the CSS style sheet:

@verbatim
(defparameter *mp3-dir* ...)

(defparameter *mp3-css* ...)

(defun start-mp3-browser ()
  (load-database *mp3-dir* *mp3s*)
  (publish-file :path "/mp3-browser.css"  :file *mp3-css* :content-type "text/css")
  (setf *song-source-type* 'playlist)
  (net.aserve::debug-on :notrap)
  (net.aserve:start :port 2001))
@end verbatim

When you invoke this function, it will print dots while it loads the ID3
information from your ID3 files. Then you can point your MP3 client at
this URL:

@verbatim
http://localhost:2001/stream.mp3
@end verbatim

and point your browser at some good starting place, such as this:

@verbatim
http://localhost:2001/browse
@end verbatim

which will let you start browsing by the default category, Genre. After
you've added some songs to the playlist, you can press Play on the MP3
client, and it should start playing the first song.

Obviously, you could improve the user interface in any of a number of
ways--for instance, if you have a lot of MP3s in your library, it might
be useful to be able to browse artists or albums by the first letter of
their names. Or maybe you could add a "Play whole album" button to the
playlist page that causes the playlist to immediately put all the songs
from the same album as the currently playing song at the top of the
playlist. Or you could change the @code{playlist} class, so instead of
playing silence when there are no songs queued up, it picks a random
song from the database. But all those ideas fall in the realm of
application design, which isn't really the topic of this book. Instead,
the next two chapters will drop back to the level of software
infrastructure to cover how the FOO HTML generation library works.

@node Practical An HTML Generation Library the Interpreter
@chapter Practical: An HTML Generation Library, the Interpreter
@anchor{#practical-an-html-generation-library-the-interpreter}
In this chapter and the next you'll take a look under the hood of the
FOO HTML generator that you've been using in the past few chapters. FOO
is an example of a kind of programming that's quite common in Common
Lisp and relatively uncommon in non-Lisp languages, namely,
@emph{language-oriented} programming. Rather than provide an API built
primarily out of functions, classes, and macros, FOO provides language
processors for a domain-specific language that you can embed in your
Common Lisp programs.

FOO provides two language processors for the same s-expression language.
One is an interpreter that takes a FOO "program" as data and interprets
it to generate HTML. The other is a compiler that compiles FOO
expressions, possibly with embedded Common Lisp code, into Common Lisp
that generates HTML and runs the embedded code. The interpreter is
exposed as the function @code{emit-html} and the compiler as the macro
@code{html}, which you used in previous chapters.

In this chapter you'll look at some of the infrastructure shared between
the interpreter and the compiler and then at the implementation of the
interpreter. In the next chapter, I'll show you how the compiler works.
@menu
* Designing a Domain-Specific Language::
* The FOO Language::
* Character Escaping::
* Indenting Printer::
* HTML Processor Interface::
* The Pretty Printer Backend::
* The Basic Evaluation Rule::
* What's Next?::
@end menu

@node Designing a Domain-Specific Language
@section Designing a Domain-Specific Language
@anchor{#designing-a-domain-specific-language}
Designing an embedded language requires two steps: first, design the
language that'll allow you to express the things you want to express,
and second, implement a processor, or processors, that accepts a
"program" in that language and either performs the actions indicated by
the program or translates the program into Common Lisp code that'll
perform equivalent behaviors.

So, step one is to design the HTML-generating language. The key to
designing a good domain-specific language is to strike the right balance
between expressiveness and concision. For instance, a highly expressive
but not very concise "language" for generating HTML is the language of
literal HTML strings. The legal "forms" of this language are strings
containing literal HTML. Language processors for this "language" could
process such forms by simply emitting them as-is.

@verbatim
(defvar *html-output* *standard-output*)

(defun emit-html (html)
  "An interpreter for the literal HTML language."
  (write-sequence html *html-output*))

(defmacro html (html)
  "A compiler for the literal HTML language."
  `(write-sequence ,html *html-output*))
@end verbatim

This "language" is highly expressive since it can express @emph{any}
HTML you could possibly want to generate.@footnote{In fact, it's
probably @emph{too} expressive since it can also generate all sorts of
output that's not even vaguely legal HTML. Of course, that might be a
feature if you need to generate HTML that's not strictly correct to
compensate for buggy Web browsers. Also, it's common for language
processors to accept programs that are syntactically correct and
otherwise well formed that'll nonetheless provoke undefined behavior
when run.} On the other hand, this language doesn't win a lot of
points for its concision because it gives you zero compression--its
input @emph{is} its output.

To design a language that gives you some useful compression without
sacrificing too much expressiveness, you need to identify the details of
the output that are either redundant or uninteresting. You can then make
those aspects of the output implicit in the semantics of the language.

For instance, because of the structure of HTML, every opening tag is
paired with a matching closing tag.@footnote{Well, almost every
tag. Certain tags such as @code{IMG} and @code{BR} don't. You'll deal
with those in the section "The Basic Evaluation Rule."} When you write
HTML by hand, you have to write those closing tags, but you can
improve the concision of your HTML-generating language by making the
closing tags implicit.

Another way you can gain concision at a slight cost in expressiveness is
to make the language processors responsible for adding appropriate
whitespace between elements--blank lines and indentation. When you're
generating HTML programmatically, you typically don't care much about
which elements have line breaks before or after them or about whether
different elements are indented relative to their parent elements.
Letting the language processor insert whitespace according to some rule
means you don't have to worry about it. As it turns out, FOO actually
supports two modes--one that uses the minimum amount of whitespace,
which allows it to generate extremely efficient code and compact HTML,
and another that generates nicely formatted HTML with different elements
indented and separated from other elements according to their role.

Another detail that's best moved into the language processor is the
escaping of certain characters that have a special meaning in HTML such
as @code{<}, @code{>}, and @code{&}. Obviously, if you generate HTML by
just printing strings to a stream, then it's up to you to replace any
occurrences of those characters in the string with the appropriate
escape sequences, @code{&lt;}, @code{&gt;} and @code{&amp;}. But if the
language processor can know which strings are to be emitted as element
data, then it can take care of automatically escaping those characters
for you.

@node The FOO Language
@section The FOO Language
@anchor{#the-foo-language}
So, enough theory. I'll give you a quick overview of the language
implemented by FOO, and then you'll look at the implementation of the
two FOO language processors--the interpreter, in this chapter, and the
compiler, in the next.

Like Lisp itself, the basic syntax of the FOO language is defined in
terms of forms made up of Lisp objects. The language defines how each
legal FOO form is translated into HTML.

The simplest FOO forms are self-evaluating Lisp objects such as
strings, numbers, and keyword symbols.@footnote{In the strict language
of the Common Lisp standard, keyword symbols aren't
@emph{self-evaluating}, though they do, in fact, evaluate to
themselves. See section 3.1.2.1.3 of the language standard or
HyperSpec for a brief discussion.} You'll need a function
@code{self-evaluating-p} that tests whether a given object is
self-evaluating for FOO's purposes.

@verbatim
(defun self-evaluating-p (form)
  (and (atom form) (if (symbolp form) (keywordp form) t)))
@end verbatim

Objects that satisfy this predicate will be emitted by converting them
to strings with @code{PRINC-TO-STRING} and then escaping any reserved
characters, such as @code{<}, @code{>}, or @code{&}. When the value is
being emitted as an attribute, the characters @code{"}, and @code{'} are
also escaped. Thus, you can invoke the @code{html} macro on a
self-evaluating object to emit it to @code{*html-output*} (which is
initially bound to @code{*STANDARD-OUTPUT*}). Table 30-1 shows how a few
different self-evaluating values will be output.

Table 30-1. FOO Output for Self-Evaluating Objects
@multitable {@code{"foo & bar"}} {@code{foo &amp; bar}} 
@item 
FOO Form
 @tab Generated HTML
@item 
@code{"foo"}
 @tab @code{foo}
@item 
@code{10}
 @tab @code{10}
@item 
@code{:foo}
 @tab @code{FOO}
@item 
@code{"foo & bar"}
 @tab @code{foo &amp; bar}
@end multitable

Of course, most HTML consists of tagged elements. The three pieces of
information that describe each element are the tag, a set of
attributes, and a body containing text and/or more HTML
elements. Thus, you need a way to represent these three pieces of
information as Lisp objects, preferably ones that the Lisp reader
already knows how to read.@footnote{The requirement to use objects
that the Lisp reader knows how to read isn't a hard-and-fast
one. Since the Lisp reader is itself customizable, you could also
define a new reader-level syntax for a new kind of object. But that
tends to be more trouble than it's worth.} If you forget about
attributes for a moment, there's an obvious mapping between Lisp lists
and HTML elements: any HTML element can be represented by a list whose
@code{FIRST} is a symbol where the name is the name of the element's
tag and whose @code{REST} is a list of self-evaluating objects or
lists representing other HTML elements. Thus:

@verbatim
<p>Foo</p> <==> (:p "Foo")

<p><i>Now</i> is the time</p> <==> (:p (:i "Now") " is the time")
@end verbatim

Now the only problem is where to squeeze in the attributes. Since most
elements have no attributes, it'd be nice if you could use the preceding
syntax for elements without attributes. FOO provides two ways to notate
elements with attributes. The first is to simply include the attributes
in the list immediately following the symbol, alternating keyword
symbols naming the attributes and objects representing the attribute
value forms. The body of the element starts with the first item in the
list that's in a position to be an attribute name and isn't a keyword
symbol. Thus:

@verbatim
HTML> (html (:p "foo"))
<p>foo</p>
NIL
HTML> (html (:p "foo " (:i "bar") " baz"))
<p>foo <i>bar</i> baz</p>
NIL
HTML> (html (:p :style "foo" "Foo"))
<p style='foo'>Foo</p>
NIL
HTML> (html (:p :id "x" :style "foo" "Foo"))
<p id='x' style='foo'>Foo</p>
NIL
@end verbatim

For folks who prefer a bit more obvious delineation between the
element's attributes and its body, FOO supports an alternative syntax:
if the first element of a list is itself a list with a keyword as
@emph{its} first element, then the outer list represents an HTML element
with that keyword indicating the tag, with the @code{REST} of the nested
list as the attributes, and with the @code{REST} of the outer list as
the body. Thus, you could write the previous two expressions like this:

@verbatim
HTML> (html ((:p :style "foo") "Foo"))
<p style='foo'>Foo</p>
NIL
HTML> (html ((:p :id "x" :style "foo") "Foo"))
<p id='x' style='foo'>Foo</p>
NIL
@end verbatim

The following function tests whether a given object matches either of
these syntaxes:

@verbatim
(defun cons-form-p (form &optional (test #'keywordp))
  (and (consp form)
       (or (funcall test (car form))
           (and (consp (car form)) (funcall test (caar form))))))
@end verbatim

You should parameterize the @code{test} function because later you'll
need to test the same two syntaxes with a slightly different predicate
on the name.

To completely abstract the differences between the two syntax variants,
you can define a function, @code{parse-cons-form}, that takes a form and
parses it into three elements, the tag, the attributes plist, and the
body list, returning them as multiple values. The code that actually
evaluates cons forms will use this function and not have to worry about
which syntax was used.

@verbatim
(defun parse-cons-form (sexp)
  (if (consp (first sexp))
    (parse-explicit-attributes-sexp sexp)
    (parse-implicit-attributes-sexp sexp)))

(defun parse-explicit-attributes-sexp (sexp)
  (destructuring-bind ((tag &rest attributes) &body body) sexp
    (values tag attributes body)))

(defun parse-implicit-attributes-sexp (sexp)
  (loop with tag = (first sexp)
     for rest on (rest sexp) by #'cddr
     while (and (keywordp (first rest)) (second rest))
     when (second rest)
       collect (first rest) into attributes and
       collect (second rest) into attributes
     end
     finally (return (values tag attributes rest))))
@end verbatim

Now that you have the basic language specified, you can think about how
you're actually going to implement the language processors. How do you
get from a series of FOO forms to the desired HTML? As I mentioned
previously, you'll be implementing two language processors for FOO: an
interpreter that walks a tree of FOO forms and emits the corresponding
HTML directly and a compiler that walks a tree and translates it into
Common Lisp code that'll emit the same HTML. Both the interpreter and
compiler will be built on top of a common foundation of code, which
provides support for things such as escaping reserved characters and
generating nicely indented output, so it makes sense to start there.

@node Character Escaping
@section Character Escaping
@anchor{#character-escaping}
The first bit of the foundation you'll need to lay is the code that
knows how to escape characters with a special meaning in HTML. There are
three such characters, and they must not appear in the text of an
element or in an attribute value; they are @code{<}, @code{>}, and
@code{&}. In element text or attribute values, these characters must be
replaced with the @emph{character reference entities} @code{&lt;},
@code{&gt};, and @code{&amp;}. Similarly, in attribute values, the
quotation marks used to delimit the value must be escaped, @code{'} with
@code{&apos;} and @code{"} with @code{&quot;}. Additionally, any
character can be represented by a numeric character reference entity
consisting of an ampersand, followed by a sharp sign, followed by the
numeric code as a base 10 integer, and followed by a semicolon. These
numeric escapes are sometimes used to embed non-ASCII characters in
HTML.

The Package
Since FOO is a low-level library, the package you develop it in doesn't
rely on much external code--just the usual dependency on names from the
@code{COMMON-LISP} package and, almost as usual, on the names of the
macro-writing macros from @code{COM.GIGAMONKEYS.MACRO-UTILITIES}. On the
other hand, the package needs to export all the names needed by code
that uses FOO. Here's the @code{DEFPACKAGE} from the source that you can
download from the book's Web site:

@verbatim
(defpackage :com.gigamonkeys.html
  (:use :common-lisp :com.gigamonkeys.macro-utilities)
  (:export :with-html-output
           :in-html-style
           :define-html-macro
           :html
           :emit-html
           :&attributes))
@end verbatim

The following function accepts a single character and returns a string
containing a character reference entity for that character:

@verbatim
(defun escape-char (char)
  (case char
    (#\& "&amp;")
    (#\< "&lt;")
    (#\> "&gt;")
    (#\' "&apos;")
    (#\" "&quot;")
    (t (format nil "&#~d;" (char-code char)))))
@end verbatim

You can use this function as the basis for a function, @code{escape},
that takes a string and a sequence of characters and returns a copy of
the first argument with all occurrences of the characters in the second
argument replaced with the corresponding character entity returned by
@code{escape-char}.

@verbatim
(defun escape (in to-escape)
  (flet ((needs-escape-p (char) (find char to-escape)))
    (with-output-to-string (out)
      (loop for start = 0 then (1+ pos)
            for pos = (position-if #'needs-escape-p in :start start)
            do (write-sequence in out :start start :end pos)
            when pos do (write-sequence (escape-char (char in pos)) out)
            while pos))))
@end verbatim

You can also define two parameters: @code{*element-escapes*}, which
contains the characters you need to escape in normal element data, and
@code{*attribute-escapes*}, which contains the set of characters to be
escaped in attribute values.

@verbatim
(defparameter *element-escapes* "<>&")
(defparameter *attribute-escapes* "<>&\"'")
@end verbatim

Here are some examples:

@verbatim
HTML> (escape "foo & bar" *element-escapes*)
"foo &amp; bar"
HTML> (escape "foo & 'bar'" *element-escapes*)
"foo &amp; 'bar'"
HTML> (escape "foo & 'bar'" *attribute-escapes*)
"foo &amp; &apos;bar&apos;"
@end verbatim

Finally, you'll need a variable, @code{*escapes*}, that will be bound to
the set of characters that need to be escaped. It's initially set to the
value of @code{*element-escapes*}, but when generating attributes, it
will, as you'll see, be rebound to the value of
@code{*attribute-escapes*}.

@verbatim
(defvar *escapes* *element-escapes*)
@end verbatim

@node Indenting Printer
@section Indenting Printer
@anchor{#indenting-printer}
To handle generating nicely indented output, you can define a class
@code{indenting-printer}, which wraps around an output stream, and
functions that use an instance of that class to emit strings to the
stream while keeping track of when it's at the beginning of the line.
The class looks like this:

@verbatim
(defclass indenting-printer ()
  ((out                 :accessor out                 :initarg :out)
   (beginning-of-line-p :accessor beginning-of-line-p :initform t)
   (indentation         :accessor indentation         :initform 0)
   (indenting-p         :accessor indenting-p         :initform t)))
@end verbatim

The main function that operates on @code{indenting-printer}s is
@code{emit}, which takes the printer and a string and emits the string
to the printer's output stream, keeping track of when it emits a newline
so it can reset the @code{beginning-of-line-p} slot.

@verbatim
(defun emit (ip string)
  (loop for start = 0 then (1+ pos)
     for pos = (position #\Newline string :start start)
     do (emit/no-newlines ip string :start start :end pos)
     when pos do (emit-newline ip)
     while pos))
@end verbatim

To actually emit the string, it uses the function
@code{emit/no-newlines}, which emits any needed indentation, via the
helper @code{indent-if-necessary}, and then writes the string to the
stream. This function can also be called directly by other code to emit
a string that's known not to contain any newlines.

@verbatim
(defun emit/no-newlines (ip string &key (start 0) end)
  (indent-if-necessary ip)
  (write-sequence string (out ip) :start start :end end)
  (unless (zerop (- (or end (length string)) start))
    (setf (beginning-of-line-p ip) nil)))
@end verbatim

The helper @code{indent-if-necessary} checks @code{beginning-of-line-p}
and @code{indenting-p} to determine whether it needs to emit indentation
and, if they're both true, emits as many spaces as indicated by the
value of @code{indentation}. Code that uses the @code{indenting-printer}
can control the indentation by manipulating the @code{indentation} and
@code{indenting-p} slots. Incrementing and decrementing
@code{indentation} changes the number of leading spaces, while setting
@code{indenting-p} to @code{NIL} can temporarily turn off indentation.

@verbatim
(defun indent-if-necessary (ip)
  (when (and (beginning-of-line-p ip) (indenting-p ip))
    (loop repeat (indentation ip) do (write-char #\Space (out ip)))
    (setf (beginning-of-line-p ip) nil)))
@end verbatim

The last two functions in the @code{indenting-printer} API are
@code{emit-newline} and @code{emit-freshline}, which are both used to
emit a newline character, similar to the @code{~%} and @code{~&}
@code{FORMAT} directives. That is, the only difference is that
@code{emit-newline} always emits a newline, while @code{emit-freshline}
does so only if @code{beginning-of-line-p} is false. Thus, multiple
calls to @code{emit-freshline} without any intervening @code{emit}s
won't result in a blank line. This is handy when one piece of code wants
to generate some output that should end with a newline while another
piece of code wants to generate some output that should start on a
newline but you don't want a blank line between the two bits of output.

@verbatim
(defun emit-newline (ip)
  (write-char #\Newline (out ip))
  (setf (beginning-of-line-p ip) t))

(defun emit-freshline (ip)
  (unless (beginning-of-line-p ip) (emit-newline ip)))
@end verbatim

With those preliminaries out of the way, you're ready to get to the guts
of the FOO processor.

@node HTML Processor Interface
@section HTML Processor Interface
@anchor{#html-processor-interface}
Now you're ready to define the interface that'll be used by the FOO
language processor to emit HTML. You can define this interface as a set
of generic functions because you'll need two implementations--one that
actually emits HTML and another that the @code{html} macro can use to
collect a list of actions that need to be performed, which can then be
optimized and compiled into code that emits the same output in a more
efficient way. I'll call this set of generic functions the @emph{backend
interface}. It consists of the following eight generic functions:

@verbatim
(defgeneric raw-string (processor string &optional newlines-p))

(defgeneric newline (processor))

(defgeneric freshline (processor))

(defgeneric indent (processor))

(defgeneric unindent (processor))

(defgeneric toggle-indenting (processor))

(defgeneric embed-value (processor value))

(defgeneric embed-code (processor code))
@end verbatim

While several of these functions have obvious correspondence to
@code{indenting-printer} functions, it's important to understand that
these generic functions define the abstract operations that are used by
the FOO language processors and won't always be implemented in terms of
calls to the @code{indenting-printer} functions.

That said, perhaps the easiest way to understand the semantics of these
abstract operations is to look at the concrete implementations of the
methods specialized on @code{html-pretty-printer}, the class used to
generate human-readable HTML.

@node The Pretty Printer Backend
@section The Pretty Printer Backend
@anchor{#the-pretty-printer-backend}
You can start by defining a class with two slots--one to hold an
instance of @code{indenting-printer} and one to hold the tab width--the
number of spaces you want to increase the indentation for each level of
nesting of HTML elements.

@verbatim
(defclass html-pretty-printer ()
  ((printer   :accessor printer   :initarg :printer)
   (tab-width :accessor tab-width :initarg :tab-width :initform 2)))
@end verbatim

Now you can implement methods specialized on @code{html-pretty-printer}
on the eight generic functions that make up the backend interface.

The FOO processors use the @code{raw-string} function to emit strings
that don't need character escaping, either because you actually want to
emit normally reserved characters or because all reserved characters
have already been escaped. Usually @code{raw-string} is invoked with
strings that don't contain newlines, so the default behavior is to use
@code{emit/no-newlines} unless the caller specifies a non-@code{NIL}
@code{newlines-p} argument.

@verbatim
(defmethod raw-string ((pp html-pretty-printer) string &optional newlines-p)
  (if newlines-p
    (emit (printer pp) string)
    (emit/no-newlines (printer pp) string)))
@end verbatim

The functions @code{newline}, @code{freshline}, @code{indent},
@code{unindent}, and @code{toggle-indenting} implement fairly
straightforward manipulations of the underlying
@code{indenting-printer}. The only wrinkle is that the HTML pretty
printer generates pretty output only when the dynamic variable
@code{*pretty*} is true. When it's @code{NIL}, you should generate
compact HTML with no unnecessary whitespace. So, these methods, with
the exception of @code{newline}, all check @code{*pretty*} before
doing anything:@footnote{Another, more purely object-oriented,
approach would be to define two classes, perhaps
@code{html-pretty-printer} and @code{html-raw-printer}, and then
define no-op methods specialized on @code{html-raw-printer} for the
methods that should do stuff only when @code{*pretty*} is
true. However, in this case, after defining all the no-op methods,
you'd end up with more code, and then you'd have the hassle of making
sure you created an instance of the right class at the right time. But
in general, using polymorphism to replace conditionals is a good
strategy.}

@verbatim
(defmethod newline ((pp html-pretty-printer))
  (emit-newline (printer pp)))

(defmethod freshline ((pp html-pretty-printer))
  (when *pretty* (emit-freshline (printer pp))))

(defmethod indent ((pp html-pretty-printer))
  (when *pretty* 
    (incf (indentation (printer pp)) (tab-width pp))))

(defmethod unindent ((pp html-pretty-printer))
  (when *pretty* 
    (decf (indentation (printer pp)) (tab-width pp))))

(defmethod toggle-indenting ((pp html-pretty-printer))
  (when *pretty* 
    (with-slots (indenting-p) (printer pp)
      (setf indenting-p (not indenting-p)))))
@end verbatim

Finally, the functions @code{embed-value} and @code{embed-code} are used
only by the FOO compiler--@code{embed-value} is used to generate code
that'll emit the value of a Common Lisp expression, while
@code{embed-code} is used to embed a bit of code to be run and its
result discarded. In the interpreter, you can't meaningfully evaluate
embedded Lisp code, so the methods on these functions always signal an
error.

@verbatim
(defmethod embed-value ((pp html-pretty-printer) value)
  (error "Can't embed values when  interpreting. Value: ~s" value))

(defmethod embed-code ((pp html-pretty-printer) code)
  (error "Can't embed code when interpreting. Code: ~s" code))
@end verbatim

Using Conditions to Have Your Cake and Eat It Too
An alternate approach would be to use @code{EVAL} to evaluate Lisp
expressions in the interpreter. The problem with this approach is that
@code{EVAL} has no access to the lexical environment. Thus, there's no
way to make something like this work:

@verbatim
(let ((x 10)) (emit-html '(:p x)))
@end verbatim

when @code{x} is a lexical variable. The symbol @code{x} that's passed
to @code{emit-html} at runtime has no particular connection to the
lexical variable named with the same symbol. The Lisp compiler arranges
for references to @code{x} in the code to refer to the variable, but
after the code is compiled, there's no longer necessarily any
association between the name @code{x} and that variable. This is the
main reason that when you think @code{EVAL} is the solution to your
problem, you're probably wrong.

However, if @code{x} was a dynamic variable, declared with @code{DEFVAR}
or @code{DEFPARAMETER} (and likely named @code{*x*} instead of
@code{x}), @code{EVAL} could get at its value. Thus, it might be useful
to allow the FOO interpreter to use @code{EVAL} in some situations. But
it's a bad idea to always use @code{EVAL}. You can get the best of both
worlds by combining the idea of using @code{EVAL} with the condition
system.

First define some error classes that you can signal when
@code{embed-value} and @code{embed-code} are called in the interpreter.

@verbatim
(define-condition embedded-lisp-in-interpreter (error)
  ((form :initarg :form :reader form)))
@end verbatim

@verbatim
(define-condition value-in-interpreter (embedded-lisp-in-interpreter) ()
  (:report
   (lambda (c s) 
     (format s "Can't embed values when interpreting. Value: ~s" (form c)))))
@end verbatim

@verbatim
(define-condition code-in-interpreter (embedded-lisp-in-interpreter) ()
  (:report
   (lambda (c s) 
     (format s "Can't embed code when interpreting. Code: ~s" (form c)))))
@end verbatim

Now you can implement @code{embed-value} and @code{embed-code} to signal
those errors @emph{and} provide a restart that'll evaluate the form with
@code{EVAL}.

@verbatim
(defmethod embed-value ((pp html-pretty-printer) value)
  (restart-case (error 'value-in-interpreter :form value)
    (evaluate ()
      :report (lambda (s) (format s "EVAL ~s in null lexical environment." value))
      (raw-string pp (escape (princ-to-string (eval value)) *escapes*) t))))
@end verbatim

@verbatim
(defmethod embed-code ((pp html-pretty-printer) code)
  (restart-case (error 'code-in-interpreter :form code)
    (evaluate ()
      :report (lambda (s) (format s "EVAL ~s in null lexical environment." code))
      (eval code))))
@end verbatim

Now you can do something like this:

@verbatim
HTML> (defvar *x* 10)
*X*
HTML> (emit-html '(:p *x*))
@end verbatim

and you'll get dropped into the debugger with this message:

@verbatim
Can't embed values when interpreting. Value: *X*
   [Condition of type VALUE-IN-INTERPRETER]
@end verbatim

@verbatim
Restarts:
  0: [EVALUATE] EVAL *X* in null lexical environment.
  1: [ABORT] Abort handling SLIME request.
  2: [ABORT] Abort entirely from this process.
@end verbatim

If you invoke the @code{evaluate} restart, @code{embed-value} will
@code{EVAL} @code{*x*}, get the value @code{10}, and generate this HTML:

@verbatim
<p>10</p>
@end verbatim

Then, as a convenience, you can provide restart functions--functions
that invoke the @code{evaluate} restart--in certain situations. The
@code{evaluate} restart function unconditionally invokes the restart,
while @code{eval-dynamic-variables} and @code{eval-code} invoke it only
if the form in the condition is a dynamic variable or potential code.

@verbatim
(defun evaluate (&optional condition)
  (declare (ignore condition))
  (invoke-restart 'evaluate))
@end verbatim

@verbatim
(defun eval-dynamic-variables (&optional condition)
  (when (and (symbolp (form condition)) (boundp (form condition)))
    (evaluate)))
@end verbatim

@verbatim
(defun eval-code (&optional condition)
  (when (consp (form condition))
    (evaluate)))
@end verbatim

Now you can use @code{HANDLER-BIND} to set up a handler to automatically
invoke the @code{evaluate} restart for you.

@verbatim
HTML> (handler-bind ((value-in-interpreter #'evaluate)) (emit-html '(:p *x*)))
<p>10</p>
T
@end verbatim

Finally, you can define a macro to provide a nicer syntax for binding
handlers for the two kinds of errors.

@verbatim
(defmacro with-dynamic-evaluation ((&key values code) &body body)
  `(handler-bind (
       ,@(if values `((value-in-interpreter #'evaluate)))
       ,@(if code `((code-in-interpreter #'evaluate))))
     ,@body))
@end verbatim

With this macro defined, you can write this:

@verbatim
HTML> (with-dynamic-evaluation (:values t) (emit-html '(:p *x*)))
<p>10</p>
T
@end verbatim

@node The Basic Evaluation Rule
@section The Basic Evaluation Rule
@anchor{#the-basic-evaluation-rule}
Now to connect the FOO language to the processor interface, all you need
is a function that takes an object and processes it, invoking the
appropriate processor functions to generate HTML. For instance, when
given a simple form like this:

@verbatim
(:p "Foo")
@end verbatim

this function might execute this sequence of calls on the processor:

@verbatim
(freshline processor)
(raw-string processor "<p" nil)
(raw-string processor ">" nil)
(raw-string processor "Foo" nil)
(raw-string processor "</p>" nil)
(freshline processor)
@end verbatim

For now you can define a simple function that just checks whether a form
is, in fact, a legal FOO form and, if it is, hands it off to the
function @code{process-sexp-html} for processing. In the next chapter,
you'll add some bells and whistles to this function to allow it to
handle macros and special operators. But for now it looks like this:

@verbatim
(defun process (processor form)
  (if (sexp-html-p form)
    (process-sexp-html processor form)
    (error "Malformed FOO form: ~s" form)))
@end verbatim

The function @code{sexp-html-p} determines whether the given object is a
legal FOO expression, either a self-evaluating form or a properly
formatted cons.

@verbatim
(defun sexp-html-p (form)
  (or (self-evaluating-p form) (cons-form-p form)))
@end verbatim

Self-evaluating forms are easily handled: just convert to a string with
@code{PRINC-TO-STRING} and escape the characters in the variable
@code{*escapes*}, which, as you'll recall, is initially bound to the
value of @code{*element-escapes*}. Cons forms you pass off to
@code{process-cons-sexp-html}.

@verbatim
(defun process-sexp-html (processor form)
  (if (self-evaluating-p form)
    (raw-string processor (escape (princ-to-string form) *escapes*) t)
    (process-cons-sexp-html processor form)))
@end verbatim

The function @code{process-cons-sexp-html} is then responsible for
emitting the opening tag, any attributes, the body, and the closing tag.
The main complication here is that to generate pretty HTML, you need to
emit fresh lines and adjust the indentation according to the type of the
element being emitted. You can categorize all the elements defined in
HTML into one of three categories: block, paragraph, and inline. Block
elements--such as @code{body} and @code{ul}--are emitted with fresh
lines before and after both their opening and closing tags and with
their contents indented one level. Paragraph elements--such as @code{p},
@code{li}, and @code{blockquote}--are emitted with a fresh line before
the opening tag and after the closing tag. Inline elements are simply
emitted in line. The following three parameters list the elements of
each type:

@verbatim
(defparameter *block-elements*
  '(:body :colgroup :dl :fieldset :form :head :html :map :noscript :object
    :ol :optgroup :pre :script :select :style :table :tbody :tfoot :thead
    :tr :ul))

(defparameter *paragraph-elements*
  '(:area :base :blockquote :br :button :caption :col :dd :div :dt :h1
    :h2 :h3 :h4 :h5 :h6 :hr :input :li :link :meta :option :p :param
    :td :textarea :th :title))

(defparameter *inline-elements*
  '(:a :abbr :acronym :address :b :bdo :big :cite :code :del :dfn :em
    :i :img :ins :kbd :label :legend :q :samp :small :span :strong :sub
    :sup :tt :var))
@end verbatim

The functions @code{block-element-p} and @code{paragraph-element-p}
test whether a given tag is a member of the corresponding
list.@footnote{You don't need a predicate for @code{*inline-elements*}
since you only ever test for block and paragraph elements. I include
the parameter here for completeness.}

@verbatim
(defun block-element-p (tag) (find tag *block-elements*))

(defun paragraph-element-p (tag) (find tag *paragraph-elements*))
@end verbatim

Two other categorizations with their own predicates are the elements
that are always empty, such as @code{br} and @code{hr}, and the three
elements, @code{pre}, @code{style}, and @code{script}, in which
whitespace is supposed to be preserved. The former are handled specially
when generating regular HTML (in other words, not XHTML) since they're
not supposed to have a closing tag. And when emitting the three tags in
which whitespace is preserved, you can temporarily turn off indentation
so the pretty printer doesn't add any spaces that aren't part of the
element's actual contents.

@verbatim
(defparameter *empty-elements*
  '(:area :base :br :col :hr :img :input :link :meta :param))

(defparameter *preserve-whitespace-elements* '(:pre :script :style))

(defun empty-element-p (tag) (find tag *empty-elements*))

(defun preserve-whitespace-p (tag) (find tag *preserve-whitespace-elements*))
@end verbatim

The last piece of information you need when generating HTML is whether
you're generating XHTML since that affects how you emit empty elements.

@verbatim
(defparameter *xhtml* nil)
@end verbatim

With all that information, you're ready to process a cons FOO form. You
use @code{parse-cons-form} to parse the list into three parts, the tag
symbol, a possibly empty plist of attribute key/value pairs, and a
possibly empty list of body forms. You then emit the opening tag, the
body, and the closing tag with the helper functions
@code{emit-open-tag}, @code{emit-element-body}, and
@code{emit-close-tag}.

@verbatim
(defun process-cons-sexp-html (processor form)
  (when (string= *escapes* *attribute-escapes*)
    (error "Can't use cons forms in attributes: ~a" form))
  (multiple-value-bind (tag attributes body) (parse-cons-form form)
    (emit-open-tag     processor tag body attributes)
    (emit-element-body processor tag body)
    (emit-close-tag    processor tag body)))
@end verbatim

In @code{emit-open-tag} you have to call @code{freshline} when
appropriate and then emit the attributes with @code{emit-attributes}.
You need to pass the element's body to @code{emit-open-tag} so when it's
emitting XHTML, it knows whether to finish the tag with @code{/>} or
@code{>}.

@verbatim
(defun emit-open-tag (processor tag body-p attributes)
  (when (or (paragraph-element-p tag) (block-element-p tag))
    (freshline processor))
  (raw-string processor (format nil "<~(~a~)" tag))
  (emit-attributes processor attributes)
  (raw-string processor (if (and *xhtml* (not body-p)) "/>" ">")))
@end verbatim

In @code{emit-attributes} the attribute names aren't evaluated since
they must be keyword symbols, but you should invoke the top-level
@code{process} function to evaluate the attribute values, binding
@code{*escapes*} to @code{*attribute-escapes*}. As a convenience for
specifying boolean attributes, whose value should be the name of the
attribute, if the value is @code{T}--not just any true value but
actually @code{T}--then you replace the value with the name of the
attribute.@footnote{While XHTML requires boolean attributes to be
notated with their name as the value to indicate a true value, in HTML
it's also legal to simply include the name of the attribute with no
value, for example, @code{<option selected>} rather than @code{<option
selected='selected'>}. All HTML 4.0-compatible browsers should
understand both forms, but some buggy browsers understand only the
no-value form for certain attributes. If you need to generate HTML for
such browsers, you'll need to hack @code{emit-attributes} to emit
those attributes a bit differently.}

@verbatim
(defun emit-attributes (processor attributes)
  (loop for (k v) on attributes by #'cddr do
       (raw-string processor (format nil " ~(~a~)='" k))
       (let ((*escapes* *attribute-escapes*))
         (process processor (if (eql v t) (string-downcase k) v)))
       (raw-string processor "'")))
@end verbatim

Emitting the element's body is similar to emitting the attribute values:
you can loop through the body calling @code{process} to evaluate each
form. The rest of the code is dedicated to emitting fresh lines and
adjusting the indentation as appropriate for the type of element.

@verbatim
(defun emit-element-body (processor tag body)
  (when (block-element-p tag)
    (freshline processor)
    (indent processor))
  (when (preserve-whitespace-p tag) (toggle-indenting processor))
  (dolist (item body)  (process processor item))
  (when (preserve-whitespace-p tag) (toggle-indenting processor))
  (when (block-element-p tag)
    (unindent processor)
    (freshline processor)))
@end verbatim

Finally, @code{emit-close-tag}, as you'd probably expect, emits the
closing tag (unless no closing tag is necessary, such as when the body
is empty and you're either emitting XHTML or the element is one of the
special empty elements). Regardless of whether you actually emit a close
tag, you need to emit a final fresh line for block and paragraph
elements.

@verbatim
(defun emit-close-tag (processor tag body-p)
  (unless (and (or *xhtml* (empty-element-p tag)) (not body-p))
    (raw-string processor (format nil "</~(~a~)>" tag)))
  (when (or (paragraph-element-p tag) (block-element-p tag))
    (freshline processor)))
@end verbatim

The function @code{process} is the basic FOO interpreter. To make it a
bit easier to use, you can define a function, @code{emit-html}, that
invokes @code{process}, passing it an @code{html-pretty-printer} and a
form to evaluate. You can define and use a helper function,
@code{get-pretty-printer}, to get the pretty printer, which returns the
current value of @code{*html-pretty-printer*} if it's bound; otherwise,
it makes a new instance of @code{html-pretty-printer} with
@code{*html-output*} as its output stream.

@verbatim
(defun emit-html (sexp) (process (get-pretty-printer) sexp))

(defun get-pretty-printer ()
  (or *html-pretty-printer*
      (make-instance 
       'html-pretty-printer
       :printer (make-instance 'indenting-printer :out *html-output*))))
@end verbatim

With this function, you can emit HTML to @code{*html-output*}. Rather
than expose the variable @code{*html-output*} as part of FOO's public
API, you should define a macro, @code{with-html-output}, that takes care
of binding the stream for you. It also lets you specify whether you want
pretty HTML output, defaulting to the value of the variable
@code{*pretty*}.

@verbatim
(defmacro with-html-output ((stream &key (pretty *pretty*)) &body body)
  `(let* ((*html-output* ,stream)
          (*pretty* ,pretty))
    ,@body))
@end verbatim

So, if you wanted to use @code{emit-html} to generate HTML to a file,
you could write the following:

@verbatim
(with-open-file (out "foo.html" :direction output)
  (with-html-output (out :pretty t)
    (emit-html *some-foo-expression*)))
@end verbatim

@node What's Next?
@section What's Next?
@anchor{#whats-next-1}
In the next chapter, you'll look at how to implement a macro that
compiles FOO expressions into Common Lisp so you can embed HTML
generation code directly into your Lisp programs. You'll also extend the
FOO language to make it a bit more expressive by adding its own flavor
of special operators and macros.

@node Practical An HTML Generation Library the Compiler
@chapter Practical: An HTML Generation Library, the Compiler
@anchor{#practical-an-html-generation-library-the-compiler}
Now you're ready to look at how the FOO compiler works. The main
difference between a compiler and an interpreter is that an interpreter
processes a program and directly generates some behavior--generating
HTML in the case of a FOO interpreter--but a compiler processes the same
program and generates code in some other language that will exhibit the
same behavior. In FOO, the compiler is a Common Lisp macro that
translates FOO into Common Lisp so it can be embedded in a Common Lisp
program. Compilers, in general, have the advantage over interpreters
that, because compilation happens in advance, they can spend a bit of
time optimizing the code they generate to make it more efficient. The
FOO compiler does that, merging literal text as much as possible in
order to emit the same HTML with a smaller number of writes than the
interpreter uses. When the compiler is a Common Lisp macro, you also
have the advantage that it's easy for the language understood by the
compiler to contain embedded Common Lisp--the compiler just has to
recognize it and embed it in the right place in the generated code. The
FOO compiler will take advantage of this capability.
@menu
* The Compiler::
* FOO Special Operators::
* FOO Macros::
* The Public API::
* The End of the Line::
@end menu

@node The Compiler
@section The Compiler
@anchor{#the-compiler}
The basic architecture of the compiler consists of three layers. First
you'll implement a class @code{html-compiler} that has one slot that
holds an adjustable vector that's used to accumulate @emph{ops}
representing the calls made to the generic functions in the backend
interface during the execution of @code{process}.

You'll then implement methods on the generic functions in the backend
interface that will store the sequence of actions in the vector. Each op
is represented by a list consisting of a keyword naming the operation
and the arguments passed to the function that generated the op. The
function @code{sexp->ops} implements the first phase of the compiler,
compiling a list of FOO forms by calling @code{process} on each form
with an instance of @code{html-compiler}.

This vector of ops stored by the compiler is then passed to a function
that optimizes it, merging consecutive @code{raw-string} ops into a
single op that emits the combined string in one go. The optimization
function can also, optionally, strip out ops that are needed only for
pretty printing, which is mostly important because it allows you to
merge more @code{raw-string} ops.

Finally, the optimized ops vector is passed to a third function,
@code{generate-code}, that returns a list of Common Lisp expressions
that will actually output the HTML. When @code{*pretty*} is true,
@code{generate-code} generates code that uses the methods specialized on
@code{html-pretty-printer} to output pretty HTML. When @code{*pretty*}
is @code{NIL}, it generates code that writes directly to the stream
@code{*html-output*}.

The macro @code{html} actually generates a body that contains two
expansions, one generated with @code{*pretty*} bound to @code{T} and one
with @code{*pretty*} bound to @code{NIL}. Which expansion is used is
determined by the runtime value of @code{*pretty*}. Thus, every function
that contains a call to @code{html} will contain code to generate both
pretty and compact output.

The other significant difference between the compiler and the
interpreter is that the compiler can embed Lisp forms in the code it
generates. To take advantage of that, you need to modify the
@code{process} function so it calls the @code{embed-code} and
@code{embed-value} functions when asked to process an expression that's
not a FOO form. Since all self-evaluating objects are valid FOO forms,
the only forms that won't be passed to @code{process-sexp-html} are
lists that don't match the syntax for FOO cons forms and non-keyword
symbols, the only atoms that aren't self-evaluating. You can assume that
any non-FOO cons is code to be run inline and all symbols are variables
whose value you should embed.

@verbatim
(defun process (processor form)
  (cond
    ((sexp-html-p form) (process-sexp-html processor form))
    ((consp form)       (embed-code processor form))
    (t                  (embed-value processor form))))
@end verbatim

Now let's look at the compiler code. First you should define two
functions that slightly abstract the vector you'll use to save ops in
the first two phases of compilation.

@verbatim
(defun make-op-buffer () (make-array 10 :adjustable t :fill-pointer 0))

(defun push-op (op ops-buffer) (vector-push-extend op ops-buffer))
@end verbatim

Next you can define the @code{html-compiler} class and the methods
specialized on it to implement the backend interface.

@verbatim
(defclass html-compiler ()
  ((ops :accessor ops :initform (make-op-buffer))))

(defmethod raw-string ((compiler html-compiler) string &optional newlines-p)
  (push-op `(:raw-string ,string ,newlines-p) (ops compiler)))

(defmethod newline ((compiler html-compiler))
  (push-op '(:newline) (ops compiler)))

(defmethod freshline ((compiler html-compiler))
  (push-op '(:freshline) (ops compiler)))

(defmethod indent ((compiler html-compiler))
  (push-op `(:indent) (ops compiler)))

(defmethod unindent ((compiler html-compiler))
  (push-op `(:unindent) (ops compiler)))

(defmethod toggle-indenting ((compiler html-compiler))
  (push-op `(:toggle-indenting) (ops compiler)))

(defmethod embed-value ((compiler html-compiler) value)
  (push-op `(:embed-value ,value ,*escapes*) (ops compiler)))

(defmethod embed-code ((compiler html-compiler) code)
  (push-op `(:embed-code ,code) (ops compiler)))
@end verbatim

With those methods defined, you can implement the first phase of the
compiler, @code{sexp->ops}.

@verbatim
(defun sexp->ops (body)
  (loop with compiler = (make-instance 'html-compiler)
     for form in body do (process compiler form)
     finally (return (ops compiler))))
@end verbatim

During this phase you don't need to worry about the value of
@code{*pretty*}: just record all the functions called by @code{process}.
Here's what @code{sexp->ops} makes of a simple FOO form:

@verbatim
HTML> (sexp->ops '((:p "Foo")))
#((:FRESHLINE) (:RAW-STRING "<p" NIL) (:RAW-STRING ">" NIL)
  (:RAW-STRING "Foo" T) (:RAW-STRING "</p>" NIL) (:FRESHLINE))
@end verbatim

The next phase, @code{optimize-static-output}, takes a vector of ops and
returns a new vector containing the optimized version. The algorithm is
simple--for each @code{:raw-string} op, it writes the string to a
temporary string buffer. Thus, consecutive @code{:raw-string} ops will
build up a single string containing the concatenation of the strings
that need to be emitted. Whenever you encounter an op other than a
@code{:raw-string} op, you convert the built-up string into a sequence
of alternating @code{:raw-string} and @code{:newline} ops with the
helper function @code{compile-buffer} and then add the next op. This
function is also where you strip out the pretty printing ops if
@code{*pretty*} is @code{NIL}.

@verbatim
(defun optimize-static-output (ops)
  (let ((new-ops (make-op-buffer)))
    (with-output-to-string (buf)
      (flet ((add-op (op) 
               (compile-buffer buf new-ops)
               (push-op op new-ops)))
        (loop for op across ops do
             (ecase (first op)
               (:raw-string (write-sequence (second op) buf))
               ((:newline :embed-value :embed-code) (add-op op))
               ((:indent :unindent :freshline :toggle-indenting)
                (when *pretty* (add-op op)))))
        (compile-buffer buf new-ops)))
    new-ops))

(defun compile-buffer (buf ops)
  (loop with str = (get-output-stream-string buf)
     for start = 0 then (1+ pos)
     for pos = (position #\Newline str :start start)
     when (< start (length str))
     do (push-op `(:raw-string ,(subseq str start pos) nil) ops)
     when pos do (push-op '(:newline) ops)
     while pos))
@end verbatim

The last step is to translate the ops into the corresponding Common Lisp
code. This phase also pays attention to the value of @code{*pretty*}.
When @code{*pretty*} is true, it generates code that invokes the backend
generic functions on @code{*html-pretty-printer*}, which will be bound
to an instance of @code{html-pretty-printer}. When @code{*pretty*} is
@code{NIL}, it generates code that writes directly to
@code{*html-output*}, the stream to which the pretty printer would send
its output.

The actual function, @code{generate-code}, is trivial.

@verbatim
(defun generate-code (ops)
  (loop for op across ops collect (apply #'op->code op)))
@end verbatim

All the work is done by methods on the generic function @code{op->code}
specializing the @code{op} argument with an @code{EQL} specializer on
the name of the op.

@verbatim
(defgeneric op->code (op &rest operands))

(defmethod op->code ((op (eql :raw-string)) &rest operands)
  (destructuring-bind (string check-for-newlines) operands
    (if *pretty*
      `(raw-string *html-pretty-printer* ,string ,check-for-newlines)
      `(write-sequence ,string *html-output*))))

(defmethod op->code ((op (eql :newline)) &rest operands)
  (if *pretty*
    `(newline *html-pretty-printer*)
    `(write-char #\Newline *html-output*)))    

(defmethod op->code ((op (eql :freshline)) &rest operands)
  (if *pretty*
    `(freshline *html-pretty-printer*)
    (error "Bad op when not pretty-printing: ~a" op)))

(defmethod op->code ((op (eql :indent)) &rest operands)
  (if *pretty*
    `(indent *html-pretty-printer*)
    (error "Bad op when not pretty-printing: ~a" op)))

(defmethod op->code ((op (eql :unindent)) &rest operands)
  (if *pretty*
    `(unindent *html-pretty-printer*)
    (error "Bad op when not pretty-printing: ~a" op)))

(defmethod op->code ((op (eql :toggle-indenting)) &rest operands)
  (if *pretty*
    `(toggle-indenting *html-pretty-printer*)
    (error "Bad op when not pretty-printing: ~a" op)))
@end verbatim

The two most interesting @code{op->code} methods are the ones that
generate code for the @code{:embed-value} and @code{:embed-code} ops. In
the @code{:embed-value} method, you can generate slightly different code
depending on the value of the @code{escapes} operand since if
@code{escapes} is @code{NIL}, you don't need to generate a call to
@code{escape}. And when both @code{*pretty*} and @code{escapes} are
@code{NIL}, you can generate code that uses @code{PRINC} to emit the
value directly to the stream.

@verbatim
(defmethod op->code ((op (eql :embed-value)) &rest operands)
  (destructuring-bind (value escapes) operands
    (if *pretty*
      (if escapes
        `(raw-string *html-pretty-printer* (escape (princ-to-string ,value) ,escapes) t)
        `(raw-string *html-pretty-printer* (princ-to-string ,value) t))
      (if escapes
        `(write-sequence (escape (princ-to-string ,value) ,escapes) *html-output*)
        `(princ ,value *html-output*)))))
@end verbatim

Thus, something like this:

@verbatim
HTML> (let ((x 10)) (html (:p x)))
<p>10</p>
NIL
@end verbatim

works because @code{html} translates @code{(:p x)} into something like
this:

@verbatim
(progn
  (write-sequence "<p>" *html-output*)
  (write-sequence (escape (princ-to-string x) "<>&") *html-output*)
  (write-sequence "</p>" *html-output*))
@end verbatim

When that code replaces the call to @code{html} in the context of the
@code{LET}, you get the following:

@verbatim
(let ((x 10))
  (progn
    (write-sequence "<p>" *html-output*)
    (write-sequence (escape (princ-to-string x) "<>&") *html-output*)
    (write-sequence "</p>" *html-output*)))
@end verbatim

and the reference to @code{x} in the generated code turns into a
reference to the lexical variable from the @code{LET} surrounding the
@code{html} form.

The @code{:embed-code} method, on the other hand, is interesting because
it's so trivial. Because @code{process} passed the form to
@code{embed-code}, which stashed it in the @code{:embed-code} op, all
you have to do is pull it out and return it.

@verbatim
(defmethod op->code ((op (eql :embed-code)) &rest operands)
  (first operands))
@end verbatim

This allows code like this to work:

@verbatim
HTML> (html (:ul (dolist (x '(foo bar baz)) (html (:li x)))))
<ul>
  <li>FOO</li>
  <li>BAR</li>
  <li>BAZ</li>
</ul>
NIL
@end verbatim

The outer call to @code{html} expands into code that does something like
this:

@verbatim
(progn
  (write-sequence "<ul>" *html-output*)
  (dolist (x '(foo bar baz)) (html (:li x)))
  (write-sequence "</ul>" *html-output*))))
@end verbatim

Then if you expand the call to @code{html} in the body of the
@code{DOLIST}, you'll get something like this:

@verbatim
(progn
  (write-sequence "<ul>" *html-output*)
  (dolist (x '(foo bar baz))
    (progn
      (write-sequence "<li>" *html-output*)
      (write-sequence (escape (princ-to-string x) "<>&") *html-output*)
      (write-sequence "</li>" *html-output*)))
  (write-sequence "</ul>" *html-output*))
@end verbatim

This code will, in fact, generate the output you saw.

@node FOO Special Operators
@section FOO Special Operators
@anchor{#foo-special-operators}
You could stop there; certainly the FOO language is expressive enough to
generate nearly any HTML you'd care to. However, you can add two
features to the language, with just a bit more code, that will make it
quite a bit more powerful: special operators and macros.

Special operators in FOO are analogous to special operators in Common
Lisp. Special operators provide ways to express things in the language
that can't be expressed in the language supported by the basic
evaluation rule. Or, another way to look at it is that special
operators provide access to the primitive mechanisms used by the
language evaluator.@footnote{The analogy between FOO's special
operators, and macros, which I'll discuss in the next section, and
Lisp's own is fairly sound. In fact, understanding how FOO's special
operators and macros work may give you some insight into why Common
Lisp is put together the way it is.}

To take a simple example, in the FOO compiler, the language evaluator
uses the @code{embed-value} function to generate code that will embed
the value of a variable in the output HTML. However, because only
symbols are passed to @code{embed-value}, there's no way, in the
language I've described so far, to embed the value of an arbitrary
Common Lisp expression; the @code{process} function passes cons cells to
@code{embed-code} rather than @code{embed-value}, so the values returned
are ignored. Typically this is what you'd want, since the main reason to
embed Lisp code in a FOO program is to use Lisp control constructs.
However, sometimes you'd like to embed computed values in the generated
HTML. For example, you might like this FOO program to generate a
paragraph tag containing a random number:

@verbatim
(:p (random 10))
@end verbatim

But that doesn't work because the code is run and its value discarded.

@verbatim
HTML> (html (:p (random 10)))
<p></p>
NIL
@end verbatim

In the language, as you've implemented it so far, you could work around
this limitation by computing the value outside the call to @code{html}
and then embedding it via a variable.

@verbatim
HTML> (let ((x (random 10))) (html (:p x)))
<p>1</p>
NIL
@end verbatim

But that's sort of annoying, particularly when you consider that if you
could arrange for the form @code{(random 10)} to be passed to
@code{embed-value} instead of @code{embed-code}, it'd do exactly what
you want. So, you can define a special operator, @code{:print}, that's
processed by the FOO language processor according to a different rule
than a normal FOO expression. Namely, instead of generating a
@code{<print>} element, it passes the form in its body to
@code{embed-value}. Thus, you can generate a paragraph containing a
random number like this:

@verbatim
HTML> (html (:p (:print (random 10))))
<p>9</p>
NIL
@end verbatim

Obviously, this special operator is useful only in compiled FOO code
since @code{embed-value} doesn't work in the interpreter. Another
special operator that can be used in both interpreted and compiled FOO
code is @code{:format}, which lets you generate output using the
@code{FORMAT} function. The arguments to the @code{:format} special
operator are a string used as a format control string and then any
arguments to be interpolated. When all the arguments to @code{:format}
are self-evaluating objects, a string is generated by passing them to
@code{FORMAT}, and that string is then emitted like any other string.
This allows such @code{:format} forms to be used in FOO passed to
@code{emit-html}. In compiled FOO, the arguments to @code{:format} can
be any Lisp expressions.

Other special operators provide control over what characters are
automatically escaped and to explicitly emit newline characters: the
@code{:noescape} special operator causes all the forms in its body to be
evaluated as regular FOO forms but with @code{*escapes*} bound to
@code{NIL}, while @code{:attribute} evaluates the forms in its body with
@code{*escapes*} bound to @code{*attribute-escapes*}. And
@code{:newline} is translated into code to emit an explicit newline.

So, how do you define special operators? There are two aspects to
processing special operators: how does the language processor recognize
forms that use special operators, and how does it know what code to run
to process each special operator?

You could hack @code{process-sexp-html} to recognize each special
operator and handle it in the appropriate manner--special operators are,
logically, part of the implementation of the language, and there aren't
going to be that many of them. However, it'd be nice to have a slightly
more modular way to add new special operators--not because users of FOO
will be able to but just for your own sanity.

Define a @emph{special form} as any list whose @code{CAR} is a symbol
that's the name of a special operator. You can mark the names of special
operators by adding a non-@code{NIL} value to the symbol's property list
under the key @code{html-special-operator}. So, you can define a
function that tests whether a given form is a special form like this:

@verbatim
(defun special-form-p (form)
  (and (consp form) (symbolp (car form)) (get (car form) 'html-special-operator)))
@end verbatim

The code that implements each special operator is responsible for taking
apart the rest of the list however it sees fit and doing whatever the
semantics of the special operator require. Assuming you'll also define a
function @code{process-special-form}, which will take the language
processor and a special form and run the appropriate code to generate a
sequence of calls on the processor object, you can augment the top-level
@code{process} function to handle special forms like this:

@verbatim
(defun process (processor form)
  (cond
    ((special-form-p form) (process-special-form processor form))
    ((sexp-html-p form)    (process-sexp-html processor form))
    ((consp form)          (embed-code processor form))
    (t                     (embed-value processor form))))
@end verbatim

You must add the @code{special-form-p} clause first because special
forms can look, syntactically, like regular FOO expressions just the way
Common Lisp's special forms can look like regular function calls.

Now you just need to implement @code{process-special-form}. Rather than
define a single monolithic function that implements all the special
operators, you should define a macro that allows you to define special
operators much like regular functions and that also takes care of adding
the @code{html-special-operator} entry to the property list of the
special operator's name. In fact, the value you store in the property
list can be a function that implements the special operator. Here's the
macro:

@verbatim
(defmacro define-html-special-operator (name (processor &rest other-parameters) &body body)
  `(eval-when (:compile-toplevel :load-toplevel :execute)
     (setf (get ',name 'html-special-operator)
           (lambda (,processor ,@other-parameters) ,@body))))
@end verbatim

This is a fairly advanced type of macro, but if you take it one line at
a time, there's nothing all that tricky about it. To see how it works,
take a simple use of the macro, the definition of the special operator
@code{:noescape}, and look at the macro expansion. If you write this:

@verbatim
(define-html-special-operator :noescape (processor &rest body)
  (let ((*escapes* nil))
    (loop for exp in body do (process processor exp))))
@end verbatim

it's as if you had written this:

@verbatim
(eval-when (:compile-toplevel :load-toplevel :execute)
  (setf (get ':noescape 'html-special-operator)
        (lambda (processor &rest body)
          (let ((*escapes* nil))
            (loop for exp in body do (process processor exp))))))
@end verbatim

The @code{EVAL-WHEN} special operator, as I discussed in Chapter 20,
ensures that the effects of code in its body will be made visible during
compilation when you compile with @code{COMPILE-FILE}. This matters if
you want to use @code{define-html-special-operator} in a file and then
use the just-defined special operator in that same file.

Then the @code{SETF} expression sets the property
@code{html-special-operator} on the symbol @code{:noescape} to an
anonymous function with the same parameter list as was specified in
@code{define-html-special-operator}. By defining
@code{define-html-special-operator} to split the parameter list in two
parts, @code{processor} and everything else, you ensure that all special
operators accept at least one argument.

The body of the anonymous function is then the body provided to
@code{define-html-special-operator}. The job of the anonymous function
is to implement the special operator by making the appropriate calls on
the backend interface to generate the correct HTML or the code that will
generate it. It can also use @code{process} to evaluate an expression as
a FOO form.

The @code{:noescape} special operator is particularly simple--all it
does is pass the forms in its body to @code{process} with
@code{*escapes*} bound to @code{NIL}. In other words, this special
operator disables the normal character escaping preformed by
@code{process-sexp-html}.

With special operators defined this way, all @code{process-special-form}
has to do is look up the anonymous function in the property list of the
special operator's name and @code{APPLY} it to the processor and rest of
the form.

@verbatim
(defun process-special-form (processor form)
  (apply (get (car form) 'html-special-operator) processor (rest form)))
@end verbatim

Now you're ready to define the five remaining FOO special operators.
Similar to @code{:noescape} is @code{:attribute}, which evaluates the
forms in its body with @code{*escapes*} bound to
@code{*attribute-escapes*}. This special operator is useful if you want
to write helper functions that output attribute values. If you write a
function like this:

@verbatim
(defun foo-value (something)
  (html (:print (frob something))))
@end verbatim

the @code{html} macro is going to generate code that escapes the
characters in @code{*element-escapes*}. But if you're planning to use
@code{foo-value} like this:

@verbatim
(html (:p :style (foo-value 42) "Foo"))
@end verbatim

then you want it to generate code that uses
@code{*attribute-escapes*}.  So, instead, you can write it like
this:@footnote{The @code{:noescape} and @code{:attribute} special
operators must be defined as special operators because FOO determines
what escapes to use at compile time, not at runtime. This allows FOO
to escape literal values at compile time, which is much more efficient
than having to scan all output at runtime.}

@verbatim
(defun foo-value (something)
  (html (:attribute (:print (frob something)))))
@end verbatim

The definition of @code{:attribute} looks like this:

@verbatim
(define-html-special-operator :attribute (processor &rest body)
  (let ((*escapes* *attribute-escapes*))
    (loop for exp in body do (process processor exp))))
@end verbatim

The next two special operators, @code{:print} and @code{:format}, are
used to output values. The @code{:print} special operator, as I
discussed earlier, is used in compiled FOO programs to embed the value
of an arbitrary Lisp expression. The @code{:format} special operator is
more or less equivalent to generating a string with
@code{(format nil ...)} and then embedding it. The primary reason to
define @code{:format} as a special operator is for convenience. This:

@verbatim
(:format "Foo: ~d" x)
@end verbatim

is nicer than this:

@verbatim
(:print (format nil "Foo: ~d" x))
@end verbatim

It also has the slight advantage that if you use @code{:format} with
arguments that are all self-evaluating, FOO can evaluate the
@code{:format} at compile time rather than waiting until runtime. The
definitions of @code{:print} and @code{:format} are as follows:

@verbatim
(define-html-special-operator :print (processor form)
  (cond
    ((self-evaluating-p form)
     (warn "Redundant :print of self-evaluating form ~s" form)
     (process-sexp-html processor form))
    (t
     (embed-value processor form))))

(define-html-special-operator :format (processor &rest args)
  (if (every #'self-evaluating-p args)
    (process-sexp-html processor (apply #'format nil args))
    (embed-value processor `(format nil ,@args))))
@end verbatim

The @code{:newline} special operator forces an output of a literal
newline, which is occasionally handy.

@verbatim
(define-html-special-operator :newline (processor)
  (newline processor))
@end verbatim

Finally, the @code{:progn} special operator is analogous to the
@code{PROGN} special operator in Common Lisp. It simply processes the
forms in its body in sequence.

@verbatim
(define-html-special-operator :progn (processor &rest body)
  (loop for exp in body do (process processor exp)))
@end verbatim

In other words, the following:

@verbatim
(html (:p (:progn "Foo " (:i "bar") " baz")))
@end verbatim

will generate the same code as this:

@verbatim
(html (:p "Foo " (:i "bar") " baz"))
@end verbatim

This might seem like a strange thing to need since normal FOO
expressions can have any number of forms in their body. However, this
special operator will come in quite handy in one situation--when writing
FOO macros, which brings you to the last language feature you need to
implement.

@node FOO Macros
@section FOO Macros
@anchor{#foo-macros}
FOO macros are similar in spirit to Common Lisp's macros. A FOO macro is
a bit of code that accepts a FOO expression as an argument and returns a
new FOO expression as the result, which is then evaluated according to
the normal FOO evaluation rules. The actual implementation is quite
similar to the implementation of special operators.

As with special operators, you can define a predicate function to test
whether a given form is a macro form.

@verbatim
(defun macro-form-p (form)
  (cons-form-p form #'(lambda (x) (and (symbolp x) (get x 'html-macro)))))
@end verbatim

You use the previously defined function @code{cons-form-p} because you
want to allow macros to be used in either of the syntaxes of nonmacro
FOO cons forms. However, you need to pass a different predicate
function, one that tests whether the form name is a symbol with a
non-@code{NIL} @code{html-macro} property. Also, as in the
implementation of special operators, you'll define a macro for defining
FOO macros, which is responsible for storing a function in the property
list of the macro's name, under the key @code{html-macro}. However,
defining a macro is a bit more complicated because FOO supports two
flavors of macro. Some macros you'll define will behave much like normal
HTML elements and may want to have easy access to a list of attributes.
Other macros will simply want raw access to the elements of their body.

You can make the distinction between the two flavors of macros implicit:
when you define a FOO macro, the parameter list can include an
@code{&attributes} parameter. If it does, the macro form will be parsed
like a regular cons form, and the macro function will be passed two
values, a plist of attributes and a list of expressions that make up the
body of the form. A macro form without an @code{&attributes} parameter
won't be parsed for attributes, and the macro function will be invoked
with a single argument, a list containing the body expressions. The
former is useful for what are essentially HTML templates. For example:

@verbatim
(define-html-macro :mytag (&attributes attrs &body body)
  `((:div :class "mytag" ,@attrs) ,@body))

HTML> (html (:mytag "Foo"))
<div class='mytag'>Foo</div>
NIL
HTML> (html (:mytag :id "bar" "Foo"))
<div class='mytag' id='bar'>Foo</div>
NIL
HTML> (html ((:mytag :id "bar") "Foo"))
<div class='mytag' id='bar'>Foo</div>
NIL
@end verbatim

The latter kind of macro is more useful for writing macros that
manipulate the forms in their body. This type of macro can function as a
kind of HTML control construct. As a trivial example, consider the
following macro that implements an @code{:if} construct:

@verbatim
(define-html-macro :if (test then else)
  `(if ,test (html ,then) (html ,else)))
@end verbatim

This macro allows you to write this:

@verbatim
(:p (:if (zerop (random 2)) "Heads" "Tails"))
@end verbatim

instead of this slightly more verbose version:

@verbatim
(:p (if (zerop (random 2)) (html "Heads") (html "Tails")))
@end verbatim

To determine which kind of macro you should generate, you need a
function that can parse the parameter list given to
@code{define-html-macro}. This function returns two values, the name
of the @code{&attributes} parameter, or @code{NIL} if there was none,
and a list containing all the elements of @code{args} after removing
the @code{&attributes} marker and the subsequent list
element.@footnote{Note that @code{&attributes} is just another symbol;
there's nothing intrinsically special about names that start with
@code{&}.}

@verbatim
(defun parse-html-macro-lambda-list (args)
  (let ((attr-cons (member '&attributes args)))
    (values 
     (cadr attr-cons)
     (nconc (ldiff args attr-cons) (cddr attr-cons)))))

HTML> (parse-html-macro-lambda-list '(a b c))
NIL
(A B C)
HTML> (parse-html-macro-lambda-list '(&attributes attrs a b c))
ATTRS
(A B C)
HTML> (parse-html-macro-lambda-list '(a b c &attributes attrs))
ATTRS
(A B C)
@end verbatim

The element following @code{&attributes} in the parameter list can also
be a destructuring parameter list.

@verbatim
HTML> (parse-html-macro-lambda-list '(&attributes (&key x y) a b c))
(&KEY X Y)
(A B C)
@end verbatim

Now you're ready to write @code{define-html-macro}. Depending on whether
there was an @code{&attributes} parameter specified, you need to
generate one form or the other of HTML macro so the main macro simply
determines which kind of HTML macro it's defining and then calls out to
a helper function to generate the right kind of code.

@verbatim
(defmacro define-html-macro (name (&rest args) &body body)
  (multiple-value-bind (attribute-var args)
      (parse-html-macro-lambda-list args)
    (if attribute-var
      (generate-macro-with-attributes name attribute-var args body)
      (generate-macro-no-attributes name args body))))
@end verbatim

The functions that actually generate the expansion look like this:

@verbatim
(defun generate-macro-with-attributes (name attribute-args args body)
  (with-gensyms (attributes form-body)
    (if (symbolp attribute-args) (setf attribute-args `(&rest ,attribute-args)))
    `(eval-when (:compile-toplevel :load-toplevel :execute)
       (setf (get ',name 'html-macro-wants-attributes) t)
       (setf (get ',name 'html-macro) 
             (lambda (,attributes ,form-body)
               (destructuring-bind (,@attribute-args) ,attributes
                 (destructuring-bind (,@args) ,form-body
                   ,@body)))))))

(defun generate-macro-no-attributes (name args body)
  (with-gensyms (form-body)
    `(eval-when (:compile-toplevel :load-toplevel :execute)
       (setf (get ',name 'html-macro-wants-attributes) nil)
       (setf (get ',name 'html-macro)
             (lambda (,form-body)
               (destructuring-bind (,@args) ,form-body ,@body)))))
@end verbatim

The macro functions you'll define accept either one or two arguments and
then use @code{DESTRUCTURING-BIND} to take them apart and bind them to
the parameters defined in the call to @code{define-html-macro}. In both
expansions you need to save the macro function in the name's property
list under @code{html-macro} and a boolean indicating whether the macro
takes an @code{&attributes} parameter under the property
@code{html-macro-wants-attributes}. You use that property in the
following function, @code{expand-macro-form}, to determine how the macro
function should be invoked:

@verbatim
(defun expand-macro-form (form)
  (if (or (consp (first form))
          (get (first form) 'html-macro-wants-attributes))
    (multiple-value-bind (tag attributes body) (parse-cons-form form)
      (funcall (get tag 'html-macro) attributes body))
    (destructuring-bind (tag &body body) form
      (funcall (get tag 'html-macro) body))))
@end verbatim

The last step is to integrate macros by adding a clause to the
dispatching @code{COND} in the top-level @code{process} function.

@verbatim
(defun process (processor form)
  (cond
    ((special-form-p form) (process-special-form processor form))
    ((macro-form-p form)   (process processor (expand-macro-form form)))
    ((sexp-html-p form)    (process-sexp-html processor form))
    ((consp form)          (embed-code processor form))
    (t                     (embed-value processor form))))
@end verbatim

This is the final version of @code{process}.

@node The Public API
@section The Public API
@anchor{#the-public-api} Now, at long last, you're ready to implement
the @code{html} macro, the main entry point to the FOO compiler. The
other parts of FOO's public API are @code{emit-html} and
@code{with-html-output}, which I discussed in the previous chapter,
and @code{define-html-macro}, which I discussed in the previous
section. The @code{define-html-macro} macro needs to be part of the
public API because FOO's users will want to write their own HTML
macros. On the other hand, @code{define-html-special-operator} isn't
part of the public API because it requires too much knowledge of FOO's
internals to define a new special operator. And there should be very
little that can't be done using the existing language and special
operators.@footnote{The one element of the underlying
language-processing infrastructure that's not currently exposed
through special operators is the indentation. If you wanted to make
FOO more flexible, albeit at the cost of making its API that much more
complex, you could add special operators for manipulating the
underlying indenting printer. But it seems like the cost of having to
explain the extra special operators would outweigh the rather small
gain in expressiveness.}

One last element of the public API, before I get to @code{html}, is
another macro, @code{in-html-style}. This macro controls whether FOO
generates XHTML or regular HTML by setting the @code{*xhtml*} variable.
The reason this needs to be a macro is because you'll want to wrap the
code that sets @code{*xhtml*} in an @code{EVAL-WHEN} so you can set it
in a file and have it affect uses of the @code{html} macro later in that
same file.

@verbatim
(defmacro in-html-style (syntax)
  (eval-when (:compile-toplevel :load-toplevel :execute)
    (case syntax
      (:html (setf *xhtml* nil))
      (:xhtml (setf *xhtml* t)))))
@end verbatim

Finally let's look at @code{html} itself. The only tricky bit about
implementing @code{html} comes from the need to generate code that can
be used to generate both pretty and compact output, depending on the
runtime value of the variable @code{*pretty*}. Thus, @code{html} needs
to generate an expansion that contains an @code{IF} expression and two
versions of the code, one compiled with @code{*pretty*} bound to true
and one compiled with it bound to @code{NIL}. To further complicate
matters, it's common for one @code{html} call to contain embedded calls
to @code{html}, like this:

@verbatim
(html (:ul (dolist (item stuff)) (html (:li item))))
@end verbatim

If the outer @code{html} expands into an @code{IF} expression with two
versions of the code, one for when @code{*pretty*} is true and one for
when it's false, it's silly for nested @code{html} forms to expand into
two versions too. In fact, it'll lead to an exponential explosion of
code since the nested @code{html} is already going to be expanded
twice--once in the @code{*pretty*}-is-true branch and once in the
@code{*pretty*}-is-false branch. If each expansion generates two
versions, then you'll have four total versions. And if the nested
@code{html} form contained another nested @code{html} form, you'd end up
with eight versions of that code. If the compiler is smart, it'll
eventually realize that most of that generated code is dead and will
eliminate it, but even figuring that out can take quite a bit of time,
slowing down compilation of any function that uses nested calls to
@code{html}.

Luckily, you can easily avoid this explosion of dead code by generating
an expansion that locally redefines the @code{html} macro, using
@code{MACROLET}, to generate only the right kind of code. First you
define a helper function that takes the vector of ops returned by
@code{sexp->ops} and runs it through @code{optimize-static-output} and
@code{generate-code}--the two phases that are affected by the value of
@code{*pretty*}--with @code{*pretty*} bound to a specified value and
that interpolates the resulting code into a @code{PROGN}. (The
@code{PROGN} returns @code{NIL} just to keep things tidy.).

@verbatim
(defun codegen-html (ops pretty)
  (let ((*pretty* pretty))
    `(progn ,@(generate-code (optimize-static-output ops)) nil)))
@end verbatim

With that function, you can then define @code{html} like this:

@verbatim
(defmacro html (&whole whole &body body)
  (declare (ignore body))
  `(if *pretty*
     (macrolet ((html (&body body) (codegen-html (sexp->ops body) t)))
       (let ((*html-pretty-printer* (get-pretty-printer))) ,whole))
     (macrolet ((html (&body body) (codegen-html (sexp->ops body) nil)))
       ,whole)))
@end verbatim

The @code{&whole} parameter represents the original @code{html} form,
and because it's interpolated into the expansion in the bodies of the
two @code{MACROLET}s, it will be reprocessed with each of the new
definitions of @code{html}, the one that generates pretty-printing code
and the other that generates non-pretty-printing code. Note that the
variable @code{*pretty*} is used both during macro expansion @emph{and}
when the resulting code is run. It's used at macro expansion time by
@code{codegen-html} to cause @code{generate-code} to generate one kind
of code or the other. And it's used at runtime, in the @code{IF}
generated by the top-level @code{html} macro, to determine whether the
pretty-printing or non-pretty-printing code should actually run.

@node The End of the Line
@section The End of the Line
@anchor{#the-end-of-the-line}
As usual, you could keep working with this code to enhance it in various
ways. One interesting avenue to pursue is to use the underlying output
generation framework to emit other kinds of output. In the version of
FOO you can download from the book's Web site, you'll find some code
that implements CSS output that can be integrated into HTML output in
both the interpreter and compiler. That's an interesting case because
CSS's syntax can't be mapped to s-expressions in such a trivial way as
HTML's can. However, if you look at that code, you'll see it's still
possible to define an s-expression syntax for representing the various
constructs available in CSS.

A more ambitious undertaking would be to add support for generating
embedded JavaScript. Done right, adding JavaScript support to FOO could
yield two big wins. One is that after you define an s-expression syntax
that you can map to JavaScript syntax, then you can start writing
macros, in Common Lisp, to add new constructs to the language you use to
write client-side code, which will then be compiled to JavaScript. The
other is that, as part of the FOO s-expression JavaScript to regular
JavaScript translation, you could deal with the subtle but annoying
differences between JavaScript implementations in different browsers.
That is, the JavaScript code that FOO generates could either contain the
appropriate conditional code to do one thing in one browser and another
in a different browser or could generate different code depending on
which browser you wanted to support. Then if you use FOO in dynamically
generated pages, it could use information about the User-Agent making
the request to generate the right flavor of JavaScript for that browser.

But if that interests you, you'll have to implement it yourself since
this is the end of the last practical chapter of this book. In the next
chapter I'll wrap things up, discussing briefly some topics that I
haven't touched on elsewhere in the book such as how to find libraries,
how to optimize Common Lisp code, and how to deliver Lisp applications.

@node Conclusion What's Next?
@chapter Conclusion: What's Next?
@anchor{#conclusion-whats-next}
I hope by now you're convinced that the title of this book isn't an
oxymoron. However, it's quite likely there's some area of programming
that's of great practical importance to you that I haven't discussed at
all. For instance, I haven't said anything about how to develop
graphical user interfaces (GUIs), how to connect to relational
databases, how to parse XML, or how to write programs that act as
clients for various network protocols. Similarly, I haven't discussed
two topics that will become important when you write real applications
in Common Lisp: optimizing your Lisp code and packaging your application
for delivery.

I'm obviously not going to cover all these topics in depth in this final
chapter. Instead, I'll give you a few pointers you can use to pursue
whichever aspect of Lisp programming interests you most.
@menu
* Finding Lisp Libraries::
* Interfacing with Other Languages::
* Make It Work Make It Right Make It Fast::
* Delivering Applications::
* Where to Go Next::
@end menu

@node Finding Lisp Libraries
@section Finding Lisp Libraries
@anchor{#finding-lisp-libraries}
While the standard library of functions, data types, and macros that
comes with Common Lisp is quite large, it provides only general-purpose
programming constructs. Specialized tasks such as writing GUIs, talking
to databases, and parsing XML require libraries beyond what are provided
by the ANSI standardized language.

The easiest way to obtain a library to do something you need may be
simply to check out your Lisp implementation. Most implementations
provide at least some facilities not specified in the language standard.
The commercial Common Lisp vendors tend to work especially hard at
providing additional libraries for their implementation in order to
justify their prices. Franz's Allegro Common Lisp, Enterprise Edition,
for instance, comes with libraries for parsing XML, speaking SOAP,
generating HTML, connecting to relational databases, and building
graphical interfaces in various ways, among others. LispWorks, another
prominent commercial Lisp, provides several similar libraries, including
a well-regarded portable GUI toolkit, CAPI, which can be used to develop
GUI applications that will run on any operating system LispWorks runs
on.

The free and open-source Common Lisp implementations typically don't
include quite so many bundled libraries, relying instead on portable
free and open-source libraries. But even those implementations usually
fill in some of the more important areas not addressed by the language
standard such as networking and multithreading.

The only disadvantage of using implementation-specific libraries is that
they tie you to the implementation that provides them. If you're
delivering end-user apps or are deploying a server-based application on
a server that you control, that may not matter a lot. But if you want to
write code to share with other Lispers or if you simply don't want to be
tied to a particular implementation, it's a little more annoying.

For portable libraries--portable either because they're written
entirely in standard Common Lisp or because they contain appropriate
read-time conditionalization to work on multiple
implementations@footnote{The combination of Common Lisp's read-time
conditionalization and macros makes it quite feasible to develop
portability libraries that do nothing but provide a common API layered
over whatever API different implementations provide for facilities not
specified in the language standard. The portable pathname library from
Chapter 15 is an example of this kind of library, albeit to smooth
over differences in interpretation of the standard rather than
implementation-dependent APIs.}--your best bet is to go to the Web.
With the usual caveats about URLs going stale as soon as they're
printed on paper, these are three of the best current starting points:

@itemize
@item
Common-Lisp.net (@code{http://www.common-lisp.net/}) is a site that
hosts free and open-source Common Lisp projects, providing version
control, mailing lists, and Web hosting of project pages. In the first
year and a half after the site went live, nearly a hundred projects were
registered.
@item
The Common Lisp Open Code Collection (CLOCC)
(@code{http://clocc.sourceforge.net/}) is a slightly older collection of
free software libraries, which are intended to be portable between
Common Lisp implementations and self-contained, not relying on any
libraries not included in CLOCC itself.
@item
Cliki (@code{http://www.cliki.net/}) is a wiki devoted to free software
in Common Lisp. While, like any wiki, it may change at any time,
typically it has quite a few links to libraries as well to various
open-source Common Lisp implementations. The eponymous software it runs
on is also written in Common Lisp.
@end itemize

Linux users running the Debian or Gentoo distributions can also easily
install an ever-growing number of Lisp libraries that have been packaged
with those distributions' packing tools, @code{apt-get} on Debian and
@code{emerge} on Gentoo.

I won't recommend any specific libraries here since the library
situation is changing every day--after years of envying the library
collections of Perl, Python, and Java, Common Lispers have, in the past
couple of years, begun to take up the challenge of giving Common Lisp
the set of libraries--both open source and commercial--that it deserves.

One area where there has been a lot of activity recently is on the GUI
front. Unlike Java and C# but like Perl, Python, and C, there's no
single way to develop GUIs in Common Lisp. Instead, it depends both on
what Common Lisp implementation you're using and what operating system
or systems you want to support.

The commercial Common Lisp implementations usually provide some way to
build GUIs for the platforms they run on. Additionally, LispWorks
provides CAPI, the previously mentioned, portable GUI API.

On the open-source side, you have a number of options. On Unix, you can
write low-level X Windows GUIs using CLX, a pure-Common Lisp
implementation of the X Windows protocol, roughly akin to xlib in C. Or
you can use various bindings to higher-level APIs and toolkits such as
GTK and Tk, much the way you might in Perl or Python.

Or, if you're looking for something completely different, you can check
out Common Lisp Interface Manager (CLIM). A descendant of the Symbolics
Lisp Machines GUI framework, CLIM is powerful but complex. Although many
commercial Common Lisp implementations actually support it, it doesn't
seem to have seen a lot of use. But in the past couple years, an
open-source implementation of CLIM, McCLIM--now hosted at
Common-Lisp.net--has been picking up steam lately, so we may be on the
verge of a CLIM renaissance.

@node Interfacing with Other Languages
@section Interfacing with Other Languages
@anchor{#interfacing-with-other-languages}
While many useful libraries can be written in "pure" Common Lisp using
only the features specified in the language standard, and many more can
be written in Lisp using nonstandard facilities provided by a given
implementation, occasionally it's more straightforward to use an
existing library written in another language, such as C.

The language standard doesn't specify a mechanism for Lisp code to
call code written in another language or even require that
implementations provide such a mechanism. But these days, almost all
Common Lisp implementations support what's called a @emph{Foreign
Function Interface}, or FFI for short.@footnote{A Foreign Function
Interface is basically equivalent to JNI in Java, XS in Perl, or the
extension module API in Python.} The basic job of an FFI is to allow
you to give Lisp enough information to be able to link in the foreign
code. Thus, if you're going to call a function from a C library, you
need to tell Lisp about how to translate the Lisp objects passed to
the function into C types and the value returned by the function back
into a Lisp object. However, each implementation provides its own FFI,
each with slightly varying capabilities and syntax. Some FFIs allow
callbacks from C to Lisp, and others don't. The Universal Foreign
Function Interface (UFFI) project provides a portability layer over
the FFIs of more than a half dozen different Common Lisp
implementations. It works by defining its own macros that expand into
appropriate FFI code for the implementation it's running in. The UFFI
takes a lowest common denominator approach, which means it can't take
advantage of all the features of different implementations' FFIs, but
it does provide a good way to build a simple Lisp wrapper around a
basic C API.@footnote{As of this writing, the two main drawbacks of
UFFI are the lack of support for callbacks from C into Lisp, which
many but not all implementations' FFIs support, and the lack of
support for CLISP, whose FFI is quite good but different enough from
the others as to not fit easily into the UFFI model.}

@node Make It Work Make It Right Make It Fast
@section Make It Work, Make It Right, Make It Fast
@anchor{#make-it-work-make-it-right-make-it-fast} As has been said
many times, and variously attributed to Donald Knuth, C.A.R. Hoare,
and Edsger Dijkstra, premature optimization is the root of all
evil.@footnote{Knuth has used the saying several times in
publications, including in his 1974 ACM Turing Award paper, "Computer
Programming as an Art," and in his paper "Structured Programs with
goto Statements." In his paper "The Errors of TeX," he attributes the
saying to C.A.R. Hoare. And Hoare, in an 2004 e-mail to Hans Genwitz
of phobia.com, said he didn't remember the origin of the saying but
that he might have attributed it to Dijkstra.} Common Lisp is an
excellent language to program in if you want to heed this wisdom yet
still need high performance. This may come as a surprise if you've
heard the conventional wisdom that Lisp is slow. In Lisp's earliest
days, when computers were programmed with punch cards, Lisp's
high-level features may have doomed it to be slower than the
competition, namely, assembly and FORTRAN. But that was a long time
ago. In the meantime, Lisp has been used for everything from creating
complex AI systems to writing operating systems, and a lot of work has
gone into figuring out how to compile Lisp into efficient code. In
this section I'll talk about some of the reasons why Common Lisp is an
excellent language for writing high-performance code and some of the
techniques for doing so.

The first reason that Lisp is an excellent language for writing
high-performance code is, ironically enough, the dynamic nature of Lisp
programming--the very thing that originally made it hard to bring Lisp's
performance up to the levels achieved by FORTRAN compilers. The reason
Common Lisp's dynamic features make it easier to write high-performance
code is that the first step to writing efficient code is to find the
right algorithms and data structures.

Common Lisp's dynamic features keep code flexible, which makes it easier
to try different approaches. Given a finite amount of time to write a
program, you're much more likely to end up with a high-performance
version if you don't spend a lot of time getting into and out of dead
ends. In Common Lisp, you can try an idea, see it's going nowhere, and
move on without having spent a ton of time convincing the compiler your
code is worthy of being run and then waiting for it to finish compiling.
You can write a straightforward but inefficient version of a function--a
@emph{code sketch}--to determine whether your basic approach is sound
and then replace that function with a more complex but more efficient
implementation if you determine that it is. And if the overall approach
turns out to be flawed, then you haven't wasted a bunch of time tuning a
function that's no longer needed, which means you have more time to find
a better approach.

The next reason Common Lisp is a good language for developing
high-performance software is that most Common Lisp implementations
come with mature compilers that generate quite efficient machine
code. I'll talk in a moment about how to help these compilers generate
code that will be competitive with code generated by C compilers, but
these implementations already are quite a bit faster than those of
languages whose implementations are less mature and use simpler
compilers or interpreters. Also, since the Lisp compiler is available
at runtime, the Lisp programmer has some possibilities that would be
hard to emulate in other languages--your programs can generate Lisp
code at runtime that's then compiled into machine code and run. If the
generated code is going to run enough times, this can be a big
win. Or, even without using the compiler at runtime, closures give you
another way to meld machine code with runtime data. For instance, the
CL-PPCRE regular expression library, running in CMUCL, is faster than
Perl's regular expression engine on some benchmarks, even though
Perl's engine is written in highly tuned C. This is presumably because
in Perl a regular expression is translated into what are essentially
bytecodes that are then interpreted by the regex engine, while
CL-PPCRE translates a regular expression into a tree of compiled
closures that invoke each other via the normal function-calling
machinery.@footnote{CL-PPCRE also takes advantage of another Common
Lisp feature I haven't discussed, @emph{compiler macros}. A compiler
macro is a special kind of macro that's given a chance to optimize
calls to a specific function by transforming calls to that function
into more efficient code. CL-PPCRE defines compiler macros for its
functions that take regular expression arguments. The compiler macros
optimize calls to those functions in which the regular expression is a
constant value by parsing the regular expression at compile time
rather than leaving it to be done at runtime. Look up
@code{DEFINE-COMPILER-MACRO} in your favorite Common Lisp reference
for more information about compiler macros.}

However, even with the right algorithm and a high-quality compiler,
you may not get the raw speed you need. Then it's time to think about
profiling and tuning. The key, in Lisp as in any language, is to
profile first to find the spots where your program is actually
spending its time and then worry about speeding up those
parts.@footnote{The word @emph{premature} in "premature optimization"
can pretty much be defined as "before profiling." Remember that even
if you can speed up a piece of code to the point where it takes
literally no time to run, you'll still speed up your program only by
whatever percentage of time it spent in that piece of code.}

You have a number of different ways to approach profiling. The language
standard provides a few rudimentary tools for measuring how long certain
forms take to execute. In particular, the @code{TIME} macro can be
wrapped around any form and will return whatever values the form returns
after printing a message to @code{*TRACE-OUTPUT*} about how long it took
to run and how much memory it used. The exact form of the message is
implementation defined.

You can use @code{TIME} for a bit of quick-and-dirty profiling to narrow
your search for bottlenecks. For instance, suppose you have a function
that's taking a long time to run and that calls two other
functions--something like this:

@verbatim
(defun foo ()
  (bar)
  (baz))
@end verbatim

If you want to see whether @code{bar} or @code{baz} is taking more time,
you can change the definition of @code{foo} to this:

@verbatim
(defun foo ()
  (time (bar))
  (time (baz)))
@end verbatim

Now you can call @code{foo}, and Lisp will print two reports, one for
@code{bar} and one for @code{baz}. The form is implementation dependent;
here's what it looks like in Allegro Common Lisp:

@verbatim
CL-USER> (foo)
; cpu time (non-gc) 60 msec user, 0 msec system
; cpu time (gc)     0 msec user, 0 msec system
; cpu time (total)  60 msec user, 0 msec system
; real time  105 msec
; space allocation:
;  24,172 cons cells, 1,696 other bytes, 0 static bytes
; cpu time (non-gc) 540 msec user, 10 msec system
; cpu time (gc)     170 msec user, 0 msec system
; cpu time (total)  710 msec user, 10 msec system
; real time  1,046 msec
; space allocation:
;  270,172 cons cells, 1,696 other bytes, 0 static bytes
@end verbatim

Of course, that'd be a bit easier to read if the output included a
label. If you use this technique a lot, it might be worth defining your
own macro like this:

@verbatim
(defmacro labeled-time (form)
  `(progn
    (format *trace-output* "~2&~a" ',form)
    (time ,form)))
@end verbatim

If you replace @code{TIME} with @code{labeled-time} in @code{foo},
you'll get this output:

@verbatim
CL-USER> (foo)

(BAR)
; cpu time (non-gc) 60 msec user, 0 msec system
; cpu time (gc)     0 msec user, 0 msec system
; cpu time (total)  60 msec user, 0 msec system
; real time  131 msec
; space allocation:
;  24,172 cons cells, 1,696 other bytes, 0 static bytes

(BAZ)
; cpu time (non-gc) 490 msec user, 0 msec system
; cpu time (gc)     190 msec user, 10 msec system
; cpu time (total)  680 msec user, 10 msec system
; real time  1,088 msec
; space allocation:
;  270,172 cons cells, 1,696 other bytes, 0 static bytes
@end verbatim

From this output, it's clear that most of the time in @code{foo} is
spent in @code{baz}.

Of course, the output from @code{TIME} gets a bit unwieldy if the form
you want to profile is called repeatedly. You can build your own
measurement tools using the functions @code{GET-INTERNAL-REAL-TIME} and
@code{GET-INTERNAL-RUN-TIME}, which return a number that increases by
the value of the constant @code{INTERNAL-TIME-UNITS-PER-SECOND} each
second. @code{GET-INTERNAL-REAL-TIME} measures @emph{wall time}, the
actual amount of time elapsed, while @code{GET-INTERNAL-RUN-TIME}
measures some implementation-defined value such as the amount of time
Lisp was actually executing or the time Lisp was executing user code and
not internal bookkeeping such as the garbage collector. Here's a trivial
but useful profiling tool built with a few macros and
@code{GET-INTERNAL-RUN-TIME}:

@verbatim
(defparameter *timing-data* ())

(defmacro with-timing (label &body body)
  (with-gensyms (start)
    `(let ((,start (get-internal-run-time)))
      (unwind-protect (progn ,@body)
        (push (list ',label ,start (get-internal-run-time)) *timing-data*)))))

(defun clear-timing-data ()
  (setf *timing-data* ()))

(defun show-timing-data ()
  (loop for (label time count time-per %-of-total) in (compile-timing-data) do
       (format t "~3d% ~a: ~d ticks over ~d calls for ~d per.~%" 
               %-of-total label time count time-per)))

(defun compile-timing-data () 
  (loop with timing-table = (make-hash-table)
     with count-table = (make-hash-table)
     for (label start end) in *timing-data*
     for time = (- end start)
     summing time into total
     do
       (incf (gethash label timing-table 0) time)
       (incf (gethash label count-table 0))
     finally 
       (return
         (sort
          (loop for label being the hash-keys in timing-table collect
               (let  ((time (gethash label timing-table))
                      (count (gethash label count-table)))
                 (list label time count (round (/ time count)) (round (* 100 (/ time total))))))
          #'> :key #'fifth))))
@end verbatim

This profiler lets you wrap a @code{with-timing} around any form; each
time the form is executed, the time it starts and the time it ends are
recorded, associating with a label you provide. The function
@code{show-timing-data} dumps out a table showing how much time was
spent in different labeled sections of code like this:

@verbatim
CL-USER> (show-timing-data)
 84% BAR: 650 ticks over 2 calls for 325 per.
 16% FOO: 120 ticks over 5 calls for 24 per.
NIL
@end verbatim

You could obviously make this profiling code more sophisticated in many
ways. Alternatively, your Lisp implementation most likely provides its
own profiling tools, which, since they have access to the internals of
the implementation, can get at information not necessarily available to
user-level code.

Once you've found the bottleneck in your code, you can start tuning. The
first thing you should try, of course, is to find a more efficient basic
algorithm--that's where the big gains are to be had. But assuming you're
already using an appropriate algorithm, then it's down to @emph{code
bumming}--locally optimizing the code so it does absolutely no more work
than necessary.

The main tools for code bumming in Common Lisp are its optional
declarations. The basic idea behind declarations in Common Lisp is that
they're used to give the compiler information it can use in a variety of
ways to generate better code.

For a simple example, consider this Common Lisp function:

@verbatim
(defun add (x y) (+ x y))
@end verbatim

I mentioned in Chapter 10 that if you compare the performance of this
function Lisp to the seemingly equivalent C function:

@verbatim
int add (int x, int y) { return x + y; }
@end verbatim

you'll likely find the Common Lisp version to be quite a bit slower,
even if your Common Lisp implementation features a high-quality native
compiler.

That's because the Common Lisp version is doing a lot more--the Common
Lisp compiler doesn't even know that the values of @code{a} and @code{b}
are numbers and so has to generate code to check at runtime. And once it
determines they @emph{are} numbers, it has to determine what types of
numbers--integers, rationals, floating point, or complex--and dispatch
to the appropriate addition routine for the actual types. And even if
@code{a} and @code{b} are integers--the case you care about--then the
addition routine has to account for the possibility that the result may
be too large to represent as a @emph{fixnum}, a number that can be
represented in a single machine word, and thus it may have to allocate a
@emph{bignum} object.

In C, on the other hand, because the type of all variables are declared,
the compiler knows exactly what kind of values @code{a} and @code{b}
will hold. And because C's arithmetic simply overflows when the result
of an addition is too large to represent in whatever type is being
returned, there's no checking for overflow and no allocation of a bignum
object to represent the result when the mathematical sum is too large to
fit in a machine word.

Thus, while the behavior of the Common Lisp code is much more likely to
be mathematically correct, the C version can probably be compiled down
to one or two machine instructions. But if you're willing to give the
Common Lisp compiler the same information the C compiler has about the
types of arguments and return values and to accept certain C-like
compromises in terms of generality and error checking, the Common Lisp
function can also be compiled down to an instruction or two.

That's what declarations are for. The main use of declarations is to
tell the compiler about the types of variables and other expressions.
For instance, you could tell the compiler that the arguments to
@code{add} are both fixnums by writing the function like this:

@verbatim
(defun add (x y)
  (declare (fixnum x y))
  (+ x y))
@end verbatim

The @code{DECLARE} expression isn't a Lisp form; rather, it's part of
the syntax of the @code{DEFUN} and must appear before any other code
in the function body.@footnote{Declarations can appear in most forms
that introduce new variables, such as @code{LET}, @code{LET*}, and the
@code{DO} family of looping macros. @code{LOOP} has its own syntax for
declaring the types of loop variables. The special operator
@code{LOCALLY}, mentioned in Chapter 20, does nothing but create a
scope in which you can make declarations.} This declaration declares
that the arguments passed for the parameters @code{x} and @code{y}
will always be fixnums. In other words, it's a promise to the
compiler, and the compiler is allowed to generate code on the
assumption that whatever you tell it is true.

To declare the type of the value returned, you can wrap the form
@code{(+ x y)} in the @code{THE} special operator. This operator takes a
type specifier, such as @code{FIXNUM}, and a form and tells the compiler
the form will evaluate to the given type. Thus, to give the Common Lisp
compiler all the information about @code{add} that the C compiler gets,
you can write it like this:

@verbatim
(defun add (x y)
  (declare (fixnum x y))
  (the fixnum (+ x y)))
@end verbatim

However, even this version needs one more declaration to give the Common
Lisp compiler the same license as the C compiler to generate fast but
dangerous code. The @code{OPTIMIZE} declaration is used to tell the
compiler how to balance five qualities: the speed of the code generated;
the amount of runtime error checking; the memory usage of the code, both
in terms of code size and runtime memory usage; the amount of debugging
information kept with the code; and the speed of the compilation
process. An @code{OPTIMIZE} declaration consists of one or more lists,
each containing one of the symbols @code{SPEED}, @code{SAFETY},
@code{SPACE}, @code{DEBUG}, and @code{COMPILATION-SPEED}, and a number
from zero to three, inclusive. The number specifies the relative
weighting the compiler should give to the corresponding quality, with
@code{3} being the most important and @code{0} meaning not important at
all. Thus, to make Common Lisp compile @code{add} more or less like a C
compiler would, you can write it like this:

@verbatim
(defun add (x y)
  (declare (optimize (speed 3) (safety 0)))
  (declare (fixnum x y))
  (the fixnum (+ x y)))
@end verbatim

Of course, now the Lisp version suffers from many of the same
liabilities as the C version--if the arguments passed aren't fixnums or
if the addition overflows, the result will be mathematically incorrect
or worse. Also, if someone calls @code{add} with a wrong number of
arguments, it may not be pretty. Thus, you should use these kinds of
declarations only after your program is working correctly. And you
should add them only where profiling shows they'll make a difference. If
you're getting reasonable performance without them, leave them out. But
when profiling shows you a real hot spot in your code and you need to
tune it up, go ahead. Because you can use declarations this way, it's
rarely necessary to rewrite code in C just for performance reasons; FFIs
are used to access existing C code, but declarations are used when
C-like performance is needed. Of course, how close you can get the
performance of a given piece of Common Lisp code to C and C++ depends
mostly on how much like C you're willing to make it.

Another code-tuning tool built into Lisp is the function
@code{DISASSEMBLE}. The exact behavior of this function is
implementation dependent because it depends on how the implementation
compiles code--whether to machine code, bytecodes, or some other form.
But the basic idea is that it shows you the code generated by the
compiler when it compiled a specific function.

Thus, you can use @code{DISASSEMBLE} to see whether your declarations
are having any effect on the code generated. And if your Lisp
implementation uses a native compiler and you know your platform's
assembly language, you can get a pretty good sense of what's actually
going on when you call one of your functions. For instance, you could
use @code{DISASSEMBLE} to get a sense of the difference between the
first version of @code{add}, with no declarations, and the final
version. First, define and compile the original version.

@verbatim
(defun add (x y) (+ x y))
@end verbatim

Then, at the REPL, call @code{DISASSEMBLE} with the name of the
function. In Allegro, it shows the following assembly-language-like dump
of the code generated by the compiler:

@verbatim
CL-USER> (disassemble 'add)
;; disassembly of #<Function ADD>
;; formals: X Y

;; code start: #x737496f4:
   0: 55         pushl  ebp
   1: 8b ec    movl ebp,esp
   3: 56         pushl  esi
   4: 83 ec 24 subl esp,$36
   7: 83 f9 02 cmpl ecx,$2
  10: 74 02    jz   14
  12: cd 61    int  $97   ; SYS::TRAP-ARGERR
  14: 80 7f cb 00 cmpb  [edi-53],$0        ; SYS::C_INTERRUPT-PENDING
  18: 74 02    jz   22
  20: cd 64    int  $100  ; SYS::TRAP-SIGNAL-HIT
  22: 8b d8    movl ebx,eax
  24: 0b da    orl  ebx,edx
  26: f6 c3 03 testb    bl,$3
  29: 75 0e    jnz  45
  31: 8b d8    movl ebx,eax
  33: 03 da    addl ebx,edx
  35: 70 08    jo   45
  37: 8b c3    movl eax,ebx
  39: f8         clc
  40: c9         leave
  41: 8b 75 fc movl esi,[ebp-4]
  44: c3         ret
  45: 8b 5f 8f movl ebx,[edi-113]    ; EXCL::+_2OP
  48: ff 57 27 call *[edi+39]   ; SYS::TRAMP-TWO
  51: eb f3    jmp  40
  53: 90         nop
; No value
@end verbatim

Clearly, there's a bunch of stuff going on here. If you're familiar with
x86 assembly language, you can probably tell what. Now compile this
version of @code{add} with all the declarations.

@verbatim
(defun add (x y)
  (declare (optimize (speed 3) (safety 0)))
  (declare (fixnum x y))
  (the fixnum (+ x y)))
@end verbatim

Now disassemble @code{add} again, and see if the declarations had any
effect.

@verbatim
CL-USER> (disassemble 'add)
;; disassembly of #<Function ADD>
;; formals: X Y

;; code start: #x7374dc34:
   0: 03 c2    addl eax,edx
   2: f8         clc
   3: 8b 75 fc movl esi,[ebp-4]
   6: c3         ret
   7: 90         nop
; No value
@end verbatim

Looks like they did.

@node Delivering Applications
@section Delivering Applications
@anchor{#delivering-applications}
Another topic of practical importance, which I didn't talk about
elsewhere in the book, is how to deliver software written in Lisp. The
main reason I neglected this topic is because there are many different
ways to do it, and which one is best for you depends on what kind of
software you need to deliver to what kind of user with what Common Lisp
implementation. In this section I'll give an overview of some of the
different options.

If you've written code you want to share with fellow Lisp programmers,
the most straightforward way to distribute it is as source
code.@footnote{The FASL files produced by @code{COMPILE-FILE} are
implementation dependent and may or may not be compatible between
different versions of the same Common Lisp implementation. Thus,
they're not a very good way to distribute Lisp code. The one time they
can be handy is as a way of providing patches to be applied to an
application running in a known version of a particular
implementation. Applying the patch simply entails @code{LOAD}ing the
FASL, and because a FASL can contain arbitrary code, it can be used to
upgrade existing data as well as to provide new code definitions.} You
can distribute a simple library as a single source file, which
programmers can @code{LOAD} into their Lisp image, possibly after
compiling it with @code{COMPILE-FILE}.

More complex libraries or applications, broken up across multiple source
files, pose an additional challenge--in order to load and compile the
code, the files need to be loaded and compiled in the correct order. For
instance, a file containing macro definitions must be loaded before you
can compile files that use those macros. And a file containing
@code{DEFPACKAGE} forms must be loaded before any files that use those
packages can even be @code{READ}. Lispers call this the @emph{system
definition} problem and typically handle it with tools called
@emph{system definition facilities} or @emph{system definition
utilities}, which are somewhat analogous to build tools such as
@code{make} or @code{ant}. As with @code{make} and @code{ant}, system
definition tools allow you to specify the dependencies between different
files and then take care of loading and compiling the files in the
correct order while trying to do only work that's necessary--recompiling
only files that have changed, for example.

These days the most widely used system definition tool is ASDF, which
stands for @emph{Another System Definition Facility}.@footnote{ASDF
was originally written by Daniel Barlow, one of the SBCL developers,
and has been included as part of SBCL for a long time and also
distributed as a stand-alone library. It has recently been adopted and
included in other implementations such as OpenMCL and Allegro.}  The
basic idea behind ASDF is that you define systems in ASD files, and
ASDF provides a number of operations on systems such as loading them
or compiling them. A system can also be defined to depend on other
systems, which will be loaded as necessary. For instance, the
following shows the contents of @code{html.asd}, the ASD file for the
FOO library from Chapters 31 and 32:

@verbatim
(defpackage :com.gigamonkeys.html-system (:use :asdf :cl))
(in-package :com.gigamonkeys.html-system)

(defsystem html
  :name "html"
  :author "Peter Seibel <peter@gigamonkeys.com>"
  :version "0.1"
  :maintainer "Peter Seibel <peter@gigamonkeys.com>"
  :license "BSD"
  :description "HTML and CSS generation from sexps."
  :long-description ""
  :components
  ((:file "packages")
   (:file "html" :depends-on ("packages"))
   (:file "css" :depends-on ("packages" "html")))
  :depends-on (:macro-utilities))
@end verbatim

If you add a symbolic link to this file from a directory listed in
@code{asdf:*central-registry*},@footnote{On Windows, where there are
no symbolic links, it works a little bit differently but roughly the
same.} then you can type this:

@verbatim
(asdf:operate 'asdf:load-op :html)
@end verbatim

to compile and load the files @code{packages.lisp}, @code{html.lisp},
and @code{html-macros.lisp} in the correct order after first making sure
the @code{:macro-utilities} system has been compiled and loaded. For
other examples of ASD files, you can look at this book's source
code--the code from each practical chapter is defined as a system with
appropriate intersystem dependencies expressed in the ASD files.

Most free and open-source Common Lisp libraries you'll find will come
with an ASD file. Some will use other system definition tools such as
the slightly older MK:DEFSYSTEM or even utilities devised by the
library's author, but the tide seems to be turning in the direction of
ASDF.@footnote{Another tool, ASDF-INSTALL, builds on top of ASDF and
MK:DEFSYSTEM, providing an easy way to automatically download and
install libraries from the network. The best starting point for
learning about ASDF-INSTALL is Edi Weitz's "A tutorial for
ASDF-INSTALL" (@code{http:// www.weitz.de/asdf-install/}).}

Of course, while ASDF makes it easy for Lispers to install Lisp
libraries, it's not much help if you want to package an application for
an end user who doesn't know or care about Lisp. If you're delivering a
pure end-user application, presumably you want to provide something the
user can download, install, and run without having to know anything
about Lisp. You can't expect them to separately download and install a
Lisp implementation. And you want them to be able to run your
application just like any other application--by double-clicking an icon
on Windows or OS X or by typing the name of the program at the command
line on Unix.

However, unlike C programs, which can typically rely on certain shared
libraries (DLLs on Windows) that make up the C "runtime" being present
as part of the operating system, Lisp programs must include a Lisp
runtime, that is, the same program you run when you start Lisp though
perhaps with certain functionality not needed to run the application
excised.

To further complicate matters, @emph{program} isn't really well defined
in Lisp. As you've seen throughout this book, the process of developing
software in Lisp is an incremental process that involves making changes
to the set of definitions and data living in your Lisp image. The
"program" is just a particular state of the image arrived at by loading
the @code{.lisp} or @code{.fasl} files that contain code that creates
the appropriate definitions and data. You could, then, distribute a Lisp
application as a Lisp runtime plus a bunch of FASL files and an
executable that starts the runtime, loads the FASLs, and somehow invokes
the appropriate starting function. However, since actually loading the
FASLs can take some time, especially if they have to do any computation
to set up the state of the world, most Common Lisp implementations
provide a way to @emph{dump an image}--to save the state of a running
Lisp to a file called an @emph{image file} or sometimes a @emph{core}.
When a Lisp runtime starts, the first thing it does is load an image
file, which it can do in much less time than it'd take to re-create the
state by loading FASL files.

Normally the image file is a default image containing only the standard
packages defined by the language and any extras provided by the
implementation. But with most implementations, you have a way to specify
a different image file. Thus, instead of packaging an app as a Lisp
runtime plus a bunch of FASLs, you can package it as a Lisp runtime plus
a single image file containing all the definitions and data that make up
your application. Then all you need is a program that launches the Lisp
runtime with the appropriate image file and invokes whatever function
serves as the entry point to the application.

This is where things get implementation and operating-system dependent.
Some Common Lisp implementations, in particular the commercial ones such
as Allegro and LispWorks, provide tools for building such an executable.
For instance, Allegro's Enterprise Edition provides a function
@code{excl:generate-application} that creates a directory containing the
Lisp runtime as a shared library, an image file, and an executable that
starts the runtime with the given image. Similarly, the LispWorks
Professional Edition "delivery" mechanism allows you to build
single-file executables of your programs. On Unix, with the various free
and open-source implementations, you can do essentially the same thing
except it's probably easier to use a shell script to start everything.

And on OS X things are even better--since all applications on OS X are
packaged as @code{.app} bundles, which are essentially directories with
a certain structure, it's not all that difficult to package all the
parts of a Lisp application as a double-clickable @code{.app} bundle.
Mikel Evins's Bosco tool makes it easy to create @code{.app} bundles for
applications running on OpenMCL.

Of course, another popular way to deliver applications these days is as
server-side applications. This is a niche where Common Lisp can really
excel--you can pick a combination of operating system and Common Lisp
implementation that works well for you, and you don't have to worry
about packaging the application to be installed by an end user. And
Common Lisp's interactive debugging and development features make it
possible to debug and upgrade a live server in ways that either just
aren't possible in a less dynamic language or would require you to build
a lot of specific infrastructure.

@node Where to Go Next
@section Where to Go Next
@anchor{#where-to-go-next}
So, that's it. Welcome to the wonderful world of Lisp. The best thing
you can do now--if you haven't already--is to start writing your own
Lisp code. Pick a project that interests you, and do it in Common Lisp.
Then do another. Lather, rinse, repeat.

However, if you need some further pointers, this section offers some
places to go. For starters, check out the @emph{Practical Common Lisp}
Web site at @code{http://www.gigamonkeys.com/book/}, where you can find
the source code from the practical chapters, errata, and links to other
Lisp resources on the Web.

In addition to the sites I mentioned in the "Finding Lisp Libraries"
section, you may also want explore the Common Lisp HyperSpec
(a.k.a. the HyperSpec or CLHS), an HTML version of the ANSI language
standard prepared by Kent Pitman and made available by LispWorks at
@code{http://www.lispworks.com/documentation/HyperSpec/index.html}. The
HyperSpec is by no means a tutorial, but it's as authoritative a guide
to the language as you can get without buying a printed copy of the
standard from ANSI and much more convenient for day-to-day
use.@footnote{SLIME incorporates an Elisp library that allows you to
automatically jump to the HyperSpec entry for any name defined in the
standard. You can also download a complete copy of the HyperSpec to
keep locally for offline browsing.}

If you want to get in touch with other Lispers, @code{comp.lang.lisp} on
Usenet and the @code{#lisp} IRC channel or the Freenode network
(@code{http://www.freenode.net}) are two of the main online hang- outs.
There are also a number of Lisp-related blogs, most of which are
aggregated on Planet Lisp at @code{http://planet.lisp.org/}.

And keep your eyes peeled in all those forums for announcements of local
Lisp users get-togethers in your area--in the past few years, Lispnik
gatherings have popped up in cities around the world, from New York to
Oakland, from Cologne to Munich, and from Geneva to Helsinki.

If you want to stick to books, here are a few suggestions. For a nice
thick reference book to stick on your desk, grab @emph{The ANSI Common
Lisp Reference Book} edited by David Margolies (Apress,
2005).@footnote{Another classic reference is @emph{Common Lisp: The
Language} by Guy Steele (Digital Press, 1984 and 1990). The first
edition, a.k.a. CLtL1, was the de facto standard for the language for
a number of years. While waiting for the official ANSI standard to be
finished, Guy Steele--who was on the ANSI committee--decided to
release a second edition to bridge the gap between CLtL1 and the
eventual standard. The second edition, now known as CLtL2, is
essentially a snapshot of the work of the standardization committee
taken at a particular moment in time near to, but not quite at, the
end of the standardization process. Consequently, CLtL2 differs from
the standard in ways that make it not a very good day-to-day
reference. It is, however, a useful historical document, particularly
because it includes documentation of some features that were dropped
from the standard before it was finished as well as commentary that
isn't part of the standard about why certain features are the way they
are.}

For more on Common Lisp's object system, you can start with
@emph{Object-Oriented Programming in Common Lisp: A Programmer's Guide
to CLOS} by Sonya E. Keene (Addison-Wesley, 1989). Then if you really
want to become an object wizard or just to stretch your mind in
interesting ways, read @emph{The Art of the Metaobject Protocol} by
Gregor Kiczales, Jim des Rivieres, and Daniel G. Bobrow (MIT Press,
1991). This book, also known as AMOP, is both an explanation of what a
metaobject protocol is and why you want one and the de facto standard
for the metaobject protocol supported by many Common Lisp
implementations.

Two books that cover general Common Lisp technique are @emph{Paradigms
of Artificial Intelligence Programming: Case Studies in Common Lisp} by
Peter Norvig (Morgan Kaufmann, 1992) and @emph{On Lisp: Advanced
Techniques for Common Lisp} by Paul Graham (Prentice Hall, 1994). The
former provides a solid introduction to artificial intelligence
techniques while teaching quite a bit about how to write good Common
Lisp code, and the latter is especially good in its treatment of macros.

If you're the kind of person who likes to know how things work down to
the bits, @emph{Lisp in Small Pieces} by Christian Queinnec (Cambridge
University Press, 1996) provides a nice blend of programming language
theory and practical Lisp implementation techniques. While it's
primarily focused on Scheme rather than Common Lisp, the same principles
apply.

For folks who want a little more theoretical look at things--or who just
want to know what it's like to be a freshman comp sci student at
M.I.T.--@emph{Structure and Interpretation of Computer Programs}, Second
Edition, by Harold Abelson, Gerald Jay Sussman, and Julie Sussman
(M.I.T. @emph{Press, 1996) is a classic computer science text that uses
Scheme to teach important programming c}oncepts. Any programmer can
learn a lot from this book--just remember that there are important
differences between Scheme and Common Lisp.

Once you've wrapped your mind around Lisp, you may want to place it in a
bit of context. Since no one can claim to really understand object
orientation who doesn't know something about Smalltalk, you might want
to start with @emph{Smalltalk-80: The Language} by Adele Goldberg and
David Robson (Addison Wesley, 1989), the standard introduction to the
core of Smalltalk. After that, @emph{Smalltalk Best Practice Patterns}
by Kent Beck (Prentice Hall, 1997) is full of good advice aimed at
Smalltalkers, much of which is applicable to any object-oriented
language.

And at the other end of the spectrum, @emph{Object-Oriented Software
Construction} by Bertrand Meyer (Prentice Hall, 1997) is an excellent
exposition of the static language mind-set from the inventor of Eiffel,
an oft-overlooked descendant of Simula and Algol. It contains much food
for thought, even for programmers working with dynamic languages such as
Common Lisp. In particular, Meyer's ideas about Design By Contract can
shed a lot of light on how one ought to use Common Lisp's condition
system.

Though not about computers per se, @emph{The Wisdom of Crowds: Why the
Many Are Smarter Than the Few and How Collective Wisdom Shapes Business,
Economies, Societies, and Nations} by James Surowiecki (Doubleday, 2004)
contains an excellent answer to the question, "If Lisp's so great how
come everybody isn't using it?" See the section on "Plank-Road Fever"
starting on page 53.

And finally, for some fun, and to learn about the influence Lisp and
Lispers have had on hacker culture, dip into (or read from cover to
cover) @emph{The New Hacker's Dictionary}, Third Edition, compiled by
Eric S. Raymond (MIT Press, 1996) and based on the original @emph{The
Hacker's Dictionary} edited by Guy Steele (Harper & Row, 1983).

But don't let all these suggestions interfere with your programming--the
only way to really learn a language is to use it. If you've made it this
far, you're certainly ready to do that. Happy hacking!

